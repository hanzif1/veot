INFO 12-25 12:39:14 api_server.py:585] vLLM API server version 0.6.4.post1
INFO 12-25 12:39:14 api_server.py:586] args: Namespace(host=None, port=8000, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='/HOME/nsccgz_zgchen/nsccgz_zgchen_6/HDD_POOL/veot/model_zoo/Qwen2.5-72B-Instruct-Int4', task='auto', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', chat_template_text_format='string', trust_remote_code=True, allowed_local_media_path=None, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=None, guided_decoding_backend='outlines', distributed_executor_backend=None, worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_model=None, speculative_model_quantization=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_draft_tensor_parallel_size=None, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, disable_logprobs_during_spec_decoding=None, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=['planner-72b'], qlora_adapter_name_or_path=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', override_neuron_config=None, override_pooler_config=None, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False)
INFO 12-25 12:39:14 api_server.py:175] Multiprocessing frontend to use ipc:///tmp/370e332e-cbc9-4e87-a668-dd543c38ad74 for IPC Path.
INFO 12-25 12:39:14 api_server.py:194] Started engine process with PID 3401542
INFO 12-25 12:39:26 config.py:350] This model supports multiple tasks: {'embedding', 'generate'}. Defaulting to 'generate'.
INFO 12-25 12:39:26 gptq_marlin.py:108] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
WARNING 12-25 12:39:26 arg_utils.py:1075] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.
INFO 12-25 12:39:32 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.
INFO 12-25 12:39:32 gptq_marlin.py:108] The model is convertible to gptq_marlin during runtime. Using gptq_marlin kernel.
WARNING 12-25 12:39:32 arg_utils.py:1075] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.
INFO 12-25 12:39:32 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='/HOME/nsccgz_zgchen/nsccgz_zgchen_6/HDD_POOL/veot/model_zoo/Qwen2.5-72B-Instruct-Int4', speculative_config=None, tokenizer='/HOME/nsccgz_zgchen/nsccgz_zgchen_6/HDD_POOL/veot/model_zoo/Qwen2.5-72B-Instruct-Int4', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=32768, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=gptq_marlin, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=planner-72b, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=True, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)
INFO 12-25 12:39:33 selector.py:135] Using Flash Attention backend.
INFO 12-25 12:39:35 model_runner.py:1072] Starting to load model /HOME/nsccgz_zgchen/nsccgz_zgchen_6/HDD_POOL/veot/model_zoo/Qwen2.5-72B-Instruct-Int4...
INFO 12-25 12:39:36 gptq_marlin.py:196] Using MacheteLinearKernel for GPTQMarlinLinearMethod
Loading safetensors checkpoint shards:   0% Completed | 0/11 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   9% Completed | 1/11 [00:05<00:58,  5.83s/it]
Loading safetensors checkpoint shards:  18% Completed | 2/11 [00:12<00:55,  6.15s/it]
Loading safetensors checkpoint shards:  27% Completed | 3/11 [00:17<00:44,  5.54s/it]
Loading safetensors checkpoint shards:  36% Completed | 4/11 [00:21<00:36,  5.27s/it]
Loading safetensors checkpoint shards:  45% Completed | 5/11 [00:28<00:34,  5.78s/it]
Loading safetensors checkpoint shards:  55% Completed | 6/11 [00:33<00:28,  5.60s/it]
Loading safetensors checkpoint shards:  64% Completed | 7/11 [00:39<00:22,  5.68s/it]
Loading safetensors checkpoint shards:  73% Completed | 8/11 [00:44<00:16,  5.55s/it]
Loading safetensors checkpoint shards:  82% Completed | 9/11 [00:47<00:09,  4.58s/it]
Loading safetensors checkpoint shards:  91% Completed | 10/11 [00:52<00:04,  4.74s/it]
Loading safetensors checkpoint shards: 100% Completed | 11/11 [00:57<00:00,  4.91s/it]
Loading safetensors checkpoint shards: 100% Completed | 11/11 [00:57<00:00,  5.25s/it]

INFO 12-25 12:40:38 model_runner.py:1077] Loading model weights took 38.7764 GB
INFO 12-25 12:40:49 worker.py:232] Memory profiling results: total_gpu_memory=79.32GiB initial_memory_usage=39.48GiB peak_torch_memory=46.23GiB memory_usage_post_profile=40.05GiB non_torch_memory=1.24GiB kv_cache_size=23.92GiB gpu_memory_utilization=0.90
INFO 12-25 12:40:50 gpu_executor.py:113] # GPU blocks: 4897, # CPU blocks: 819
INFO 12-25 12:40:50 gpu_executor.py:117] Maximum concurrency for 32768 tokens per request: 2.39x
INFO 12-25 12:40:51 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 12-25 12:40:51 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 12-25 12:41:04 model_runner.py:1518] Graph capturing finished in 12 secs, took 0.51 GiB
INFO 12-25 12:41:05 api_server.py:249] vLLM to use /tmp/tmpb8sgvsk0 as PROMETHEUS_MULTIPROC_DIR
INFO 12-25 12:41:05 launcher.py:19] Available routes are:
INFO 12-25 12:41:05 launcher.py:27] Route: /openapi.json, Methods: GET, HEAD
INFO 12-25 12:41:05 launcher.py:27] Route: /docs, Methods: GET, HEAD
INFO 12-25 12:41:05 launcher.py:27] Route: /docs/oauth2-redirect, Methods: GET, HEAD
INFO 12-25 12:41:05 launcher.py:27] Route: /redoc, Methods: GET, HEAD
INFO 12-25 12:41:05 launcher.py:27] Route: /health, Methods: GET
INFO 12-25 12:41:05 launcher.py:27] Route: /tokenize, Methods: POST
INFO 12-25 12:41:05 launcher.py:27] Route: /detokenize, Methods: POST
INFO 12-25 12:41:05 launcher.py:27] Route: /v1/models, Methods: GET
INFO 12-25 12:41:05 launcher.py:27] Route: /version, Methods: GET
INFO 12-25 12:41:05 launcher.py:27] Route: /v1/chat/completions, Methods: POST
INFO 12-25 12:41:05 launcher.py:27] Route: /v1/completions, Methods: POST
INFO 12-25 12:41:05 launcher.py:27] Route: /v1/embeddings, Methods: POST
INFO:     Started server process [3401326]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO 12-25 12:41:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:41:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:41:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:41:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:41:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:42:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:43:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:44:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:45:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:46:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:47:55 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:05 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:15 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:25 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:35 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:45 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:48 logger.py:37] Received request chatcmpl-af171df6699840b2b4c5ac7ceeb03b43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the genre of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:48 logger.py:37] Received request chatcmpl-2db502ce994340c8aebcc431e0b8260e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following features/items is not discussed in the video in relation to the tomb?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:48 engine.py:267] Added request chatcmpl-af171df6699840b2b4c5ac7ceeb03b43.
INFO 12-25 12:48:48 engine.py:267] Added request chatcmpl-2db502ce994340c8aebcc431e0b8260e.
INFO 12-25 12:48:48 logger.py:37] Received request chatcmpl-85bf0092e7874cbab7f11a973dffcebe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When demonstrating the Germany modern Christmas tree is initially decorated with apples, candles and berries, which kind of the decoration has the largest number?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:48 logger.py:37] Received request chatcmpl-ba7711095c6548aeb299eb535c8d4a01: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many red socks are above the fireplace at the end of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:48 engine.py:267] Added request chatcmpl-85bf0092e7874cbab7f11a973dffcebe.
INFO 12-25 12:48:48 engine.py:267] Added request chatcmpl-ba7711095c6548aeb299eb535c8d4a01.
INFO 12-25 12:48:50 metrics.py:449] Avg prompt throughput: 55.1 tokens/s, Avg generation throughput: 77.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54594 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:48:59 logger.py:37] Received request chatcmpl-44bee9dc2510498f8f42c16244140690: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following reasons motivated the archaeologists to excavate the tomb?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:59 engine.py:267] Added request chatcmpl-44bee9dc2510498f8f42c16244140690.
INFO 12-25 12:48:59 logger.py:37] Received request chatcmpl-a2d507543a654820a87b97fc510b6342: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many porcelain jars were discovered in the niches located in the primary chamber of the tomb?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:59 logger.py:37] Received request chatcmpl-c0ba34fd00c6460f8f0ce71a3d47e506: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video telling when the burger placed in the upper right corner at the end of the video first appears?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:59 logger.py:37] Received request chatcmpl-56923ee30d1842fd8f87084a3aa672f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many national flags appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:48:59 metrics.py:449] Avg prompt throughput: 7.5 tokens/s, Avg generation throughput: 48.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:48:59 engine.py:267] Added request chatcmpl-a2d507543a654820a87b97fc510b6342.
INFO 12-25 12:48:59 engine.py:267] Added request chatcmpl-c0ba34fd00c6460f8f0ce71a3d47e506.
INFO 12-25 12:48:59 engine.py:267] Added request chatcmpl-56923ee30d1842fd8f87084a3aa672f8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:04 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:05 logger.py:37] Received request chatcmpl-7be419bfff6c4bf2a6619f69b8edb2a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which country is the food featured in the video recognized worldwide?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:05 engine.py:267] Added request chatcmpl-7be419bfff6c4bf2a6619f69b8edb2a5.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:05 logger.py:37] Received request chatcmpl-f47c27193dc04b769011a53b2a252b1f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following is considered the earliest stage of human evolution?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:05 engine.py:267] Added request chatcmpl-f47c27193dc04b769011a53b2a252b1f.
INFO 12-25 12:49:07 logger.py:37] Received request chatcmpl-531386616eba454bb2fbf602df7ebf5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Given the information provided by the video, during which stage of human evolution did the regression of body hair occur rapidly?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:07 engine.py:267] Added request chatcmpl-531386616eba454bb2fbf602df7ebf5e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:08 logger.py:37] Received request chatcmpl-bb0ad0fe8b1f4768be52773bd9f1b4a6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, in which state did human\'s ancestors first begin to walk on two legs?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:08 engine.py:267] Added request chatcmpl-bb0ad0fe8b1f4768be52773bd9f1b4a6.
INFO 12-25 12:49:09 metrics.py:449] Avg prompt throughput: 56.3 tokens/s, Avg generation throughput: 119.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:13 logger.py:37] Received request chatcmpl-f3b84e40ed5143fca84d727062e96f6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many individuals were in the car when Archduke Franz Ferdinand was assassinated?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:13 engine.py:267] Added request chatcmpl-f3b84e40ed5143fca84d727062e96f6d.
INFO 12-25 12:49:13 logger.py:37] Received request chatcmpl-b4e05a90944f4c0c8d3add383dae2468: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the trigger that set off the war mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:13 engine.py:267] Added request chatcmpl-b4e05a90944f4c0c8d3add383dae2468.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:14 logger.py:37] Received request chatcmpl-29ed0549fa884b838de661062f4c71c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is one of the symbols of the festival that is introduced by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:14 engine.py:267] Added request chatcmpl-29ed0549fa884b838de661062f4c71c0.
INFO 12-25 12:49:14 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 98.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:15 logger.py:37] Received request chatcmpl-d337d38825c64373ad5ee998d996bb61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is incorrect regarding the events in Sarajevo depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:15 engine.py:267] Added request chatcmpl-d337d38825c64373ad5ee998d996bb61.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:19 logger.py:37] Received request chatcmpl-341601b73591434aa91cbc3f3d2ca66c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened when Irish imiggrants brought the tradition of St. Patrick\'s Day to America?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:19 engine.py:267] Added request chatcmpl-341601b73591434aa91cbc3f3d2ca66c.
INFO 12-25 12:49:19 metrics.py:449] Avg prompt throughput: 28.5 tokens/s, Avg generation throughput: 107.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:20 logger.py:37] Received request chatcmpl-6400edcb49214cb7a5e0eba67de6af96: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of communication is listed before Semaphore?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:20 engine.py:267] Added request chatcmpl-6400edcb49214cb7a5e0eba67de6af96.
INFO 12-25 12:49:20 logger.py:37] Received request chatcmpl-52e2d0214f144a9ea4e0564b30ebd847: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special about the celebration in New York according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:20 engine.py:267] Added request chatcmpl-52e2d0214f144a9ea4e0564b30ebd847.
INFO 12-25 12:49:21 logger.py:37] Received request chatcmpl-22bac3e9e8954c01ab3c9d0146648c17: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the smoke generated by the man depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:21 engine.py:267] Added request chatcmpl-22bac3e9e8954c01ab3c9d0146648c17.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:24 metrics.py:449] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 120.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:26 logger.py:37] Received request chatcmpl-7613a18f4fce42fbac18fbe49237d9b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the second half of the video show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:26 logger.py:37] Received request chatcmpl-332776ce7a404fd7b9f57e5c30da00ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the specific sentence in the smart phone that makes the man embarrassed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:26 engine.py:267] Added request chatcmpl-7613a18f4fce42fbac18fbe49237d9b3.
INFO 12-25 12:49:26 engine.py:267] Added request chatcmpl-332776ce7a404fd7b9f57e5c30da00ac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:29 logger.py:37] Received request chatcmpl-37d6306666af4c999189285bab417eaa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different guitar-shaped instruments are there in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:29 logger.py:37] Received request chatcmpl-1340bae914714a35a64a09d95cb441f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what color pen did the author use when he wrote "guitar" for the second time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:29 engine.py:267] Added request chatcmpl-37d6306666af4c999189285bab417eaa.
INFO 12-25 12:49:29 engine.py:267] Added request chatcmpl-1340bae914714a35a64a09d95cb441f2.
INFO 12-25 12:49:29 metrics.py:449] Avg prompt throughput: 53.4 tokens/s, Avg generation throughput: 107.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:32 logger.py:37] Received request chatcmpl-b72dc52901af452e8dd0937dac76a54a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be learned from this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:32 engine.py:267] Added request chatcmpl-b72dc52901af452e8dd0937dac76a54a.
INFO 12-25 12:49:33 logger.py:37] Received request chatcmpl-c4f3e98e19614b22b5342697a4d617e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of clothes is QuYuan wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:33 engine.py:267] Added request chatcmpl-c4f3e98e19614b22b5342697a4d617e0.
INFO 12-25 12:49:34 metrics.py:449] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 130.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:36 logger.py:37] Received request chatcmpl-732718cd4ae14aebaa0af3516d2c9851: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which day does the festival fall on the lunar calendar?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:36 engine.py:267] Added request chatcmpl-732718cd4ae14aebaa0af3516d2c9851.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:39 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 133.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:40 logger.py:37] Received request chatcmpl-5dea20f435f54b0da78e780d1f8df80c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the color of the cosmos introduced by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:40 engine.py:267] Added request chatcmpl-5dea20f435f54b0da78e780d1f8df80c.
INFO 12-25 12:49:41 logger.py:37] Received request chatcmpl-53670c9c45a3480cb8bda57ff9fb4c31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following is the main reason why people commemorate Qu Yuan?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:41 engine.py:267] Added request chatcmpl-53670c9c45a3480cb8bda57ff9fb4c31.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:43 logger.py:37] Received request chatcmpl-beeb9e724f674ca391d38caf5cad2295: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the animation, which place does not the copilot travel to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:43 engine.py:267] Added request chatcmpl-beeb9e724f674ca391d38caf5cad2295.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:44 metrics.py:449] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:46 logger.py:37] Received request chatcmpl-6b7e31190bf943ab9773c9935f4149d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the pattern on the clothing of the staff who is behaving informally at the airline counter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:46 engine.py:267] Added request chatcmpl-6b7e31190bf943ab9773c9935f4149d0.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:46 logger.py:37] Received request chatcmpl-45cb1caa95c84d5aa8f29439a5420eac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the kind of the dance in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:46 engine.py:267] Added request chatcmpl-45cb1caa95c84d5aa8f29439a5420eac.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:48 logger.py:37] Received request chatcmpl-1a6b6b6334494249885355b277e618fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the color of the tape in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:48 engine.py:267] Added request chatcmpl-1a6b6b6334494249885355b277e618fd.
INFO 12-25 12:49:49 logger.py:37] Received request chatcmpl-01a594c52da64504b69fc972e82fcb27: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following describes the reason why the student ate the banana?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:49 engine.py:267] Added request chatcmpl-01a594c52da64504b69fc972e82fcb27.
INFO 12-25 12:49:49 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 105.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:52 logger.py:37] Received request chatcmpl-6fe533a7ecae4b278cb1d5046ee0ebeb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the student do after eating the banana in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:52 engine.py:267] Added request chatcmpl-6fe533a7ecae4b278cb1d5046ee0ebeb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:55 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 124.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 12:49:55 logger.py:37] Received request chatcmpl-67bc350bb3e549989ac1dc6e29e1139a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following ingredients is not used in the artwork?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:55 logger.py:37] Received request chatcmpl-1672246d097549f3a03236b376c42ce7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the moves in the last scene of this dance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:55 engine.py:267] Added request chatcmpl-67bc350bb3e549989ac1dc6e29e1139a.
INFO 12-25 12:49:55 engine.py:267] Added request chatcmpl-1672246d097549f3a03236b376c42ce7.
INFO 12-25 12:49:56 logger.py:37] Received request chatcmpl-91ce9b4b40b84dae8012348ce0eeeb5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following can be identified as Susan White-Oakes\' most recent art piece, based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:56 engine.py:267] Added request chatcmpl-91ce9b4b40b84dae8012348ce0eeeb5b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:49:59 logger.py:37] Received request chatcmpl-d61b1fd0fbd34bb08772ec426e7f670c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the next step taken by the operator after filling the bottle with oil?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:49:59 engine.py:267] Added request chatcmpl-d61b1fd0fbd34bb08772ec426e7f670c.
INFO 12-25 12:50:00 metrics.py:449] Avg prompt throughput: 55.0 tokens/s, Avg generation throughput: 117.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:01 logger.py:37] Received request chatcmpl-7708759dc11542d398e2e3e2e6e7dc4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Susan White-Oakes often do before polishing the whole body?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:01 engine.py:267] Added request chatcmpl-7708759dc11542d398e2e3e2e6e7dc4e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:03 logger.py:37] Received request chatcmpl-cf0c41e2027f420683a07cd1ad740256: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what happened when the painting was sold?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:03 engine.py:267] Added request chatcmpl-cf0c41e2027f420683a07cd1ad740256.
INFO 12-25 12:50:04 logger.py:37] Received request chatcmpl-caf9ccdee72a49aaaa7afc22cbab0660: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which elements are depicted in the painting introduced by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:04 engine.py:267] Added request chatcmpl-caf9ccdee72a49aaaa7afc22cbab0660.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:05 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:06 logger.py:37] Received request chatcmpl-976a83bba8f94d2d80537b0439fea689: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is visible in the background of the video when the miniature bottle is shown empty?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:06 engine.py:267] Added request chatcmpl-976a83bba8f94d2d80537b0439fea689.
INFO 12-25 12:50:07 logger.py:37] Received request chatcmpl-1a6c30801cf4480e8ce4ac899373f304: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When was the painting mentioned in the video painted?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:07 engine.py:267] Added request chatcmpl-1a6c30801cf4480e8ce4ac899373f304.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:10 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:11 logger.py:37] Received request chatcmpl-f90f0bc269e1491ba0cb08f2f8dd88a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following elements is not present in the "Starry Sky"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:11 logger.py:37] Received request chatcmpl-4b2516ac412a48a4bb1dd1a2edeae51c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following elements does not appear in the paintings primarily mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:11 engine.py:267] Added request chatcmpl-f90f0bc269e1491ba0cb08f2f8dd88a9.
INFO 12-25 12:50:11 engine.py:267] Added request chatcmpl-4b2516ac412a48a4bb1dd1a2edeae51c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:15 metrics.py:449] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 119.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:15 logger.py:37] Received request chatcmpl-ba23834486a14c0687258d1bcb31f242: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is Susan White-Oakes\' latest art work made of?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:15 engine.py:267] Added request chatcmpl-ba23834486a14c0687258d1bcb31f242.
INFO 12-25 12:50:16 logger.py:37] Received request chatcmpl-f927085e37244966aa3bb38d564ae456: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which finger does not need to press the strings when playing Em9?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:16 engine.py:267] Added request chatcmpl-f927085e37244966aa3bb38d564ae456.
INFO 12-25 12:50:16 logger.py:37] Received request chatcmpl-be28f0c247174ffbb59da2e4a46949b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In this video, why some keys are blue while others are green?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:16 engine.py:267] Added request chatcmpl-be28f0c247174ffbb59da2e4a46949b9.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:17 logger.py:37] Received request chatcmpl-dd4926aff2d944fca0a78d06a3d32bc0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the characters in this video mean?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:17 engine.py:267] Added request chatcmpl-dd4926aff2d944fca0a78d06a3d32bc0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:20 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 115.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:50:20 logger.py:37] Received request chatcmpl-c1763f1988e84c0c8aad82523f5a19db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, which of the following statements is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:20 engine.py:267] Added request chatcmpl-c1763f1988e84c0c8aad82523f5a19db.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:21 logger.py:37] Received request chatcmpl-67156c47edfc460a80a7274dbd41b065: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the raven doing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:22 engine.py:267] Added request chatcmpl-67156c47edfc460a80a7274dbd41b065.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:24 logger.py:37] Received request chatcmpl-c90f047f200647ce9b779ab2474c4e47: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the author\'s intention in presenting a scene where all birds fly away except for one on the branch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:24 engine.py:267] Added request chatcmpl-c90f047f200647ce9b779ab2474c4e47.
INFO 12-25 12:50:25 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:50:25 logger.py:37] Received request chatcmpl-1f3c06456f63417484a63cc4e667f87a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the YouTuber do at the latter part of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:25 engine.py:267] Added request chatcmpl-1f3c06456f63417484a63cc4e667f87a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:28 logger.py:37] Received request chatcmpl-81724d88514944f3b694444e9aef1625: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, what is the maximum number of fingers required to play this piece of music?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:28 logger.py:37] Received request chatcmpl-745bb72dddc64fa9a0af9aabdc53e5d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, where is the best spot for tourists to take aerial photos of the sculpture mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:28 engine.py:267] Added request chatcmpl-81724d88514944f3b694444e9aef1625.
INFO 12-25 12:50:28 engine.py:267] Added request chatcmpl-745bb72dddc64fa9a0af9aabdc53e5d7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:30 metrics.py:449] Avg prompt throughput: 44.6 tokens/s, Avg generation throughput: 117.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:50:31 logger.py:37] Received request chatcmpl-6fa5013484e7489e9ae8e46a7155833c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following statements provides the most accurate explanation for why the Statue of Liberty is green in color?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:31 engine.py:267] Added request chatcmpl-6fa5013484e7489e9ae8e46a7155833c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:34 logger.py:37] Received request chatcmpl-a0b077b4a77541baab4fe2c2fdc0fb8c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the photographer who took pictures of the three tourists in the video take the photo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:34 engine.py:267] Added request chatcmpl-a0b077b4a77541baab4fe2c2fdc0fb8c.
INFO 12-25 12:50:35 metrics.py:449] Avg prompt throughput: 29.6 tokens/s, Avg generation throughput: 111.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:50:35 logger.py:37] Received request chatcmpl-dc1e2b974ec94db088e14abb9095a5da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many kinds of chords are played in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:35 engine.py:267] Added request chatcmpl-dc1e2b974ec94db088e14abb9095a5da.
INFO 12-25 12:50:35 logger.py:37] Received request chatcmpl-07aad1748a4a4101b00adbc57571d36b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how long should one wait before cracking the same knuckle again?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:35 engine.py:267] Added request chatcmpl-07aad1748a4a4101b00adbc57571d36b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:38 logger.py:37] Received request chatcmpl-ef45580c0ce54047a5953210b66d7a48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does mRNA come from in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:38 engine.py:267] Added request chatcmpl-ef45580c0ce54047a5953210b66d7a48.
INFO 12-25 12:50:40 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 137.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:42 logger.py:37] Received request chatcmpl-5897139c58914272a97db5e2352b595a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the mechanism/process that can break down bacteria according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:42 engine.py:267] Added request chatcmpl-5897139c58914272a97db5e2352b595a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:44 logger.py:37] Received request chatcmpl-66548e802af3435cbf4b108aa47ef8ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following could be the main topic of the video segment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:44 engine.py:267] Added request chatcmpl-66548e802af3435cbf4b108aa47ef8ab.
INFO 12-25 12:50:44 logger.py:37] Received request chatcmpl-271222b3fc9446c8a58233d066470f75: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the cell membrane of the virus-invaded cell in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:44 logger.py:37] Received request chatcmpl-9b49af27dd5f419193b2cbbf0d88ac03: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Whom is the poem in the video written by?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:44 engine.py:267] Added request chatcmpl-271222b3fc9446c8a58233d066470f75.
INFO 12-25 12:50:44 engine.py:267] Added request chatcmpl-9b49af27dd5f419193b2cbbf0d88ac03.
INFO 12-25 12:50:45 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 90.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:49 logger.py:37] Received request chatcmpl-9ac487525a1f44f8acbd51b102753e56: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What might be the primary focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:49 engine.py:267] Added request chatcmpl-9ac487525a1f44f8acbd51b102753e56.
INFO 12-25 12:50:50 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 145.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:52 logger.py:37] Received request chatcmpl-65c5fe4981ed43cabd164e247d64ae6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which option best describes the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:52 engine.py:267] Added request chatcmpl-65c5fe4981ed43cabd164e247d64ae6d.
INFO 12-25 12:50:53 logger.py:37] Received request chatcmpl-0137b9811a5c410e9d60cb0bd9add520: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video depict?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:53 engine.py:267] Added request chatcmpl-0137b9811a5c410e9d60cb0bd9add520.
INFO 12-25 12:50:54 logger.py:37] Received request chatcmpl-3036ee9aee5542ff96ce90c7b568f756: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following accurately describes the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:54 engine.py:267] Added request chatcmpl-3036ee9aee5542ff96ce90c7b568f756.
INFO 12-25 12:50:55 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 108.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:50:59 logger.py:37] Received request chatcmpl-4220841120d2403b831ff80b230631de: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following features is NOT visible on the model of the heart in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:59 logger.py:37] Received request chatcmpl-bb082ed2d59448a89c04b702fb1879b8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of cells are highlighted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:50:59 engine.py:267] Added request chatcmpl-4220841120d2403b831ff80b230631de.
INFO 12-25 12:50:59 engine.py:267] Added request chatcmpl-bb082ed2d59448a89c04b702fb1879b8.
INFO 12-25 12:51:00 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 108.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:00 logger.py:37] Received request chatcmpl-2cdde1b301d640ad983959230387c62e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which object is depicted as a small flying black dot at the start of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:00 engine.py:267] Added request chatcmpl-2cdde1b301d640ad983959230387c62e.
INFO 12-25 12:51:01 logger.py:37] Received request chatcmpl-3567a71f11dc434891caeb523ed2a542: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What detail does the caption provide about the term "synovial" at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:01 engine.py:267] Added request chatcmpl-3567a71f11dc434891caeb523ed2a542.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:05 metrics.py:449] Avg prompt throughput: 28.4 tokens/s, Avg generation throughput: 128.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:05 logger.py:37] Received request chatcmpl-e25fa144059e4a49b798fbfa7211f76c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What process might these cells be undergoing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:05 engine.py:267] Added request chatcmpl-e25fa144059e4a49b798fbfa7211f76c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:09 logger.py:37] Received request chatcmpl-ac9101bd3b1d4c20a5aed35baf9aa047: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which organization is responsible for publishing the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:09 engine.py:267] Added request chatcmpl-ac9101bd3b1d4c20a5aed35baf9aa047.
INFO 12-25 12:51:09 logger.py:37] Received request chatcmpl-a002db3a54e0450eb0fb86d71f886488: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which cell shown in the video is of the same type as the white cell scrolling at the beginning?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:09 engine.py:267] Added request chatcmpl-a002db3a54e0450eb0fb86d71f886488.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:10 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 110.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:10 logger.py:37] Received request chatcmpl-42381b04f25749acbcaf591a23a34b7f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What organ did the woman in the video remove from the medical model?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:10 engine.py:267] Added request chatcmpl-42381b04f25749acbcaf591a23a34b7f.
INFO 12-25 12:51:12 logger.py:37] Received request chatcmpl-850fb404fa8f4f2a8a28270c2c351dad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the purpose of the content shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:12 engine.py:267] Added request chatcmpl-850fb404fa8f4f2a8a28270c2c351dad.
INFO 12-25 12:51:15 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 135.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:17 logger.py:37] Received request chatcmpl-8d21524c8ace4f03899b3f2ce6b57ff9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different people appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:17 engine.py:267] Added request chatcmpl-8d21524c8ace4f03899b3f2ce6b57ff9.
INFO 12-25 12:51:17 logger.py:37] Received request chatcmpl-9d44bdec468f47f289a2be78e9c5c654: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:17 engine.py:267] Added request chatcmpl-9d44bdec468f47f289a2be78e9c5c654.
INFO 12-25 12:51:17 logger.py:37] Received request chatcmpl-c9b5e1c5cd2149709fbd05daec6bffc2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the woman need to drink water at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:17 engine.py:267] Added request chatcmpl-c9b5e1c5cd2149709fbd05daec6bffc2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:20 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 106.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:20 logger.py:37] Received request chatcmpl-e367462282d842c09b0056b54d8b550e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What structure is primarily depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:20 engine.py:267] Added request chatcmpl-e367462282d842c09b0056b54d8b550e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:24 logger.py:37] Received request chatcmpl-0d9264b55c3547939d3882d37f850b19: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:24 engine.py:267] Added request chatcmpl-0d9264b55c3547939d3882d37f850b19.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:25 logger.py:37] Received request chatcmpl-d8961b73549d4f51bdcade5393157989: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is the main function of the organelle featured in the footage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:25 engine.py:267] Added request chatcmpl-d8961b73549d4f51bdcade5393157989.
INFO 12-25 12:51:25 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 118.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:25 logger.py:37] Received request chatcmpl-199f308de16b4b62b8d95f37708f4969: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What organelle is depicted at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:25 engine.py:267] Added request chatcmpl-199f308de16b4b62b8d95f37708f4969.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:30 logger.py:37] Received request chatcmpl-53e7e0e0c58f492f92783ce37f3500ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What level of magnification is used to view the cells in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:30 engine.py:267] Added request chatcmpl-53e7e0e0c58f492f92783ce37f3500ed.
INFO 12-25 12:51:30 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 139.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:31 logger.py:37] Received request chatcmpl-5115ba65490143758cb17cc0dc2d3d3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most likely message being conveyed by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:31 engine.py:267] Added request chatcmpl-5115ba65490143758cb17cc0dc2d3d3f.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:32 logger.py:37] Received request chatcmpl-b073f6c6faa04387b7aad4e4694749a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video illustrating when there are three buildings appear in the video at the same time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:32 engine.py:267] Added request chatcmpl-b073f6c6faa04387b7aad4e4694749a9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:34 logger.py:37] Received request chatcmpl-ffdab482786c45529e4e1015a0acdc11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which best summarizes the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:34 engine.py:267] Added request chatcmpl-ffdab482786c45529e4e1015a0acdc11.
INFO 12-25 12:51:35 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 127.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:37 logger.py:37] Received request chatcmpl-444732c88cbf4992adb181650585611e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements can be inferred from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:37 engine.py:267] Added request chatcmpl-444732c88cbf4992adb181650585611e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:39 logger.py:37] Received request chatcmpl-9a6d4c6a88714663bfda09f407c9665d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the types of assets included within Will\'s "Assets Under Management" visual bar in the video, showcasing the composition of the mutual fund\'s holdings?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:39 engine.py:267] Added request chatcmpl-9a6d4c6a88714663bfda09f407c9665d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:40 metrics.py:449] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 126.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:41 logger.py:37] Received request chatcmpl-bc3c1d751f8b4489bac305653726af64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many laptops are produced in the company factory in the video animation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:41 logger.py:37] Received request chatcmpl-e4559a93249c4673917702581d44746a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which historical figure is visually depicted in a framed portrait in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:41 engine.py:267] Added request chatcmpl-bc3c1d751f8b4489bac305653726af64.
INFO 12-25 12:51:41 engine.py:267] Added request chatcmpl-e4559a93249c4673917702581d44746a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:43 logger.py:37] Received request chatcmpl-ad800c1e8a304abb8da5bc5b303539ce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which human organ is visible in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:43 engine.py:267] Added request chatcmpl-ad800c1e8a304abb8da5bc5b303539ce.
INFO 12-25 12:51:45 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 121.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:47 logger.py:37] Received request chatcmpl-e7003b6980f34da3bcc628e53b05f368: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on data presented in the video, what was the approximate difference in value between the US bond market and the US stock market as of 2020?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:47 engine.py:267] Added request chatcmpl-e7003b6980f34da3bcc628e53b05f368.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:50 metrics.py:449] Avg prompt throughput: 16.9 tokens/s, Avg generation throughput: 136.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:51 logger.py:37] Received request chatcmpl-8fe84318db27426caa8841d9bcef7139: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the combination of a bond certificate and the UK flag most likely symbolize in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:51 engine.py:267] Added request chatcmpl-8fe84318db27426caa8841d9bcef7139.
INFO 12-25 12:51:52 logger.py:37] Received request chatcmpl-e0f37faf7fc243c2933ff389ae1614f0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the ATP in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:52 engine.py:267] Added request chatcmpl-e0f37faf7fc243c2933ff389ae1614f0.
INFO 12-25 12:51:52 logger.py:37] Received request chatcmpl-77ceff12373b4ecba55976616b74b32f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:52 engine.py:267] Added request chatcmpl-77ceff12373b4ecba55976616b74b32f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:55 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 103.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:51:55 logger.py:37] Received request chatcmpl-2973cb90137b493f8c48b6c0f89928cc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what visual aid is used to compare the nominal minimum wage with its value in 2019 dollars, demonstrating the impact of inflation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:55 engine.py:267] Added request chatcmpl-2973cb90137b493f8c48b6c0f89928cc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:51:59 logger.py:37] Received request chatcmpl-3074a38df3b749ca9a94a7a1cb39dd1d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:51:59 engine.py:267] Added request chatcmpl-3074a38df3b749ca9a94a7a1cb39dd1d.
INFO 12-25 12:52:00 metrics.py:449] Avg prompt throughput: 29.7 tokens/s, Avg generation throughput: 111.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 12:52:00 logger.py:37] Received request chatcmpl-ea0c69d1d8164739a3138eb1f3c1fad6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what direction does the video author draw the various financial institutions?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:00 engine.py:267] Added request chatcmpl-ea0c69d1d8164739a3138eb1f3c1fad6.
INFO 12-25 12:52:00 logger.py:37] Received request chatcmpl-cd131923f8d74588a18d59f7dc758adc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many new advertising situations are introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:00 engine.py:267] Added request chatcmpl-cd131923f8d74588a18d59f7dc758adc.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:05 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 132.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 12:52:05 logger.py:37] Received request chatcmpl-2bc793257d3844ddb921794f3f8aeb33: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the stopwatch in the upper right corner of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:05 engine.py:267] Added request chatcmpl-2bc793257d3844ddb921794f3f8aeb33.
INFO 12-25 12:52:07 logger.py:37] Received request chatcmpl-712308bf4317446c817efd45a185e60b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What visual element is used to showcase companies that are included in the Dow Jones Industrial Average?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:07 logger.py:37] Received request chatcmpl-9de37c5d456b4081acb5d01b994cbf17: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which denominations of bills and/or coins are shown in the animation at the beginning of the video, and what is the total value of these denominations?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:07 engine.py:267] Added request chatcmpl-712308bf4317446c817efd45a185e60b.
INFO 12-25 12:52:07 engine.py:267] Added request chatcmpl-9de37c5d456b4081acb5d01b994cbf17.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:09 logger.py:37] Received request chatcmpl-aaa8987146b441d5a616d6afaf2ee96d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the estimated value of the global marketing industry?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:09 engine.py:267] Added request chatcmpl-aaa8987146b441d5a616d6afaf2ee96d.
INFO 12-25 12:52:10 metrics.py:449] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 111.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:15 logger.py:37] Received request chatcmpl-d1ae22bc8d174b1fa1265eb4b632b106: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of clothing is worn by the first person selling bananas in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:15 logger.py:37] Received request chatcmpl-a13948c765b849ff9b28f31d322556c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which best summarizes the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:15 engine.py:267] Added request chatcmpl-d1ae22bc8d174b1fa1265eb4b632b106.
INFO 12-25 12:52:15 engine.py:267] Added request chatcmpl-a13948c765b849ff9b28f31d322556c9.
INFO 12-25 12:52:15 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 115.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:52:16 logger.py:37] Received request chatcmpl-560ac7b358bb44fb879abfe37c552200: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How much did sales increase at Dunkin\' Donuts locations situated near the scent marketing dispensers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:16 engine.py:267] Added request chatcmpl-560ac7b358bb44fb879abfe37c552200.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:20 metrics.py:449] Avg prompt throughput: 14.3 tokens/s, Avg generation throughput: 149.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:22 logger.py:37] Received request chatcmpl-6a9629da251b4e2996744321a53633f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:22 engine.py:267] Added request chatcmpl-6a9629da251b4e2996744321a53633f3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:22 logger.py:37] Received request chatcmpl-ebdeb956db9144af944b88242adcb53c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When did the events described in the video take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:22 engine.py:267] Added request chatcmpl-ebdeb956db9144af944b88242adcb53c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:24 logger.py:37] Received request chatcmpl-0ce3330c735b418aa810c3e0e4275497: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of Canada on the map in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:24 engine.py:267] Added request chatcmpl-0ce3330c735b418aa810c3e0e4275497.
INFO 12-25 12:52:24 logger.py:37] Received request chatcmpl-f40c80e6519d449a8092c3c398a3f031: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the correct order for the three indices presented in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:24 engine.py:267] Added request chatcmpl-f40c80e6519d449a8092c3c398a3f031.
INFO 12-25 12:52:25 metrics.py:449] Avg prompt throughput: 51.7 tokens/s, Avg generation throughput: 99.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:29 logger.py:37] Received request chatcmpl-a7aaa53bf9a34bf5bac6ba463a7480f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which aspect does the video describe the role of finance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:29 engine.py:267] Added request chatcmpl-a7aaa53bf9a34bf5bac6ba463a7480f5.
INFO 12-25 12:52:30 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 115.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:30 logger.py:37] Received request chatcmpl-5cae688a34c1450997530f2e9322942f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which time is displayed on the clock in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:30 logger.py:37] Received request chatcmpl-a90810ab181b4d338f62c127e7e85769: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times is the sun visible in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:30 engine.py:267] Added request chatcmpl-5cae688a34c1450997530f2e9322942f.
INFO 12-25 12:52:30 engine.py:267] Added request chatcmpl-a90810ab181b4d338f62c127e7e85769.
INFO 12-25 12:52:32 logger.py:37] Received request chatcmpl-be506bb17d814f0caf99dfee7bfdbee4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:32 engine.py:267] Added request chatcmpl-be506bb17d814f0caf99dfee7bfdbee4.
INFO 12-25 12:52:35 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 137.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:36 logger.py:37] Received request chatcmpl-38b15b3404c84e8e8877d365abec5833: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following companies is not featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:37 engine.py:267] Added request chatcmpl-38b15b3404c84e8e8877d365abec5833.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:38 logger.py:37] Received request chatcmpl-b131dc8bf0ab457f948aaf2b89178ec7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How was the video most likely made?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:38 engine.py:267] Added request chatcmpl-b131dc8bf0ab457f948aaf2b89178ec7.
INFO 12-25 12:52:39 logger.py:37] Received request chatcmpl-f33188ac07a64058bfe76a77e259268a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many bodies are created after the collision?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:39 engine.py:267] Added request chatcmpl-f33188ac07a64058bfe76a77e259268a.
INFO 12-25 12:52:40 metrics.py:449] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 117.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:42 logger.py:37] Received request chatcmpl-b0f72c72f69b448fa2381aae49ebb6c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was Amazon\'s stock price at the peak of the dot-com bubble?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:42 engine.py:267] Added request chatcmpl-b0f72c72f69b448fa2381aae49ebb6c0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:45 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:46 logger.py:37] Received request chatcmpl-9fb8f49f02f14a128c891e96b2661651: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:46 engine.py:267] Added request chatcmpl-9fb8f49f02f14a128c891e96b2661651.
INFO 12-25 12:52:47 logger.py:37] Received request chatcmpl-9a1809758b93475992fabf8f58b7f5f0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are watching TV in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:47 engine.py:267] Added request chatcmpl-9a1809758b93475992fabf8f58b7f5f0.
INFO 12-25 12:52:47 logger.py:37] Received request chatcmpl-aaeef09ef12e48e097e8901a08768a20: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:47 engine.py:267] Added request chatcmpl-aaeef09ef12e48e097e8901a08768a20.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:49 logger.py:37] Received request chatcmpl-b97e555c10e74666b03f72f408ed98f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people can be seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:49 engine.py:267] Added request chatcmpl-b97e555c10e74666b03f72f408ed98f3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:50 metrics.py:449] Avg prompt throughput: 49.3 tokens/s, Avg generation throughput: 111.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 12:52:51 logger.py:37] Received request chatcmpl-70b2ae11f4194242945e47ec1d7a43a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:51 engine.py:267] Added request chatcmpl-70b2ae11f4194242945e47ec1d7a43a0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:55 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 134.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 12:52:55 logger.py:37] Received request chatcmpl-d060082abb6449c89921e3e7c7327600: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the roof object fly?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:55 engine.py:267] Added request chatcmpl-d060082abb6449c89921e3e7c7327600.
INFO 12-25 12:52:56 logger.py:37] Received request chatcmpl-eba2b5240cd04f46b7e0bccfad0329e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When is the zodiacal light visible from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:56 engine.py:267] Added request chatcmpl-eba2b5240cd04f46b7e0bccfad0329e5.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:52:58 logger.py:37] Received request chatcmpl-fbeef43b96d44340a24e6e63a67f86df: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT known to occur during a total solar eclipse, according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:58 logger.py:37] Received request chatcmpl-e9f5ae3bc1294743868f70d2ed9128c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people in the video doing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:52:58 engine.py:267] Added request chatcmpl-fbeef43b96d44340a24e6e63a67f86df.
INFO 12-25 12:52:58 engine.py:267] Added request chatcmpl-e9f5ae3bc1294743868f70d2ed9128c7.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:00 metrics.py:449] Avg prompt throughput: 51.0 tokens/s, Avg generation throughput: 107.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:01 logger.py:37] Received request chatcmpl-c38d417f42a94d9cb8b89dd550301048: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:01 engine.py:267] Added request chatcmpl-c38d417f42a94d9cb8b89dd550301048.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:04 logger.py:37] Received request chatcmpl-747f8a6cb17648d18c3e0bfdd995a1e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the instructor in the video appear in different scenarios?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:04 logger.py:37] Received request chatcmpl-9c9a44fe3401423d8b5fea07c9801e60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most likely cause of the disaster in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:04 engine.py:267] Added request chatcmpl-747f8a6cb17648d18c3e0bfdd995a1e0.
INFO 12-25 12:53:04 engine.py:267] Added request chatcmpl-9c9a44fe3401423d8b5fea07c9801e60.
INFO 12-25 12:53:05 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:07 logger.py:37] Received request chatcmpl-d6f30bd75de94d86a30b3b23db8f7d65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main point of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:07 engine.py:267] Added request chatcmpl-d6f30bd75de94d86a30b3b23db8f7d65.
INFO 12-25 12:53:10 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 142.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:13 logger.py:37] Received request chatcmpl-53275f0f754345eca2ef2b8596b21005: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:13 logger.py:37] Received request chatcmpl-3251bbc798374132845991113f8f49f6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which type of disaster is portrayed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:13 logger.py:37] Received request chatcmpl-dbb3cb7f2bd0495fb1327d87ad044f11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where were the people in the video located while observing the total solar eclipse?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:13 engine.py:267] Added request chatcmpl-53275f0f754345eca2ef2b8596b21005.
INFO 12-25 12:53:13 engine.py:267] Added request chatcmpl-3251bbc798374132845991113f8f49f6.
INFO 12-25 12:53:13 engine.py:267] Added request chatcmpl-dbb3cb7f2bd0495fb1327d87ad044f11.
INFO 12-25 12:53:15 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:17 logger.py:37] Received request chatcmpl-8c1a6967bcd54e48bf50ed845211be5a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which galaxies are depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:17 engine.py:267] Added request chatcmpl-8c1a6967bcd54e48bf50ed845211be5a.
INFO 12-25 12:53:20 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 145.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:22 logger.py:37] Received request chatcmpl-3dd7dcbba5024a92a80c01840fab1d4b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What astronomical phenomenon is depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:22 engine.py:267] Added request chatcmpl-3dd7dcbba5024a92a80c01840fab1d4b.
INFO 12-25 12:53:23 logger.py:37] Received request chatcmpl-407d9a2a6e304cfe8af1d41d43b39146: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following emotions might the individuals in the video be feeling?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:23 engine.py:267] Added request chatcmpl-407d9a2a6e304cfe8af1d41d43b39146.
INFO 12-25 12:53:24 logger.py:37] Received request chatcmpl-eb09330a6bc2429d8d22d98418ea23fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements can be inferred about the Triangulum Galaxy (M33) based on the information presented in the video about the other two galaxies?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:24 engine.py:267] Added request chatcmpl-eb09330a6bc2429d8d22d98418ea23fe.
INFO 12-25 12:53:25 metrics.py:449] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:29 logger.py:37] Received request chatcmpl-0ab440a5c5364847a5138850b15714c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which feature of the astronaut\'s equipment indicates that they can move independently in space in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:29 engine.py:267] Added request chatcmpl-0ab440a5c5364847a5138850b15714c2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:30 metrics.py:449] Avg prompt throughput: 14.1 tokens/s, Avg generation throughput: 148.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:31 logger.py:37] Received request chatcmpl-b30c8f128bf04e3cafca1680b342c561: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first celestial object shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:31 engine.py:267] Added request chatcmpl-b30c8f128bf04e3cafca1680b342c561.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:32 logger.py:37] Received request chatcmpl-e38f079f43ea41cd9dbdc7a0f5262cee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the No.2 celestial event shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:32 engine.py:267] Added request chatcmpl-e38f079f43ea41cd9dbdc7a0f5262cee.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:35 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 133.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:36 logger.py:37] Received request chatcmpl-dd5b08884643428ea29ab26df7d9d9a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What significant event is the number at the bottom of the video referring to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:36 engine.py:267] Added request chatcmpl-dd5b08884643428ea29ab26df7d9d9a8.
INFO 12-25 12:53:37 logger.py:37] Received request chatcmpl-2cc7918d81c84c9f9666b46136c69845: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What direction should one face to observe the No.5 celestial event?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:37 engine.py:267] Added request chatcmpl-2cc7918d81c84c9f9666b46136c69845.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:40 logger.py:37] Received request chatcmpl-2fbfefc64ba04069b476a098a337f588: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What might be the immediate consequence of such an event according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:40 engine.py:267] Added request chatcmpl-2fbfefc64ba04069b476a098a337f588.
INFO 12-25 12:53:40 metrics.py:449] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 108.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:41 logger.py:37] Received request chatcmpl-01110107ed9f4ad5b98dab1cef20e2ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the scenes shot on Indus River and Yangze River have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:41 engine.py:267] Added request chatcmpl-01110107ed9f4ad5b98dab1cef20e2ee.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:43 logger.py:37] Received request chatcmpl-7c5dd25925724a8eb069710bc0dc9be7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statement is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:43 engine.py:267] Added request chatcmpl-7c5dd25925724a8eb069710bc0dc9be7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:45 logger.py:37] Received request chatcmpl-4842ecc6080848f2adf21f61c7c8b85f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Considering the context of the astronaut in the video, what historic milestone might this represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:45 engine.py:267] Added request chatcmpl-4842ecc6080848f2adf21f61c7c8b85f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:45 metrics.py:449] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:46 logger.py:37] Received request chatcmpl-4fcf7d2a160347639d0799463f6995ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity is being performed by the astronaut in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:46 engine.py:267] Added request chatcmpl-4fcf7d2a160347639d0799463f6995ea.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:48 logger.py:37] Received request chatcmpl-49d132ae6815400ca08210adf48a3317: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color of clothing is the painter wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:48 engine.py:267] Added request chatcmpl-49d132ae6815400ca08210adf48a3317.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:50 metrics.py:449] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 120.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:53:51 logger.py:37] Received request chatcmpl-d4c7813f626c4e9bbbb412f66b1e8f9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how do the geologists collect lava safely?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:51 engine.py:267] Added request chatcmpl-d4c7813f626c4e9bbbb412f66b1e8f9c.
INFO 12-25 12:53:51 logger.py:37] Received request chatcmpl-00c64c2ab3bc4267aa34853fa47ab543: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many bridges can be spotted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:51 engine.py:267] Added request chatcmpl-00c64c2ab3bc4267aa34853fa47ab543.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:54 logger.py:37] Received request chatcmpl-be8421b5c8d9406490a81f3ef0997d40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On what date is the total eclipse supposed to occur in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:54 engine.py:267] Added request chatcmpl-be8421b5c8d9406490a81f3ef0997d40.
INFO 12-25 12:53:55 logger.py:37] Received request chatcmpl-1503f01b476a4affb4edd7dee426a1d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:55 engine.py:267] Added request chatcmpl-1503f01b476a4affb4edd7dee426a1d6.
INFO 12-25 12:53:55 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 115.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:57 logger.py:37] Received request chatcmpl-b15f2d2b112641e0a60472c8fab2efcf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is cold water formed on the sea surface?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:57 engine.py:267] Added request chatcmpl-b15f2d2b112641e0a60472c8fab2efcf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:53:59 logger.py:37] Received request chatcmpl-1c8eee1413884b0db5343af3c98b109d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which river\'s bank is it possible to see snow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:53:59 engine.py:267] Added request chatcmpl-1c8eee1413884b0db5343af3c98b109d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:00 metrics.py:449] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 126.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:01 logger.py:37] Received request chatcmpl-e13ba36aab54436fa5fc20dbf31c7f1d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, what is the reason for the phenomenon that the atmospheric temperature in some places is lower than the sea water temperature?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:01 engine.py:267] Added request chatcmpl-e13ba36aab54436fa5fc20dbf31c7f1d.
INFO 12-25 12:54:02 logger.py:37] Received request chatcmpl-915c90b2da5e4b0d872b62f7ab5116fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many climbers are there in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:02 engine.py:267] Added request chatcmpl-915c90b2da5e4b0d872b62f7ab5116fc.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:04 logger.py:37] Received request chatcmpl-02caf9de44cb4551ad8ef85bc18b5dfe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does "you" in the video represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:04 engine.py:267] Added request chatcmpl-02caf9de44cb4551ad8ef85bc18b5dfe.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:05 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 116.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:54:06 logger.py:37] Received request chatcmpl-65b24618725549bca69055efa3380879: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the color of lava change when exposed to the air for a short while?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:06 engine.py:267] Added request chatcmpl-65b24618725549bca69055efa3380879.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:07 logger.py:37] Received request chatcmpl-2789a030ba004d43bf381cdeefe9344a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the focal point in the scene referred to as "thrive" by the speaker?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:07 engine.py:267] Added request chatcmpl-2789a030ba004d43bf381cdeefe9344a.
INFO 12-25 12:54:10 metrics.py:449] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:14 logger.py:37] Received request chatcmpl-d75798969b644567aeb0dbe5342bda99: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct sequence of events in the formation of rain?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:14 engine.py:267] Added request chatcmpl-d75798969b644567aeb0dbe5342bda99.
INFO 12-25 12:54:15 logger.py:37] Received request chatcmpl-c3f8be3979c94613ababecc7daa232d9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is considered to be the primary cause of El Nio?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:15 logger.py:37] Received request chatcmpl-a67943cb267846149c6d0a15c0b3c55a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the geologists cool the lava down?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:15 engine.py:267] Added request chatcmpl-c3f8be3979c94613ababecc7daa232d9.
INFO 12-25 12:54:15 engine.py:267] Added request chatcmpl-a67943cb267846149c6d0a15c0b3c55a.
INFO 12-25 12:54:15 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 77.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 12:54:16 logger.py:37] Received request chatcmpl-049fe431b4b64053a95eb196a2a9d8f6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, which one is the most direct cause of the phenomenon that the smoke flows towards the lamp?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:16 engine.py:267] Added request chatcmpl-049fe431b4b64053a95eb196a2a9d8f6.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:20 metrics.py:449] Avg prompt throughput: 15.7 tokens/s, Avg generation throughput: 124.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:21 logger.py:37] Received request chatcmpl-ed6e71f447e4409980e418f7b726d2dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many circles can be observed in the first few seconds of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:21 logger.py:37] Received request chatcmpl-d3abac63926244ac9243c3acb811bf04: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is one of the causes of wind according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:21 logger.py:37] Received request chatcmpl-1c483094b25647e3823026bc1a4eadec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the red color in the circle most likely to represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:21 engine.py:267] Added request chatcmpl-ed6e71f447e4409980e418f7b726d2dc.
INFO 12-25 12:54:21 engine.py:267] Added request chatcmpl-d3abac63926244ac9243c3acb811bf04.
INFO 12-25 12:54:21 engine.py:267] Added request chatcmpl-1c483094b25647e3823026bc1a4eadec.
INFO 12-25 12:54:22 logger.py:37] Received request chatcmpl-86d9d00131f048aba14858872ff6e96f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the speaker in the video dress like?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:22 engine.py:267] Added request chatcmpl-86d9d00131f048aba14858872ff6e96f.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:25 logger.py:37] Received request chatcmpl-f85a376e9801414bb43e5990ba7b2ee1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which element doesn\'t show up in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:25 engine.py:267] Added request chatcmpl-f85a376e9801414bb43e5990ba7b2ee1.
INFO 12-25 12:54:25 metrics.py:449] Avg prompt throughput: 63.9 tokens/s, Avg generation throughput: 112.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 152.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:54:30 logger.py:37] Received request chatcmpl-288110e276b64926a6b3e6ffef2f5d2a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what do the three curved lines extending from bottom up symbolize?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:30 engine.py:267] Added request chatcmpl-288110e276b64926a6b3e6ffef2f5d2a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:33 logger.py:37] Received request chatcmpl-8e64b18ede5c4f3d9a2563c89e97d900: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following elements does not appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:33 engine.py:267] Added request chatcmpl-8e64b18ede5c4f3d9a2563c89e97d900.
INFO 12-25 12:54:34 logger.py:37] Received request chatcmpl-e4ede8e0676c41008164c5ede5026866: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item was not featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:34 engine.py:267] Added request chatcmpl-e4ede8e0676c41008164c5ede5026866.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:35 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 128.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:37 logger.py:37] Received request chatcmpl-6ad5441ef8894852889c8df674a9630c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following facts is not caused by the iceberg mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:37 logger.py:37] Received request chatcmpl-82c1dc5584914f36b78c889c2846fc0b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color are the mountains in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:37 engine.py:267] Added request chatcmpl-6ad5441ef8894852889c8df674a9630c.
INFO 12-25 12:54:37 engine.py:267] Added request chatcmpl-82c1dc5584914f36b78c889c2846fc0b.
INFO 12-25 12:54:40 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 128.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:43 logger.py:37] Received request chatcmpl-180ac5b8797d46f09f7ecd7bc9e9c311: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statement is true according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:43 engine.py:267] Added request chatcmpl-180ac5b8797d46f09f7ecd7bc9e9c311.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:45 logger.py:37] Received request chatcmpl-551abc89ffaf40638c0dab9cd915458e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statement is true according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:45 engine.py:267] Added request chatcmpl-551abc89ffaf40638c0dab9cd915458e.
INFO 12-25 12:54:45 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 12:54:46 logger.py:37] Received request chatcmpl-a23464e257ff4dcea72e8a28741bf92d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What information is shown in the video regarding Portugal\'s GDP?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:46 logger.py:37] Received request chatcmpl-8461ae919f284970b2d13f70bda8f581: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order did the movement occur in the focused image within the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:46 engine.py:267] Added request chatcmpl-a23464e257ff4dcea72e8a28741bf92d.
INFO 12-25 12:54:46 engine.py:267] Added request chatcmpl-8461ae919f284970b2d13f70bda8f581.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:50 logger.py:37] Received request chatcmpl-cbd6d4ba5cce4420bfe7f2d6a44f1591: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ocean do the thunderstorms in the video need to cross before they reach America?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:50 engine.py:267] Added request chatcmpl-cbd6d4ba5cce4420bfe7f2d6a44f1591.
INFO 12-25 12:54:50 metrics.py:449] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:52 logger.py:37] Received request chatcmpl-93531b0caa904590baec6c8771352c3c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many red flags appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:52 engine.py:267] Added request chatcmpl-93531b0caa904590baec6c8771352c3c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:53 logger.py:37] Received request chatcmpl-07d4e2611fd24562910b49170354e822: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which option best represents the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:53 engine.py:267] Added request chatcmpl-07d4e2611fd24562910b49170354e822.
INFO 12-25 12:54:55 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 132.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:54:58 logger.py:37] Received request chatcmpl-8b6afed984dc4f908ac543067512cc5c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the fate of the double-story building showcased in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:58 engine.py:267] Added request chatcmpl-8b6afed984dc4f908ac543067512cc5c.
INFO 12-25 12:54:59 logger.py:37] Received request chatcmpl-28f680ffad424de4988b25c1043a276d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:54:59 engine.py:267] Added request chatcmpl-28f680ffad424de4988b25c1043a276d.
INFO 12-25 12:55:00 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 128.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:02 logger.py:37] Received request chatcmpl-37c0ead9e46442f685cd096f9749d7e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the woman in the video with short hair, wearing a black top, and donning a white scarf?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:02 engine.py:267] Added request chatcmpl-37c0ead9e46442f685cd096f9749d7e2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:04 logger.py:37] Received request chatcmpl-4e1e7084a2464f4890a5a7a0d587c80b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following keywords was not mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:04 engine.py:267] Added request chatcmpl-4e1e7084a2464f4890a5a7a0d587c80b.
INFO 12-25 12:55:05 logger.py:37] Received request chatcmpl-584d7b6d1d9e4bb491c9b70067fcba28: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the website that appears at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:05 engine.py:267] Added request chatcmpl-584d7b6d1d9e4bb491c9b70067fcba28.
INFO 12-25 12:55:05 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 120.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:08 logger.py:37] Received request chatcmpl-15a1fc1ca0714083a465149171f9b9ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the identity of the individual sitting in the center of the video, wearing glasses, and holding a small hammer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:08 engine.py:267] Added request chatcmpl-15a1fc1ca0714083a465149171f9b9ab.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:10 logger.py:37] Received request chatcmpl-14484173594f4d5faea329f3da630deb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the object that appears after the red door opens in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:10 engine.py:267] Added request chatcmpl-14484173594f4d5faea329f3da630deb.
INFO 12-25 12:55:10 metrics.py:449] Avg prompt throughput: 28.5 tokens/s, Avg generation throughput: 132.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:14 logger.py:37] Received request chatcmpl-5d9ae2925297481ab50801de15d8ec00: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals are visible in the introductory shot of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:14 logger.py:37] Received request chatcmpl-a633ba30382447f1958685740c31b13c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video introduce?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:14 engine.py:267] Added request chatcmpl-5d9ae2925297481ab50801de15d8ec00.
INFO 12-25 12:55:14 engine.py:267] Added request chatcmpl-a633ba30382447f1958685740c31b13c.
INFO 12-25 12:55:15 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 129.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:20 logger.py:37] Received request chatcmpl-fef227d0b02641e584bff84d2b58428a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the main topic of the video below?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:20 logger.py:37] Received request chatcmpl-bbc388e9e99646ba98574b1151210ee1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What topic is introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:20 engine.py:267] Added request chatcmpl-fef227d0b02641e584bff84d2b58428a.
INFO 12-25 12:55:20 engine.py:267] Added request chatcmpl-bbc388e9e99646ba98574b1151210ee1.
INFO 12-25 12:55:20 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 100.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 12:55:21 logger.py:37] Received request chatcmpl-29eefda2e50d431ba4f85c134c752844: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the colors of the three doors that appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:21 engine.py:267] Added request chatcmpl-29eefda2e50d431ba4f85c134c752844.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:24 logger.py:37] Received request chatcmpl-6e76d4a103414ee884168916f979f5bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people wearing a white shirt and a person wearing a black shirt doing together in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:24 engine.py:267] Added request chatcmpl-6e76d4a103414ee884168916f979f5bf.
INFO 12-25 12:55:25 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 140.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:28 logger.py:37] Received request chatcmpl-d271816dd3334424a923ced89d238349: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man doing at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:28 engine.py:267] Added request chatcmpl-d271816dd3334424a923ced89d238349.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:29 logger.py:37] Received request chatcmpl-d16f854973e442e5b5ff4455af719b7a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the object illustrated in the second point in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:29 engine.py:267] Added request chatcmpl-d16f854973e442e5b5ff4455af719b7a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:30 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 126.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:55:32 logger.py:37] Received request chatcmpl-848a7bd3e29a47a4860861aec0c58aeb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people can be seen holding cameras in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:32 logger.py:37] Received request chatcmpl-8d4156b587f6461ca29bc6102fc6d7ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the pencils that individuals are grasping for drawing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:32 engine.py:267] Added request chatcmpl-848a7bd3e29a47a4860861aec0c58aeb.
INFO 12-25 12:55:32 engine.py:267] Added request chatcmpl-8d4156b587f6461ca29bc6102fc6d7ca.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:35 logger.py:37] Received request chatcmpl-8b7245f0ed834e37ae2e91d91feb2489: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement accurately describes the job of the man shown in the center of the video who is wearing a black suit?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:35 logger.py:37] Received request chatcmpl-cfa37048fb314e9da581ed5c99439788: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many adult men, aged 18 years or older, can be seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:35 engine.py:267] Added request chatcmpl-8b7245f0ed834e37ae2e91d91feb2489.
INFO 12-25 12:55:35 engine.py:267] Added request chatcmpl-cfa37048fb314e9da581ed5c99439788.
INFO 12-25 12:55:35 metrics.py:449] Avg prompt throughput: 55.9 tokens/s, Avg generation throughput: 101.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 155.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:42 logger.py:37] Received request chatcmpl-549003885636490182fc44f026ae6e6e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the island that is shown at the start of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:42 engine.py:267] Added request chatcmpl-549003885636490182fc44f026ae6e6e.
INFO 12-25 12:55:43 logger.py:37] Received request chatcmpl-921a357202be48f9bc358bce82244c9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item does not the man wear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:43 engine.py:267] Added request chatcmpl-921a357202be48f9bc358bce82244c9c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:43 logger.py:37] Received request chatcmpl-a87ccefbbe37484e9858b428a72561d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity can be seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:43 engine.py:267] Added request chatcmpl-a87ccefbbe37484e9858b428a72561d6.
INFO 12-25 12:55:45 metrics.py:449] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 126.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:49 logger.py:37] Received request chatcmpl-8666a7334afd46eca2877a731ee93c5d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many areas are divided into the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:50 engine.py:267] Added request chatcmpl-8666a7334afd46eca2877a731ee93c5d.
INFO 12-25 12:55:50 logger.py:37] Received request chatcmpl-2d62759d8ed04c2e9de179370e09b7a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT mentioned in the new labor law?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:50 engine.py:267] Added request chatcmpl-2d62759d8ed04c2e9de179370e09b7a5.
INFO 12-25 12:55:50 logger.py:37] Received request chatcmpl-7e51f7dbb7da4733b8d64dc254da52e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:50 engine.py:267] Added request chatcmpl-7e51f7dbb7da4733b8d64dc254da52e1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:50 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 122.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:55:51 logger.py:37] Received request chatcmpl-bf10b9a6260d4ab8b7876d5c25e79c77: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the icon of Keyborad Cleaner app shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:51 engine.py:267] Added request chatcmpl-bf10b9a6260d4ab8b7876d5c25e79c77.
INFO 12-25 12:55:55 metrics.py:449] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 149.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:55:58 logger.py:37] Received request chatcmpl-b9cc3ee7284648ffb98dd8bcd01077e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the animation demonstrate the impact of insufficient sleep on one\'s abilities?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:58 engine.py:267] Added request chatcmpl-b9cc3ee7284648ffb98dd8bcd01077e2.
INFO 12-25 12:55:59 logger.py:37] Received request chatcmpl-cb0af8a87a7d4ad9a196f586349caf10: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first thing depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:59 engine.py:267] Added request chatcmpl-cb0af8a87a7d4ad9a196f586349caf10.
INFO 12-25 12:55:59 logger.py:37] Received request chatcmpl-e7f4473d86ad47efb812cf76c46ee195: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly states the number of people visible in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:59 logger.py:37] Received request chatcmpl-abb45d2499984a0c8fcc42ed8cf66d50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:55:59 engine.py:267] Added request chatcmpl-e7f4473d86ad47efb812cf76c46ee195.
INFO 12-25 12:55:59 engine.py:267] Added request chatcmpl-abb45d2499984a0c8fcc42ed8cf66d50.
INFO 12-25 12:56:00 metrics.py:449] Avg prompt throughput: 51.4 tokens/s, Avg generation throughput: 84.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:06 logger.py:37] Received request chatcmpl-427b79aa7ca44b54badcdd824b315d6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many hours of sleep does this video recommend adults aim to achieve each day, as depicted in the animation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:06 engine.py:267] Added request chatcmpl-427b79aa7ca44b54badcdd824b315d6a.
INFO 12-25 12:56:06 metrics.py:449] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 115.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:56:07 logger.py:37] Received request chatcmpl-f66ee4b7cbff4b7da1a660875adf9259: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is left of the wine on the animation when suggesting avoiding stimulants?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:08 logger.py:37] Received request chatcmpl-96f914ce96e849a698b6d1cf170fb455: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the sequence of steps introduced in this video? (a) Walk and practice using the brakes. (b) Glide to practice balancing. (c) Find a good space and safety considerations. (d) Start to pedal. (e) Adjust the seat.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:08 logger.py:37] Received request chatcmpl-29c6f2d456a74f6189c18e3850cc3555: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the brown item pinned on the speaker\'s waist?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:08 engine.py:267] Added request chatcmpl-f66ee4b7cbff4b7da1a660875adf9259.
INFO 12-25 12:56:08 engine.py:267] Added request chatcmpl-96f914ce96e849a698b6d1cf170fb455.
INFO 12-25 12:56:08 engine.py:267] Added request chatcmpl-29c6f2d456a74f6189c18e3850cc3555.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:11 metrics.py:449] Avg prompt throughput: 48.2 tokens/s, Avg generation throughput: 116.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 12:56:12 logger.py:37] Received request chatcmpl-40575f71b9e345d7a5951182aa558335: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many steps does the man walk in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:12 engine.py:267] Added request chatcmpl-40575f71b9e345d7a5951182aa558335.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:15 logger.py:37] Received request chatcmpl-2f6b74e8e74245918a43e805f55fdf7f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cups appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:15 logger.py:37] Received request chatcmpl-ac084cde0dde497cb0773e240318d783: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which smart phone is advertised on the screen of the laptop?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:15 logger.py:37] Received request chatcmpl-1af06c2c1e1245a98e4d2b1d387beaac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the right pose demonstrated in the animation when sitting on the bike before starting to ride?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:15 engine.py:267] Added request chatcmpl-2f6b74e8e74245918a43e805f55fdf7f.
INFO 12-25 12:56:15 engine.py:267] Added request chatcmpl-ac084cde0dde497cb0773e240318d783.
INFO 12-25 12:56:15 engine.py:267] Added request chatcmpl-1af06c2c1e1245a98e4d2b1d387beaac.
INFO 12-25 12:56:16 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 96.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:21 logger.py:37] Received request chatcmpl-b486b5c7a91a4ef0a0a5911201bf7247: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man use to clean the keyboard in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:21 engine.py:267] Added request chatcmpl-b486b5c7a91a4ef0a0a5911201bf7247.
INFO 12-25 12:56:21 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 148.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:24 logger.py:37] Received request chatcmpl-8e87a7ffb3c34aaca9f24cd6101a96f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, where is the point B when drawing imaginary lines?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:24 engine.py:267] Added request chatcmpl-8e87a7ffb3c34aaca9f24cd6101a96f7.
INFO 12-25 12:56:25 logger.py:37] Received request chatcmpl-82694db96d0442e49f9be6e7598edd46: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following items is not hanging on the walls?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:25 engine.py:267] Added request chatcmpl-82694db96d0442e49f9be6e7598edd46.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:26 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 122.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:56:28 logger.py:37] Received request chatcmpl-7483bc70fc43477cb98586d1e3856183: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:28 logger.py:37] Received request chatcmpl-67e467e7b5c54318a947eedbf44217d9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On which shirt does the man show drawing imaginary lines?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:28 engine.py:267] Added request chatcmpl-7483bc70fc43477cb98586d1e3856183.
INFO 12-25 12:56:28 engine.py:267] Added request chatcmpl-67e467e7b5c54318a947eedbf44217d9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:30 logger.py:37] Received request chatcmpl-33ae7bda9cb141bcae551cdbdfd7d634: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:30 engine.py:267] Added request chatcmpl-33ae7bda9cb141bcae551cdbdfd7d634.
INFO 12-25 12:56:31 metrics.py:449] Avg prompt throughput: 36.5 tokens/s, Avg generation throughput: 113.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:56:32 logger.py:37] Received request chatcmpl-aba5286d6d994b5a8ad624f1cc90c713: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:32 engine.py:267] Added request chatcmpl-aba5286d6d994b5a8ad624f1cc90c713.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:33 logger.py:37] Received request chatcmpl-3c8cd7b0543142249632d1e95047d4d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When does the man take a long exhaled breath in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:33 engine.py:267] Added request chatcmpl-3c8cd7b0543142249632d1e95047d4d5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:35 logger.py:37] Received request chatcmpl-32fe7391c93c40ed85e229a8b0ff1b7f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of rope to the dog of white?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:35 engine.py:267] Added request chatcmpl-32fe7391c93c40ed85e229a8b0ff1b7f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:36 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 120.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:38 logger.py:37] Received request chatcmpl-81d777cc7f164918ac4cb0eba992e75c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the tall drinking glass initially held by the woman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:38 engine.py:267] Added request chatcmpl-81d777cc7f164918ac4cb0eba992e75c.
INFO 12-25 12:56:39 logger.py:37] Received request chatcmpl-7791187186d34209bc7a355270b8eb5c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which side of the tie is shorter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:39 logger.py:37] Received request chatcmpl-6b5211d9d112421d813e14410995b737: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the size of the back touchscreen display in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:39 engine.py:267] Added request chatcmpl-7791187186d34209bc7a355270b8eb5c.
INFO 12-25 12:56:39 engine.py:267] Added request chatcmpl-6b5211d9d112421d813e14410995b737.
INFO 12-25 12:56:41 metrics.py:449] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 107.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:44 logger.py:37] Received request chatcmpl-a335029601464197be65f556dcaa38a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, what is the purpose of adding fresh produce to the water?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:44 logger.py:37] Received request chatcmpl-a5ef442918c34be187fa8a227d24697c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item is similar in size to the loop depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:44 engine.py:267] Added request chatcmpl-a335029601464197be65f556dcaa38a7.
INFO 12-25 12:56:44 engine.py:267] Added request chatcmpl-a5ef442918c34be187fa8a227d24697c.
INFO 12-25 12:56:45 logger.py:37] Received request chatcmpl-9aaf749101ed466fa6f884e06d334e46: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How are the tomatoes in the video placed when introducing the fourth tip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:45 engine.py:267] Added request chatcmpl-9aaf749101ed466fa6f884e06d334e46.
INFO 12-25 12:56:46 metrics.py:449] Avg prompt throughput: 40.1 tokens/s, Avg generation throughput: 103.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:48 logger.py:37] Received request chatcmpl-2bc9aa528386498d8d87d13b06d5ab42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what location was the video most likely recorded?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:48 engine.py:267] Added request chatcmpl-2bc9aa528386498d8d87d13b06d5ab42.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:50 logger.py:37] Received request chatcmpl-1bece3d1ee374ba19bdff39e2d53cf73: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which vegetable is not visible in this video when introducing the first tip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:50 engine.py:267] Added request chatcmpl-1bece3d1ee374ba19bdff39e2d53cf73.
INFO 12-25 12:56:51 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 134.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:54 logger.py:37] Received request chatcmpl-924724437fd84630b0680930926f4164: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which choice best summarizes the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:54 engine.py:267] Added request chatcmpl-924724437fd84630b0680930926f4164.
INFO 12-25 12:56:55 logger.py:37] Received request chatcmpl-19cc976c081844868853ffc0bd5b3bd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order do the six tips are introduced in the video? (a) Clip coupons. (b) Eat at home. (c) Freeze leftovers. (d) Cook once, eat twice. (e) Meal plan. (f) Buy in bulk.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:55 engine.py:267] Added request chatcmpl-19cc976c081844868853ffc0bd5b3bd8.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:56:56 metrics.py:449] Avg prompt throughput: 33.5 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:56:57 logger.py:37] Received request chatcmpl-7ba48d79ca214a88a23a59607f92cf4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options describes a common trait shared by the characters in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:57 engine.py:267] Added request chatcmpl-7ba48d79ca214a88a23a59607f92cf4e.
INFO 12-25 12:56:58 logger.py:37] Received request chatcmpl-f5a70e7b801d4af39fd760f4f68d722c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what are the resistance bands parallel to when the man is pulling apart?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:56:58 engine.py:267] Added request chatcmpl-f5a70e7b801d4af39fd760f4f68d722c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:01 logger.py:37] Received request chatcmpl-3158ad8126d34e4a835ab77af6aa6718: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s wrong with this car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:01 engine.py:267] Added request chatcmpl-3158ad8126d34e4a835ab77af6aa6718.
INFO 12-25 12:57:01 metrics.py:449] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:05 logger.py:37] Received request chatcmpl-fdf0bc3d08644ab5809859933f927769: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the purpose of using a hammer to hit the car in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:05 logger.py:37] Received request chatcmpl-92f4ef551eb94d65964ce3c815fc757f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:05 logger.py:37] Received request chatcmpl-25b132884dc64f9e90e5fa6e3e19c4cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many methods for disengaging Super Cruise are mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:05 engine.py:267] Added request chatcmpl-fdf0bc3d08644ab5809859933f927769.
INFO 12-25 12:57:05 engine.py:267] Added request chatcmpl-92f4ef551eb94d65964ce3c815fc757f.
INFO 12-25 12:57:05 engine.py:267] Added request chatcmpl-25b132884dc64f9e90e5fa6e3e19c4cd.
INFO 12-25 12:57:06 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 97.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:09 logger.py:37] Received request chatcmpl-207b318ac8b34ebc932071e0be02bd1c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:09 engine.py:267] Added request chatcmpl-207b318ac8b34ebc932071e0be02bd1c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:11 logger.py:37] Received request chatcmpl-07e888546ba345f692296f43c741ce90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the car model written on the registration plate that can be seen in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:11 engine.py:267] Added request chatcmpl-07e888546ba345f692296f43c741ce90.
INFO 12-25 12:57:11 logger.py:37] Received request chatcmpl-7a3e93e26be84061a9f56f8e04597231: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the pants worn by the young girl who converses with the elderly man on the subway?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:11 engine.py:267] Added request chatcmpl-7a3e93e26be84061a9f56f8e04597231.
INFO 12-25 12:57:11 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 113.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:13 logger.py:37] Received request chatcmpl-d903b711315d46acaaa27ce9bfca2bed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which colors are not present on the car, including the color of the lights, shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:13 engine.py:267] Added request chatcmpl-d903b711315d46acaaa27ce9bfca2bed.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:14 logger.py:37] Received request chatcmpl-e098381f82e44d3fa5bda773b5b73652: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, how many books can be seen resting on the living room table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:14 engine.py:267] Added request chatcmpl-e098381f82e44d3fa5bda773b5b73652.
INFO 12-25 12:57:16 metrics.py:449] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 134.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:19 logger.py:37] Received request chatcmpl-ca5b659288104ababa51a448bb02f2b7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:19 logger.py:37] Received request chatcmpl-ecce6cf74466444bba11a4e4dce7cdb9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:19 engine.py:267] Added request chatcmpl-ca5b659288104ababa51a448bb02f2b7.
INFO 12-25 12:57:19 engine.py:267] Added request chatcmpl-ecce6cf74466444bba11a4e4dce7cdb9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:20 logger.py:37] Received request chatcmpl-36a8be9387fc496295da76017d19aa85: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:20 engine.py:267] Added request chatcmpl-36a8be9387fc496295da76017d19aa85.
INFO 12-25 12:57:21 metrics.py:449] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 116.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:28 logger.py:37] Received request chatcmpl-4c1616bdd1ee4442a7ae1c98d232656b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is accurate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:28 engine.py:267] Added request chatcmpl-4c1616bdd1ee4442a7ae1c98d232656b.
INFO 12-25 12:57:28 logger.py:37] Received request chatcmpl-98cea17d976b49f7bc9772eb5656a7bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of aircraft model is being used as an example when explaining gas turbines in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:28 engine.py:267] Added request chatcmpl-98cea17d976b49f7bc9772eb5656a7bc.
INFO 12-25 12:57:28 metrics.py:449] Avg prompt throughput: 10.2 tokens/s, Avg generation throughput: 102.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 12:57:28 logger.py:37] Received request chatcmpl-e95b66bf550248b391c5cf8e8ff5ad49: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which task was not completed by the robots?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:28 engine.py:267] Added request chatcmpl-e95b66bf550248b391c5cf8e8ff5ad49.
INFO 12-25 12:57:29 logger.py:37] Received request chatcmpl-aa5529d4a0c5440fb3389f02cea6e146: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many changes in the development of mobile phones are introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:29 engine.py:267] Added request chatcmpl-aa5529d4a0c5440fb3389f02cea6e146.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:33 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:33 logger.py:37] Received request chatcmpl-2b35e6bc66834d2286717ffc9fa52ca4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the purpose of changing the size of the hole of the center formed by stainless steel leaves?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:33 engine.py:267] Added request chatcmpl-2b35e6bc66834d2286717ffc9fa52ca4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:35 logger.py:37] Received request chatcmpl-fcd12410aab84f00be3cc2e387433f58: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many humanoid robots can be identified in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:35 logger.py:37] Received request chatcmpl-d62bc799f17e4d359903f937ffde6f65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is the total number of measurements involved in chip manufacturing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:35 engine.py:267] Added request chatcmpl-fcd12410aab84f00be3cc2e387433f58.
INFO 12-25 12:57:35 engine.py:267] Added request chatcmpl-d62bc799f17e4d359903f937ffde6f65.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:37 logger.py:37] Received request chatcmpl-dd766a190743495192a345ebfef5376c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What speed is displayed on the car dashboard in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:37 engine.py:267] Added request chatcmpl-dd766a190743495192a345ebfef5376c.
INFO 12-25 12:57:38 metrics.py:449] Avg prompt throughput: 54.5 tokens/s, Avg generation throughput: 110.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:40 logger.py:37] Received request chatcmpl-0e8cb9f97f9b40e4a364f6c35ebd1362: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:40 engine.py:267] Added request chatcmpl-0e8cb9f97f9b40e4a364f6c35ebd1362.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:43 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 139.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:57:44 logger.py:37] Received request chatcmpl-7ad4de1b2ef04e2991ee5a429485cb7d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the girl want to do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:44 engine.py:267] Added request chatcmpl-7ad4de1b2ef04e2991ee5a429485cb7d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:48 logger.py:37] Received request chatcmpl-5382c6add3e54512b006a498cb432078: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:48 logger.py:37] Received request chatcmpl-0b56d20d36724bbaaaae4af2041d6fce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the butterfly occur in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:48 engine.py:267] Added request chatcmpl-5382c6add3e54512b006a498cb432078.
INFO 12-25 12:57:48 engine.py:267] Added request chatcmpl-0b56d20d36724bbaaaae4af2041d6fce.
INFO 12-25 12:57:48 metrics.py:449] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 118.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:50 logger.py:37] Received request chatcmpl-d1370eeabfc14d57b0fe8a8d55414db5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What might be the age of the girl in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:50 logger.py:37] Received request chatcmpl-d4378628397841689eaa30d465ac355a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many glass discs are there inside the disassembled lens in the video, at minimum?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:50 engine.py:267] Added request chatcmpl-d1370eeabfc14d57b0fe8a8d55414db5.
INFO 12-25 12:57:50 engine.py:267] Added request chatcmpl-d4378628397841689eaa30d465ac355a.
INFO 12-25 12:57:53 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 132.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:55 logger.py:37] Received request chatcmpl-b4449ed578cc4917889eb9fb0a18fb14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the fences on both sides of the room in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:55 engine.py:267] Added request chatcmpl-b4449ed578cc4917889eb9fb0a18fb14.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:57 logger.py:37] Received request chatcmpl-af3b78d6f4994af7918a37766dd1d45b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What action does the monkey do after being rescued?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:57 engine.py:267] Added request chatcmpl-af3b78d6f4994af7918a37766dd1d45b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:57:58 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 118.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:57:58 logger.py:37] Received request chatcmpl-733ae5dbed5b494e967d55b369611767: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the girl perceive her future with regard to decision-making and control?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:58 engine.py:267] Added request chatcmpl-733ae5dbed5b494e967d55b369611767.
INFO 12-25 12:57:59 logger.py:37] Received request chatcmpl-e731fff47b9f4fa2adfdfcbd32d59407: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:57:59 engine.py:267] Added request chatcmpl-e731fff47b9f4fa2adfdfcbd32d59407.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:02 logger.py:37] Received request chatcmpl-a716e966775641e1ba389332d42a273a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following statements is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:02 engine.py:267] Added request chatcmpl-a716e966775641e1ba389332d42a273a.
INFO 12-25 12:58:03 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:58:03 logger.py:37] Received request chatcmpl-c3d0b3f7068a4ec0ac1a19e5242bd5b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal is the character depicted as in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:03 engine.py:267] Added request chatcmpl-c3d0b3f7068a4ec0ac1a19e5242bd5b3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:05 logger.py:37] Received request chatcmpl-fdc59a63aa624c209142bfbf85fb90fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the monkey depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:05 engine.py:267] Added request chatcmpl-fdc59a63aa624c209142bfbf85fb90fd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:08 logger.py:37] Received request chatcmpl-3d8a560d61cd40209446c32c74fd278a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the girl feel in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:08 engine.py:267] Added request chatcmpl-3d8a560d61cd40209446c32c74fd278a.
INFO 12-25 12:58:08 metrics.py:449] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:10 logger.py:37] Received request chatcmpl-b7da6421adcf4ad9972146ebd4324db7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:10 engine.py:267] Added request chatcmpl-b7da6421adcf4ad9972146ebd4324db7.
INFO 12-25 12:58:11 logger.py:37] Received request chatcmpl-1bb1bd799c054d3e8e06d2a62af7cdba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which person placed their leg on the table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:11 engine.py:267] Added request chatcmpl-1bb1bd799c054d3e8e06d2a62af7cdba.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:13 metrics.py:449] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 123.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:58:14 logger.py:37] Received request chatcmpl-f9025629f660424d8ff6c45346da005f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the girl\'s mom want her to do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:14 logger.py:37] Received request chatcmpl-fd009e817e454844b38e6882b853fa65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, which animal is seeking to capture the two ghost cowboys?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:14 engine.py:267] Added request chatcmpl-f9025629f660424d8ff6c45346da005f.
INFO 12-25 12:58:14 engine.py:267] Added request chatcmpl-fd009e817e454844b38e6882b853fa65.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:16 logger.py:37] Received request chatcmpl-b6f9848b388443a9bd9eab3f8d5452e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the number of three-dimensional graphics that can be seen in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:16 engine.py:267] Added request chatcmpl-b6f9848b388443a9bd9eab3f8d5452e5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:18 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:20 logger.py:37] Received request chatcmpl-24e0583157374bebb711c5ff2b5d1d14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following does the girl desire?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:20 logger.py:37] Received request chatcmpl-e5a355098c014d1083e7cad8c1f0b663: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What weapon does the protagonist use in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:20 engine.py:267] Added request chatcmpl-24e0583157374bebb711c5ff2b5d1d14.
INFO 12-25 12:58:20 engine.py:267] Added request chatcmpl-e5a355098c014d1083e7cad8c1f0b663.
INFO 12-25 12:58:20 logger.py:37] Received request chatcmpl-fe246c40dc6247a7904684da0c8e2434: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which object does the creature hold in its hand?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:20 engine.py:267] Added request chatcmpl-fe246c40dc6247a7904684da0c8e2434.
INFO 12-25 12:58:23 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 114.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:24 logger.py:37] Received request chatcmpl-5503a2e7a9c0453c9e172a8d9550fab0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the girl feel in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:24 engine.py:267] Added request chatcmpl-5503a2e7a9c0453c9e172a8d9550fab0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:27 logger.py:37] Received request chatcmpl-e36e8ff4c1c042fdb8ed7c12c7f50d69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal appears in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:27 engine.py:267] Added request chatcmpl-e36e8ff4c1c042fdb8ed7c12c7f50d69.
INFO 12-25 12:58:28 metrics.py:449] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 131.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:30 logger.py:37] Received request chatcmpl-d8ff42173976428abcff5b451a676f49: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What animal saves the monkey in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:30 engine.py:267] Added request chatcmpl-d8ff42173976428abcff5b451a676f49.
INFO 12-25 12:58:31 logger.py:37] Received request chatcmpl-eef25ed4f1c54342837888b2313d3f14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity do the two ghost cowboys enjoy while horse riding as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:31 engine.py:267] Added request chatcmpl-eef25ed4f1c54342837888b2313d3f14.
INFO 12-25 12:58:31 logger.py:37] Received request chatcmpl-efa22b1009fa41fe92d988476069094e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What element is unavailable for the protagonist to use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:31 engine.py:267] Added request chatcmpl-efa22b1009fa41fe92d988476069094e.
INFO 12-25 12:58:33 metrics.py:449] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 128.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:37 logger.py:37] Received request chatcmpl-cc7ad3b6e65a45cab1544e6a98e6b336: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the traffic situation in the city?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:37 engine.py:267] Added request chatcmpl-cc7ad3b6e65a45cab1544e6a98e6b336.
INFO 12-25 12:58:37 logger.py:37] Received request chatcmpl-61b55fe751f4440e8921db1b7e9fdca7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the man in the video angry?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:37 engine.py:267] Added request chatcmpl-61b55fe751f4440e8921db1b7e9fdca7.
INFO 12-25 12:58:37 logger.py:37] Received request chatcmpl-c37941b42fb54d63b71f3b610134d91d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which location is the current whereabouts of the creature?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:37 engine.py:267] Added request chatcmpl-c37941b42fb54d63b71f3b610134d91d.
INFO 12-25 12:58:38 metrics.py:449] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 89.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 12:58:38 logger.py:37] Received request chatcmpl-f8d56acecdfc422faff0f8916e90e314: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two ghost cowboys like to do when they ride horses according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:38 engine.py:267] Added request chatcmpl-f8d56acecdfc422faff0f8916e90e314.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:43 logger.py:37] Received request chatcmpl-fe895320289e40758994c90e81a5650a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two spider-men do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:43 engine.py:267] Added request chatcmpl-fe895320289e40758994c90e81a5650a.
INFO 12-25 12:58:43 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 114.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:58:44 logger.py:37] Received request chatcmpl-5726508ea4734839a0957963a231727e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which type of tree is depicted behind the meditating panda?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:44 logger.py:37] Received request chatcmpl-52797ae7267d4976835eb23e1576072f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are wearing ties in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:44 engine.py:267] Added request chatcmpl-5726508ea4734839a0957963a231727e.
INFO 12-25 12:58:44 engine.py:267] Added request chatcmpl-52797ae7267d4976835eb23e1576072f.
INFO 12-25 12:58:44 logger.py:37] Received request chatcmpl-8b478d4ddac5451eb901efb8353af691: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the right one become at the end?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:44 engine.py:267] Added request chatcmpl-8b478d4ddac5451eb901efb8353af691.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:48 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 134.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:49 logger.py:37] Received request chatcmpl-a5ae5b69331144ce84709795ecbbcc4b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which character also appears in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:49 engine.py:267] Added request chatcmpl-a5ae5b69331144ce84709795ecbbcc4b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:51 logger.py:37] Received request chatcmpl-bf0d2b41a1224bdd83c98e7c38e4f731: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many Spider-Men are visible in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:51 engine.py:267] Added request chatcmpl-bf0d2b41a1224bdd83c98e7c38e4f731.
INFO 12-25 12:58:51 logger.py:37] Received request chatcmpl-a1bd1c0d00394534a0af3b9ec4747e0d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, who is about to get married?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:51 engine.py:267] Added request chatcmpl-a1bd1c0d00394534a0af3b9ec4747e0d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:53 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 110.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 12:58:53 logger.py:37] Received request chatcmpl-d39ca43b654d4bfebcd6035607a1aa9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the two people in the video doing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:53 engine.py:267] Added request chatcmpl-d39ca43b654d4bfebcd6035607a1aa9c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:58 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:58:59 logger.py:37] Received request chatcmpl-1649285e43124304a63ab6ca33f93dcd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, what happens when the black spider-man is blamed by the other spider-man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:59 engine.py:267] Added request chatcmpl-1649285e43124304a63ab6ca33f93dcd.
INFO 12-25 12:58:59 logger.py:37] Received request chatcmpl-73a48f588f9e4046b45aa05fd7060b36: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the panda use to fight with enemies in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:58:59 engine.py:267] Added request chatcmpl-73a48f588f9e4046b45aa05fd7060b36.
INFO 12-25 12:59:00 logger.py:37] Received request chatcmpl-0de6123665e84640bcf794c4d96b673e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following items is in the safe?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:00 engine.py:267] Added request chatcmpl-0de6123665e84640bcf794c4d96b673e.
INFO 12-25 12:59:01 logger.py:37] Received request chatcmpl-29c8d7c711f54460be8f2779d9494663: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man in the video eating?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:01 engine.py:267] Added request chatcmpl-29c8d7c711f54460be8f2779d9494663.
INFO 12-25 12:59:03 metrics.py:449] Avg prompt throughput: 53.4 tokens/s, Avg generation throughput: 99.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:06 logger.py:37] Received request chatcmpl-3ed8758303c24eab8b36d932b09bda00: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the person in the video transfer the phone to another person?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:06 engine.py:267] Added request chatcmpl-3ed8758303c24eab8b36d932b09bda00.
INFO 12-25 12:59:06 logger.py:37] Received request chatcmpl-40adcd4c4b1445588e23fce20e01c527: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who speaks the most in the room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:06 engine.py:267] Added request chatcmpl-40adcd4c4b1445588e23fce20e01c527.
INFO 12-25 12:59:07 logger.py:37] Received request chatcmpl-f6615779272c4e0e8492a17097b40e9e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the man answering the phone in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:07 engine.py:267] Added request chatcmpl-f6615779272c4e0e8492a17097b40e9e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:08 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 100.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 12:59:09 logger.py:37] Received request chatcmpl-03298e628b5e4356bdc26c230d4b41d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the lamp next to the sofa in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:09 engine.py:267] Added request chatcmpl-03298e628b5e4356bdc26c230d4b41d0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:11 logger.py:37] Received request chatcmpl-a0c4b5536bd844e9921a241f29b3d5ef: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item does the man throw into the trash at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:11 engine.py:267] Added request chatcmpl-a0c4b5536bd844e9921a241f29b3d5ef.
INFO 12-25 12:59:12 logger.py:37] Received request chatcmpl-0e868ea0e0694a49910aa196605fb47a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people in the video arguing about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:12 engine.py:267] Added request chatcmpl-0e868ea0e0694a49910aa196605fb47a.
INFO 12-25 12:59:13 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 124.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:15 logger.py:37] Received request chatcmpl-915ce56e5bcf421ea20ed1d69bbb2752: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the weather like when the helicopter takes off?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:15 engine.py:267] Added request chatcmpl-915ce56e5bcf421ea20ed1d69bbb2752.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:18 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 134.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 12:59:19 logger.py:37] Received request chatcmpl-d5e223ed3ebd442d9d75fa3aaec50e75: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main color of the mug in the room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:19 engine.py:267] Added request chatcmpl-d5e223ed3ebd442d9d75fa3aaec50e75.
INFO 12-25 12:59:19 logger.py:37] Received request chatcmpl-78c982cd6fa4402a9b9de752d336115d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the reason for the woman in the video crying?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:19 engine.py:267] Added request chatcmpl-78c982cd6fa4402a9b9de752d336115d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:20 logger.py:37] Received request chatcmpl-2d3bc6ad0e744560a6bace90dbff8959: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the man in the video laugh at the end?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:20 engine.py:267] Added request chatcmpl-2d3bc6ad0e744560a6bace90dbff8959.
INFO 12-25 12:59:21 logger.py:37] Received request chatcmpl-ee2c38369e0b4f7b81e4efd4830b38f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the hair color of the smoking man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:21 engine.py:267] Added request chatcmpl-ee2c38369e0b4f7b81e4efd4830b38f2.
INFO 12-25 12:59:23 metrics.py:449] Avg prompt throughput: 50.6 tokens/s, Avg generation throughput: 100.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:27 logger.py:37] Received request chatcmpl-24d011fda73242229b0268e66c6fd48c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals are present in the room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:27 engine.py:267] Added request chatcmpl-24d011fda73242229b0268e66c6fd48c.
INFO 12-25 12:59:27 logger.py:37] Received request chatcmpl-28cc18cc5e4f4796af54d11218dd98ba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Whar color is the helicopter in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:27 engine.py:267] Added request chatcmpl-28cc18cc5e4f4796af54d11218dd98ba.
INFO 12-25 12:59:28 metrics.py:449] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 86.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 12:59:28 logger.py:37] Received request chatcmpl-42a51de9fd674e87a95690e73a1519bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What number does the person type in at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:28 engine.py:267] Added request chatcmpl-42a51de9fd674e87a95690e73a1519bc.
INFO 12-25 12:59:28 logger.py:37] Received request chatcmpl-383eadf8b3334d7f952f127d6bcc03fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the attitude of the teacher towards the girl\'s appearance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:28 engine.py:267] Added request chatcmpl-383eadf8b3334d7f952f127d6bcc03fb.
INFO 12-25 12:59:33 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 151.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:35 logger.py:37] Received request chatcmpl-0b1185a26f22404d8528cc3d9ba1da54: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many birds can be observed perched on the street lamp in the first half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:35 engine.py:267] Added request chatcmpl-0b1185a26f22404d8528cc3d9ba1da54.
INFO 12-25 12:59:36 logger.py:37] Received request chatcmpl-d8ec91b745cb4371b0c04b5006db922a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following shows up as Iron-Man flies away?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:36 engine.py:267] Added request chatcmpl-d8ec91b745cb4371b0c04b5006db922a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:37 logger.py:37] Received request chatcmpl-51f1b30f55bf48939ab4979ce95b3db0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, what does the woman do to the man next to her?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:37 engine.py:267] Added request chatcmpl-51f1b30f55bf48939ab4979ce95b3db0.
INFO 12-25 12:59:38 logger.py:37] Received request chatcmpl-a41be9bfd4444d718ec0ae57d5d104f0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What object is the man in the gray T-shirt pulling?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:38 engine.py:267] Added request chatcmpl-a41be9bfd4444d718ec0ae57d5d104f0.
INFO 12-25 12:59:38 metrics.py:449] Avg prompt throughput: 54.2 tokens/s, Avg generation throughput: 94.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:42 logger.py:37] Received request chatcmpl-82c91aacb2bc4e08942ceaf468d9041a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens after the helicopter takes off in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:42 engine.py:267] Added request chatcmpl-82c91aacb2bc4e08942ceaf468d9041a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:43 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 138.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 12:59:44 logger.py:37] Received request chatcmpl-b724e9b38ba04fe2a190b9db8acedf71: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What activities do students engage in within the room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:44 engine.py:267] Added request chatcmpl-b724e9b38ba04fe2a190b9db8acedf71.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:45 logger.py:37] Received request chatcmpl-a4ee1b275ceb42539b6f981db39d09f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the second half of the video, the man held up several spheres with both hands. How many spheres did he hold up in total during this time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:45 engine.py:267] Added request chatcmpl-a4ee1b275ceb42539b6f981db39d09f1.
INFO 12-25 12:59:46 logger.py:37] Received request chatcmpl-d24452b67931414f8d5a58922737a937: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man do in the helicopter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:46 engine.py:267] Added request chatcmpl-d24452b67931414f8d5a58922737a937.
INFO 12-25 12:59:48 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 123.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:52 logger.py:37] Received request chatcmpl-4f7eba8012c94c0491891f20ecad1d1f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what is the polar bear mother waiting for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:52 logger.py:37] Received request chatcmpl-fd583024831e4359a12b400841fcd192: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of the video, what is the number of pills displayed on the board being held by an individual?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:52 engine.py:267] Added request chatcmpl-4f7eba8012c94c0491891f20ecad1d1f.
INFO 12-25 12:59:52 logger.py:37] Received request chatcmpl-eacd61de1f7646339b7a863d51aaafa3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man at the table doing while others speak to him?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:52 engine.py:267] Added request chatcmpl-fd583024831e4359a12b400841fcd192.
INFO 12-25 12:59:52 engine.py:267] Added request chatcmpl-eacd61de1f7646339b7a863d51aaafa3.
INFO 12-25 12:59:52 logger.py:37] Received request chatcmpl-1296f94d6e474a6898eb2b1fde3c01ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the attitude of the man who sits at the table when others speak to him?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:52 engine.py:267] Added request chatcmpl-1296f94d6e474a6898eb2b1fde3c01ee.
INFO 12-25 12:59:53 metrics.py:449] Avg prompt throughput: 55.0 tokens/s, Avg generation throughput: 76.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:57 logger.py:37] Received request chatcmpl-1a810b4696964c208d8b043fe05ca6ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of collecting sap from a rubber tree in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:57 engine.py:267] Added request chatcmpl-1a810b4696964c208d8b043fe05ca6ab.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 12:59:58 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 12:59:58 logger.py:37] Received request chatcmpl-f560fd25a4aa415da3c4bab7161f3655: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the protective gloves worn by the person in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:58 engine.py:267] Added request chatcmpl-f560fd25a4aa415da3c4bab7161f3655.
INFO 12-25 12:59:59 logger.py:37] Received request chatcmpl-7a1bf8b8bdc64f5290a1ad85a23411d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following outcomes occurs when the boy with brown hair and no glasses indicates the feather?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:59 engine.py:267] Added request chatcmpl-7a1bf8b8bdc64f5290a1ad85a23411d8.
INFO 12-25 12:59:59 logger.py:37] Received request chatcmpl-6a68aef918714e7d8fdb9cfad559eb07: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many polar bears are visible/seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 12:59:59 engine.py:267] Added request chatcmpl-6a68aef918714e7d8fdb9cfad559eb07.
INFO 12-25 13:00:03 metrics.py:449] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 136.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:06 logger.py:37] Received request chatcmpl-8110fb6721514340a2820ac0a953a70d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the frequency at which a seal needs to surface for air?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:06 engine.py:267] Added request chatcmpl-8110fb6721514340a2820ac0a953a70d.
INFO 12-25 13:00:07 logger.py:37] Received request chatcmpl-5f7eaa154f054f52b8c9c07e72b428f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which disease is the subject of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:07 engine.py:267] Added request chatcmpl-5f7eaa154f054f52b8c9c07e72b428f4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:08 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 122.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:09 logger.py:37] Received request chatcmpl-52707c7deab54dab8f9c437358c4a9f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the information provided in the video, approximately what is the height of these emperor penguin chicks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:09 engine.py:267] Added request chatcmpl-52707c7deab54dab8f9c437358c4a9f9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:11 logger.py:37] Received request chatcmpl-70822cdaf72149b69692aa2e3a9ccb86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which material was used to create the perfect sphere in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:11 engine.py:267] Added request chatcmpl-70822cdaf72149b69692aa2e3a9ccb86.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:13 metrics.py:449] Avg prompt throughput: 27.5 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:14 logger.py:37] Received request chatcmpl-69386ca28be444adb1d982fd53c5545b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the people in the village show in the video used to illuminate the night?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:14 engine.py:267] Added request chatcmpl-69386ca28be444adb1d982fd53c5545b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:16 logger.py:37] Received request chatcmpl-b13871b2c5e94d739976a532eaa5dfc7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the age range of the cat in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:16 logger.py:37] Received request chatcmpl-62d9cf28465040259960b72ffbee2ccf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the estimated age of the sand cats shown in the video according to the scientists?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:16 engine.py:267] Added request chatcmpl-b13871b2c5e94d739976a532eaa5dfc7.
INFO 12-25 13:00:16 engine.py:267] Added request chatcmpl-62d9cf28465040259960b72ffbee2ccf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:18 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:18 logger.py:37] Received request chatcmpl-aace74167a064c5786f24d3530fe485b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the people in the video appear emotionally?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:18 engine.py:267] Added request chatcmpl-aace74167a064c5786f24d3530fe485b.
INFO 12-25 13:00:19 logger.py:37] Received request chatcmpl-3ca92406f3e8446a8d4f5671a33624b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man in a dark shirt and jeans holding in his hand at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:19 engine.py:267] Added request chatcmpl-3ca92406f3e8446a8d4f5671a33624b3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:23 logger.py:37] Received request chatcmpl-76874e2c77ec4fc5be3c65fa70647c86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the animal in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:23 engine.py:267] Added request chatcmpl-76874e2c77ec4fc5be3c65fa70647c86.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:23 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 116.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:24 logger.py:37] Received request chatcmpl-06444a69e64147738b2cc8b6e53ecc70: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which hand did the person in the video wear a glove on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:24 engine.py:267] Added request chatcmpl-06444a69e64147738b2cc8b6e53ecc70.
INFO 12-25 13:00:24 logger.py:37] Received request chatcmpl-0ca2694e6a844860917f3952768bc2be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many streams did the cat cross in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:24 engine.py:267] Added request chatcmpl-0ca2694e6a844860917f3952768bc2be.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:28 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 128.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:28 logger.py:37] Received request chatcmpl-40664411ae4e4f6c93d182b1f5be44c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color pattern of the cat in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:28 engine.py:267] Added request chatcmpl-40664411ae4e4f6c93d182b1f5be44c0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:31 logger.py:37] Received request chatcmpl-1c0fa6e70f724cdc8456b29093962d02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color is the coat worn by the news anchor at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:31 engine.py:267] Added request chatcmpl-1c0fa6e70f724cdc8456b29093962d02.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:32 logger.py:37] Received request chatcmpl-6065664d62e4491d96b35c73ca7ac8f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many sand cats that can be observed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:32 engine.py:267] Added request chatcmpl-6065664d62e4491d96b35c73ca7ac8f5.
INFO 12-25 13:00:33 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:34 logger.py:37] Received request chatcmpl-161f20f21af546e184167a0af3c964a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the total number of bird species that are visible in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:34 engine.py:267] Added request chatcmpl-161f20f21af546e184167a0af3c964a4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:36 logger.py:37] Received request chatcmpl-4adc7601a50e450fb27e355a3f7fd079: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why is this plant called the most dangerous plant in the desert?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:36 engine.py:267] Added request chatcmpl-4adc7601a50e450fb27e355a3f7fd079.
INFO 12-25 13:00:37 logger.py:37] Received request chatcmpl-59070c61910f4d7b8d807025fa308f44: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color is the dress worn by the woman next to Obama in the video clip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:37 engine.py:267] Added request chatcmpl-59070c61910f4d7b8d807025fa308f44.
INFO 12-25 13:00:38 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 125.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:40 logger.py:37] Received request chatcmpl-25ccb698f9cd41bd85571773ce7c6081: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many giant petrels are seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:40 engine.py:267] Added request chatcmpl-25ccb698f9cd41bd85571773ce7c6081.
INFO 12-25 13:00:43 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 147.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:45 logger.py:37] Received request chatcmpl-964238329b88464899c238f50287a798: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, what color is the bowling ball next to the world\'s shortest woman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:45 engine.py:267] Added request chatcmpl-964238329b88464899c238f50287a798.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:46 logger.py:37] Received request chatcmpl-e18743e528e342a1b564d38038a5dffb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following events occurred in India?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:46 engine.py:267] Added request chatcmpl-e18743e528e342a1b564d38038a5dffb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:48 logger.py:37] Received request chatcmpl-b63454f07c164460b901282027632fb8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why is it very difficult to capture footage of sand cats?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:48 engine.py:267] Added request chatcmpl-b63454f07c164460b901282027632fb8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:48 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 118.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:00:49 logger.py:37] Received request chatcmpl-e1345dcac8c84f89ba95c0c57dfff510: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:49 logger.py:37] Received request chatcmpl-9680ec5bd57b4865ae5a0aa08b3c8d60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of clothing is the person wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:49 engine.py:267] Added request chatcmpl-e1345dcac8c84f89ba95c0c57dfff510.
INFO 12-25 13:00:49 engine.py:267] Added request chatcmpl-9680ec5bd57b4865ae5a0aa08b3c8d60.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:53 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 130.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:54 logger.py:37] Received request chatcmpl-cc5480062e1746708441252a511e8bdb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what was the reason for the town\'s evacuation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:54 engine.py:267] Added request chatcmpl-cc5480062e1746708441252a511e8bdb.
INFO 12-25 13:00:55 logger.py:37] Received request chatcmpl-ec2f79197eaa4d2594162b1add3f88e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason for the lamp\'s action in the video, slapping the human portrayed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:55 engine.py:267] Added request chatcmpl-ec2f79197eaa4d2594162b1add3f88e2.
INFO 12-25 13:00:55 logger.py:37] Received request chatcmpl-20557b44a7be422d9a3fdeaf7951232a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what problem does the world\'s shortest woman have?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:55 engine.py:267] Added request chatcmpl-20557b44a7be422d9a3fdeaf7951232a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:58 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 117.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:00:59 logger.py:37] Received request chatcmpl-378c5b7183e0455d9bc98ea4323300c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the approximate temperature shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:00:59 engine.py:267] Added request chatcmpl-378c5b7183e0455d9bc98ea4323300c2.
INFO 12-25 13:01:00 logger.py:37] Received request chatcmpl-19d475b704a14f8da1a8f9b61d8f0483: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was sentenced to have guilt in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:00 engine.py:267] Added request chatcmpl-19d475b704a14f8da1a8f9b61d8f0483.
INFO 12-25 13:01:00 logger.py:37] Received request chatcmpl-1c325a246571410b8c2568f5009a6a9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which license plate is shown on Obama\'s car in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:00 engine.py:267] Added request chatcmpl-1c325a246571410b8c2568f5009a6a9c.
INFO 12-25 13:01:03 metrics.py:449] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 119.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:06 logger.py:37] Received request chatcmpl-46255ddeb88d487fa38002c35d474958: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the information presented in the video, what natural disaster did France experience that was identified as its worst ever?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:06 engine.py:267] Added request chatcmpl-46255ddeb88d487fa38002c35d474958.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:07 logger.py:37] Received request chatcmpl-0157f4dc392d48909153180caffadd07: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided in the video, which of the following locations is where the shooting occurred?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:07 engine.py:267] Added request chatcmpl-0157f4dc392d48909153180caffadd07.
INFO 12-25 13:01:08 metrics.py:449] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 116.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:01:08 logger.py:37] Received request chatcmpl-fe1a39bb587a439685f2ce0b66d67be2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What brand of car does Obama have in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:08 engine.py:267] Added request chatcmpl-fe1a39bb587a439685f2ce0b66d67be2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:10 logger.py:37] Received request chatcmpl-23ec6f5e4cbf465dbb30ab63edc6c06f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements about Thailand\'s agenda on air pollution is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:10 engine.py:267] Added request chatcmpl-23ec6f5e4cbf465dbb30ab63edc6c06f.
INFO 12-25 13:01:11 logger.py:37] Received request chatcmpl-0bfbb8ebecc547839a02b48e21587500: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following options correctly identifies Joe Davis?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:11 engine.py:267] Added request chatcmpl-0bfbb8ebecc547839a02b48e21587500.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:13 metrics.py:449] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 123.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:01:14 logger.py:37] Received request chatcmpl-3d68be787afb4206bcc08e5a15c3285c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many days in the year 2023 were there no recorded incidents of air pollution in Bangkok?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:14 engine.py:267] Added request chatcmpl-3d68be787afb4206bcc08e5a15c3285c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:16 logger.py:37] Received request chatcmpl-d76a3041ea6f42c39e5e3e66f61282a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the interviewed girl appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:16 engine.py:267] Added request chatcmpl-d76a3041ea6f42c39e5e3e66f61282a0.
INFO 12-25 13:01:17 logger.py:37] Received request chatcmpl-1abb28f3f0ba4c749355a28c4b8bdd6c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the cowboy subdue the criminal according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:17 logger.py:37] Received request chatcmpl-112d88c92ebe43c290984c0f6bbd08b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What colour is the news presenter\'s coat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:17 engine.py:267] Added request chatcmpl-1abb28f3f0ba4c749355a28c4b8bdd6c.
INFO 12-25 13:01:17 engine.py:267] Added request chatcmpl-112d88c92ebe43c290984c0f6bbd08b9.
INFO 12-25 13:01:18 metrics.py:449] Avg prompt throughput: 53.7 tokens/s, Avg generation throughput: 97.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:21 logger.py:37] Received request chatcmpl-d8ba039a2c254cb9a4da1de8214033d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the primary demand of farmers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:21 engine.py:267] Added request chatcmpl-d8ba039a2c254cb9a4da1de8214033d7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:23 logger.py:37] Received request chatcmpl-e3475e35fedf4d53936b83c814a2e82a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is on the legend when he is hit by the turret?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:23 engine.py:267] Added request chatcmpl-e3475e35fedf4d53936b83c814a2e82a.
INFO 12-25 13:01:23 metrics.py:449] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 131.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:26 logger.py:37] Received request chatcmpl-2eeb39d6404743f6b7bee1fd4bcc2c57: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the atmosphere portrayed in the video like?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:26 engine.py:267] Added request chatcmpl-2eeb39d6404743f6b7bee1fd4bcc2c57.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:27 logger.py:37] Received request chatcmpl-f603f5cc88ab45ee9e5ef0c2b10fe680: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what was the overall mood of the people interviewed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:27 engine.py:267] Added request chatcmpl-f603f5cc88ab45ee9e5ef0c2b10fe680.
INFO 12-25 13:01:28 logger.py:37] Received request chatcmpl-b0ba5e3e4de2459787953623309f40af: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many residents have been evacuated from the town?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:28 engine.py:267] Added request chatcmpl-b0ba5e3e4de2459787953623309f40af.
INFO 12-25 13:01:28 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 114.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:32 logger.py:37] Received request chatcmpl-d826fc190cd1417d96d98e10df15caa1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which legend is knocked down in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:32 engine.py:267] Added request chatcmpl-d826fc190cd1417d96d98e10df15caa1.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:33 logger.py:37] Received request chatcmpl-9322606d1c294f5993cc5526603c540c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the mood of the people interviewed in the video who experienced the blizzard?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:33 engine.py:267] Added request chatcmpl-9322606d1c294f5993cc5526603c540c.
INFO 12-25 13:01:33 metrics.py:449] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 118.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:01:34 logger.py:37] Received request chatcmpl-da15d885ace54eb48090e688f0716ffa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason for entering cold water in the video during the winter season?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:34 logger.py:37] Received request chatcmpl-466c05c2ed9345608e246ea4bae9b87c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothes were the boys being interviewed wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:34 engine.py:267] Added request chatcmpl-da15d885ace54eb48090e688f0716ffa.
INFO 12-25 13:01:34 engine.py:267] Added request chatcmpl-466c05c2ed9345608e246ea4bae9b87c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:38 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 135.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:39 logger.py:37] Received request chatcmpl-ec1ac32f71c445c6bc4f273ddf202bf4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color is the news anchor\'s top at the start of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:39 engine.py:267] Added request chatcmpl-ec1ac32f71c445c6bc4f273ddf202bf4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:40 logger.py:37] Received request chatcmpl-b992d5862f694dc3ac25ff6d05974ec3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened in the mountains captured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:40 engine.py:267] Added request chatcmpl-b992d5862f694dc3ac25ff6d05974ec3.
INFO 12-25 13:01:41 logger.py:37] Received request chatcmpl-6d6e60d727724943b12a703fe410d3eb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of weapon does the slain legend retrieve?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:41 engine.py:267] Added request chatcmpl-6d6e60d727724943b12a703fe410d3eb.
INFO 12-25 13:01:42 logger.py:37] Received request chatcmpl-6b1f1a56c40d4881a73d949a05d46637: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the reason why the interviewed man frequently observes snow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:42 engine.py:267] Added request chatcmpl-6b1f1a56c40d4881a73d949a05d46637.
INFO 12-25 13:01:43 metrics.py:449] Avg prompt throughput: 51.8 tokens/s, Avg generation throughput: 106.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:47 logger.py:37] Received request chatcmpl-9ea5262ea1384be9b63d134757265897: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why is this fossil discovery special?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:47 engine.py:267] Added request chatcmpl-9ea5262ea1384be9b63d134757265897.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:48 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 105.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:01:48 logger.py:37] Received request chatcmpl-a671a159924643ae8b1df7b1166bd8ba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, where were the ichthyosaur fossils found this time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:48 engine.py:267] Added request chatcmpl-a671a159924643ae8b1df7b1166bd8ba.
INFO 12-25 13:01:49 logger.py:37] Received request chatcmpl-e4296dbf4996475a920f41179cdace3c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the information presented in the video, what was the exact number of individuals present in the store at the time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:49 engine.py:267] Added request chatcmpl-e4296dbf4996475a920f41179cdace3c.
INFO 12-25 13:01:50 logger.py:37] Received request chatcmpl-8184afcd4ca34ae28f38bdc8940a52e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many persons are shot to death by the player before he is dead?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:50 engine.py:267] Added request chatcmpl-8184afcd4ca34ae28f38bdc8940a52e9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:53 metrics.py:449] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 126.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:01:54 logger.py:37] Received request chatcmpl-01621abc59294dd19eeb00295061b5a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what happened in the supermarket?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:54 engine.py:267] Added request chatcmpl-01621abc59294dd19eeb00295061b5a7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:01:56 logger.py:37] Received request chatcmpl-e32f3db1a4c54dcbb0add53d2c28a9ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, who will benefit from the change buffs of armors?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:56 logger.py:37] Received request chatcmpl-ae232b4e0eda44d3abe4f6b686779f54: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the player see upon exiting the building?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:56 engine.py:267] Added request chatcmpl-e32f3db1a4c54dcbb0add53d2c28a9ad.
INFO 12-25 13:01:56 engine.py:267] Added request chatcmpl-ae232b4e0eda44d3abe4f6b686779f54.
INFO 12-25 13:01:57 logger.py:37] Received request chatcmpl-33970ba70a624a9c8ece91596fd80d81: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What profession is the legend in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:01:57 engine.py:267] Added request chatcmpl-33970ba70a624a9c8ece91596fd80d81.
INFO 12-25 13:01:58 metrics.py:449] Avg prompt throughput: 50.7 tokens/s, Avg generation throughput: 96.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:01 logger.py:37] Received request chatcmpl-d9c1541f3793494ca1d4801a5ef9d169: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the armor that first be described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:01 engine.py:267] Added request chatcmpl-d9c1541f3793494ca1d4801a5ef9d169.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:02 logger.py:37] Received request chatcmpl-30569c77c0b14646b2fd612201eef018: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events occur when the player presses R?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:02 engine.py:267] Added request chatcmpl-30569c77c0b14646b2fd612201eef018.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:03 logger.py:37] Received request chatcmpl-22e991ec8d8a427faecc5d2238b31b5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cars are overtaken in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:03 engine.py:267] Added request chatcmpl-22e991ec8d8a427faecc5d2238b31b5e.
INFO 12-25 13:02:03 metrics.py:449] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:02:04 logger.py:37] Received request chatcmpl-bb7999a28c664c559291a6160bf4aba4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is thrown out when pressing Q on the keyboard?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:04 engine.py:267] Added request chatcmpl-bb7999a28c664c559291a6160bf4aba4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:07 logger.py:37] Received request chatcmpl-27fe49d0cddc48a5a0575f3f8eb7b13a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many legends are featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:07 engine.py:267] Added request chatcmpl-27fe49d0cddc48a5a0575f3f8eb7b13a.
INFO 12-25 13:02:08 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:11 logger.py:37] Received request chatcmpl-38e0fa741e154c97884323a9a1f74137: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the legend, when the character with a fox tail goes left, what is her intention or goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:11 engine.py:267] Added request chatcmpl-38e0fa741e154c97884323a9a1f74137.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:12 logger.py:37] Received request chatcmpl-92c903746d61456f91d2d69ccc872d11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which location serves as the battleground in the fight?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:12 engine.py:267] Added request chatcmpl-92c903746d61456f91d2d69ccc872d11.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:13 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 139.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:14 logger.py:37] Received request chatcmpl-7d5c6792bd7843668881ec96e882060d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the car in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:14 engine.py:267] Added request chatcmpl-7d5c6792bd7843668881ec96e882060d.
INFO 12-25 13:02:15 logger.py:37] Received request chatcmpl-b5bb0640897b4375af2de9c7083c1bd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill is used by the legend who slays the enemy?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:15 engine.py:267] Added request chatcmpl-b5bb0640897b4375af2de9c7083c1bd8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:17 logger.py:37] Received request chatcmpl-24724bbcb03d479097f7043ca9ad76be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color is the pistol used by the player?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:17 engine.py:267] Added request chatcmpl-24724bbcb03d479097f7043ca9ad76be.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:18 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 116.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:19 logger.py:37] Received request chatcmpl-6a90bf6d4a0c4d9a86ca662d55738f55: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is on the wall that the player shoot at?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:19 engine.py:267] Added request chatcmpl-6a90bf6d4a0c4d9a86ca662d55738f55.
INFO 12-25 13:02:21 logger.py:37] Received request chatcmpl-f68f96e0cc54409ca74d6f3f3e9dea40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:21 engine.py:267] Added request chatcmpl-f68f96e0cc54409ca74d6f3f3e9dea40.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:23 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:25 logger.py:37] Received request chatcmpl-ce739041dffe4495b1eb16259b810c99: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player is running the pick-and-roll for the other players?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:25 logger.py:37] Received request chatcmpl-d0fac42ee56e43dcad789370d7c5d798: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are his gloves in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:25 engine.py:267] Added request chatcmpl-ce739041dffe4495b1eb16259b810c99.
INFO 12-25 13:02:25 engine.py:267] Added request chatcmpl-d0fac42ee56e43dcad789370d7c5d798.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:28 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 114.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:02:29 logger.py:37] Received request chatcmpl-7a4240432a474ad4a6e962c16d0b6b0a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the player finally dead?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:29 engine.py:267] Added request chatcmpl-7a4240432a474ad4a6e962c16d0b6b0a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:32 logger.py:37] Received request chatcmpl-0772e888dee845a8bd3e24a118b67798: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when the player approaches the window first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:32 engine.py:267] Added request chatcmpl-0772e888dee845a8bd3e24a118b67798.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:33 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:02:34 logger.py:37] Received request chatcmpl-ac330dbda9b044c2a1656ece187ccc5a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the player that ends the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:34 engine.py:267] Added request chatcmpl-ac330dbda9b044c2a1656ece187ccc5a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:35 logger.py:37] Received request chatcmpl-33e2548a35874ceda0935fa9087c7c23: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many shots does the player take in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:35 engine.py:267] Added request chatcmpl-33e2548a35874ceda0935fa9087c7c23.
INFO 12-25 13:02:36 logger.py:37] Received request chatcmpl-2d2c3314e9704a90be23bdb6c03884a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the location of the scene being depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:36 engine.py:267] Added request chatcmpl-2d2c3314e9704a90be23bdb6c03884a1.
INFO 12-25 13:02:38 metrics.py:449] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 127.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:41 logger.py:37] Received request chatcmpl-cdff03efeddc4f2795eb18042708024f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many craches occurs in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:41 logger.py:37] Received request chatcmpl-1389529d8740451b8cc6878f110094ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the first player in the video to take a shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:41 engine.py:267] Added request chatcmpl-cdff03efeddc4f2795eb18042708024f.
INFO 12-25 13:02:41 engine.py:267] Added request chatcmpl-1389529d8740451b8cc6878f110094ff.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:43 metrics.py:449] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 118.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:02:45 logger.py:37] Received request chatcmpl-c51a8702bce54d178ac056f5612a041b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the main color of the racetrack?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:45 logger.py:37] Received request chatcmpl-352badb20076432a9b29c3521ca1df89: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What the weather is like when the race begins?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:45 engine.py:267] Added request chatcmpl-c51a8702bce54d178ac056f5612a041b.
INFO 12-25 13:02:45 engine.py:267] Added request chatcmpl-352badb20076432a9b29c3521ca1df89.
INFO 12-25 13:02:48 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:50 logger.py:37] Received request chatcmpl-d2d298bf03a44f289319deddb2bdd1a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what happens to the car when it is running?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:50 engine.py:267] Added request chatcmpl-d2d298bf03a44f289319deddb2bdd1a8.
INFO 12-25 13:02:52 logger.py:37] Received request chatcmpl-f7bf9b8cdeea4c989ba89538de1c90fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options explains why the man is screaming at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:52 logger.py:37] Received request chatcmpl-384bf5c0222e4e4fb33846a3e495a17c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what happens to the car when it is running?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:52 logger.py:37] Received request chatcmpl-f02860643c6e4331bf6ce52a58e15671: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the pattern on the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:52 engine.py:267] Added request chatcmpl-f7bf9b8cdeea4c989ba89538de1c90fa.
INFO 12-25 13:02:52 engine.py:267] Added request chatcmpl-384bf5c0222e4e4fb33846a3e495a17c.
INFO 12-25 13:02:52 engine.py:267] Added request chatcmpl-f02860643c6e4331bf6ce52a58e15671.
INFO 12-25 13:02:53 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 93.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:57 logger.py:37] Received request chatcmpl-ee12d3b20d6f4df2970f3d51ece0756a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the remaining time in seconds when the player in the video takes a free throw during the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:57 engine.py:267] Added request chatcmpl-ee12d3b20d6f4df2970f3d51ece0756a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:58 logger.py:37] Received request chatcmpl-1ec2d869de4a48d0af7d6a4f5304266d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player does the video call for to finally put the ball in the basket?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:58 engine.py:267] Added request chatcmpl-1ec2d869de4a48d0af7d6a4f5304266d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:02:58 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 115.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:02:59 logger.py:37] Received request chatcmpl-248d27afc1ba4f3fbe58f98ffea57149: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:02:59 engine.py:267] Added request chatcmpl-248d27afc1ba4f3fbe58f98ffea57149.
INFO 12-25 13:03:00 logger.py:37] Received request chatcmpl-d0653db44214410187e5fa7a187a9806: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sport\'s tactics are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:00 engine.py:267] Added request chatcmpl-d0653db44214410187e5fa7a187a9806.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:03 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 129.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:04 logger.py:37] Received request chatcmpl-04dc4f96bf624b45b9de05ce48f3ee85: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player finished the dunk?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:04 engine.py:267] Added request chatcmpl-04dc4f96bf624b45b9de05ce48f3ee85.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:07 logger.py:37] Received request chatcmpl-0f9aac89645c4d2cba185d6b93a24455: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player in the video dunks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:07 engine.py:267] Added request chatcmpl-0f9aac89645c4d2cba185d6b93a24455.
INFO 12-25 13:03:08 logger.py:37] Received request chatcmpl-5b712777245443bebd56afdde355f447: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people in the video cheering for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:08 logger.py:37] Received request chatcmpl-8a64db63524940d7b7df9a7dc85f2a78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What team currently has the lead in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:08 engine.py:267] Added request chatcmpl-5b712777245443bebd56afdde355f447.
INFO 12-25 13:03:08 engine.py:267] Added request chatcmpl-8a64db63524940d7b7df9a7dc85f2a78.
INFO 12-25 13:03:08 metrics.py:449] Avg prompt throughput: 48.3 tokens/s, Avg generation throughput: 103.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:14 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:14 logger.py:37] Received request chatcmpl-f2ac303a8e40489c9d888dce594db712: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player in the video scores first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:14 logger.py:37] Received request chatcmpl-13e0701c87c7410d80f82e7980685698: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following describes the unique aspect of this basketball game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:14 engine.py:267] Added request chatcmpl-f2ac303a8e40489c9d888dce594db712.
INFO 12-25 13:03:14 engine.py:267] Added request chatcmpl-13e0701c87c7410d80f82e7980685698.
INFO 12-25 13:03:15 logger.py:37] Received request chatcmpl-fc0a5288491d4ed986edbad44394eec1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which type of basketball game is being played in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:15 engine.py:267] Added request chatcmpl-fc0a5288491d4ed986edbad44394eec1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:17 logger.py:37] Received request chatcmpl-4b8f7f0affc9406aa8f8f6a825ada384: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which country does the player who takes the last shot in the video hail?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:17 engine.py:267] Added request chatcmpl-4b8f7f0affc9406aa8f8f6a825ada384.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:19 metrics.py:449] Avg prompt throughput: 51.2 tokens/s, Avg generation throughput: 111.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:20 logger.py:37] Received request chatcmpl-499fdef56d8b40c8b4e0b4eabaa16a13: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport is being played in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:20 logger.py:37] Received request chatcmpl-920142448c05415b832b3c12ed8b5831: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who dunks in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:20 engine.py:267] Added request chatcmpl-499fdef56d8b40c8b4e0b4eabaa16a13.
INFO 12-25 13:03:20 engine.py:267] Added request chatcmpl-920142448c05415b832b3c12ed8b5831.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:23 logger.py:37] Received request chatcmpl-1bf258ff54f3473eaa0f4d9df9dfd044: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes why the man appeared upset in the middle of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:23 engine.py:267] Added request chatcmpl-1bf258ff54f3473eaa0f4d9df9dfd044.
INFO 12-25 13:03:24 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 115.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:28 logger.py:37] Received request chatcmpl-03bffaf0637f4c2ba5e3aae7391b106a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the rabbit do while the man is flying up to dunk?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:28 engine.py:267] Added request chatcmpl-03bffaf0637f4c2ba5e3aae7391b106a.
INFO 12-25 13:03:29 metrics.py:449] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:30 logger.py:37] Received request chatcmpl-9d6d817604394116836d88099716bcfa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times did the No. 7 in red score in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:30 logger.py:37] Received request chatcmpl-988384026a3d4fb994fa7205fe5273e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:30 logger.py:37] Received request chatcmpl-6c58a3989fd644e9a01573096cfd411e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many challengers does the protagonist in the video take on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:30 engine.py:267] Added request chatcmpl-9d6d817604394116836d88099716bcfa.
INFO 12-25 13:03:30 engine.py:267] Added request chatcmpl-988384026a3d4fb994fa7205fe5273e0.
INFO 12-25 13:03:30 engine.py:267] Added request chatcmpl-6c58a3989fd644e9a01573096cfd411e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:34 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 120.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:34 logger.py:37] Received request chatcmpl-23c3320231d94148a9fec2616dc756c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the total number of people guarding basketball players in orange shoes in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:34 engine.py:267] Added request chatcmpl-23c3320231d94148a9fec2616dc756c9.
INFO 12-25 13:03:35 logger.py:37] Received request chatcmpl-8a4536af9ebe469b9dae0d303e3e58c4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which basketball rule is featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:35 engine.py:267] Added request chatcmpl-8a4536af9ebe469b9dae0d303e3e58c4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:38 logger.py:37] Received request chatcmpl-57bd37e005cd4d1a9b418e5484b8a7c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what\'s the last name of the white team wearing number 13?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:38 engine.py:267] Added request chatcmpl-57bd37e005cd4d1a9b418e5484b8a7c1.
INFO 12-25 13:03:39 metrics.py:449] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 113.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:39 logger.py:37] Received request chatcmpl-925f1b1298fd480c9130b2c15bb18c0b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why was the athlete in the video called for a traveling violation despite not being a foul?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:39 engine.py:267] Added request chatcmpl-925f1b1298fd480c9130b2c15bb18c0b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:42 logger.py:37] Received request chatcmpl-3f7d41dd5c1b4737bd01273b6eeab25d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main theme of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:42 engine.py:267] Added request chatcmpl-3f7d41dd5c1b4737bd01273b6eeab25d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:44 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 143.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:45 logger.py:37] Received request chatcmpl-3ca0be332c29440dacda24b21e36f514: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What story does the video tell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:45 engine.py:267] Added request chatcmpl-3ca0be332c29440dacda24b21e36f514.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:46 logger.py:37] Received request chatcmpl-34aadbde12a34e2980eadd30161bf962: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred from the video about the location of the FIFA World Cup 2026 Final?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:46 engine.py:267] Added request chatcmpl-34aadbde12a34e2980eadd30161bf962.
INFO 12-25 13:03:47 logger.py:37] Received request chatcmpl-ec5710c8e5aa4fff9a47678d35ffd112: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which person in the video is shown to shoot the ball the highest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:47 logger.py:37] Received request chatcmpl-85925a533b814cab93f693bc00de484b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players are in the beach volleyball game shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:47 engine.py:267] Added request chatcmpl-ec5710c8e5aa4fff9a47678d35ffd112.
INFO 12-25 13:03:47 engine.py:267] Added request chatcmpl-85925a533b814cab93f693bc00de484b.
INFO 12-25 13:03:49 metrics.py:449] Avg prompt throughput: 52.7 tokens/s, Avg generation throughput: 94.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:51 logger.py:37] Received request chatcmpl-b5be7b2540934e9692b916fe1d83bf92: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color of the T-shirt worn by the boy in black skin, who appears at the beginning and end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:51 engine.py:267] Added request chatcmpl-b5be7b2540934e9692b916fe1d83bf92.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:54 metrics.py:449] Avg prompt throughput: 15.4 tokens/s, Avg generation throughput: 126.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:03:55 logger.py:37] Received request chatcmpl-4edab2560e92471f9f0d7c148484444a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the players celebrate scoring the first goal in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:55 logger.py:37] Received request chatcmpl-87bf353c8a7246ed982a19b5a970052b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What event is this video most likely associated with?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:55 engine.py:267] Added request chatcmpl-4edab2560e92471f9f0d7c148484444a.
INFO 12-25 13:03:55 engine.py:267] Added request chatcmpl-87bf353c8a7246ed982a19b5a970052b.
INFO 12-25 13:03:55 logger.py:37] Received request chatcmpl-d2436502ef434159939fde4873694c94: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What technical moves do the players perform in the third clip in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:03:55 engine.py:267] Added request chatcmpl-d2436502ef434159939fde4873694c94.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:03:59 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:00 logger.py:37] Received request chatcmpl-0edf55ec4e01480bb99e23924c4d157e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first goal, which player passed the ball to number 7 in red?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:00 engine.py:267] Added request chatcmpl-0edf55ec4e01480bb99e23924c4d157e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:02 logger.py:37] Received request chatcmpl-eb267ebb4eeb49f38a1bac12e9009fd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which one of the following jersey sizes does the man wear when he enters the NBA at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:02 logger.py:37] Received request chatcmpl-8c3ec2d88ebc4ed2ae081fa2a669b94c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the name of player 18?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:02 engine.py:267] Added request chatcmpl-eb267ebb4eeb49f38a1bac12e9009fd8.
INFO 12-25 13:04:02 engine.py:267] Added request chatcmpl-8c3ec2d88ebc4ed2ae081fa2a669b94c.
INFO 12-25 13:04:03 logger.py:37] Received request chatcmpl-29ef095b54de49cb9d77e7e24eca3d59: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player in the video ends the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:03 engine.py:267] Added request chatcmpl-29ef095b54de49cb9d77e7e24eca3d59.
INFO 12-25 13:04:04 metrics.py:449] Avg prompt throughput: 53.9 tokens/s, Avg generation throughput: 91.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 153.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:10 logger.py:37] Received request chatcmpl-fcff26faf44a4813824ce62cf942d291: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of the video, what is the man standing next to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:10 engine.py:267] Added request chatcmpl-fcff26faf44a4813824ce62cf942d291.
INFO 12-25 13:04:10 logger.py:37] Received request chatcmpl-0ab8807c96ec4231a1a5163d4432ece9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which location is most likely to host the FIFA World Cup based on the given landmark and promotional event in. this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:10 engine.py:267] Added request chatcmpl-0ab8807c96ec4231a1a5163d4432ece9.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:10 logger.py:37] Received request chatcmpl-bb2b70deb52543babef60e5db7bb64a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team does the player, seen wearing the number 10 shirt and scoring multiple goals in the video, belong to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:10 engine.py:267] Added request chatcmpl-bb2b70deb52543babef60e5db7bb64a1.
INFO 12-25 13:04:11 logger.py:37] Received request chatcmpl-c34e573fa88848c894d5c4e302fe2c9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Judging by the score and time, what can be inferred about Qatar\'s performance in this match so far?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:11 engine.py:267] Added request chatcmpl-c34e573fa88848c894d5c4e302fe2c9a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:14 metrics.py:449] Avg prompt throughput: 58.8 tokens/s, Avg generation throughput: 111.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:04:15 logger.py:37] Received request chatcmpl-14f0d961f7bc47d98512b82cfae44fb6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player\'s goal highlights video is being shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:15 engine.py:267] Added request chatcmpl-14f0d961f7bc47d98512b82cfae44fb6.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:19 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 140.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:04:19 logger.py:37] Received request chatcmpl-16e38d77b3e94ab0828000ce62f5610b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Referring to ths video, which company sponsored the competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:19 engine.py:267] Added request chatcmpl-16e38d77b3e94ab0828000ce62f5610b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:22 logger.py:37] Received request chatcmpl-62afe9d177d84aa9a2524b81352bff62: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country did Portugal score against in the last goal of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:22 logger.py:37] Received request chatcmpl-fafefd5ca73446c8b3d8a67b2072417d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score following the goal being scored?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:22 engine.py:267] Added request chatcmpl-62afe9d177d84aa9a2524b81352bff62.
INFO 12-25 13:04:22 engine.py:267] Added request chatcmpl-fafefd5ca73446c8b3d8a67b2072417d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:24 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 111.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:04:24 logger.py:37] Received request chatcmpl-dcb851e594a642649b11b5be9baa839b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the two main colors of the Portuguese team uniforms featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:24 engine.py:267] Added request chatcmpl-dcb851e594a642649b11b5be9baa839b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:27 logger.py:37] Received request chatcmpl-fd9de6a40d6041bdb9b255d6da70adca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many goals can be seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:27 engine.py:267] Added request chatcmpl-fd9de6a40d6041bdb9b255d6da70adca.
INFO 12-25 13:04:27 logger.py:37] Received request chatcmpl-0adf69ffdc174a9b85d73244fcf3af52: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options best describes the scene in the background behind the man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:28 engine.py:267] Added request chatcmpl-0adf69ffdc174a9b85d73244fcf3af52.
INFO 12-25 13:04:29 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 98.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:04:29 logger.py:37] Received request chatcmpl-59b5fffe43764e1585dcb34c2a1076eb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score of the football match at the time 78:32?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:29 logger.py:37] Received request chatcmpl-01a663b5e3d94aeeaefa6334df04ffd1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who ultimately won the high jump competition in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:29 engine.py:267] Added request chatcmpl-59b5fffe43764e1585dcb34c2a1076eb.
INFO 12-25 13:04:29 engine.py:267] Added request chatcmpl-01a663b5e3d94aeeaefa6334df04ffd1.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:33 logger.py:37] Received request chatcmpl-413e2d371f0b43bfbe7bb1152c4482f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many Mbappe\'s spectacular goals does the video show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:33 engine.py:267] Added request chatcmpl-413e2d371f0b43bfbe7bb1152c4482f9.
INFO 12-25 13:04:34 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 127.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:04:35 logger.py:37] Received request chatcmpl-81ccb3c4d6a74e519cb332993eab185b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which company\'s advertisement did not appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:35 engine.py:267] Added request chatcmpl-81ccb3c4d6a74e519cb332993eab185b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:36 logger.py:37] Received request chatcmpl-279f5a93886a4d1d872c376f3eacdbda: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following players serves from the backcourt?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:36 engine.py:267] Added request chatcmpl-279f5a93886a4d1d872c376f3eacdbda.
INFO 12-25 13:04:37 logger.py:37] Received request chatcmpl-19a43b3b82db4a3097c338cb9f704070: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team is the player most likely representing based on the indication of his jersey in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:37 engine.py:267] Added request chatcmpl-19a43b3b82db4a3097c338cb9f704070.
INFO 12-25 13:04:39 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:41 logger.py:37] Received request chatcmpl-6d2639369ad445f7bc950c656cd9fa9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who could be the man in the white shirt clapping in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:41 engine.py:267] Added request chatcmpl-6d2639369ad445f7bc950c656cd9fa9a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:42 logger.py:37] Received request chatcmpl-fcc45b4991bf44ca94c7329f5730c23b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player is substituted with player 19?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:42 engine.py:267] Added request chatcmpl-fcc45b4991bf44ca94c7329f5730c23b.
INFO 12-25 13:04:43 logger.py:37] Received request chatcmpl-16e42a0130d64b71b0f4fe3ad56d3be5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many groups of athletes\' competitions are recorded in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:43 engine.py:267] Added request chatcmpl-16e42a0130d64b71b0f4fe3ad56d3be5.
INFO 12-25 13:04:44 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 119.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:47 logger.py:37] Received request chatcmpl-62fb4d8feb1a4eb7948d4adbd790693d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team scored in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:47 engine.py:267] Added request chatcmpl-62fb4d8feb1a4eb7948d4adbd790693d.
INFO 12-25 13:04:49 metrics.py:449] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 142.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:51 logger.py:37] Received request chatcmpl-24928c0272f9406d9eedcf3a52f2535e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player delivers the pass to number 9 to score the goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:51 engine.py:267] Added request chatcmpl-24928c0272f9406d9eedcf3a52f2535e.
INFO 12-25 13:04:52 logger.py:37] Received request chatcmpl-66f66b32bdb74dddb7bceb64b59be510: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the competition in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:52 engine.py:267] Added request chatcmpl-66f66b32bdb74dddb7bceb64b59be510.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:54 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:56 logger.py:37] Received request chatcmpl-551325737a2f4166bd1ac1ebe5a3ee1f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country\'s athlete\'s high jump process is documented in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:56 engine.py:267] Added request chatcmpl-551325737a2f4166bd1ac1ebe5a3ee1f.
INFO 12-25 13:04:56 logger.py:37] Received request chatcmpl-a785ffe0f2304dcf8cd83fb2bdc579bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes are competing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:04:56 engine.py:267] Added request chatcmpl-a785ffe0f2304dcf8cd83fb2bdc579bc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:04:59 metrics.py:449] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 110.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:00 logger.py:37] Received request chatcmpl-5ed6d772e34e4780b7ac44534e52bb0e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What emotion is represented by the number 9 in blue after scoring a goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:00 engine.py:267] Added request chatcmpl-5ed6d772e34e4780b7ac44534e52bb0e.
INFO 12-25 13:05:00 logger.py:37] Received request chatcmpl-cad1234b2b6d47f6b63d0f11bda506da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes are competing on the track in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:00 engine.py:267] Added request chatcmpl-cad1234b2b6d47f6b63d0f11bda506da.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:04 metrics.py:449] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 135.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:04 logger.py:37] Received request chatcmpl-da505c55ef0744d1a99fd44bb5afbefd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the competition event currently taking place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:04 engine.py:267] Added request chatcmpl-da505c55ef0744d1a99fd44bb5afbefd.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:08 logger.py:37] Received request chatcmpl-5162b7caab1a490ca8dec3681567b31b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What swimming stroke does the athlete in the video use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:08 logger.py:37] Received request chatcmpl-ee4a2cc28c9c4483bc16a8dc06f61bd9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes are doing high jumps in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:08 engine.py:267] Added request chatcmpl-5162b7caab1a490ca8dec3681567b31b.
INFO 12-25 13:05:08 engine.py:267] Added request chatcmpl-ee4a2cc28c9c4483bc16a8dc06f61bd9.
INFO 12-25 13:05:09 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 111.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:09 logger.py:37] Received request chatcmpl-0cd4f2aad75a41b39920146917e33897: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Assuming groups are numbered in chronological order of appearance in the video, with the first group being the one that appears first in the video. To which group does the athlete who fell in the video belong?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:09 engine.py:267] Added request chatcmpl-0cd4f2aad75a41b39920146917e33897.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:12 logger.py:37] Received request chatcmpl-c85757f17e5041488c36fd4585a81142: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the competition event currently taking place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:12 engine.py:267] Added request chatcmpl-c85757f17e5041488c36fd4585a81142.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:14 metrics.py:449] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 144.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:16 logger.py:37] Received request chatcmpl-5ab00e10003441d096c5088f742932ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes\' long jumps are recorded in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:16 logger.py:37] Received request chatcmpl-7ecef7d60e5543a1be52476b3b82da79: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the competition event taking place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:16 engine.py:267] Added request chatcmpl-5ab00e10003441d096c5088f742932ff.
INFO 12-25 13:05:16 engine.py:267] Added request chatcmpl-7ecef7d60e5543a1be52476b3b82da79.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:18 logger.py:37] Received request chatcmpl-f2b6a82788834f46830b1a9879b194c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the athlete who won the second place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:19 engine.py:267] Added request chatcmpl-f2b6a82788834f46830b1a9879b194c0.
INFO 12-25 13:05:19 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 110.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:20 logger.py:37] Received request chatcmpl-22ee00a6d008470fa8ca84307057c15e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times do the athletes in the event shown in the video need to touch the pool wall?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:20 engine.py:267] Added request chatcmpl-22ee00a6d008470fa8ca84307057c15e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:22 logger.py:37] Received request chatcmpl-b08172319b4644f29c976f6c73294375: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which country does the first-place athlete in the video originate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:22 engine.py:267] Added request chatcmpl-b08172319b4644f29c976f6c73294375.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:24 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:24 logger.py:37] Received request chatcmpl-007b10b138194391817d20280759a529: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the shortest time to reach the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:24 engine.py:267] Added request chatcmpl-007b10b138194391817d20280759a529.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:26 logger.py:37] Received request chatcmpl-a1b9b927595a41b1b261e5d46f1cfbd9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where and when was the diving scene in the video taken?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:26 engine.py:267] Added request chatcmpl-a1b9b927595a41b1b261e5d46f1cfbd9.
INFO 12-25 13:05:27 logger.py:37] Received request chatcmpl-016a5696264a4971a3d8a6fac5dda7e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes in the video achieved a high jump distance of over 9 meters?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:27 engine.py:267] Added request chatcmpl-016a5696264a4971a3d8a6fac5dda7e5.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:29 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 117.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:29 logger.py:37] Received request chatcmpl-0aceace5c13f4b16a1da112007c91d65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What swimming stroke does the athlete in the video use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:29 engine.py:267] Added request chatcmpl-0aceace5c13f4b16a1da112007c91d65.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:32 logger.py:37] Received request chatcmpl-65e61b6acdfa460da90082bda1bd80a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was the first athlete to reach the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:32 engine.py:267] Added request chatcmpl-65e61b6acdfa460da90082bda1bd80a1.
INFO 12-25 13:05:34 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 145.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:35 logger.py:37] Received request chatcmpl-d2043da2be07411eb93c3c28c3bfe44e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was the first athlete to reach the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:35 engine.py:267] Added request chatcmpl-d2043da2be07411eb93c3c28c3bfe44e.
INFO 12-25 13:05:36 logger.py:37] Received request chatcmpl-6c6dc8eabb2c4895a0c3d42e43b9a3c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the competition event taking place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:36 engine.py:267] Added request chatcmpl-6c6dc8eabb2c4895a0c3d42e43b9a3c7.
INFO 12-25 13:05:39 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 133.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:41 logger.py:37] Received request chatcmpl-cb6061d09b774e109b74a84dbec0e28c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country does the swimmer who was given a close-up in the video hail from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:41 engine.py:267] Added request chatcmpl-cb6061d09b774e109b74a84dbec0e28c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:42 logger.py:37] Received request chatcmpl-078bdcf2a77e4d5381ab233aa37e6304: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times did the two athletes dive together at the same time in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:42 engine.py:267] Added request chatcmpl-078bdcf2a77e4d5381ab233aa37e6304.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:44 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 104.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:44 logger.py:37] Received request chatcmpl-7302b958951d4d0ca73d0f37bfa4b0bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When and where did the match in the video take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:44 logger.py:37] Received request chatcmpl-88aa025904604dd4a728cd2dc56eca50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the logo on the pitcher\'s chest who wears a blue and red sports shirt and orange helmet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:44 engine.py:267] Added request chatcmpl-7302b958951d4d0ca73d0f37bfa4b0bf.
INFO 12-25 13:05:44 engine.py:267] Added request chatcmpl-88aa025904604dd4a728cd2dc56eca50.
INFO 12-25 13:05:49 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 150.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:52 logger.py:37] Received request chatcmpl-13feffcdec36466cb49434fcb9f2cd66: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player was the winner of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:52 engine.py:267] Added request chatcmpl-13feffcdec36466cb49434fcb9f2cd66.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:52 logger.py:37] Received request chatcmpl-cba1bd57b4984ca8864bbbfc8707a0bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the time difference in seconds between the second and third place in the competition results shown at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:52 engine.py:267] Added request chatcmpl-cba1bd57b4984ca8864bbbfc8707a0bd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:54 logger.py:37] Received request chatcmpl-6e54b4dcb7e94817bbd7a4f36fc752a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When was the game hosted?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:54 engine.py:267] Added request chatcmpl-6e54b4dcb7e94817bbd7a4f36fc752a8.
INFO 12-25 13:05:54 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 105.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:54 logger.py:37] Received request chatcmpl-0a416459e0c341e38f9e5c495cfcc814: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player was the winner of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:54 engine.py:267] Added request chatcmpl-0a416459e0c341e38f9e5c495cfcc814.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:57 logger.py:37] Received request chatcmpl-c694d0b014a14109b76a49dd7bf04a40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country do the athletes shown at the beginning of the video come from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:57 engine.py:267] Added request chatcmpl-c694d0b014a14109b76a49dd7bf04a40.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:05:59 logger.py:37] Received request chatcmpl-fd0b90e735174288b0217b967381e901: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the last ball in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:59 engine.py:267] Added request chatcmpl-fd0b90e735174288b0217b967381e901.
INFO 12-25 13:05:59 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 118.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:05:59 logger.py:37] Received request chatcmpl-93704ec312ee467681a99e36f1292339: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the baseball umpire do after the second ball?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:05:59 engine.py:267] Added request chatcmpl-93704ec312ee467681a99e36f1292339.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:01 logger.py:37] Received request chatcmpl-bcb0a1161a1c4890bdabe0816db5547f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:01 engine.py:267] Added request chatcmpl-bcb0a1161a1c4890bdabe0816db5547f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:04 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 126.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:04 logger.py:37] Received request chatcmpl-df34bc451cee4a87927a70c7eaff7585: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes can be seen crossing the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:04 engine.py:267] Added request chatcmpl-df34bc451cee4a87927a70c7eaff7585.
INFO 12-25 13:06:05 logger.py:37] Received request chatcmpl-e0ba33820b104f9dac398538292c1d58: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the winner win this rally?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:05 engine.py:267] Added request chatcmpl-e0ba33820b104f9dac398538292c1d58.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:07 logger.py:37] Received request chatcmpl-38edbb41832d46ebad4199db83583c7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score after this game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:07 engine.py:267] Added request chatcmpl-38edbb41832d46ebad4199db83583c7c.
INFO 12-25 13:06:08 logger.py:37] Received request chatcmpl-f82ff3641da34d8e8068e4fe0badd81a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of balls is absent from the table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:08 engine.py:267] Added request chatcmpl-f82ff3641da34d8e8068e4fe0badd81a.
INFO 12-25 13:06:09 metrics.py:449] Avg prompt throughput: 49.5 tokens/s, Avg generation throughput: 116.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:12 logger.py:37] Received request chatcmpl-9e97cd819af74e119173dda2d5fbfca8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many rallies did the two athletes play?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:12 engine.py:267] Added request chatcmpl-9e97cd819af74e119173dda2d5fbfca8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:14 logger.py:37] Received request chatcmpl-924e7ec57a474935a01bbe0a39a42391: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players are wearing black shirts in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:14 engine.py:267] Added request chatcmpl-924e7ec57a474935a01bbe0a39a42391.
INFO 12-25 13:06:14 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 118.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:15 logger.py:37] Received request chatcmpl-2c462c52416f441b9e5eccf61200e951: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sentence describes this rally according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:15 engine.py:267] Added request chatcmpl-2c462c52416f441b9e5eccf61200e951.
INFO 12-25 13:06:16 logger.py:37] Received request chatcmpl-d91e43e047e1474393494fbe594c471f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following occurred in the last rally?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:16 engine.py:267] Added request chatcmpl-d91e43e047e1474393494fbe594c471f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:18 logger.py:37] Received request chatcmpl-9cd83c21fabb46f5b1966b2e45d3fe71: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man in black doing while standing beside the field and in front of the Dove board?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:19 engine.py:267] Added request chatcmpl-9cd83c21fabb46f5b1966b2e45d3fe71.
INFO 12-25 13:06:19 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:21 logger.py:37] Received request chatcmpl-0a88b3705682401398586b739665b19d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the final score of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:22 engine.py:267] Added request chatcmpl-0a88b3705682401398586b739665b19d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:24 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:25 logger.py:37] Received request chatcmpl-c011bd63b70e430697264adf1ab3013f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which number is located on the back of the blue man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:25 engine.py:267] Added request chatcmpl-c011bd63b70e430697264adf1ab3013f.
INFO 12-25 13:06:26 logger.py:37] Received request chatcmpl-83b82f85e8b8479bb57b6de4ca317a6b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who smashed the decisive ball?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:26 engine.py:267] Added request chatcmpl-83b82f85e8b8479bb57b6de4ca317a6b.
INFO 12-25 13:06:26 logger.py:37] Received request chatcmpl-78d2f613e9f84e4d8061a85eefae4222: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the white team win this game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:26 engine.py:267] Added request chatcmpl-78d2f613e9f84e4d8061a85eefae4222.
INFO 12-25 13:06:29 metrics.py:449] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 124.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:31 logger.py:37] Received request chatcmpl-02f9705b94e340ad8d802368d9b836e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What Latin texts are inscribed on the man\'s chest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:31 engine.py:267] Added request chatcmpl-02f9705b94e340ad8d802368d9b836e8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:32 logger.py:37] Received request chatcmpl-deb5fcce29be485791468c111f3d1d93: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which flag is being held by the spectator?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:32 engine.py:267] Added request chatcmpl-deb5fcce29be485791468c111f3d1d93.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:33 logger.py:37] Received request chatcmpl-0f1313c159d04b7a87260eab0bbbd568: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the blue car with a decoration of fire on the hood?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:33 engine.py:267] Added request chatcmpl-0f1313c159d04b7a87260eab0bbbd568.
INFO 12-25 13:06:34 logger.py:37] Received request chatcmpl-e44333382f7c4f0597d8ea169ab1cdff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players are participating in the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:34 engine.py:267] Added request chatcmpl-e44333382f7c4f0597d8ea169ab1cdff.
INFO 12-25 13:06:34 metrics.py:449] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 101.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:39 logger.py:37] Received request chatcmpl-74445d5d1f65486e9bbc3d748670324e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport are the two athletes playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:39 engine.py:267] Added request chatcmpl-74445d5d1f65486e9bbc3d748670324e.
INFO 12-25 13:06:40 logger.py:37] Received request chatcmpl-b915b8fa62704fd2a7f29adc213e07db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the blue player during the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:40 engine.py:267] Added request chatcmpl-b915b8fa62704fd2a7f29adc213e07db.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:41 logger.py:37] Received request chatcmpl-6e51479038f54839bac4057b863f78ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following sentences is accurate based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:41 engine.py:267] Added request chatcmpl-6e51479038f54839bac4057b863f78ab.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:44 metrics.py:449] Avg prompt throughput: 37.2 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:45 logger.py:37] Received request chatcmpl-a15bca9530de4fd98df8b1b960bd887c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothes is the singer wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:45 engine.py:267] Added request chatcmpl-a15bca9530de4fd98df8b1b960bd887c.
INFO 12-25 13:06:46 logger.py:37] Received request chatcmpl-9f37c6b5b5f6464da5511bba58c4be72: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people on the stage doing in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:46 engine.py:267] Added request chatcmpl-9f37c6b5b5f6464da5511bba58c4be72.
INFO 12-25 13:06:47 logger.py:37] Received request chatcmpl-98dd1fbcb46d4ed18dafd38533844390: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the current score of the ongoing game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:47 engine.py:267] Added request chatcmpl-98dd1fbcb46d4ed18dafd38533844390.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:49 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 114.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:49 logger.py:37] Received request chatcmpl-d8de559b9daf40cc95dca0ec611a153e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What country won first place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:49 engine.py:267] Added request chatcmpl-d8de559b9daf40cc95dca0ec611a153e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:52 logger.py:37] Received request chatcmpl-2e2acc47867049caa83195e0cb1dc0fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals are shown singing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:52 logger.py:37] Received request chatcmpl-a09dbca78e1446239fc688f9caea06b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is happening in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:52 engine.py:267] Added request chatcmpl-2e2acc47867049caa83195e0cb1dc0fb.
INFO 12-25 13:06:52 engine.py:267] Added request chatcmpl-a09dbca78e1446239fc688f9caea06b9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:54 metrics.py:449] Avg prompt throughput: 35.8 tokens/s, Avg generation throughput: 132.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:06:55 logger.py:37] Received request chatcmpl-b77fa19d859f45b1a604b20c8dd1a53e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What action did the man in blue take towards the goalkeeper in yellow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:55 engine.py:267] Added request chatcmpl-b77fa19d859f45b1a604b20c8dd1a53e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:06:56 logger.py:37] Received request chatcmpl-a0dc9cd4997943e19d0467651ab158cc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of pants is the person wearing while playing the piano in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:06:56 engine.py:267] Added request chatcmpl-a0dc9cd4997943e19d0467651ab158cc.
INFO 12-25 13:06:59 metrics.py:449] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 138.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:01 logger.py:37] Received request chatcmpl-493adc8e6f15455eba0c7b0476f60a9b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What instrument is the character in the middle playing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:01 engine.py:267] Added request chatcmpl-493adc8e6f15455eba0c7b0476f60a9b.
INFO 12-25 13:07:02 logger.py:37] Received request chatcmpl-e029da2c2a96474a853c9714c83d1285: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the wig worn by the character playing the guitar?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:02 logger.py:37] Received request chatcmpl-622c926350ea445191a1b451c26b309e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the red texts recognized on the white wall?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:02 engine.py:267] Added request chatcmpl-e029da2c2a96474a853c9714c83d1285.
INFO 12-25 13:07:02 engine.py:267] Added request chatcmpl-622c926350ea445191a1b451c26b309e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:04 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:07:05 logger.py:37] Received request chatcmpl-324476e9fa6f4dce8abb150c8fc86ad1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which individual does the singer wearing a yellow dress embrace?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:05 engine.py:267] Added request chatcmpl-324476e9fa6f4dce8abb150c8fc86ad1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:08 logger.py:37] Received request chatcmpl-cff5cf835004442ea35d53efb332f782: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following venue types is most likely the setting of the scene, given its context?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:08 logger.py:37] Received request chatcmpl-2a5ee0520f1e43619379ff4faf81d2fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be seen in the background directly above the heads of the main characters?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:08 engine.py:267] Added request chatcmpl-cff5cf835004442ea35d53efb332f782.
INFO 12-25 13:07:08 engine.py:267] Added request chatcmpl-2a5ee0520f1e43619379ff4faf81d2fe.
INFO 12-25 13:07:09 metrics.py:449] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 129.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:12 logger.py:37] Received request chatcmpl-87e9a6a08e8a4ed085d698eb378c6a8d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many men and women are presenting on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:12 engine.py:267] Added request chatcmpl-87e9a6a08e8a4ed085d698eb378c6a8d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:13 logger.py:37] Received request chatcmpl-caa5d40d5ac243c984178d4575f95452: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the backdrop and costumes, which demographic is the intended audience for the show in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:13 engine.py:267] Added request chatcmpl-caa5d40d5ac243c984178d4575f95452.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:14 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 138.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:07:15 logger.py:37] Received request chatcmpl-ded25adf4e374222901c8c610e6436d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which genre best describes the performance based on the activity and costumes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:15 engine.py:267] Added request chatcmpl-ded25adf4e374222901c8c610e6436d7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:19 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 150.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:20 logger.py:37] Received request chatcmpl-fcbe480c3b4b473f8d766a2511b7a2a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals are currently present on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:20 engine.py:267] Added request chatcmpl-fcbe480c3b4b473f8d766a2511b7a2a4.
INFO 12-25 13:07:20 logger.py:37] Received request chatcmpl-0c210b3cd98348bb96ba9aa0741f6978: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In this video, which stage setting is featured at the beginning of the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:20 engine.py:267] Added request chatcmpl-0c210b3cd98348bb96ba9aa0741f6978.
INFO 12-25 13:07:21 logger.py:37] Received request chatcmpl-ec107540ff7e49b98d1f95e0bd8b0c21: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the exact number of performers in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:21 engine.py:267] Added request chatcmpl-ec107540ff7e49b98d1f95e0bd8b0c21.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:23 logger.py:37] Received request chatcmpl-5c9df624d8084456bf958a0964309267: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which person in the video is being slapped by the man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:23 engine.py:267] Added request chatcmpl-5c9df624d8084456bf958a0964309267.
INFO 12-25 13:07:24 metrics.py:449] Avg prompt throughput: 51.2 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:27 logger.py:37] Received request chatcmpl-cc55620da7a940b69bd183f17b6c5dc6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item is being held by the actor in the image on the poster displayed at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:27 logger.py:37] Received request chatcmpl-a7c5f26634134e4c9c06d7dbd93be268: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the audience\'s reaction to the singer\'s performance in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:27 engine.py:267] Added request chatcmpl-cc55620da7a940b69bd183f17b6c5dc6.
INFO 12-25 13:07:27 engine.py:267] Added request chatcmpl-a7c5f26634134e4c9c06d7dbd93be268.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:29 metrics.py:449] Avg prompt throughput: 28.9 tokens/s, Avg generation throughput: 123.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:07:30 logger.py:37] Received request chatcmpl-204b80b624ee43658b8ea1a8a0f0c181: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item does the man display to the woman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:30 engine.py:267] Added request chatcmpl-204b80b624ee43658b8ea1a8a0f0c181.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:34 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:07:34 logger.py:37] Received request chatcmpl-63f371257f554cafba537e9b205ff2bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which country will host this live stage event?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:34 engine.py:267] Added request chatcmpl-63f371257f554cafba537e9b205ff2bf.
INFO 12-25 13:07:35 logger.py:37] Received request chatcmpl-b301f114789d4fc683613c6605ee5631: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements best describes the relationship between the two characters in this scene based on the available information?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:35 engine.py:267] Added request chatcmpl-b301f114789d4fc683613c6605ee5631.
INFO 12-25 13:07:35 logger.py:37] Received request chatcmpl-e22c1e8b4bb14ac89209c72da1c828f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity is the most likely one for the two main people in the image?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:35 engine.py:267] Added request chatcmpl-e22c1e8b4bb14ac89209c72da1c828f4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:38 logger.py:37] Received request chatcmpl-508a65b899c241a1ba77199de0b66022: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the audience\'s reaction, what is the most likely atmosphere in the venue?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:38 engine.py:267] Added request chatcmpl-508a65b899c241a1ba77199de0b66022.
INFO 12-25 13:07:39 metrics.py:449] Avg prompt throughput: 55.4 tokens/s, Avg generation throughput: 129.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:41 logger.py:37] Received request chatcmpl-232738d574f444959abf74252b75bf5d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the tone of the play?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:41 engine.py:267] Added request chatcmpl-232738d574f444959abf74252b75bf5d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:43 logger.py:37] Received request chatcmpl-ddd8bb49586546ae8e8fa283ac4c0beb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many tricks are performed in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:43 engine.py:267] Added request chatcmpl-ddd8bb49586546ae8e8fa283ac4c0beb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:44 logger.py:37] Received request chatcmpl-39c0b2828c5643d28a989fd3ad52352d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the pattern on the backdrop of the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:44 engine.py:267] Added request chatcmpl-39c0b2828c5643d28a989fd3ad52352d.
INFO 12-25 13:07:44 metrics.py:449] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 127.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:07:45 logger.py:37] Received request chatcmpl-c14a90e7721d480c85dbcfe87a245449: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, how many judges are watching the show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:45 engine.py:267] Added request chatcmpl-c14a90e7721d480c85dbcfe87a245449.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:47 logger.py:37] Received request chatcmpl-49d3d2440bb84858a338638c6d8cdb80: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main event taking place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:47 engine.py:267] Added request chatcmpl-49d3d2440bb84858a338638c6d8cdb80.
INFO 12-25 13:07:49 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 139.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:51 logger.py:37] Received request chatcmpl-e6fe7b4d75b448609f226952fb364476: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the characters\' costumes and the stage setup, which of the following types of performance is most likely being portrayed in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:51 engine.py:267] Added request chatcmpl-e6fe7b4d75b448609f226952fb364476.
INFO 12-25 13:07:52 logger.py:37] Received request chatcmpl-227093435c474a92bab401901b608511: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, when are the lights turned on during the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:52 logger.py:37] Received request chatcmpl-2f7741e3da3f4198962e24a0368b3aed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According the video, what makes the audience shocked and rise to applaud?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:52 engine.py:267] Added request chatcmpl-227093435c474a92bab401901b608511.
INFO 12-25 13:07:52 engine.py:267] Added request chatcmpl-2f7741e3da3f4198962e24a0368b3aed.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:54 logger.py:37] Received request chatcmpl-808c6b93f4b74f31a7d24dfe39ede43d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What finger is wrapped with the third rubber band trick in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:54 engine.py:267] Added request chatcmpl-808c6b93f4b74f31a7d24dfe39ede43d.
INFO 12-25 13:07:54 metrics.py:449] Avg prompt throughput: 55.5 tokens/s, Avg generation throughput: 103.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:57 logger.py:37] Received request chatcmpl-9a981bc18ffe49c49398d0de87f43b22: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the magician not do according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:07:57 engine.py:267] Added request chatcmpl-9a981bc18ffe49c49398d0de87f43b22.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:07:59 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 104.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:00 logger.py:37] Received request chatcmpl-6e028be70de142d398433f44406d55f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does she do after picking a pink ball from the thunder in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:00 engine.py:267] Added request chatcmpl-6e028be70de142d398433f44406d55f8.
INFO 12-25 13:08:00 logger.py:37] Received request chatcmpl-70abefe074d04636b76df4ae49e0f3ce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the performers sitting down?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:00 engine.py:267] Added request chatcmpl-70abefe074d04636b76df4ae49e0f3ce.
INFO 12-25 13:08:00 logger.py:37] Received request chatcmpl-a8b517ab06ca4aecaa57830145c0a94c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which regional clothes does the performer wear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:00 engine.py:267] Added request chatcmpl-a8b517ab06ca4aecaa57830145c0a94c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:04 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 129.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:04 logger.py:37] Received request chatcmpl-3b877cbcb89f4558b6561787c08ef737: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the tools the man in this video used to perform magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:04 engine.py:267] Added request chatcmpl-3b877cbcb89f4558b6561787c08ef737.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:06 logger.py:37] Received request chatcmpl-97fffc98497740b09d1165a31c1bd0ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens to the balloon in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:06 engine.py:267] Added request chatcmpl-97fffc98497740b09d1165a31c1bd0ee.
INFO 12-25 13:08:07 logger.py:37] Received request chatcmpl-17d7e20008eb4d908778de017f6903a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what most likely roles do the man and woman have alongside the magician?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:07 engine.py:267] Added request chatcmpl-17d7e20008eb4d908778de017f6903a4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:09 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:10 logger.py:37] Received request chatcmpl-6aaeedff1c164e309a396b6a63a86fb0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is visible on the background screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:10 engine.py:267] Added request chatcmpl-6aaeedff1c164e309a396b6a63a86fb0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:12 logger.py:37] Received request chatcmpl-86c7a4fb578c4285ba5cd49d7c92629d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the black plastic bag shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:12 engine.py:267] Added request chatcmpl-86c7a4fb578c4285ba5cd49d7c92629d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:13 logger.py:37] Received request chatcmpl-ad5e54ee93314e68a8e364bbfc225faf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the performer\'s hair in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:13 engine.py:267] Added request chatcmpl-ad5e54ee93314e68a8e364bbfc225faf.
INFO 12-25 13:08:14 logger.py:37] Received request chatcmpl-2ce5bc40c4234d4ba98cc7da1f13ea27: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the performer have in his hand at the beginning of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:14 engine.py:267] Added request chatcmpl-2ce5bc40c4234d4ba98cc7da1f13ea27.
INFO 12-25 13:08:14 metrics.py:449] Avg prompt throughput: 52.0 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:19 logger.py:37] Received request chatcmpl-c12212fb27c545ed937ff3b22c855399: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:19 engine.py:267] Added request chatcmpl-c12212fb27c545ed937ff3b22c855399.
INFO 12-25 13:08:19 metrics.py:449] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 128.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:20 logger.py:37] Received request chatcmpl-af6f209ad43348f0a50c9560e7d2ee72: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following items is not placed on the judge\'s table who is speaking at the end of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:20 engine.py:267] Added request chatcmpl-af6f209ad43348f0a50c9560e7d2ee72.
INFO 12-25 13:08:21 logger.py:37] Received request chatcmpl-62d8bc3e6ea84560913d6a474dfeaeed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, what does the performer do when he leaves the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:21 engine.py:267] Added request chatcmpl-62d8bc3e6ea84560913d6a474dfeaeed.
INFO 12-25 13:08:21 logger.py:37] Received request chatcmpl-7b25d6fc824b4ff2a6a5f8bdcc4a10ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sentence best describes the first rubber band trick shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:21 engine.py:267] Added request chatcmpl-7b25d6fc824b4ff2a6a5f8bdcc4a10ec.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:24 logger.py:37] Received request chatcmpl-cd35b4ecca8c46c084be2f5daba08a5c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the subject matter of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:24 engine.py:267] Added request chatcmpl-cd35b4ecca8c46c084be2f5daba08a5c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:24 metrics.py:449] Avg prompt throughput: 55.3 tokens/s, Avg generation throughput: 113.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:26 logger.py:37] Received request chatcmpl-c134cccdc88447e3abf721123af45dc7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the magic trick in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:26 engine.py:267] Added request chatcmpl-c134cccdc88447e3abf721123af45dc7.
INFO 12-25 13:08:27 logger.py:37] Received request chatcmpl-ace6e2ff498a4440b49fce27afa6a487: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do the men on the stage look similar to each other?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:27 logger.py:37] Received request chatcmpl-d45e3ceb6af84efb91f9fe420e488056: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothes does the performer wear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:27 engine.py:267] Added request chatcmpl-ace6e2ff498a4440b49fce27afa6a487.
INFO 12-25 13:08:27 engine.py:267] Added request chatcmpl-d45e3ceb6af84efb91f9fe420e488056.
INFO 12-25 13:08:29 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 110.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:32 logger.py:37] Received request chatcmpl-821d3e9bdbbf4c2bbb5df878efb554b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What caused the sudden fall of the woman in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:32 engine.py:267] Added request chatcmpl-821d3e9bdbbf4c2bbb5df878efb554b3.
INFO 12-25 13:08:32 logger.py:37] Received request chatcmpl-5fc620201e344457abed13ccae063a8f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the woman respond to the performance in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:32 engine.py:267] Added request chatcmpl-5fc620201e344457abed13ccae063a8f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:34 logger.py:37] Received request chatcmpl-10d8808798004c419b9c00b2f484d81e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what occurs when the magician taps only the man on the shoulder?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:34 engine.py:267] Added request chatcmpl-10d8808798004c419b9c00b2f484d81e.
INFO 12-25 13:08:34 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 123.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:38 logger.py:37] Received request chatcmpl-0f782e58f83b46d1874b7ec87002d136: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two men first perform on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:38 engine.py:267] Added request chatcmpl-0f782e58f83b46d1874b7ec87002d136.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:39 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 115.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:40 logger.py:37] Received request chatcmpl-b1ad4d8c02c84c6396a393e9aacbf5f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the colors of the fan?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:40 logger.py:37] Received request chatcmpl-0137352e90ca4cf9a8fb15876dc761da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many individuals are in the bathroom?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:40 engine.py:267] Added request chatcmpl-b1ad4d8c02c84c6396a393e9aacbf5f1.
INFO 12-25 13:08:40 engine.py:267] Added request chatcmpl-0137352e90ca4cf9a8fb15876dc761da.
INFO 12-25 13:08:41 logger.py:37] Received request chatcmpl-2ae27947de744b1bacdd893bef58cd21: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:41 engine.py:267] Added request chatcmpl-2ae27947de744b1bacdd893bef58cd21.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:44 metrics.py:449] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 128.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:44 logger.py:37] Received request chatcmpl-8860039de8bd4c1f9bf8fe8a8787e9df: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the background behind the woman in FaceTime?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:44 engine.py:267] Added request chatcmpl-8860039de8bd4c1f9bf8fe8a8787e9df.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:46 logger.py:37] Received request chatcmpl-77b693a87552458c9cd4eeb8457495ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the opening scene of the video, how many stars are present on the trophy situated on the left hand side of the screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:46 engine.py:267] Added request chatcmpl-77b693a87552458c9cd4eeb8457495ee.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:48 logger.py:37] Received request chatcmpl-0ea5c6b14d9f42a6879cb9d010022b49: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According the video, what is the appearance of the clothes worn by the man holding a dog?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:48 engine.py:267] Added request chatcmpl-0ea5c6b14d9f42a6879cb9d010022b49.
INFO 12-25 13:08:49 metrics.py:449] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 130.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:51 logger.py:37] Received request chatcmpl-0d632c40be3a4503a9cc047bb2bd0820: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the final score of the man in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:51 engine.py:267] Added request chatcmpl-0d632c40be3a4503a9cc047bb2bd0820.
INFO 12-25 13:08:53 logger.py:37] Received request chatcmpl-3c6e5037f84e4b71b4bcbbd1cb294614: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what country does the shortest woman in the world come from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:53 engine.py:267] Added request chatcmpl-3c6e5037f84e4b71b4bcbbd1cb294614.
INFO 12-25 13:08:53 logger.py:37] Received request chatcmpl-7ed6e367cc264638bb436146da61fd9f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement accurately describes a similarity between the two men in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:53 engine.py:267] Added request chatcmpl-7ed6e367cc264638bb436146da61fd9f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:54 metrics.py:449] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 113.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:08:56 logger.py:37] Received request chatcmpl-c06b4eae177c4ae1aca0f68209e73b18: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the opening scene of the video, what color tie is the man wearing with his suit?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:56 engine.py:267] Added request chatcmpl-c06b4eae177c4ae1aca0f68209e73b18.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:58 logger.py:37] Received request chatcmpl-3dede3194f8144d38998b17e901d8e78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why were the two people so happy in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:58 engine.py:267] Added request chatcmpl-3dede3194f8144d38998b17e901d8e78.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:08:59 logger.py:37] Received request chatcmpl-63889b791ae44e59b5832e078551651f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothing is the man wearing while holding the dog in the second half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:08:59 engine.py:267] Added request chatcmpl-63889b791ae44e59b5832e078551651f.
INFO 12-25 13:08:59 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:01 logger.py:37] Received request chatcmpl-8491e6765765401aaccdd9343f7d0211: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the curves they draw on the screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:01 engine.py:267] Added request chatcmpl-8491e6765765401aaccdd9343f7d0211.
INFO 12-25 13:09:02 logger.py:37] Received request chatcmpl-9ac0e467f52e4ad1a8986f4607922923: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the wheels of the skateboard used by the dog in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:02 engine.py:267] Added request chatcmpl-9ac0e467f52e4ad1a8986f4607922923.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:04 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 135.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:06 logger.py:37] Received request chatcmpl-a9d3cf1745c94dbbb301037f78e06dd2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which statement is true regarding the height comparison of the world\'s shortest man and shortest woman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:06 engine.py:267] Added request chatcmpl-a9d3cf1745c94dbbb301037f78e06dd2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:08 logger.py:37] Received request chatcmpl-893a2db4a7154aeb99ac7f189adace50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What game are they playing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:08 engine.py:267] Added request chatcmpl-893a2db4a7154aeb99ac7f189adace50.
INFO 12-25 13:09:09 logger.py:37] Received request chatcmpl-36d9ffb97f214ceebce5312d21f089f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are wearing ties in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:09 engine.py:267] Added request chatcmpl-36d9ffb97f214ceebce5312d21f089f8.
INFO 12-25 13:09:09 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 113.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:12 logger.py:37] Received request chatcmpl-ab2d2393c2914733a3b031509f308ff9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the beginning of the video, during which holiday was the video most likely recorded?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:12 engine.py:267] Added request chatcmpl-ab2d2393c2914733a3b031509f308ff9.
INFO 12-25 13:09:13 logger.py:37] Received request chatcmpl-1b0c0817bb7749cda32896e783633dd6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the total number of people in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:13 engine.py:267] Added request chatcmpl-1b0c0817bb7749cda32896e783633dd6.
INFO 12-25 13:09:14 metrics.py:449] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 142.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:18 logger.py:37] Received request chatcmpl-82c6633fc0b7483fb3dece35495f1a78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was the first person to press the button and turn the chair around in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:18 engine.py:267] Added request chatcmpl-82c6633fc0b7483fb3dece35495f1a78.
INFO 12-25 13:09:19 logger.py:37] Received request chatcmpl-559921b9a5e3475db58d5422fe40df45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which instrument is the performer on the stage holding in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:19 engine.py:267] Added request chatcmpl-559921b9a5e3475db58d5422fe40df45.
INFO 12-25 13:09:19 metrics.py:449] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 127.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:23 logger.py:37] Received request chatcmpl-b20aa653ecc84412b4436b0353a3faac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color shoes is the man wearing in the video who is playing the obstacle course game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:23 engine.py:267] Added request chatcmpl-b20aa653ecc84412b4436b0353a3faac.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:24 logger.py:37] Received request chatcmpl-dd3f3a2609724530ab9529612f7bc5cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video,who spends more time on their phone?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:24 engine.py:267] Added request chatcmpl-dd3f3a2609724530ab9529612f7bc5cd.
INFO 12-25 13:09:24 metrics.py:449] Avg prompt throughput: 13.9 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:25 logger.py:37] Received request chatcmpl-9f797924e99f4bb08b3ab8fd31408481: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people were shown in the video drawing on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:25 engine.py:267] Added request chatcmpl-9f797924e99f4bb08b3ab8fd31408481.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:27 logger.py:37] Received request chatcmpl-fc70a85a9c964ff18976c1823c7fad32: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country\'s flag is on the ribbon in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:27 engine.py:267] Added request chatcmpl-fc70a85a9c964ff18976c1823c7fad32.
INFO 12-25 13:09:29 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 143.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:32 logger.py:37] Received request chatcmpl-f103b32d9bc74b638567c3e11fcba6cc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the little girl not do after the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:32 engine.py:267] Added request chatcmpl-f103b32d9bc74b638567c3e11fcba6cc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:33 logger.py:37] Received request chatcmpl-71051a7d13214b9b89897360be9cdeaa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which option correctly indicates the number of microphones on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:33 engine.py:267] Added request chatcmpl-71051a7d13214b9b89897360be9cdeaa.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:34 logger.py:37] Received request chatcmpl-7a04d7e92e884bea8dea4992acd3e86d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which hairstyle is being worn by the host on stage in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:34 engine.py:267] Added request chatcmpl-7a04d7e92e884bea8dea4992acd3e86d.
INFO 12-25 13:09:34 metrics.py:449] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 98.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:35 logger.py:37] Received request chatcmpl-c18032fb48fb41bfa37c624489efe0a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the words spoken by the person in the video, what is the main significance of the activity shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:35 engine.py:267] Added request chatcmpl-c18032fb48fb41bfa37c624489efe0a7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:38 logger.py:37] Received request chatcmpl-60465c9b04c443a3b0a63deaf569e7e7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the little girl\'s expression, how does she feel after finishing her performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:38 engine.py:267] Added request chatcmpl-60465c9b04c443a3b0a63deaf569e7e7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:39 logger.py:37] Received request chatcmpl-d4402e7781d74f4c907c2817a81b0965: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people were challenged by the person in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:39 engine.py:267] Added request chatcmpl-d4402e7781d74f4c907c2817a81b0965.
INFO 12-25 13:09:40 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 132.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:42 logger.py:37] Received request chatcmpl-31af3f18c07248b8af8e704b805f4866: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:42 engine.py:267] Added request chatcmpl-31af3f18c07248b8af8e704b805f4866.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:44 logger.py:37] Received request chatcmpl-a0f1748738224d1e81ac24f926d86d52: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill is not included in the little girl\'s performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:44 engine.py:267] Added request chatcmpl-a0f1748738224d1e81ac24f926d86d52.
INFO 12-25 13:09:45 metrics.py:449] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 129.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:45 logger.py:37] Received request chatcmpl-be0cfead1b9c461eb44f4f1d5ab6c711: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the girl wear during the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:45 engine.py:267] Added request chatcmpl-be0cfead1b9c461eb44f4f1d5ab6c711.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:47 logger.py:37] Received request chatcmpl-7335e5f29e66422f945b130602726c90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the background for the stage when the little girl and her mom jump on ropes in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:47 engine.py:267] Added request chatcmpl-7335e5f29e66422f945b130602726c90.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:50 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:50 logger.py:37] Received request chatcmpl-f9f1b892c36c4ea3bbe164db0b6e1407: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Did they successfully play the game of telephone in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:50 logger.py:37] Received request chatcmpl-47ecd0ac03f941f684b2448ead5a0b2c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be seen on her chin when she is being interviewd in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:50 engine.py:267] Added request chatcmpl-f9f1b892c36c4ea3bbe164db0b6e1407.
INFO 12-25 13:09:50 engine.py:267] Added request chatcmpl-47ecd0ac03f941f684b2448ead5a0b2c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:52 logger.py:37] Received request chatcmpl-5ead0019d6d545f195aa437a3e6208ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:52 engine.py:267] Added request chatcmpl-5ead0019d6d545f195aa437a3e6208ee.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:53 logger.py:37] Received request chatcmpl-5460ca3a34ab4b74bf92d4f943a5a446: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the little girl wearing shorts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:53 engine.py:267] Added request chatcmpl-5460ca3a34ab4b74bf92d4f943a5a446.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:55 metrics.py:449] Avg prompt throughput: 50.8 tokens/s, Avg generation throughput: 124.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:09:55 logger.py:37] Received request chatcmpl-a07ecd564b234e0880e31fd582edad8c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the male performer wear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:56 engine.py:267] Added request chatcmpl-a07ecd564b234e0880e31fd582edad8c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:09:58 logger.py:37] Received request chatcmpl-dcae9ca34e6a4296a615bf2f048ba75d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals depicted in the video are wearing glasses?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:58 engine.py:267] Added request chatcmpl-dcae9ca34e6a4296a615bf2f048ba75d.
INFO 12-25 13:09:59 logger.py:37] Received request chatcmpl-afd2b9c1a4254c0ab8456c5c13d176f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sentence best describes the girl\'s dress?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:09:59 engine.py:267] Added request chatcmpl-afd2b9c1a4254c0ab8456c5c13d176f2.
INFO 12-25 13:10:00 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:02 logger.py:37] Received request chatcmpl-82b0630920364be19bc304493a1e6776: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the girl wear above the head during her performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:02 engine.py:267] Added request chatcmpl-82b0630920364be19bc304493a1e6776.
INFO 12-25 13:10:02 logger.py:37] Received request chatcmpl-adc180913d0342358199668480bc31b1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which pose appears in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:02 engine.py:267] Added request chatcmpl-adc180913d0342358199668480bc31b1.
INFO 12-25 13:10:05 metrics.py:449] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 130.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:08 logger.py:37] Received request chatcmpl-52911dd21a3549f48f83dddeb724e162: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the athletes wear during their performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:08 logger.py:37] Received request chatcmpl-a5859c658b184b678d1cbc224367a23b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sports in this video involve athletes utilizing humans as tools?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:08 engine.py:267] Added request chatcmpl-52911dd21a3549f48f83dddeb724e162.
INFO 12-25 13:10:08 engine.py:267] Added request chatcmpl-a5859c658b184b678d1cbc224367a23b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:10 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 125.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:11 logger.py:37] Received request chatcmpl-001429aaf75e4830be40f46354f413fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times do the two people in the video give different answers to the question?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:11 engine.py:267] Added request chatcmpl-001429aaf75e4830be40f46354f413fb.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:14 logger.py:37] Received request chatcmpl-22ef72e3482b43e19f966568a0bc212f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where do the events in this video take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:14 engine.py:267] Added request chatcmpl-22ef72e3482b43e19f966568a0bc212f.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:15 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 119.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:15 logger.py:37] Received request chatcmpl-02cef8f4ce6f4a64b84e041fd95da567: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the ending pose of the team at the end of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:15 engine.py:267] Added request chatcmpl-02cef8f4ce6f4a64b84e041fd95da567.
INFO 12-25 13:10:16 logger.py:37] Received request chatcmpl-1c01bd875b5f469096e0ac8ced32b228: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man wear outside the house?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:16 engine.py:267] Added request chatcmpl-1c01bd875b5f469096e0ac8ced32b228.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:20 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 125.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:20 logger.py:37] Received request chatcmpl-11b114fa8ad642049c785413b6fdae4b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the rope pulled by the person during the ice bucket challenge in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:20 engine.py:267] Added request chatcmpl-11b114fa8ad642049c785413b6fdae4b.
INFO 12-25 13:10:20 logger.py:37] Received request chatcmpl-c3ffd0ef47e246db801fd6467d0459fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many rolls does the girl do in her performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:20 engine.py:267] Added request chatcmpl-c3ffd0ef47e246db801fd6467d0459fd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:22 logger.py:37] Received request chatcmpl-bdea56c57d6e45aeb4241d4663bb8f74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color do the clothes of the two players have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:22 engine.py:267] Added request chatcmpl-bdea56c57d6e45aeb4241d4663bb8f74.
INFO 12-25 13:10:23 logger.py:37] Received request chatcmpl-88b2410d630d4b4da7328898e4ce0a4d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill does not appear in her performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:23 engine.py:267] Added request chatcmpl-88b2410d630d4b4da7328898e4ce0a4d.
INFO 12-25 13:10:25 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:27 logger.py:37] Received request chatcmpl-f62b64bb37584da384f848df708a6071: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If the man is 180cm tall, what is the estimated diameter of the pilates ball which the man is playing with?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:27 engine.py:267] Added request chatcmpl-f62b64bb37584da384f848df708a6071.
INFO 12-25 13:10:28 logger.py:37] Received request chatcmpl-d44ca4883abf4e90b97cd8ddacf6df0e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the woman\'s nails?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:28 engine.py:267] Added request chatcmpl-d44ca4883abf4e90b97cd8ddacf6df0e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:30 metrics.py:449] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 105.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:30 logger.py:37] Received request chatcmpl-c9a60067eed64559a7d91af4d2e445c4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:30 engine.py:267] Added request chatcmpl-c9a60067eed64559a7d91af4d2e445c4.
INFO 12-25 13:10:30 logger.py:37] Received request chatcmpl-8c7b31d47bb44b38bd08aee811b45677: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the bottle cap?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:30 engine.py:267] Added request chatcmpl-8c7b31d47bb44b38bd08aee811b45677.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:35 metrics.py:449] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 139.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:37 logger.py:37] Received request chatcmpl-ca89e6ba9bdc416ab02561019ad4e957: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill does not appear in her performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:37 logger.py:37] Received request chatcmpl-e83b9dd590f34c798aa0fffb925e663b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different kinds of snow globes are made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:37 logger.py:37] Received request chatcmpl-2a62f2316e4c4646a870e01d8d4b2445: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the ending pose in the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:37 engine.py:267] Added request chatcmpl-ca89e6ba9bdc416ab02561019ad4e957.
INFO 12-25 13:10:37 engine.py:267] Added request chatcmpl-e83b9dd590f34c798aa0fffb925e663b.
INFO 12-25 13:10:37 engine.py:267] Added request chatcmpl-2a62f2316e4c4646a870e01d8d4b2445.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:39 logger.py:37] Received request chatcmpl-9137da7cac2d41bcba6b1cc53a216e95: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus or main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:39 engine.py:267] Added request chatcmpl-9137da7cac2d41bcba6b1cc53a216e95.
INFO 12-25 13:10:40 metrics.py:449] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 96.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:44 logger.py:37] Received request chatcmpl-240a3b7994e547aabf1ae708537eb3dd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:44 engine.py:267] Added request chatcmpl-240a3b7994e547aabf1ae708537eb3dd.
INFO 12-25 13:10:44 logger.py:37] Received request chatcmpl-49f5bbf24b634949bea9ccdee343bfd3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what synchronized action do the two performers engage in simultaneously?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:44 logger.py:37] Received request chatcmpl-eaf757ce279744279afb5e6082246107: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, which hand is used to hold the glue gun?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:44 engine.py:267] Added request chatcmpl-49f5bbf24b634949bea9ccdee343bfd3.
INFO 12-25 13:10:44 engine.py:267] Added request chatcmpl-eaf757ce279744279afb5e6082246107.
INFO 12-25 13:10:45 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 85.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:45 logger.py:37] Received request chatcmpl-ca037927671249ab96d6c6299b8c835e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the pistil in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:45 engine.py:267] Added request chatcmpl-ca037927671249ab96d6c6299b8c835e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:49 logger.py:37] Received request chatcmpl-5c9ea127945147d28da78a8de6114334: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individuals are in the team, with each person dressed in yellow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:49 engine.py:267] Added request chatcmpl-5c9ea127945147d28da78a8de6114334.
INFO 12-25 13:10:50 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 121.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:10:50 logger.py:37] Received request chatcmpl-be99caac56e7485296150c43316239d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many spoons are used to make the holder in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:50 engine.py:267] Added request chatcmpl-be99caac56e7485296150c43316239d0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:51 logger.py:37] Received request chatcmpl-ac137a3748d1416aa285868fc078ead1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the shape of the paper shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:51 engine.py:267] Added request chatcmpl-ac137a3748d1416aa285868fc078ead1.
INFO 12-25 13:10:51 logger.py:37] Received request chatcmpl-a458c842a4d54c9cb67570d15dc842dd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second paper animal made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:51 engine.py:267] Added request chatcmpl-a458c842a4d54c9cb67570d15dc842dd.
INFO 12-25 13:10:55 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 140.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:10:57 logger.py:37] Received request chatcmpl-85a06b14317946f99373fd6088b26579: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which tool is not necessary to make a snow globe?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:10:57 engine.py:267] Added request chatcmpl-85a06b14317946f99373fd6088b26579.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:00 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 101.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:11:00 logger.py:37] Received request chatcmpl-35b999b6fa7c4617bc3e62cfa0084a25: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As shown in the video, where are the candles placed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:00 logger.py:37] Received request chatcmpl-63e2e84936ce41f3bba8e7d890204bf4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How are the bottle caps placed at the beginning of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:00 engine.py:267] Added request chatcmpl-35b999b6fa7c4617bc3e62cfa0084a25.
INFO 12-25 13:11:00 engine.py:267] Added request chatcmpl-63e2e84936ce41f3bba8e7d890204bf4.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:01 logger.py:37] Received request chatcmpl-b4fe303a765c4068aa9936dfc6dccff6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the physique of the athletes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:01 engine.py:267] Added request chatcmpl-b4fe303a765c4068aa9936dfc6dccff6.
INFO 12-25 13:11:02 logger.py:37] Received request chatcmpl-de98e7c58bd64e2b9b6283091d3aa9a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the right order of the tools appearing in the video when making a paper peony? (a) Glue gun. (b) Yellow paper. (c) Pink paper. (d) Scissors.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:02 engine.py:267] Added request chatcmpl-de98e7c58bd64e2b9b6283091d3aa9a8.
INFO 12-25 13:11:05 metrics.py:449] Avg prompt throughput: 56.7 tokens/s, Avg generation throughput: 130.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:06 logger.py:37] Received request chatcmpl-0ca45d79ca16463d9128f9e4ef592d80: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the size of the rectangular paper?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:06 engine.py:267] Added request chatcmpl-0ca45d79ca16463d9128f9e4ef592d80.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:07 logger.py:37] Received request chatcmpl-f703d139b98149e6b2499d891ce49612: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different tricks does the man show inside the house?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:07 engine.py:267] Added request chatcmpl-f703d139b98149e6b2499d891ce49612.
INFO 12-25 13:11:08 logger.py:37] Received request chatcmpl-ed774c4ad9f544b981b7bea243e05ba1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, how many times is the paper folded before cutting by scissors?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:08 engine.py:267] Added request chatcmpl-ed774c4ad9f544b981b7bea243e05ba1.
INFO 12-25 13:11:10 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:13 logger.py:37] Received request chatcmpl-111c81d40ba04114b68403f2b096088c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many candle holders are made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:13 logger.py:37] Received request chatcmpl-463b43b25a154ab4b58697d35dc3d430: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, in what manner is the paper initially folded?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:13 engine.py:267] Added request chatcmpl-111c81d40ba04114b68403f2b096088c.
INFO 12-25 13:11:13 engine.py:267] Added request chatcmpl-463b43b25a154ab4b58697d35dc3d430.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:14 logger.py:37] Received request chatcmpl-797881bde5a24f79b229911ed2e84516: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the stage background where several male performers are holding long sticks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:14 engine.py:267] Added request chatcmpl-797881bde5a24f79b229911ed2e84516.
INFO 12-25 13:11:15 logger.py:37] Received request chatcmpl-381673291c154c05aeb06acf30d0f326: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the right order of actions the video encourages to do after finishing making a paper butterfly? (a) Click Likes. (b) Subscribe. (c) Set Notifications.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:15 engine.py:267] Added request chatcmpl-381673291c154c05aeb06acf30d0f326.
INFO 12-25 13:11:15 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 98.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:17 logger.py:37] Received request chatcmpl-eaef8a29df844612a0f6effbb9b275b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the chef in the video end up cutting with a knife?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:17 engine.py:267] Added request chatcmpl-eaef8a29df844612a0f6effbb9b275b2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:20 metrics.py:449] Avg prompt throughput: 30.6 tokens/s, Avg generation throughput: 136.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:11:20 logger.py:37] Received request chatcmpl-aabd2a64da524747a3babe58e7b209dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the objects next to the girl on the sticker of the orange cap?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:20 engine.py:267] Added request chatcmpl-aabd2a64da524747a3babe58e7b209dc.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:21 logger.py:37] Received request chatcmpl-e913b28dd1d44edfb8f1c9c4dd7cda11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which tool is not necessary to make a rubber band car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:21 engine.py:267] Added request chatcmpl-e913b28dd1d44edfb8f1c9c4dd7cda11.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:22 logger.py:37] Received request chatcmpl-a584fca1e64c4abdbf546e431763d965: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the last step that this video showcases to DIY a keychain using popsicle sticks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:22 engine.py:267] Added request chatcmpl-a584fca1e64c4abdbf546e431763d965.
INFO 12-25 13:11:23 logger.py:37] Received request chatcmpl-aeebbbc0a9074b74b9d64e9732a13378: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient in the video is not used as a decoration at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:23 engine.py:267] Added request chatcmpl-aeebbbc0a9074b74b9d64e9732a13378.
INFO 12-25 13:11:25 metrics.py:449] Avg prompt throughput: 55.6 tokens/s, Avg generation throughput: 114.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:27 logger.py:37] Received request chatcmpl-635f5bda9d654715ad23720fceb203a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which object does the holder made in this video visually resemble?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:27 engine.py:267] Added request chatcmpl-635f5bda9d654715ad23720fceb203a9.
INFO 12-25 13:11:28 logger.py:37] Received request chatcmpl-13106ec7505e424e95294d3766b10ac3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which food item is cut in half with a knife by the person in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:28 logger.py:37] Received request chatcmpl-bc608700ddb74bff80b9eb4a121cb6b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the scissors that are used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:28 engine.py:267] Added request chatcmpl-13106ec7505e424e95294d3766b10ac3.
INFO 12-25 13:11:28 engine.py:267] Added request chatcmpl-bc608700ddb74bff80b9eb4a121cb6b3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:30 logger.py:37] Received request chatcmpl-4a506fd4fe3a4f9f9769db232d9098a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following could have caused the dark spots in the mayonnaise?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:30 engine.py:267] Added request chatcmpl-4a506fd4fe3a4f9f9769db232d9098a0.
INFO 12-25 13:11:30 metrics.py:449] Avg prompt throughput: 53.3 tokens/s, Avg generation throughput: 97.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:34 logger.py:37] Received request chatcmpl-428433349a5648ffabc3f63fcb0e44be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is used first in the video to make this dish?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:34 engine.py:267] Added request chatcmpl-428433349a5648ffabc3f63fcb0e44be.
INFO 12-25 13:11:34 logger.py:37] Received request chatcmpl-320f17cdb5d14ac9a63e7d76ffad6b7f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the intended use or function of the needle used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:34 engine.py:267] Added request chatcmpl-320f17cdb5d14ac9a63e7d76ffad6b7f.
INFO 12-25 13:11:35 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 95.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:11:36 logger.py:37] Received request chatcmpl-a2788746dc23455ea38d613367d2c09c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason for cutting out the center of the pineapple slice in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:36 engine.py:267] Added request chatcmpl-a2788746dc23455ea38d613367d2c09c.
INFO 12-25 13:11:36 logger.py:37] Received request chatcmpl-354699cc599f41778bcaec7bfd9346c5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:36 engine.py:267] Added request chatcmpl-354699cc599f41778bcaec7bfd9346c5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:40 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 136.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:41 logger.py:37] Received request chatcmpl-e53c1d29bf2443d7a819f60ee128154e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of food is being prepared in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:41 logger.py:37] Received request chatcmpl-3de6e4a2ec1348dd9259341386a0000d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different kinds of animal faces are made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:41 engine.py:267] Added request chatcmpl-e53c1d29bf2443d7a819f60ee128154e.
INFO 12-25 13:11:41 engine.py:267] Added request chatcmpl-3de6e4a2ec1348dd9259341386a0000d.
INFO 12-25 13:11:42 logger.py:37] Received request chatcmpl-345373ed20e6438bb8bc65c972a3aaa6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many customers can be seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:42 engine.py:267] Added request chatcmpl-345373ed20e6438bb8bc65c972a3aaa6.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:44 logger.py:37] Received request chatcmpl-c6973262760c452facc32d349335bc9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the main ingredients in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:44 engine.py:267] Added request chatcmpl-c6973262760c452facc32d349335bc9a.
INFO 12-25 13:11:45 metrics.py:449] Avg prompt throughput: 50.2 tokens/s, Avg generation throughput: 109.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:49 logger.py:37] Received request chatcmpl-302e0914bb1d4c54bec494eec9f5c28c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many peppers can be seen on the plate in the video\'s final shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:49 engine.py:267] Added request chatcmpl-302e0914bb1d4c54bec494eec9f5c28c.
INFO 12-25 13:11:50 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 129.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:11:50 logger.py:37] Received request chatcmpl-11f59a24e8dd44c3a00351c5551443e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What common objects do the candle holders made in this video share?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:50 engine.py:267] Added request chatcmpl-11f59a24e8dd44c3a00351c5551443e2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:53 logger.py:37] Received request chatcmpl-ed6024a7f66b4d5e941bcf524ac704a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason for the crocodile in the video to grow taller?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:53 engine.py:267] Added request chatcmpl-ed6024a7f66b4d5e941bcf524ac704a5.
INFO 12-25 13:11:54 logger.py:37] Received request chatcmpl-221b16d77b3d4c25813b0cb4b8f705e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:54 engine.py:267] Added request chatcmpl-221b16d77b3d4c25813b0cb4b8f705e8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:55 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 122.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:11:56 logger.py:37] Received request chatcmpl-2b0c43821891488cab45114dd7ea9847: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:56 engine.py:267] Added request chatcmpl-2b0c43821891488cab45114dd7ea9847.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:11:58 logger.py:37] Received request chatcmpl-18fde8b28a6d446ca4e1e21a053e9d0e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the objective or purpose of this do-it-yourself (DIY) project?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:11:58 engine.py:267] Added request chatcmpl-18fde8b28a6d446ca4e1e21a053e9d0e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:00 logger.py:37] Received request chatcmpl-93042cfc0dbe446a89923b97214b8d98: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following cooking methods causes the smoke seen in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:00 engine.py:267] Added request chatcmpl-93042cfc0dbe446a89923b97214b8d98.
INFO 12-25 13:12:00 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:02 logger.py:37] Received request chatcmpl-a5f06012a9e54e0eb2bb9a6b241e6027: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the spoon used for mixing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:02 engine.py:267] Added request chatcmpl-a5f06012a9e54e0eb2bb9a6b241e6027.
INFO 12-25 13:12:02 logger.py:37] Received request chatcmpl-4dee6a5eb7634eb69f6356e344f4fb30: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which snack does the main character in the video prefer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:02 engine.py:267] Added request chatcmpl-4dee6a5eb7634eb69f6356e344f4fb30.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:05 logger.py:37] Received request chatcmpl-c62274eab5fd4d6ab2e6d85724bb71b1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the two butterflies made of paper?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:05 engine.py:267] Added request chatcmpl-c62274eab5fd4d6ab2e6d85724bb71b1.
INFO 12-25 13:12:05 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 120.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:08 logger.py:37] Received request chatcmpl-e42aaf21d1fd4933801e89d326d924f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the clothing worn by the individuals in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:08 logger.py:37] Received request chatcmpl-4fea73e269c64e389d4cc87028e44112: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:08 engine.py:267] Added request chatcmpl-e42aaf21d1fd4933801e89d326d924f3.
INFO 12-25 13:12:08 engine.py:267] Added request chatcmpl-4fea73e269c64e389d4cc87028e44112.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:10 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 109.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:10 logger.py:37] Received request chatcmpl-25c062fecf3f405ba9cd6a15a6564ede: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is written on the first made keychains?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:10 engine.py:267] Added request chatcmpl-25c062fecf3f405ba9cd6a15a6564ede.
INFO 12-25 13:12:10 logger.py:37] Received request chatcmpl-254906dd04a5401d8706a7fdaf7e2f2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the food in the video destroyed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:10 engine.py:267] Added request chatcmpl-254906dd04a5401d8706a7fdaf7e2f2e.
INFO 12-25 13:12:15 metrics.py:449] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 148.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:17 logger.py:37] Received request chatcmpl-33e9f30c0dfc4dfca2befa83b70217d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject matter of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:17 logger.py:37] Received request chatcmpl-afc48e4baab54dd49bba6d9b64b0ad8f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:17 engine.py:267] Added request chatcmpl-33e9f30c0dfc4dfca2befa83b70217d5.
INFO 12-25 13:12:17 engine.py:267] Added request chatcmpl-afc48e4baab54dd49bba6d9b64b0ad8f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:20 logger.py:37] Received request chatcmpl-05507dcb614f4e6db5f6d8305a4fb0d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the surface of the pepper in the video turn yellow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:20 engine.py:267] Added request chatcmpl-05507dcb614f4e6db5f6d8305a4fb0d8.
INFO 12-25 13:12:20 metrics.py:449] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 105.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:20 logger.py:37] Received request chatcmpl-08894678cae34c31af254094482ea8a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many earrings does the woman in the video have on her left ear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:20 engine.py:267] Added request chatcmpl-08894678cae34c31af254094482ea8a3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:24 logger.py:37] Received request chatcmpl-5cea11d00c784b978b75a48a2071b854: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What tool is used in the video to stir ingredients?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:24 logger.py:37] Received request chatcmpl-01797558c3374efb9519f48b30c2808e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the bicycle parked against the wall?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:24 engine.py:267] Added request chatcmpl-5cea11d00c784b978b75a48a2071b854.
INFO 12-25 13:12:24 engine.py:267] Added request chatcmpl-01797558c3374efb9519f48b30c2808e.
INFO 12-25 13:12:25 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 123.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:28 logger.py:37] Received request chatcmpl-dec8985283f644e09e21ee9667e0e333: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where was the video most likely shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:28 engine.py:267] Added request chatcmpl-dec8985283f644e09e21ee9667e0e333.
INFO 12-25 13:12:28 logger.py:37] Received request chatcmpl-4be719b92da14e2aa6344b3eeb602cd4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:28 engine.py:267] Added request chatcmpl-4be719b92da14e2aa6344b3eeb602cd4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:30 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:30 logger.py:37] Received request chatcmpl-8c85650fbfdb44ccac0b7dc61b02897e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the food in the video swell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:30 engine.py:267] Added request chatcmpl-8c85650fbfdb44ccac0b7dc61b02897e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:33 logger.py:37] Received request chatcmpl-6d6d6d1ccfc649e29b9adb4c5db1e12d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following objects is the pink satin high-heeled shoe placed on in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:33 engine.py:267] Added request chatcmpl-6d6d6d1ccfc649e29b9adb4c5db1e12d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:35 logger.py:37] Received request chatcmpl-bfd93f6d30664ae29bb7e1d1864f0b41: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the shoes worn by the boy with the white hat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:35 engine.py:267] Added request chatcmpl-bfd93f6d30664ae29bb7e1d1864f0b41.
INFO 12-25 13:12:35 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 133.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:41 logger.py:37] Received request chatcmpl-1ce8b01a88fa47a7acf1ef4c494121db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which dish is served last in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:41 logger.py:37] Received request chatcmpl-fda390f6c3884376a9104effbdd00a27: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which musical instrument did the man play upon entering the classroom?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:41 engine.py:267] Added request chatcmpl-1ce8b01a88fa47a7acf1ef4c494121db.
INFO 12-25 13:12:41 engine.py:267] Added request chatcmpl-fda390f6c3884376a9104effbdd00a27.
INFO 12-25 13:12:41 metrics.py:449] Avg prompt throughput: 9.9 tokens/s, Avg generation throughput: 89.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:41 logger.py:37] Received request chatcmpl-9bc7071d9b60460cb7e285e6c1b44ef5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second step in the production process?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:41 engine.py:267] Added request chatcmpl-9bc7071d9b60460cb7e285e6c1b44ef5.
INFO 12-25 13:12:42 logger.py:37] Received request chatcmpl-dea627b872984d9d8cc3dae37331c380: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many outfits did the male protagonist change in total in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:42 engine.py:267] Added request chatcmpl-dea627b872984d9d8cc3dae37331c380.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:45 logger.py:37] Received request chatcmpl-a42a64aca11f453aa606678717c203b7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the potential risks associated with exotic animal diseases according to the bulletin board in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:45 engine.py:267] Added request chatcmpl-a42a64aca11f453aa606678717c203b7.
INFO 12-25 13:12:46 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:46 logger.py:37] Received request chatcmpl-a717efd3207f4265b5004e96538b05e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What animal doesn\'t appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:46 engine.py:267] Added request chatcmpl-a717efd3207f4265b5004e96538b05e3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:49 logger.py:37] Received request chatcmpl-69a1f413012c4febb3e01299b6ee6cf7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the man speaking in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:49 engine.py:267] Added request chatcmpl-69a1f413012c4febb3e01299b6ee6cf7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:51 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 134.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:12:51 logger.py:37] Received request chatcmpl-5d3d03033b284dc380444e18d0ebfd37: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, how many people are there on the staircase along a coastal hillside?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:51 engine.py:267] Added request chatcmpl-5d3d03033b284dc380444e18d0ebfd37.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:53 logger.py:37] Received request chatcmpl-c130383f547345f482f1dac4de52454e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the correct order of cosmetics used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:53 engine.py:267] Added request chatcmpl-c130383f547345f482f1dac4de52454e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:56 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 139.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:57 logger.py:37] Received request chatcmpl-017239f0e5cd413cad6327ab8f03a0b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the people in the video eat potato chips?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:57 engine.py:267] Added request chatcmpl-017239f0e5cd413cad6327ab8f03a0b2.
INFO 12-25 13:12:57 logger.py:37] Received request chatcmpl-460a56b3c46e4aaa8690583bdf1fcc48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order of skincare products used before makeup in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:57 engine.py:267] Added request chatcmpl-460a56b3c46e4aaa8690583bdf1fcc48.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:12:59 logger.py:37] Received request chatcmpl-39a7d074e8c547ba8317a489cea52fe1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many items are stored in the box displayed at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:12:59 engine.py:267] Added request chatcmpl-39a7d074e8c547ba8317a489cea52fe1.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:01 logger.py:37] Received request chatcmpl-5ad3f8f76b9a44bd858b8805d77d7fe9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many outfits did the female protagonist change in total in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:01 engine.py:267] Added request chatcmpl-5ad3f8f76b9a44bd858b8805d77d7fe9.
INFO 12-25 13:13:01 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 118.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:03 logger.py:37] Received request chatcmpl-eaf273c9bb3f4d4fb4d6837eac2f4b12: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the total number of nominations received by the movie "Oppenheimer"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:03 engine.py:267] Added request chatcmpl-eaf273c9bb3f4d4fb4d6837eac2f4b12.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:06 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 132.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:07 logger.py:37] Received request chatcmpl-bce5cc075f594b32ad7f40068563ce01: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the laughing grandmother\'s attire in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:07 engine.py:267] Added request chatcmpl-bce5cc075f594b32ad7f40068563ce01.
INFO 12-25 13:13:07 logger.py:37] Received request chatcmpl-c03986518cb14375abfaa55c02234118: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where did the video take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:07 engine.py:267] Added request chatcmpl-c03986518cb14375abfaa55c02234118.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:09 logger.py:37] Received request chatcmpl-7021deda17e04dc48b587fc5879f608a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:09 engine.py:267] Added request chatcmpl-7021deda17e04dc48b587fc5879f608a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:11 metrics.py:449] Avg prompt throughput: 36.6 tokens/s, Avg generation throughput: 121.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:11 logger.py:37] Received request chatcmpl-8bbac6f345db4eeaa77f33e06c8e3cd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which daily activity is not shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:11 engine.py:267] Added request chatcmpl-8bbac6f345db4eeaa77f33e06c8e3cd8.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:18 logger.py:37] Received request chatcmpl-c47f1af2a1454bf99a8db3a991b333ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people in total can be seen in the video sitting at the table eating breakfast?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:18 engine.py:267] Added request chatcmpl-c47f1af2a1454bf99a8db3a991b333ab.
INFO 12-25 13:13:18 logger.py:37] Received request chatcmpl-4aaff1a06c374cd7a34b83e684c15ecf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the emotion of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:18 logger.py:37] Received request chatcmpl-f6af42d522f44869a5fffe2926689d2a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the woman\'s manicure in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:18 logger.py:37] Received request chatcmpl-f0344499f0724a01837b248ac4bbf792: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best describes the shape of the perfume bottle?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:18 engine.py:267] Added request chatcmpl-4aaff1a06c374cd7a34b83e684c15ecf.
INFO 12-25 13:13:18 engine.py:267] Added request chatcmpl-f6af42d522f44869a5fffe2926689d2a.
INFO 12-25 13:13:18 engine.py:267] Added request chatcmpl-f0344499f0724a01837b248ac4bbf792.
INFO 12-25 13:13:18 metrics.py:449] Avg prompt throughput: 18.0 tokens/s, Avg generation throughput: 87.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:23 metrics.py:449] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 152.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:24 logger.py:37] Received request chatcmpl-a647cb447b0048fba12d6658431a25e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what is the primary mode of transportation for the boys to get to school?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:24 engine.py:267] Added request chatcmpl-a647cb447b0048fba12d6658431a25e2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:28 logger.py:37] Received request chatcmpl-13762619af3b438eba34575e860ea0fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the number of the first lipstick she used?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:28 engine.py:267] Added request chatcmpl-13762619af3b438eba34575e860ea0fd.
INFO 12-25 13:13:28 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 131.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:29 logger.py:37] Received request chatcmpl-146ec669fd8941e7a968b8c123703c94: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the characteristics of the makeup in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:29 engine.py:267] Added request chatcmpl-146ec669fd8941e7a968b8c123703c94.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:31 logger.py:37] Received request chatcmpl-134b0954e63e42c19826e8f79be78708: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the woman in the video do after brushing her teeth?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:31 logger.py:37] Received request chatcmpl-de619d9cb7e748ceb2a03f34558ee324: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How long does it take for the girl in the video to get from home to work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:31 engine.py:267] Added request chatcmpl-134b0954e63e42c19826e8f79be78708.
INFO 12-25 13:13:31 engine.py:267] Added request chatcmpl-de619d9cb7e748ceb2a03f34558ee324.
INFO 12-25 13:13:33 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 119.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:37 logger.py:37] Received request chatcmpl-d3cc2b7057514c1a86bdef2fc939e158: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is used to apply eye cream in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:37 engine.py:267] Added request chatcmpl-d3cc2b7057514c1a86bdef2fc939e158.
INFO 12-25 13:13:38 logger.py:37] Received request chatcmpl-30a952ee90b04ecbabaccab41eee3e2d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first thing the heroine in the video does after going out in the morning?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:38 engine.py:267] Added request chatcmpl-30a952ee90b04ecbabaccab41eee3e2d.
INFO 12-25 13:13:38 logger.py:37] Received request chatcmpl-71fa40f3c5e441868fd681e77542dd04: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item did not appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:38 logger.py:37] Received request chatcmpl-4d689651c5b24c9a810132989a14ffeb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the woman wearing when standing in front of the mirror?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:38 engine.py:267] Added request chatcmpl-71fa40f3c5e441868fd681e77542dd04.
INFO 12-25 13:13:38 engine.py:267] Added request chatcmpl-4d689651c5b24c9a810132989a14ffeb.
INFO 12-25 13:13:38 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 78.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:43 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 157.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:46 logger.py:37] Received request chatcmpl-05627363076942218c14d2245ff6d7ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which topic does the video cover?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:46 logger.py:37] Received request chatcmpl-b41afad1615542119a83d72c51ec98a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which outfit is the male protagonist wearing on the train in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:46 logger.py:37] Received request chatcmpl-39a6833fbdcf4496a4da7ad453f58e1d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What country is the lady in the video from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:46 engine.py:267] Added request chatcmpl-05627363076942218c14d2245ff6d7ac.
INFO 12-25 13:13:46 engine.py:267] Added request chatcmpl-b41afad1615542119a83d72c51ec98a0.
INFO 12-25 13:13:46 engine.py:267] Added request chatcmpl-39a6833fbdcf4496a4da7ad453f58e1d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:48 metrics.py:449] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 92.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:49 logger.py:37] Received request chatcmpl-910a3ee03e664b0b9d167c9a88ac563c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:49 engine.py:267] Added request chatcmpl-910a3ee03e664b0b9d167c9a88ac563c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:51 logger.py:37] Received request chatcmpl-bd287edd9f3a4dc98eb3682d33bb2275: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the woman wearing with a light green striped handbag in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:51 logger.py:37] Received request chatcmpl-43a1595f864149b3b522838251c09e32: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the woman sitting on the floor ready to do at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:51 engine.py:267] Added request chatcmpl-bd287edd9f3a4dc98eb3682d33bb2275.
INFO 12-25 13:13:51 engine.py:267] Added request chatcmpl-43a1595f864149b3b522838251c09e32.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:54 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 111.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:13:55 logger.py:37] Received request chatcmpl-810389cd258b48ca8344b4b60ef2909b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are shown having lunch with the woman in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:55 logger.py:37] Received request chatcmpl-3a363b0e75e1476c88d9034dd217c67d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of these tests does the lady shown in the video perform on the patient NOT include?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:55 engine.py:267] Added request chatcmpl-810389cd258b48ca8344b4b60ef2909b.
INFO 12-25 13:13:55 engine.py:267] Added request chatcmpl-3a363b0e75e1476c88d9034dd217c67d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:58 logger.py:37] Received request chatcmpl-6209997e3c444a6ab1ad093afe59c1e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, at what time do classes begin at the boys\' school?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:58 engine.py:267] Added request chatcmpl-6209997e3c444a6ab1ad093afe59c1e5.
INFO 12-25 13:13:59 metrics.py:449] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 115.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:13:59 logger.py:37] Received request chatcmpl-7a66bc0c6e4e44d8a34674a264bc230c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the sponge ball used for applying foundation in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:13:59 engine.py:267] Added request chatcmpl-7a66bc0c6e4e44d8a34674a264bc230c.
INFO 12-25 13:14:00 logger.py:37] Received request chatcmpl-d94aa0a233c249d0851e96eb070a816e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What mode of transportation does the man in the video use to go out?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:00 engine.py:267] Added request chatcmpl-d94aa0a233c249d0851e96eb070a816e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:02 logger.py:37] Received request chatcmpl-dc94d093aa7d43a5abb96db3bb9dd1bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time does the man in the video get up?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:02 engine.py:267] Added request chatcmpl-dc94d093aa7d43a5abb96db3bb9dd1bc.
INFO 12-25 13:14:04 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 126.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:05 logger.py:37] Received request chatcmpl-50324ea90c6842a492aaf523a5910e38: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of transportation does the boy in the video take to and from school?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:05 logger.py:37] Received request chatcmpl-22b23a9cefd14092a1d234f4bdae6f6c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the pregnant woman wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:05 engine.py:267] Added request chatcmpl-50324ea90c6842a492aaf523a5910e38.
INFO 12-25 13:14:05 engine.py:267] Added request chatcmpl-22b23a9cefd14092a1d234f4bdae6f6c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:08 logger.py:37] Received request chatcmpl-49643cff0d064ae8aacf99be73ac152f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the person in the video do after brushing his teeth?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:08 engine.py:267] Added request chatcmpl-49643cff0d064ae8aacf99be73ac152f.
INFO 12-25 13:14:09 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:11 logger.py:37] Received request chatcmpl-9f6a77bd0271491594b7236d1c191709: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of cell phone is the person in the video using?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:11 engine.py:267] Added request chatcmpl-9f6a77bd0271491594b7236d1c191709.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:12 logger.py:37] Received request chatcmpl-eaafce898b2e4691992827d75df37496: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many meals did the woman in the video have with other people?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:12 engine.py:267] Added request chatcmpl-eaafce898b2e4691992827d75df37496.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:14 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:14:14 logger.py:37] Received request chatcmpl-950489fd80bd4cca974b8d806fa49936: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity does the protagonist not engage in?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:14 engine.py:267] Added request chatcmpl-950489fd80bd4cca974b8d806fa49936.
INFO 12-25 13:14:15 logger.py:37] Received request chatcmpl-5f45e2fd98814435884c8fe9bc61f7ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the capacity of the refill if the capacity of a bottle of perfume is 50mL?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:15 engine.py:267] Added request chatcmpl-5f45e2fd98814435884c8fe9bc61f7ca.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:19 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 124.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:14:19 logger.py:37] Received request chatcmpl-44894c0dacc7445fbbb9198b9fe6ea5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:19 engine.py:267] Added request chatcmpl-44894c0dacc7445fbbb9198b9fe6ea5b.
INFO 12-25 13:14:20 logger.py:37] Received request chatcmpl-065af2175b0f41dfac2181d04669c735: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color shirt is the protagonist wearing when he speaks in the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:20 engine.py:267] Added request chatcmpl-065af2175b0f41dfac2181d04669c735.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:22 logger.py:37] Received request chatcmpl-2831ee5f56084c57a225da650d8d02a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of street performance is showcased in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:22 logger.py:37] Received request chatcmpl-c2fff4b28fd2469a86da0de163ac8008: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After cleaning her floor in the video, what did the woman do next?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:22 engine.py:267] Added request chatcmpl-2831ee5f56084c57a225da650d8d02a5.
INFO 12-25 13:14:22 engine.py:267] Added request chatcmpl-c2fff4b28fd2469a86da0de163ac8008.
INFO 12-25 13:14:24 metrics.py:449] Avg prompt throughput: 51.1 tokens/s, Avg generation throughput: 114.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:25 logger.py:37] Received request chatcmpl-b272862097f7402da12c3aed8f353572: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the shoes the man in the video is wearing during his run?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:25 engine.py:267] Added request chatcmpl-b272862097f7402da12c3aed8f353572.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:28 logger.py:37] Received request chatcmpl-8417cc9c44bb4279b4b68d74749bcb1c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people join in a toast at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:28 logger.py:37] Received request chatcmpl-ca8d042da00046f6991d58a5f543c2e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the mode of transportation for the woman in the video to get to work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:28 engine.py:267] Added request chatcmpl-8417cc9c44bb4279b4b68d74749bcb1c.
INFO 12-25 13:14:28 engine.py:267] Added request chatcmpl-ca8d042da00046f6991d58a5f543c2e8.
INFO 12-25 13:14:29 metrics.py:449] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 107.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:14:29 logger.py:37] Received request chatcmpl-7ea3ab3a27c74d2abc1e45f0ef945f56: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:29 engine.py:267] Added request chatcmpl-7ea3ab3a27c74d2abc1e45f0ef945f56.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:32 logger.py:37] Received request chatcmpl-fbd3db0908654ff1a74ac691dae05f68: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which activity is not shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:32 engine.py:267] Added request chatcmpl-fbd3db0908654ff1a74ac691dae05f68.
INFO 12-25 13:14:34 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 143.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:35 logger.py:37] Received request chatcmpl-bfcb2ea44be142a19112e55125f5d1bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second class the boys are taking in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:35 engine.py:267] Added request chatcmpl-bfcb2ea44be142a19112e55125f5d1bd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:36 logger.py:37] Received request chatcmpl-c77a7d54b0b2457b8245aa4bef22d404: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country is the main character in the video most likely to travel to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:36 engine.py:267] Added request chatcmpl-c77a7d54b0b2457b8245aa4bef22d404.
INFO 12-25 13:14:37 logger.py:37] Received request chatcmpl-9db564ed7b4b403584f9bfe7381c4f15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what does the man\'s facial expression look like when he sees the scorpion skewer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:37 engine.py:267] Added request chatcmpl-9db564ed7b4b403584f9bfe7381c4f15.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:39 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 106.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:14:39 logger.py:37] Received request chatcmpl-63ec5b53c14441548275a9501147b671: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What feature of the cell phone did the person in the video use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:39 engine.py:267] Added request chatcmpl-63ec5b53c14441548275a9501147b671.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:42 logger.py:37] Received request chatcmpl-14780b7f1981451f96d222bb402e4cda: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which city is the video showcasing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:42 engine.py:267] Added request chatcmpl-14780b7f1981451f96d222bb402e4cda.
INFO 12-25 13:14:43 logger.py:37] Received request chatcmpl-dc59fbce729c4751a7a69377039152f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What scenery does the video mainly show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:43 engine.py:267] Added request chatcmpl-dc59fbce729c4751a7a69377039152f8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:44 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 120.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:45 logger.py:37] Received request chatcmpl-4680f8ac86ba4d9ebe14f9e238e95352: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where did the heroine in the video change into high heels?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:45 engine.py:267] Added request chatcmpl-4680f8ac86ba4d9ebe14f9e238e95352.
INFO 12-25 13:14:46 logger.py:37] Received request chatcmpl-4e561c9ae5224119b8e1bcdb768f6c1f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of transport does the protagonist in the video take to set off?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:46 engine.py:267] Added request chatcmpl-4e561c9ae5224119b8e1bcdb768f6c1f.
INFO 12-25 13:14:49 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 137.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:51 logger.py:37] Received request chatcmpl-d17ef22e86e14bd2b8ecaaf35ade200b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color clothing is the protagonist wearing while carrying a tripod over his shoulder?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:51 engine.py:267] Added request chatcmpl-d17ef22e86e14bd2b8ecaaf35ade200b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:52 logger.py:37] Received request chatcmpl-6feaf9a3e17f43e6a42a1b82168529a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which hair color does the little boy have while playing the guitar in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:52 engine.py:267] Added request chatcmpl-6feaf9a3e17f43e6a42a1b82168529a5.
INFO 12-25 13:14:53 logger.py:37] Received request chatcmpl-a272c20bcdee47319efb6667311d03c5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the lady\'s mode of transport to work in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:53 logger.py:37] Received request chatcmpl-395def263b0d4959b67d873d31592809: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which building does the protagonist capture on his phone in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:53 engine.py:267] Added request chatcmpl-a272c20bcdee47319efb6667311d03c5.
INFO 12-25 13:14:53 engine.py:267] Added request chatcmpl-395def263b0d4959b67d873d31592809.
INFO 12-25 13:14:54 metrics.py:449] Avg prompt throughput: 53.2 tokens/s, Avg generation throughput: 92.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:57 logger.py:37] Received request chatcmpl-d8e8693c85cf43be854b0e468e1e8611: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the weather like when the family goes out?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:57 engine.py:267] Added request chatcmpl-d8e8693c85cf43be854b0e468e1e8611.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:58 logger.py:37] Received request chatcmpl-d4ea48b92986440187b5d46f4747574c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What activities does the protagonist do with his friends in the snow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:58 engine.py:267] Added request chatcmpl-d4ea48b92986440187b5d46f4747574c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:14:59 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 119.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:14:59 logger.py:37] Received request chatcmpl-dc9fc2112c334f039800f2b32c421d92: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following items is the man in the video doing at the gym?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:14:59 engine.py:267] Added request chatcmpl-dc9fc2112c334f039800f2b32c421d92.
INFO 12-25 13:15:00 logger.py:37] Received request chatcmpl-13bf378eab9d40d7b086e44931ba3414: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What camera does the protagonist in the video use to shoot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:00 engine.py:267] Added request chatcmpl-13bf378eab9d40d7b086e44931ba3414.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:03 logger.py:37] Received request chatcmpl-8435a883eee14fdf9b37818691e22972: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the total number of baby birds shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:03 engine.py:267] Added request chatcmpl-8435a883eee14fdf9b37818691e22972.
INFO 12-25 13:15:03 logger.py:37] Received request chatcmpl-7eb404c4caa34a4b9100f5d1a456ea41: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most likely role of the blonde woman in the video, clad in a blue T-shirt and black shorts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:03 engine.py:267] Added request chatcmpl-7eb404c4caa34a4b9100f5d1a456ea41.
INFO 12-25 13:15:04 metrics.py:449] Avg prompt throughput: 54.5 tokens/s, Avg generation throughput: 105.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:08 logger.py:37] Received request chatcmpl-5bc69a46a0d7451389aef7892089618f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man shown in the video do after swimming?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:08 engine.py:267] Added request chatcmpl-5bc69a46a0d7451389aef7892089618f.
INFO 12-25 13:15:09 logger.py:37] Received request chatcmpl-62fd226281b84e3a99208a50f3856cb8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What food is the child eating in the video when the family is dining at a restaurant?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:09 engine.py:267] Added request chatcmpl-62fd226281b84e3a99208a50f3856cb8.
INFO 12-25 13:15:09 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:10 logger.py:37] Received request chatcmpl-e8fc92cbb199446c87417216de425018: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people have their backs to the camera in the sunset scene?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:10 engine.py:267] Added request chatcmpl-e8fc92cbb199446c87417216de425018.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:14 logger.py:37] Received request chatcmpl-7cad9c6998c6451d8f18644b5ab6a43f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which region is the most likely destination of the subject in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:14 engine.py:267] Added request chatcmpl-7cad9c6998c6451d8f18644b5ab6a43f.
INFO 12-25 13:15:14 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 123.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:15:14 logger.py:37] Received request chatcmpl-71dbe3289def41eea05a7cd9fd3a3dbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:14 engine.py:267] Added request chatcmpl-71dbe3289def41eea05a7cd9fd3a3dbe.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:19 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 144.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:15:19 logger.py:37] Received request chatcmpl-e5836307a4dd46249a76dfd25d1b790e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the train in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:19 engine.py:267] Added request chatcmpl-e5836307a4dd46249a76dfd25d1b790e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:24 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:15:24 logger.py:37] Received request chatcmpl-57528aa419dc41339a426e037dbe6de6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the bunny in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:24 logger.py:37] Received request chatcmpl-d931957b13b749f3ad37b26a69403872: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following topics is the most likely focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:24 engine.py:267] Added request chatcmpl-57528aa419dc41339a426e037dbe6de6.
INFO 12-25 13:15:24 engine.py:267] Added request chatcmpl-d931957b13b749f3ad37b26a69403872.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:25 logger.py:37] Received request chatcmpl-4b4197d1c8354dacb0602bc26fde1bd0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "During which season does the protagonists in the video probably set out?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:25 engine.py:267] Added request chatcmpl-4b4197d1c8354dacb0602bc26fde1bd0.
INFO 12-25 13:15:26 logger.py:37] Received request chatcmpl-730eb770ca334f068d1554be2803befc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the animal in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:26 engine.py:267] Added request chatcmpl-730eb770ca334f068d1554be2803befc.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:29 metrics.py:449] Avg prompt throughput: 50.2 tokens/s, Avg generation throughput: 121.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:30 logger.py:37] Received request chatcmpl-c798ec5ea33f45bdb1cf3584dc85b869: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "To which location does the person in the video travel in Australia?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:30 engine.py:267] Added request chatcmpl-c798ec5ea33f45bdb1cf3584dc85b869.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:31 logger.py:37] Received request chatcmpl-e7f097be0e464c2bafd7b046ba883539: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where are the final scenes in the video most likely shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:31 engine.py:267] Added request chatcmpl-e7f097be0e464c2bafd7b046ba883539.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:33 logger.py:37] Received request chatcmpl-d6185280847f44f68a447d98267bd1c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the person do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:33 engine.py:267] Added request chatcmpl-d6185280847f44f68a447d98267bd1c9.
INFO 12-25 13:15:34 logger.py:37] Received request chatcmpl-c680d401f2cb48b58777aae2c3269cf1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the bunny\'s behavior after being placed on the ground?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:34 engine.py:267] Added request chatcmpl-c680d401f2cb48b58777aae2c3269cf1.
INFO 12-25 13:15:34 metrics.py:449] Avg prompt throughput: 50.8 tokens/s, Avg generation throughput: 101.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:38 logger.py:37] Received request chatcmpl-8d026fddaa8444788ba86a74a6bea05f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the lateral distance of the Buddha in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:38 engine.py:267] Added request chatcmpl-8d026fddaa8444788ba86a74a6bea05f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:39 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 144.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:41 logger.py:37] Received request chatcmpl-7a76499839bc4725a27289e3ed57f96d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do these animals do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:41 logger.py:37] Received request chatcmpl-345fbd01933c4e7aaca2a56f05b2790c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the animal do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:41 engine.py:267] Added request chatcmpl-7a76499839bc4725a27289e3ed57f96d.
INFO 12-25 13:15:41 engine.py:267] Added request chatcmpl-345fbd01933c4e7aaca2a56f05b2790c.
INFO 12-25 13:15:42 logger.py:37] Received request chatcmpl-da1e5f6340c74bd6befd1c09ed9c79f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is this video most likely shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:42 engine.py:267] Added request chatcmpl-da1e5f6340c74bd6befd1c09ed9c79f1.
INFO 12-25 13:15:44 metrics.py:449] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 108.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:49 logger.py:37] Received request chatcmpl-876c4c9149084be3b30c88feeccac01b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the animal in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:49 engine.py:267] Added request chatcmpl-876c4c9149084be3b30c88feeccac01b.
INFO 12-25 13:15:49 logger.py:37] Received request chatcmpl-e5662747f0de4db2aa64a55c81710f6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how many airboxes can be observed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:49 logger.py:37] Received request chatcmpl-63aaf84a018442029041fc0979c11e14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people in the video doing in the lake?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:49 engine.py:267] Added request chatcmpl-e5662747f0de4db2aa64a55c81710f6f.
INFO 12-25 13:15:49 engine.py:267] Added request chatcmpl-63aaf84a018442029041fc0979c11e14.
INFO 12-25 13:15:49 metrics.py:449] Avg prompt throughput: 10.8 tokens/s, Avg generation throughput: 92.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:15:50 logger.py:37] Received request chatcmpl-11da93286aed45fa8ef837bccc89a78f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the shape of its nose?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:50 engine.py:267] Added request chatcmpl-11da93286aed45fa8ef837bccc89a78f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:54 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 144.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:15:55 logger.py:37] Received request chatcmpl-68a86d7aedff4c8eb528ad5973d418d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many main tourists are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:55 engine.py:267] Added request chatcmpl-68a86d7aedff4c8eb528ad5973d418d6.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:15:57 logger.py:37] Received request chatcmpl-b67492f67d154f79bfc34eea10601394: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the animals in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:57 logger.py:37] Received request chatcmpl-dd34254538ee4f358feeb8a3a63b358c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the animal do to the glove in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:15:57 engine.py:267] Added request chatcmpl-b67492f67d154f79bfc34eea10601394.
INFO 12-25 13:15:57 engine.py:267] Added request chatcmpl-dd34254538ee4f358feeb8a3a63b358c.
INFO 12-25 13:15:59 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:01 logger.py:37] Received request chatcmpl-06148678edd64c4a89b47d295416f030: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the animal in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:01 engine.py:267] Added request chatcmpl-06148678edd64c4a89b47d295416f030.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:04 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 143.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:05 logger.py:37] Received request chatcmpl-9a27a3d61a89466c819cf21641718d85: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the behavior of the fox when a person appears in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:05 engine.py:267] Added request chatcmpl-9a27a3d61a89466c819cf21641718d85.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:08 logger.py:37] Received request chatcmpl-e01f9e990dc74bfab1f0956af42e80ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are in the family that is playing with a dog at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:08 engine.py:267] Added request chatcmpl-e01f9e990dc74bfab1f0956af42e80ca.
INFO 12-25 13:16:08 logger.py:37] Received request chatcmpl-25c47b4c2f604146985926c94d905fbf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what manner do the children in the video get transported by their parents?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:08 engine.py:267] Added request chatcmpl-25c47b4c2f604146985926c94d905fbf.
INFO 12-25 13:16:09 logger.py:37] Received request chatcmpl-2cbc311b161e47fa9384be23e84a0a6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is this video most likely shot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:09 engine.py:267] Added request chatcmpl-2cbc311b161e47fa9384be23e84a0a6d.
INFO 12-25 13:16:09 metrics.py:449] Avg prompt throughput: 53.2 tokens/s, Avg generation throughput: 102.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:12 logger.py:37] Received request chatcmpl-9bdef11f52fc4fa9929ede7773a4416c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which kind of pets is not introduced in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:12 engine.py:267] Added request chatcmpl-9bdef11f52fc4fa9929ede7773a4416c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:14 logger.py:37] Received request chatcmpl-40d1db2469eb44d7a9b58c90a96a9c33: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who finishes training first in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:14 engine.py:267] Added request chatcmpl-40d1db2469eb44d7a9b58c90a96a9c33.
INFO 12-25 13:16:14 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 116.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:15 logger.py:37] Received request chatcmpl-1a37fd481577462189e576d1680cf223: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the protagonist of the video most likely reach their destination?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:15 engine.py:267] Added request chatcmpl-1a37fd481577462189e576d1680cf223.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:17 logger.py:37] Received request chatcmpl-5ceaaba69cba47f58262a90f2e9aa323: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the animal in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:17 engine.py:267] Added request chatcmpl-5ceaaba69cba47f58262a90f2e9aa323.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:19 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 129.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:20 logger.py:37] Received request chatcmpl-c4d121c6eebf44e7aad7a5667100357e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What exercise is the woman in black doing at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:20 engine.py:267] Added request chatcmpl-c4d121c6eebf44e7aad7a5667100357e.
INFO 12-25 13:16:21 logger.py:37] Received request chatcmpl-f4e9e173b1434dc1ba806c81e840965e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people were exercising in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:21 logger.py:37] Received request chatcmpl-4988a42ad9d94290aa11e6d038da79fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following accurately describes the events depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:21 engine.py:267] Added request chatcmpl-f4e9e173b1434dc1ba806c81e840965e.
INFO 12-25 13:16:21 engine.py:267] Added request chatcmpl-4988a42ad9d94290aa11e6d038da79fa.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:24 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 118.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:25 logger.py:37] Received request chatcmpl-3a0dd18a79b047279a7fd34a62f0ff42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many foxes appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:25 engine.py:267] Added request chatcmpl-3a0dd18a79b047279a7fd34a62f0ff42.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:26 logger.py:37] Received request chatcmpl-b8d8c2e15c7d4b11b8262c573094e8c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which training exercise in the video does the man perform with the assistance of an elastic rope?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:26 engine.py:267] Added request chatcmpl-b8d8c2e15c7d4b11b8262c573094e8c0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:29 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:30 logger.py:37] Received request chatcmpl-82321847cf0e4765bde15cbc5e6a5b2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the first bunny hide?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:30 logger.py:37] Received request chatcmpl-a73781862b6e4830be990e247d78a528: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times did the man in the video with no shirt on his upper body race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:30 engine.py:267] Added request chatcmpl-82321847cf0e4765bde15cbc5e6a5b2e.
INFO 12-25 13:16:30 engine.py:267] Added request chatcmpl-a73781862b6e4830be990e247d78a528.
INFO 12-25 13:16:31 logger.py:37] Received request chatcmpl-da22e8a7f3744130aebad02134d067a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subsequent move demonstrated in the video after completing the demonstration of box jumps?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:31 engine.py:267] Added request chatcmpl-da22e8a7f3744130aebad02134d067a9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:33 logger.py:37] Received request chatcmpl-d72162e83f8041d4835176bb0b37027c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the animal do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:33 engine.py:267] Added request chatcmpl-d72162e83f8041d4835176bb0b37027c.
INFO 12-25 13:16:34 metrics.py:449] Avg prompt throughput: 51.7 tokens/s, Avg generation throughput: 125.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:38 logger.py:37] Received request chatcmpl-6f45888779644386afbbff237645ff85: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main ability to compete in the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:38 engine.py:267] Added request chatcmpl-6f45888779644386afbbff237645ff85.
INFO 12-25 13:16:38 logger.py:37] Received request chatcmpl-c9ac6c1b608445cd8b1fd0185f1851ba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many animals appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:38 logger.py:37] Received request chatcmpl-752c6052753742bc897d977b7fb39604: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the person in the background, wearing a white top and black shorts, doing while the person in pink is speaking at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:38 engine.py:267] Added request chatcmpl-c9ac6c1b608445cd8b1fd0185f1851ba.
INFO 12-25 13:16:38 engine.py:267] Added request chatcmpl-752c6052753742bc897d977b7fb39604.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:39 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 100.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:41 logger.py:37] Received request chatcmpl-ffa1bd8651014bd8a0070d07a6e53187: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color of fish is absent from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:41 engine.py:267] Added request chatcmpl-ffa1bd8651014bd8a0070d07a6e53187.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:44 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 136.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:16:45 logger.py:37] Received request chatcmpl-df5769fe9b02458ab8bf8161c5c1c4f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the participant need to place his/her hand during the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:45 engine.py:267] Added request chatcmpl-df5769fe9b02458ab8bf8161c5c1c4f3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:48 logger.py:37] Received request chatcmpl-261d6c9255984d80b7e05d197292abd9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the posture of the bunny?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:48 engine.py:267] Added request chatcmpl-261d6c9255984d80b7e05d197292abd9.
INFO 12-25 13:16:49 logger.py:37] Received request chatcmpl-69441d8991154c34a3b332b942e3993c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which training exercise was not demonstrated in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:49 logger.py:37] Received request chatcmpl-407df55bba864b63838479c0bdbbf094: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who of the two people competing in the second group in the video reaches the finish line first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:49 engine.py:267] Added request chatcmpl-69441d8991154c34a3b332b942e3993c.
INFO 12-25 13:16:49 engine.py:267] Added request chatcmpl-407df55bba864b63838479c0bdbbf094.
INFO 12-25 13:16:49 metrics.py:449] Avg prompt throughput: 52.1 tokens/s, Avg generation throughput: 108.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:52 logger.py:37] Received request chatcmpl-6f7ed3639a044feeaf3dd670da96abf3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How long does the video recommend performing the third introduced move at the beginning?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:53 engine.py:267] Added request chatcmpl-6f7ed3639a044feeaf3dd670da96abf3.
INFO 12-25 13:16:54 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 141.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:16:56 logger.py:37] Received request chatcmpl-e5a071cb3e09457cb82a6c6f49456cbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the cat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:56 engine.py:267] Added request chatcmpl-e5a071cb3e09457cb82a6c6f49456cbe.
INFO 12-25 13:16:57 logger.py:37] Received request chatcmpl-5297d6e3300947678e4fa0c0bffc41d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the main speaker during the latter half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:57 engine.py:267] Added request chatcmpl-5297d6e3300947678e4fa0c0bffc41d2.
INFO 12-25 13:16:58 logger.py:37] Received request chatcmpl-3737be129fb24e64a500a5338a7e73d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:58 engine.py:267] Added request chatcmpl-3737be129fb24e64a500a5338a7e73d6.
INFO 12-25 13:16:59 logger.py:37] Received request chatcmpl-a64d5667f8d741f290af99c5ca76c0fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which sport is not featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:16:59 engine.py:267] Added request chatcmpl-a64d5667f8d741f290af99c5ca76c0fc.
INFO 12-25 13:16:59 metrics.py:449] Avg prompt throughput: 48.9 tokens/s, Avg generation throughput: 93.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:02 logger.py:37] Received request chatcmpl-71f90cb11aaf429f9af1defed30bc485: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the foxes in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:02 engine.py:267] Added request chatcmpl-71f90cb11aaf429f9af1defed30bc485.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:04 logger.py:37] Received request chatcmpl-57e7fc8871784bbca46989dfe2604c29: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many sit-ups did the man in the video, wearing a pink top and black pants, perform?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:04 logger.py:37] Received request chatcmpl-da992f66495d4497a2c399eabafde563: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What were the movements of the individuals in the video during the competition process?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:04 engine.py:267] Added request chatcmpl-57e7fc8871784bbca46989dfe2604c29.
INFO 12-25 13:17:04 engine.py:267] Added request chatcmpl-da992f66495d4497a2c399eabafde563.
INFO 12-25 13:17:04 metrics.py:449] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:05 logger.py:37] Received request chatcmpl-8d9be0e76733490d8e32c874fec84172: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the job of the male protagonist in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:05 engine.py:267] Added request chatcmpl-8d9be0e76733490d8e32c874fec84172.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:09 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 139.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:10 logger.py:37] Received request chatcmpl-a481496884d043aab96a01bf1efb2eb5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many sets of jumps did the two men do in total at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:10 engine.py:267] Added request chatcmpl-a481496884d043aab96a01bf1efb2eb5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:11 logger.py:37] Received request chatcmpl-4dafe2d1a0634251a2da08f61ffdc224: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the team wearing green perform in the game shown in the video compared to their game against the team in red that took place 10 years ago?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:11 engine.py:267] Added request chatcmpl-4dafe2d1a0634251a2da08f61ffdc224.
INFO 12-25 13:17:12 logger.py:37] Received request chatcmpl-428a51ad402548dfb406523a79558b57: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time of day is depicted in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:12 engine.py:267] Added request chatcmpl-428a51ad402548dfb406523a79558b57.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:14 metrics.py:449] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 111.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:15 logger.py:37] Received request chatcmpl-c68997df8aa346dca518dd228a417bb7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the exercise demonstrated after the squatting exercise in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:15 engine.py:267] Added request chatcmpl-c68997df8aa346dca518dd228a417bb7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:17 logger.py:37] Received request chatcmpl-8dfb8971fc9c45b39c9af430960eb25e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which part of their body do they not need to touch during the movement prior to grabbing the conical object?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:17 engine.py:267] Added request chatcmpl-8dfb8971fc9c45b39c9af430960eb25e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:19 logger.py:37] Received request chatcmpl-469f73ddaf8b4f9d9b34996af9c719b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When receiving what instruction in the video, the movement needs to be stopped?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:19 engine.py:267] Added request chatcmpl-469f73ddaf8b4f9d9b34996af9c719b9.
INFO 12-25 13:17:19 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:20 logger.py:37] Received request chatcmpl-30488d5c2f2944968463b801b7ca7a99: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What game are they playing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:20 engine.py:267] Added request chatcmpl-30488d5c2f2944968463b801b7ca7a99.
INFO 12-25 13:17:21 logger.py:37] Received request chatcmpl-41d9f455e0d949848029a98755c5dd50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is Ms. Milani\'s boss\' clothing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:21 engine.py:267] Added request chatcmpl-41d9f455e0d949848029a98755c5dd50.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:24 logger.py:37] Received request chatcmpl-2f03a7de9773453e97a8c7dfa36ff607: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the last to reach the finish line at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:24 engine.py:267] Added request chatcmpl-2f03a7de9773453e97a8c7dfa36ff607.
INFO 12-25 13:17:25 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 121.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:27 logger.py:37] Received request chatcmpl-90abce78e3a14fcf965b1dd4cde20fdb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many games are played in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:27 engine.py:267] Added request chatcmpl-90abce78e3a14fcf965b1dd4cde20fdb.
INFO 12-25 13:17:28 logger.py:37] Received request chatcmpl-10d84548fac047e8946b877d491a571e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What mode of transportation does the male protagonist use to get home from work according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:28 engine.py:267] Added request chatcmpl-10d84548fac047e8946b877d491a571e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:30 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 127.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:30 logger.py:37] Received request chatcmpl-b4229bacfd4240d5b9ddd17e4b0c746e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are on each team in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:30 engine.py:267] Added request chatcmpl-b4229bacfd4240d5b9ddd17e4b0c746e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:32 logger.py:37] Received request chatcmpl-cc49a442a7d4465bba3b4f391ea3b3b8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the statements is not in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:32 engine.py:267] Added request chatcmpl-cc49a442a7d4465bba3b4f391ea3b3b8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:34 logger.py:37] Received request chatcmpl-ffbd1e6d8d31480aa9a4e7b18f4ab7fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, how did China score their goals in the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:34 engine.py:267] Added request chatcmpl-ffbd1e6d8d31480aa9a4e7b18f4ab7fc.
INFO 12-25 13:17:35 metrics.py:449] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:35 logger.py:37] Received request chatcmpl-d50fd5857bba492f951c372d8902bda7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the sport of skipping appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:35 engine.py:267] Added request chatcmpl-d50fd5857bba492f951c372d8902bda7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:40 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:40 logger.py:37] Received request chatcmpl-11538af4f68c49479197251f6d96bbed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the man feel about the food?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:40 engine.py:267] Added request chatcmpl-11538af4f68c49479197251f6d96bbed.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:41 logger.py:37] Received request chatcmpl-3bc4e57fba1e4f93afaddf0b8b91beb2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothes does the performer wear during the spider magic act?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:41 engine.py:267] Added request chatcmpl-3bc4e57fba1e4f93afaddf0b8b91beb2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:42 logger.py:37] Received request chatcmpl-faab41ee52ee471dad34662bf83c8c3b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which mode of transportation is not shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:42 engine.py:267] Added request chatcmpl-faab41ee52ee471dad34662bf83c8c3b.
INFO 12-25 13:17:43 logger.py:37] Received request chatcmpl-7fb421d722b249b98bfb1d756dda5d41: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different types of sports equipment were demonstrated in detail by the people in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:43 engine.py:267] Added request chatcmpl-7fb421d722b249b98bfb1d756dda5d41.
INFO 12-25 13:17:45 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 124.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:46 logger.py:37] Received request chatcmpl-cafa230015b34edaae9c57ed90d81407: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:46 engine.py:267] Added request chatcmpl-cafa230015b34edaae9c57ed90d81407.
INFO 12-25 13:17:48 logger.py:37] Received request chatcmpl-5de441b9aade48b683855f1e5a040b89: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal is the man\'s pet depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:48 engine.py:267] Added request chatcmpl-5de441b9aade48b683855f1e5a040b89.
INFO 12-25 13:17:48 logger.py:37] Received request chatcmpl-d732855afe6a48729b31e7b87a9ff408: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which was the duration of the male protagonist\'s morning work in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:48 engine.py:267] Added request chatcmpl-d732855afe6a48729b31e7b87a9ff408.
INFO 12-25 13:17:50 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 109.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:52 logger.py:37] Received request chatcmpl-6ca7005db4234ea68371cc4ec28782a2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle part of the video, why does the man with gray and white beard and black glasses wave and greet the restaurant staff repeatedly when he enters the restaurant?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:52 engine.py:267] Added request chatcmpl-6ca7005db4234ea68371cc4ec28782a2.
INFO 12-25 13:17:52 logger.py:37] Received request chatcmpl-e1b05714910e4fb9af9310f3407da760: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary item that the two men in the video utilize for their workout?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:52 engine.py:267] Added request chatcmpl-e1b05714910e4fb9af9310f3407da760.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:55 metrics.py:449] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 120.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:17:55 logger.py:37] Received request chatcmpl-8f084b9075f2498fb02d495b92867bf0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how does the magician demonstrate his skill with a Rubik\'s Cube?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:55 engine.py:267] Added request chatcmpl-8f084b9075f2498fb02d495b92867bf0.
INFO 12-25 13:17:56 logger.py:37] Received request chatcmpl-1e3405a10f974ada803f84b00b4dc86c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following is typically used as the filling in wontons?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:56 engine.py:267] Added request chatcmpl-1e3405a10f974ada803f84b00b4dc86c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:17:58 logger.py:37] Received request chatcmpl-f4e85dfb31d24b4c856ff2b2c0f9fc72: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who won the game in the group closest to the camera in the final game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:17:58 engine.py:267] Added request chatcmpl-f4e85dfb31d24b4c856ff2b2c0f9fc72.
INFO 12-25 13:18:00 metrics.py:449] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 134.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:02 logger.py:37] Received request chatcmpl-4c0c300b5a6a467b9efc9831ecc760cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following track athletes did not cause any disruption by knocking down railings during the competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:02 engine.py:267] Added request chatcmpl-4c0c300b5a6a467b9efc9831ecc760cb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:03 logger.py:37] Received request chatcmpl-0ada12d66c5b4504ace4ea942cf9df6b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who finally find the lost city?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:03 logger.py:37] Received request chatcmpl-97ff76b4666d4dfea3f9cac8b71a9937: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary difference between Arbeitslosengeld and Brgergeld, as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:03 engine.py:267] Added request chatcmpl-0ada12d66c5b4504ace4ea942cf9df6b.
INFO 12-25 13:18:03 engine.py:267] Added request chatcmpl-97ff76b4666d4dfea3f9cac8b71a9937.
INFO 12-25 13:18:04 logger.py:37] Received request chatcmpl-ef5f013a483842498cdce6934ee3c218: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many squats did the lady in the video do?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:04 engine.py:267] Added request chatcmpl-ef5f013a483842498cdce6934ee3c218.
INFO 12-25 13:18:05 metrics.py:449] Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 89.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:11 logger.py:37] Received request chatcmpl-0fa0864e7b1c4377b4c2915b24dce11e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the early part of the video, when the man with the gray and white beard and black glasses sits at the table, what does the man in the burgundy shirt next to him say when he says \'no\'?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:11 engine.py:267] Added request chatcmpl-0fa0864e7b1c4377b4c2915b24dce11e.
INFO 12-25 13:18:11 logger.py:37] Received request chatcmpl-4e4ed3e5f4b449328178991a038fce84: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When the video talks about sea level rise, what is the time span?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:11 logger.py:37] Received request chatcmpl-7a7fd64e225a40a68ce0ba43026b99f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the temperament of the pet in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:11 engine.py:267] Added request chatcmpl-4e4ed3e5f4b449328178991a038fce84.
INFO 12-25 13:18:11 engine.py:267] Added request chatcmpl-7a7fd64e225a40a68ce0ba43026b99f1.
INFO 12-25 13:18:11 logger.py:37] Received request chatcmpl-1a58111952b5462488fe2fc2e687e504: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team won the last game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:11 engine.py:267] Added request chatcmpl-1a58111952b5462488fe2fc2e687e504.
INFO 12-25 13:18:15 metrics.py:449] Avg prompt throughput: 57.6 tokens/s, Avg generation throughput: 122.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:17 logger.py:37] Received request chatcmpl-e7f0e9ec4e1041109cf58d538f884166: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who started the custom of restraining hand activities in pulic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:17 engine.py:267] Added request chatcmpl-e7f0e9ec4e1041109cf58d538f884166.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:18 logger.py:37] Received request chatcmpl-da01abcd6cdc47879d46bbf774d8b2ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which color dress is the woman wearing, who is in the video and is also wearing brown heels?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:18 engine.py:267] Added request chatcmpl-da01abcd6cdc47879d46bbf774d8b2ee.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:20 logger.py:37] Received request chatcmpl-d5ca1f90985a414996daa2794f65c3e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which track athlete knocked down the railing first in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:20 engine.py:267] Added request chatcmpl-d5ca1f90985a414996daa2794f65c3e1.
INFO 12-25 13:18:20 metrics.py:449] Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 107.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:18:21 logger.py:37] Received request chatcmpl-57c8a94dcf5d4a1c8b44d7c80d5b67f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why Cusco and Tenochtitlan can be easily found while Amazonian settlements can not?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:21 engine.py:267] Added request chatcmpl-57c8a94dcf5d4a1c8b44d7c80d5b67f5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:22 logger.py:37] Received request chatcmpl-7bfaf60380b34c7d8b2818fdc5f15869: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events are in correct order?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:22 engine.py:267] Added request chatcmpl-7bfaf60380b34c7d8b2818fdc5f15869.
INFO 12-25 13:18:25 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 136.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:28 logger.py:37] Received request chatcmpl-65b17868b7b24a7e870a3d8494d270e4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many ships are shown in the map while the sinking ship sending out message?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:28 engine.py:267] Added request chatcmpl-65b17868b7b24a7e870a3d8494d270e4.
INFO 12-25 13:18:29 logger.py:37] Received request chatcmpl-1182d137053a4620a6e063f353bf72a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where were the video clips of the mountain tour taken from among the following options?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:29 logger.py:37] Received request chatcmpl-6bb9128b2cb8403badfe686d97c2aee1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player scored the final goal of the match in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:29 engine.py:267] Added request chatcmpl-1182d137053a4620a6e063f353bf72a0.
INFO 12-25 13:18:29 engine.py:267] Added request chatcmpl-6bb9128b2cb8403badfe686d97c2aee1.
INFO 12-25 13:18:30 metrics.py:449] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 101.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:32 logger.py:37] Received request chatcmpl-971b5a3265994e19bf3284ec881c4f3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events happened before 72 BCE?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:32 engine.py:267] Added request chatcmpl-971b5a3265994e19bf3284ec881c4f3f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:35 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 133.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:18:35 logger.py:37] Received request chatcmpl-889b26690ed54f6dae8d9ebee3131e03: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the visual cues provided by the video, where did not the magician perform his magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:36 engine.py:267] Added request chatcmpl-889b26690ed54f6dae8d9ebee3131e03.
INFO 12-25 13:18:36 logger.py:37] Received request chatcmpl-1f05c2a65d6141d088411ca07ce320b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the main character in the video put his hand in the coat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:36 engine.py:267] Added request chatcmpl-1f05c2a65d6141d088411ca07ce320b5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:39 logger.py:37] Received request chatcmpl-678466ce10b84e268ac027c95fe8fb74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people attended in the assasination of Caesar according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:39 engine.py:267] Added request chatcmpl-678466ce10b84e268ac027c95fe8fb74.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:40 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 124.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:18:41 logger.py:37] Received request chatcmpl-32a5e517ba74409186205a33a41f7199: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the later part of the video, why is it not recommended for the man with gray and white beard and black glasses to say \'ciao\'?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:41 engine.py:267] Added request chatcmpl-32a5e517ba74409186205a33a41f7199.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:43 logger.py:37] Received request chatcmpl-f2dece751cfa441b91cb50b81b964033: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the overall message of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:43 engine.py:267] Added request chatcmpl-f2dece751cfa441b91cb50b81b964033.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:44 logger.py:37] Received request chatcmpl-e1cb68be7da9402e971887d73ad092c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following ideas about the Temple\'s design is not innovative?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:44 engine.py:267] Added request chatcmpl-e1cb68be7da9402e971887d73ad092c9.
INFO 12-25 13:18:45 metrics.py:449] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 113.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:18:45 logger.py:37] Received request chatcmpl-6fbd6a51b7ec4851a0180550057e37ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened when Che Guevara failed to rally rebels in the Congo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:45 engine.py:267] Added request chatcmpl-6fbd6a51b7ec4851a0180550057e37ad.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:47 logger.py:37] Received request chatcmpl-5c5dae02d7774c59bed5785a3e002006: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does this video mention Victor Garber?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:47 engine.py:267] Added request chatcmpl-5c5dae02d7774c59bed5785a3e002006.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:50 logger.py:37] Received request chatcmpl-ec4456af9d324ef39d5ce3b5c4c2db02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man eating in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:50 logger.py:37] Received request chatcmpl-abf93dc171d7442281f1ebe21e5b7531: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the cowherd use the bull\'s magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:50 engine.py:267] Added request chatcmpl-ec4456af9d324ef39d5ce3b5c4c2db02.
INFO 12-25 13:18:50 engine.py:267] Added request chatcmpl-abf93dc171d7442281f1ebe21e5b7531.
INFO 12-25 13:18:50 metrics.py:449] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:51 logger.py:37] Received request chatcmpl-dbf99190d70c4077aeeb3f64ce3a1062: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the colors of the famous statue of Augustus Caesar that is supposed to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:51 engine.py:267] Added request chatcmpl-dbf99190d70c4077aeeb3f64ce3a1062.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:55 metrics.py:449] Avg prompt throughput: 13.8 tokens/s, Avg generation throughput: 140.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:56 logger.py:37] Received request chatcmpl-9c904f7a63204b08bc87033a4f94117c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the accurate sequence for the video to present its content? (a) Sunken cities. (b) Sunken ships. (c) Sunken things used to learn about ancient people.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:56 engine.py:267] Added request chatcmpl-9c904f7a63204b08bc87033a4f94117c.
INFO 12-25 13:18:57 logger.py:37] Received request chatcmpl-7e0e65d6066c4d00b88161176b2917b1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Michael Bierut mention religious symbols?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:57 engine.py:267] Added request chatcmpl-7e0e65d6066c4d00b88161176b2917b1.
INFO 12-25 13:18:57 logger.py:37] Received request chatcmpl-a217f97df6fa42c4ac726390ec58d2fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the main character in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:18:58 engine.py:267] Added request chatcmpl-a217f97df6fa42c4ac726390ec58d2fd.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:18:59 logger.py:37] Received request chatcmpl-68b7c8a5182a4ec48867200fa935f81f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the total number of athletes who participated in the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:00 engine.py:267] Added request chatcmpl-68b7c8a5182a4ec48867200fa935f81f.
INFO 12-25 13:19:00 metrics.py:449] Avg prompt throughput: 56.3 tokens/s, Avg generation throughput: 99.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:02 logger.py:37] Received request chatcmpl-febb482f8a87464a8205a6b5ef84c009: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following elements isn\'t mentioned in the painting "The Emperor Napoleon in His Study at the Tuileries"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:02 engine.py:267] Added request chatcmpl-febb482f8a87464a8205a6b5ef84c009.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:05 metrics.py:449] Avg prompt throughput: 15.1 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:19:05 logger.py:37] Received request chatcmpl-4236af0ea2d64058af1f0d815b2d4d9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Whose portrait is on the cup of the judge in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:05 engine.py:267] Added request chatcmpl-4236af0ea2d64058af1f0d815b2d4d9a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:06 logger.py:37] Received request chatcmpl-c9305ccd594a49ccb2e65622a79cc424: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about the violin-learner in the video is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:06 engine.py:267] Added request chatcmpl-c9305ccd594a49ccb2e65622a79cc424.
INFO 12-25 13:19:07 logger.py:37] Received request chatcmpl-3081e5755e284efba81ce635187bf6f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color of pants is the female commentator wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:07 engine.py:267] Added request chatcmpl-3081e5755e284efba81ce635187bf6f5.
INFO 12-25 13:19:07 logger.py:37] Received request chatcmpl-8fda4673867d441b9bf6845c87b41eb4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many princesses flew away when the cowherd approached?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:07 engine.py:267] Added request chatcmpl-8fda4673867d441b9bf6845c87b41eb4.
INFO 12-25 13:19:10 metrics.py:449] Avg prompt throughput: 52.6 tokens/s, Avg generation throughput: 111.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:13 logger.py:37] Received request chatcmpl-676841a774e54c1ea314dad4e701e705: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the color of Gabriel Garca Mrquez\'s car in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:13 engine.py:267] Added request chatcmpl-676841a774e54c1ea314dad4e701e705.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:15 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 130.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:19:15 logger.py:37] Received request chatcmpl-5069405708304605ab31da40f440e06d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people from East Germany had fled to West Germany by 1961?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:15 engine.py:267] Added request chatcmpl-5069405708304605ab31da40f440e06d.
INFO 12-25 13:19:15 logger.py:37] Received request chatcmpl-69161aef0ff84f46b6fe9f36612104bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following features can not describe Spartacus?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:15 engine.py:267] Added request chatcmpl-69161aef0ff84f46b6fe9f36612104bd.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:17 logger.py:37] Received request chatcmpl-881f1fcade544f1bbc928f7cfff7b10c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many man-made ditches are found recently?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:17 engine.py:267] Added request chatcmpl-881f1fcade544f1bbc928f7cfff7b10c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:19 logger.py:37] Received request chatcmpl-faa18b7420224adc9ab6a709a9048ca8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events happened after Polonius\'s death?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:19 engine.py:267] Added request chatcmpl-faa18b7420224adc9ab6a709a9048ca8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:20 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 124.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:19:21 logger.py:37] Received request chatcmpl-325738c206184ad6826c7607d6be4123: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:21 logger.py:37] Received request chatcmpl-d5822d4f11774334a5794f7e04c52153: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Michael Bierut take as an example to illustrate pictoral logos?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:21 engine.py:267] Added request chatcmpl-325738c206184ad6826c7607d6be4123.
INFO 12-25 13:19:21 engine.py:267] Added request chatcmpl-d5822d4f11774334a5794f7e04c52153.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:23 logger.py:37] Received request chatcmpl-9dd682becf1a45b7b74173401dbdf934: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:23 engine.py:267] Added request chatcmpl-9dd682becf1a45b7b74173401dbdf934.
INFO 12-25 13:19:24 logger.py:37] Received request chatcmpl-2ed68e7f511d4877bd01235da134cba7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the correct order of the following events? 1. Creating basic background. 2. Add a few flowers to the painting. 3. Building up the texture of the painting even more. 4. Drawing the pads of the water lilies.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:24 engine.py:267] Added request chatcmpl-2ed68e7f511d4877bd01235da134cba7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:25 metrics.py:449] Avg prompt throughput: 58.3 tokens/s, Avg generation throughput: 106.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:19:26 logger.py:37] Received request chatcmpl-731b5e4a1281424ab60ddb32f25d3126: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many defending layers were there in the barrier in the east of the Berlin wall accoridng to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:26 engine.py:267] Added request chatcmpl-731b5e4a1281424ab60ddb32f25d3126.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:28 logger.py:37] Received request chatcmpl-6585246096244bcb819ed689d122dcf9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of this video for the audience?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:28 engine.py:267] Added request chatcmpl-6585246096244bcb819ed689d122dcf9.
INFO 12-25 13:19:29 logger.py:37] Received request chatcmpl-ff0869a26030456c8cb9812f33ad7f5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of clothes is the speaker wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:29 logger.py:37] Received request chatcmpl-4ade036565154e43bbd2bcdb3a57b04d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the teacher\'s attitude toward the student when the student attempts to play middle C on the violin?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:29 engine.py:267] Added request chatcmpl-ff0869a26030456c8cb9812f33ad7f5e.
INFO 12-25 13:19:29 engine.py:267] Added request chatcmpl-4ade036565154e43bbd2bcdb3a57b04d.
INFO 12-25 13:19:30 metrics.py:449] Avg prompt throughput: 54.7 tokens/s, Avg generation throughput: 101.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:34 logger.py:37] Received request chatcmpl-2a5d732abae94a628d76170a4c82bc2d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:34 engine.py:267] Added request chatcmpl-2a5d732abae94a628d76170a4c82bc2d.
INFO 12-25 13:19:34 logger.py:37] Received request chatcmpl-ac23ec51629b4b55b5c29a6c859d4d84: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who embraces the Parthenon Temple in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:34 engine.py:267] Added request chatcmpl-ac23ec51629b4b55b5c29a6c859d4d84.
INFO 12-25 13:19:35 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 131.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:36 logger.py:37] Received request chatcmpl-b94291f6f9bf4db8afafea8336b0cc32: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color shoes does the little girl wear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:36 engine.py:267] Added request chatcmpl-b94291f6f9bf4db8afafea8336b0cc32.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:38 logger.py:37] Received request chatcmpl-cd01c0c4b4b24188b8183bab442b3099: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why can the tenth artist create potteries with marbled designs?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:38 engine.py:267] Added request chatcmpl-cd01c0c4b4b24188b8183bab442b3099.
INFO 12-25 13:19:38 logger.py:37] Received request chatcmpl-ac900e9d20b74041b56219aeb3efbbbd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did Nike do when a graphic design student submit her work in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:38 engine.py:267] Added request chatcmpl-ac900e9d20b74041b56219aeb3efbbbd.
INFO 12-25 13:19:40 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:43 logger.py:37] Received request chatcmpl-b17b208dcebb47f397f44f78241acc61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video focus on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:43 engine.py:267] Added request chatcmpl-b17b208dcebb47f397f44f78241acc61.
INFO 12-25 13:19:44 logger.py:37] Received request chatcmpl-0385f1ebde704e5ab5e4e15f5408a961: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was weaver doing when the cowherd saw her at the first time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:44 engine.py:267] Added request chatcmpl-0385f1ebde704e5ab5e4e15f5408a961.
INFO 12-25 13:19:44 logger.py:37] Received request chatcmpl-bf11492e62ee4b2aa99f946426b88cf3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following features can describe Hamlet in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:44 logger.py:37] Received request chatcmpl-0929c264423c42568106c4d6a3e85784: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many listeners gave busking donations to the girl before she started playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:44 engine.py:267] Added request chatcmpl-bf11492e62ee4b2aa99f946426b88cf3.
INFO 12-25 13:19:44 engine.py:267] Added request chatcmpl-0929c264423c42568106c4d6a3e85784.
INFO 12-25 13:19:45 metrics.py:449] Avg prompt throughput: 51.9 tokens/s, Avg generation throughput: 100.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:48 logger.py:37] Received request chatcmpl-9693d3ba3f2b4d5e82eaf7317098b91c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which cellular structure is responsible for receiving proteins according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:48 engine.py:267] Added request chatcmpl-9693d3ba3f2b4d5e82eaf7317098b91c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:50 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 141.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:51 logger.py:37] Received request chatcmpl-3a3f200e70774c36a11e0948c552bbc2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened when the main character owned an army of about 120,000 soldiers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:51 engine.py:267] Added request chatcmpl-3a3f200e70774c36a11e0948c552bbc2.
INFO 12-25 13:19:52 logger.py:37] Received request chatcmpl-99e5b627437f47b7b77ca0af9923f1b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following plots about the book was not mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:52 engine.py:267] Added request chatcmpl-99e5b627437f47b7b77ca0af9923f1b5.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:54 logger.py:37] Received request chatcmpl-c0521f8c77dd49c5b326992780536145: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which style does the painting in the video belong to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:54 engine.py:267] Added request chatcmpl-c0521f8c77dd49c5b326992780536145.
INFO 12-25 13:19:55 metrics.py:449] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 114.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:19:55 logger.py:37] Received request chatcmpl-66f16fe0df3b434abb31b86ba7eaacaa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which cells are contained within the lymph nodes, as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:55 engine.py:267] Added request chatcmpl-66f16fe0df3b434abb31b86ba7eaacaa.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:19:57 logger.py:37] Received request chatcmpl-0fe9dd3934e1413bb2a5d03491fe426a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the video organize the story of Che Guevara?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:57 engine.py:267] Added request chatcmpl-0fe9dd3934e1413bb2a5d03491fe426a.
INFO 12-25 13:19:58 logger.py:37] Received request chatcmpl-dd59f92775634ae8b430f9153736fa09: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why didn\'t the English king kill Hamlet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:19:58 engine.py:267] Added request chatcmpl-dd59f92775634ae8b430f9153736fa09.
INFO 12-25 13:20:00 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:02 logger.py:37] Received request chatcmpl-3b27395299ec4a7488d297f023f8a783: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was David doing according to the sculpture?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:02 engine.py:267] Added request chatcmpl-3b27395299ec4a7488d297f023f8a783.
INFO 12-25 13:20:04 logger.py:37] Received request chatcmpl-4fca335b85f84c44a31d36082949b23e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the sculture supposed to stay?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:04 logger.py:37] Received request chatcmpl-95f545daee8f47fa8a103ebbbb1684fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the brain-computer interface company introduced at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:04 logger.py:37] Received request chatcmpl-b00c2cd39432480db406709cfef0bcd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events happened after the fall of the Berlin Wall, according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:04 engine.py:267] Added request chatcmpl-4fca335b85f84c44a31d36082949b23e.
INFO 12-25 13:20:04 engine.py:267] Added request chatcmpl-95f545daee8f47fa8a103ebbbb1684fc.
INFO 12-25 13:20:04 engine.py:267] Added request chatcmpl-b00c2cd39432480db406709cfef0bcd8.
INFO 12-25 13:20:05 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 80.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:08 logger.py:37] Received request chatcmpl-1629308fa97e4c209edd5688ba1c517a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first artist\'s specialty in pottery?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:08 engine.py:267] Added request chatcmpl-1629308fa97e4c209edd5688ba1c517a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:09 logger.py:37] Received request chatcmpl-dfc32115cc0240c4ba760df567fbf8d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which one is listed top 2 according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:09 engine.py:267] Added request chatcmpl-dfc32115cc0240c4ba760df567fbf8d0.
INFO 12-25 13:20:10 logger.py:37] Received request chatcmpl-32c748e192b04b0f827e23fd83446b5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:10 engine.py:267] Added request chatcmpl-32c748e192b04b0f827e23fd83446b5b.
INFO 12-25 13:20:10 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 124.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:13 logger.py:37] Received request chatcmpl-b87e84208d07437fa37babe1ca41c8e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following methods of revealing the original color of the ancient art work is not mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:13 engine.py:267] Added request chatcmpl-b87e84208d07437fa37babe1ca41c8e1.
INFO 12-25 13:20:13 logger.py:37] Received request chatcmpl-4338e11ab9c049e182ed1f4273c8523c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the following events are presented in the video? (a) The nucleus is introduced. (b) Base pairing. (c) Cell division.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:13 engine.py:267] Added request chatcmpl-4338e11ab9c049e182ed1f4273c8523c.
INFO 12-25 13:20:15 metrics.py:449] Avg prompt throughput: 32.2 tokens/s, Avg generation throughput: 133.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:18 logger.py:37] Received request chatcmpl-ea666d6023574f919c7c9e6893b6dfc1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cases of Parkinson\'s disease are mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:18 engine.py:267] Added request chatcmpl-ea666d6023574f919c7c9e6893b6dfc1.
INFO 12-25 13:20:19 logger.py:37] Received request chatcmpl-14d0bd6be15d400e85a49d63cb3f8935: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main color of Hugh Hope\'s work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:19 logger.py:37] Received request chatcmpl-d491d9cad50f44788ccea6a686a25e9b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two people at the beginning of the video have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:19 engine.py:267] Added request chatcmpl-14d0bd6be15d400e85a49d63cb3f8935.
INFO 12-25 13:20:19 engine.py:267] Added request chatcmpl-d491d9cad50f44788ccea6a686a25e9b.
INFO 12-25 13:20:20 metrics.py:449] Avg prompt throughput: 38.9 tokens/s, Avg generation throughput: 107.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:22 logger.py:37] Received request chatcmpl-d8bb1df266af4b9fa98fd8fb14b6c0b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions of the blue, bisected cell at the beginning of the video is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:22 engine.py:267] Added request chatcmpl-d8bb1df266af4b9fa98fd8fb14b6c0b3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:24 logger.py:37] Received request chatcmpl-a8fe5feb5a2741a2804875f200f43830: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the company BiVACOR in the field of medical devices?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:24 engine.py:267] Added request chatcmpl-a8fe5feb5a2741a2804875f200f43830.
INFO 12-25 13:20:25 logger.py:37] Received request chatcmpl-1e151c7ed241474e8434508059cd14d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What instrument is the little girl playing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:25 engine.py:267] Added request chatcmpl-1e151c7ed241474e8434508059cd14d7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:25 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 116.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:20:26 logger.py:37] Received request chatcmpl-8b44b2f57f404cb994c5f85b27f26707: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the context of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:26 engine.py:267] Added request chatcmpl-8b44b2f57f404cb994c5f85b27f26707.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:28 logger.py:37] Received request chatcmpl-dc013b9838e04ab3a5119b25cd59cd9b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the context of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:28 engine.py:267] Added request chatcmpl-dc013b9838e04ab3a5119b25cd59cd9b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:30 metrics.py:449] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 142.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:31 logger.py:37] Received request chatcmpl-6a7e7a077b06483387ac6699a951c33a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about the author is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:31 engine.py:267] Added request chatcmpl-6a7e7a077b06483387ac6699a951c33a.
INFO 12-25 13:20:32 logger.py:37] Received request chatcmpl-91172150f77c447f83540655ffb24a10: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which company is featured in the video but not mentioned in the audio?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:32 engine.py:267] Added request chatcmpl-91172150f77c447f83540655ffb24a10.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:34 logger.py:37] Received request chatcmpl-44ad6c12fe2e41cfb6dc0f77b11c0df5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which components are part of the object described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:34 engine.py:267] Added request chatcmpl-44ad6c12fe2e41cfb6dc0f77b11c0df5.
INFO 12-25 13:20:35 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 120.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:36 logger.py:37] Received request chatcmpl-c1179866e2bf4f69a1132c04d9581d54: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following materials used to recreate Monate\'s Water Lilies is not neccessary?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:36 engine.py:267] Added request chatcmpl-c1179866e2bf4f69a1132c04d9581d54.
INFO 12-25 13:20:37 logger.py:37] Received request chatcmpl-5f320d7c8039454bad2299dd509d2fd2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many individual electrodes are distributed across the circular hole in Neuralink\'s device?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:37 engine.py:267] Added request chatcmpl-5f320d7c8039454bad2299dd509d2fd2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:39 logger.py:37] Received request chatcmpl-0c24ba40eaa5466fb1d0a7e49000163f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how much did the central bank drop interest rates during the epidemic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:39 engine.py:267] Added request chatcmpl-0c24ba40eaa5466fb1d0a7e49000163f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:40 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 118.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:20:40 logger.py:37] Received request chatcmpl-9bff72bace5e42dbb955a19c73b54c48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:40 engine.py:267] Added request chatcmpl-9bff72bace5e42dbb955a19c73b54c48.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:42 logger.py:37] Received request chatcmpl-c1df1498c4174e5c92e307c05d23969f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the medical technique that takes up the most space in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:42 engine.py:267] Added request chatcmpl-c1df1498c4174e5c92e307c05d23969f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:45 logger.py:37] Received request chatcmpl-b16906b33c48438c8bd107cab0cb31a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about Zaha Hadid\'s work is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:45 engine.py:267] Added request chatcmpl-b16906b33c48438c8bd107cab0cb31a7.
INFO 12-25 13:20:45 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 133.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:48 logger.py:37] Received request chatcmpl-fdf390cccf9042e48bd6df8f848925df: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Inferring from the video, what is the characteristic of Shein Corp?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:48 logger.py:37] Received request chatcmpl-2bdcf2dff4804fbfb9e4403ef1a62533: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why should exercise be included as a part of maintaining a healthy lymphatic system, according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:48 engine.py:267] Added request chatcmpl-fdf390cccf9042e48bd6df8f848925df.
INFO 12-25 13:20:48 engine.py:267] Added request chatcmpl-2bdcf2dff4804fbfb9e4403ef1a62533.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:49 logger.py:37] Received request chatcmpl-affbaaad6ebe40b1a344bb389008c423: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:49 engine.py:267] Added request chatcmpl-affbaaad6ebe40b1a344bb389008c423.
INFO 12-25 13:20:50 logger.py:37] Received request chatcmpl-c0421e2e163344cdabc6e0421e0a55d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is responsible for gene activation according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:50 engine.py:267] Added request chatcmpl-c0421e2e163344cdabc6e0421e0a55d2.
INFO 12-25 13:20:50 metrics.py:449] Avg prompt throughput: 52.6 tokens/s, Avg generation throughput: 93.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:54 logger.py:37] Received request chatcmpl-f8dc92796e3745019f97fb647a707dd9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:54 logger.py:37] Received request chatcmpl-ff47a8ba2bf745e083ece86fd5578a6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many heart transplants are performed annually, and how many are requested in the U.S. and worldwide?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:54 engine.py:267] Added request chatcmpl-f8dc92796e3745019f97fb647a707dd9.
INFO 12-25 13:20:54 engine.py:267] Added request chatcmpl-ff47a8ba2bf745e083ece86fd5578a6d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:20:55 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 114.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:20:56 logger.py:37] Received request chatcmpl-842050e31fd14792abb964769020cb6b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the sequence of events in the video showing the following? (a) A rolling T-cell. (b) Human hair follicles ooze oil. (c) Plasma cell division.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:56 engine.py:267] Added request chatcmpl-842050e31fd14792abb964769020cb6b.
INFO 12-25 13:20:56 logger.py:37] Received request chatcmpl-52a0bbd641a644d790eb423d256aa19d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does Jacob Clifford appear alone in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:20:56 engine.py:267] Added request chatcmpl-52a0bbd641a644d790eb423d256aa19d.
INFO 12-25 13:21:00 metrics.py:449] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 139.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:02 logger.py:37] Received request chatcmpl-fbc6fc13f17f4a6997d336f4309db8ce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the exact order in which the video presents the following events? (a) Application of respiratory cells to cardiovascular cure therapy. (b) The use of nanorobots in cancer treatment. (c) Nanorobots for haemostasis.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:02 engine.py:267] Added request chatcmpl-fbc6fc13f17f4a6997d336f4309db8ce.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:03 logger.py:37] Received request chatcmpl-559177fb0f6f4b1b808b4b3f99b748be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens to your brain when you\'re in your 70s according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:03 engine.py:267] Added request chatcmpl-559177fb0f6f4b1b808b4b3f99b748be.
INFO 12-25 13:21:04 logger.py:37] Received request chatcmpl-c377dba6405c48d880f7975257c7f596: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct chronological order in which the following parts of the video appear? (a) Human lungs. (b) Protein folding distortion. (c) Mice, plants and cells.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:04 engine.py:267] Added request chatcmpl-c377dba6405c48d880f7975257c7f596.
INFO 12-25 13:21:05 metrics.py:449] Avg prompt throughput: 52.9 tokens/s, Avg generation throughput: 113.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:08 logger.py:37] Received request chatcmpl-44dee77e4eb64db795d136433ad79fd6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What event wasn\'t mentioned within the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:08 engine.py:267] Added request chatcmpl-44dee77e4eb64db795d136433ad79fd6.
INFO 12-25 13:21:09 logger.py:37] Received request chatcmpl-6174201e86c74c679d75ea6a5f1fcfe6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What issue related to mitochondria is discussed in the context of Parkinson\'s disease, as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:09 engine.py:267] Added request chatcmpl-6174201e86c74c679d75ea6a5f1fcfe6.
INFO 12-25 13:21:09 logger.py:37] Received request chatcmpl-9194c8cc4ce64b25ba3d98557f1b2144: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video mentions a potential risk associated with focusing solely on short-term stock price performance. What is this risk?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:09 engine.py:267] Added request chatcmpl-9194c8cc4ce64b25ba3d98557f1b2144.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:10 metrics.py:449] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 106.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:21:11 logger.py:37] Received request chatcmpl-886975d6138146d5bbadbd65b06a59db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of Neuralink\'s first product, Telepathy according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:11 engine.py:267] Added request chatcmpl-886975d6138146d5bbadbd65b06a59db.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:14 logger.py:37] Received request chatcmpl-cfb4830c58af43bbab4d25ce5eed1eac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Extrapolating from the video, when was Shein founded?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:14 engine.py:267] Added request chatcmpl-cfb4830c58af43bbab4d25ce5eed1eac.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:15 metrics.py:449] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 125.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:15 logger.py:37] Received request chatcmpl-f6ff0b1ed61e4408ab8b3d715238b49b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:16 engine.py:267] Added request chatcmpl-f6ff0b1ed61e4408ab8b3d715238b49b.
INFO 12-25 13:21:16 logger.py:37] Received request chatcmpl-4ce7e93ad42c4181a77892e7507e6b3c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is a potential disadvantage for a corn farmer who chooses NOT to participate in the futures market?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:16 engine.py:267] Added request chatcmpl-4ce7e93ad42c4181a77892e7507e6b3c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:18 logger.py:37] Received request chatcmpl-73b9b5f4df5f4037bc5fe6dd6520ee8b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the third future topic in medicine mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:18 engine.py:267] Added request chatcmpl-73b9b5f4df5f4037bc5fe6dd6520ee8b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:20 metrics.py:449] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 128.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:21:20 logger.py:37] Received request chatcmpl-5aaa811385ed473fa4948417fd27008a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the following patterns appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:20 engine.py:267] Added request chatcmpl-5aaa811385ed473fa4948417fd27008a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:22 logger.py:37] Received request chatcmpl-a1cfbf53a0794c1692658f5cb0d5d0d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is a key advantage for hotel owners who choose to franchise with a major brand?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:22 engine.py:267] Added request chatcmpl-a1cfbf53a0794c1692658f5cb0d5d0d8.
INFO 12-25 13:21:23 logger.py:37] Received request chatcmpl-36c343fa7da4487d895df583ff9c410e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "For which diseases will respiratory cells potentially be used in treatment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:23 logger.py:37] Received request chatcmpl-3488718a72bd4da18d381f11b283fd97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Suppose Emily purchased some company stock in 2005 at a price of $50 per share. She passed away in 2020, when the stock\'s market value was $150 per share. If her heir, John, sold the stock in 2023 for $180 per share. Assume the capital gains tax rate is 15%. According to the \'step-up in basis\' rule, how much capital gains tax would John need to pay?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:23 engine.py:267] Added request chatcmpl-36c343fa7da4487d895df583ff9c410e.
INFO 12-25 13:21:23 engine.py:267] Added request chatcmpl-3488718a72bd4da18d381f11b283fd97.
INFO 12-25 13:21:25 metrics.py:449] Avg prompt throughput: 70.9 tokens/s, Avg generation throughput: 104.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:27 logger.py:37] Received request chatcmpl-d1b5204b246c49e59e3aec07b9f80d71: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what event caused CCO\'s stock price to plummet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:27 engine.py:267] Added request chatcmpl-d1b5204b246c49e59e3aec07b9f80d71.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:30 metrics.py:449] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 111.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:21:30 logger.py:37] Received request chatcmpl-c8b73f56693c4896a26e01cd8d34d37d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:30 engine.py:267] Added request chatcmpl-c8b73f56693c4896a26e01cd8d34d37d.
INFO 12-25 13:21:30 logger.py:37] Received request chatcmpl-7600d1875f14429a96c3bc378b0d6442: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following investment strategies does Warren Buffet advocate for in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:30 engine.py:267] Added request chatcmpl-7600d1875f14429a96c3bc378b0d6442.
INFO 12-25 13:21:31 logger.py:37] Received request chatcmpl-059f5dcfe8c847abb35a52281c137387: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the price of apples go up in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:31 engine.py:267] Added request chatcmpl-059f5dcfe8c847abb35a52281c137387.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:35 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 132.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:36 logger.py:37] Received request chatcmpl-8f9c0693ebc74cfab4cb1c33e1a859ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is different from the other chapters in the video when introducing the children\'s chapter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:36 logger.py:37] Received request chatcmpl-e1ed862e1ace487bab26859125e53ddb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many astronaut sleeping capsules are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:36 engine.py:267] Added request chatcmpl-8f9c0693ebc74cfab4cb1c33e1a859ab.
INFO 12-25 13:21:36 engine.py:267] Added request chatcmpl-e1ed862e1ace487bab26859125e53ddb.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:37 logger.py:37] Received request chatcmpl-3f4118e8806f4eb3a30b8589eeb262c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main point of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:37 engine.py:267] Added request chatcmpl-3f4118e8806f4eb3a30b8589eeb262c7.
INFO 12-25 13:21:38 logger.py:37] Received request chatcmpl-24eda4124b554b0cb28918a3d1fc436e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement best summarises the role of the economics term pointed to by the green arrow at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:38 engine.py:267] Added request chatcmpl-24eda4124b554b0cb28918a3d1fc436e.
INFO 12-25 13:21:40 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 113.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:42 logger.py:37] Received request chatcmpl-cf0f7b3f6dad48e790b0e89d207c6471: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the billionaires appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:42 engine.py:267] Added request chatcmpl-cf0f7b3f6dad48e790b0e89d207c6471.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:44 logger.py:37] Received request chatcmpl-a05b8785ac674d6ca3360825848137e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Approximately how much time does the rocket in the video take from launch to when it reaches 1000km/h?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:44 logger.py:37] Received request chatcmpl-78eac2a12b58447995c3b5ef5229cb7e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which building appears in the video when the central bank is mentioned?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:44 logger.py:37] Received request chatcmpl-63b8b32d0b3044c2bdceaf62f02305dd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, how did investors respond to the availability of mortgage-backed securities and CDOs in the early 2000s?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:44 engine.py:267] Added request chatcmpl-a05b8785ac674d6ca3360825848137e2.
INFO 12-25 13:21:44 engine.py:267] Added request chatcmpl-78eac2a12b58447995c3b5ef5229cb7e.
INFO 12-25 13:21:44 engine.py:267] Added request chatcmpl-63b8b32d0b3044c2bdceaf62f02305dd.
INFO 12-25 13:21:45 metrics.py:449] Avg prompt throughput: 58.1 tokens/s, Avg generation throughput: 92.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:50 logger.py:37] Received request chatcmpl-84c453d34d4e458c8b49b734c2f4a5bb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the woman speaking in a white blouse in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:50 engine.py:267] Added request chatcmpl-84c453d34d4e458c8b49b734c2f4a5bb.
INFO 12-25 13:21:50 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 146.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:52 logger.py:37] Received request chatcmpl-a3d4c3d3452b40a69d6e66d5500a4c6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video highlights a disparity between a booming stock market and other economic indicators. Which of the following best exemplifies this disparity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:52 engine.py:267] Added request chatcmpl-a3d4c3d3452b40a69d6e66d5500a4c6d.
INFO 12-25 13:21:53 logger.py:37] Received request chatcmpl-8b7baaeaa78d4a69a964f32121d433d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the intended educational purpose of this video for the viewer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:53 engine.py:267] Added request chatcmpl-8b7baaeaa78d4a69a964f32121d433d4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:55 logger.py:37] Received request chatcmpl-07108ffce0824f389a92c000015504ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second planet observed by the main character of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:55 engine.py:267] Added request chatcmpl-07108ffce0824f389a92c000015504ff.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:55 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:21:56 logger.py:37] Received request chatcmpl-b2cac28f395c4296a00233fdc519dd38: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As shown in the video, if a money launderer is rigging a bet, what stage of money laundering might it be at?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:56 engine.py:267] Added request chatcmpl-b2cac28f395c4296a00233fdc519dd38.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:21:59 logger.py:37] Received request chatcmpl-a20707eb112547889579fd9f42077b67: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the astronaut show us at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:59 engine.py:267] Added request chatcmpl-a20707eb112547889579fd9f42077b67.
INFO 12-25 13:21:59 logger.py:37] Received request chatcmpl-734402b059734ec5921cbd4d87828abe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what happened in early 2020 in response to the COVID-19 pandemic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:21:59 engine.py:267] Added request chatcmpl-734402b059734ec5921cbd4d87828abe.
INFO 12-25 13:22:00 metrics.py:449] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 125.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:02 logger.py:37] Received request chatcmpl-d87c400ef4374f1e96e889e9fa0cb33f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:02 engine.py:267] Added request chatcmpl-d87c400ef4374f1e96e889e9fa0cb33f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:04 logger.py:37] Received request chatcmpl-2abd8128b2bd4afa99064bc4a478bcc4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what were the key factors that contributed to the 2008 financial crisis in the United States?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:04 engine.py:267] Added request chatcmpl-2abd8128b2bd4afa99064bc4a478bcc4.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:05 metrics.py:449] Avg prompt throughput: 28.2 tokens/s, Avg generation throughput: 125.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:22:06 logger.py:37] Received request chatcmpl-cb107156a90c40258a8cad62a85d6176: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what is a major factor influencing hotel room prices in dynamic cities?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:06 logger.py:37] Received request chatcmpl-1e0f99fb0c0d498c8479abdc24fbd3b4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What unfortunate event occurred during the middle of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:06 engine.py:267] Added request chatcmpl-cb107156a90c40258a8cad62a85d6176.
INFO 12-25 13:22:06 engine.py:267] Added request chatcmpl-1e0f99fb0c0d498c8479abdc24fbd3b4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:08 logger.py:37] Received request chatcmpl-78045faf3f2f43f39217472315e1039a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main issue addressed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:08 engine.py:267] Added request chatcmpl-78045faf3f2f43f39217472315e1039a.
INFO 12-25 13:22:10 metrics.py:449] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 131.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:14 logger.py:37] Received request chatcmpl-4078dc3764e84a2cbac4d11a9af917ef: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As shown in the video, how many companies compete with the coffee company?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:14 engine.py:267] Added request chatcmpl-4078dc3764e84a2cbac4d11a9af917ef.
INFO 12-25 13:22:14 logger.py:37] Received request chatcmpl-94f70b28b64144debb449a96e5c98bba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If a cereal company predicts a potential increase in corn prices in the coming months, what action might they take in the futures market?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:14 engine.py:267] Added request chatcmpl-94f70b28b64144debb449a96e5c98bba.
INFO 12-25 13:22:15 logger.py:37] Received request chatcmpl-404cb0ffaed6428d84bdf7151890b62d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:15 engine.py:267] Added request chatcmpl-404cb0ffaed6428d84bdf7151890b62d.
INFO 12-25 13:22:15 metrics.py:449] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 95.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:22:15 logger.py:37] Received request chatcmpl-7ad30000b99142149f9100b6454e537e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the main character in the video dip a drop of coffee and drip it back?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:15 engine.py:267] Added request chatcmpl-7ad30000b99142149f9100b6454e537e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:20 metrics.py:449] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 143.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:22 logger.py:37] Received request chatcmpl-b3cdfc2bbbc14c9b9209fa9de59e08ce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the astronaut in the video doing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:22 logger.py:37] Received request chatcmpl-4bc82ac04f9a4b969645a29fd9e8ee5a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order were the following mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:22 engine.py:267] Added request chatcmpl-b3cdfc2bbbc14c9b9209fa9de59e08ce.
INFO 12-25 13:22:22 engine.py:267] Added request chatcmpl-4bc82ac04f9a4b969645a29fd9e8ee5a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:23 logger.py:37] Received request chatcmpl-4f8173599ccd47ac9e13857c14c65ac1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what is the main reason why central banks avoid simply printing more money during an economic crisis?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:23 engine.py:267] Added request chatcmpl-4f8173599ccd47ac9e13857c14c65ac1.
INFO 12-25 13:22:24 logger.py:37] Received request chatcmpl-973bec6025504a5887fa15d58fc98b6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle of the video a photo is shown, what are the dots on the photo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:24 engine.py:267] Added request chatcmpl-973bec6025504a5887fa15d58fc98b6f.
INFO 12-25 13:22:25 metrics.py:449] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 101.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:28 logger.py:37] Received request chatcmpl-c20682d70706431495337960a3d054c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle of the video, what is recorded on the shown below the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:28 engine.py:267] Added request chatcmpl-c20682d70706431495337960a3d054c2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:30 logger.py:37] Received request chatcmpl-3b86763a056e4380a7db3c4544b1a681: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, in which tier of hotels do major brands like Marriott and Hyatt still predominantly own and operate the properties?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:30 engine.py:267] Added request chatcmpl-3b86763a056e4380a7db3c4544b1a681.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:30 metrics.py:449] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 127.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:22:31 logger.py:37] Received request chatcmpl-70caeb70c1d04560b2a8e103209a8e42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the shirt that the speaker is wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:31 engine.py:267] Added request chatcmpl-70caeb70c1d04560b2a8e103209a8e42.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:32 logger.py:37] Received request chatcmpl-f032e81ee9f447638b4904336fc664a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following gravitational wave detectors was featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:32 engine.py:267] Added request chatcmpl-f032e81ee9f447638b4904336fc664a5.
INFO 12-25 13:22:33 logger.py:37] Received request chatcmpl-67fb4e3dd3e845db889692e5ef0a38b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The main character of the video is observing the surface of the moon when he notices a straight line, what is it?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:33 engine.py:267] Added request chatcmpl-67fb4e3dd3e845db889692e5ef0a38b5.
INFO 12-25 13:22:35 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 124.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:37 logger.py:37] Received request chatcmpl-89f2a043cd8e41d0ba6d8c7f6ec5022c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:37 engine.py:267] Added request chatcmpl-89f2a043cd8e41d0ba6d8c7f6ec5022c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:40 logger.py:37] Received request chatcmpl-5d16feb09be24b5999306241d4a3859e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following causes is not mentioned in the video when it comes to ocean current?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:40 engine.py:267] Added request chatcmpl-5d16feb09be24b5999306241d4a3859e.
INFO 12-25 13:22:40 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:22:40 logger.py:37] Received request chatcmpl-4d5d012f973b4a56b6a838776834a61f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which specific phenomenon during the video demonstrated the correctness of general relativity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:40 engine.py:267] Added request chatcmpl-4d5d012f973b4a56b6a838776834a61f.
INFO 12-25 13:22:41 logger.py:37] Received request chatcmpl-9113320377e74bad8758b151d03c3d64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:41 engine.py:267] Added request chatcmpl-9113320377e74bad8758b151d03c3d64.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:45 logger.py:37] Received request chatcmpl-2aee109c511d4f7f8bef466456a43f6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which detail in the video indicates that the astronaut is currently outside the International Space Station (ISS)?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:45 engine.py:267] Added request chatcmpl-2aee109c511d4f7f8bef466456a43f6a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:45 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 119.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:22:46 logger.py:37] Received request chatcmpl-f73e4bb4f7234322921bae4f51e18d67: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the speaker explain before introducing MS4?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:46 engine.py:267] Added request chatcmpl-f73e4bb4f7234322921bae4f51e18d67.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:47 logger.py:37] Received request chatcmpl-45a2a7cc3a0e46d188206c869362ba86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What significant event increased the number of objects in Earth\'s orbit in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:47 engine.py:267] Added request chatcmpl-45a2a7cc3a0e46d188206c869362ba86.
INFO 12-25 13:22:48 logger.py:37] Received request chatcmpl-8907d8183177425eb65b49e2bb57d557: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who does the video focus on regarding their work with globular clusters?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:48 engine.py:267] Added request chatcmpl-8907d8183177425eb65b49e2bb57d557.
INFO 12-25 13:22:50 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 125.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:52 logger.py:37] Received request chatcmpl-2d7449f517b54254b9787d516b00d61a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the speaker mean when mentioning images of livestock and grazing animals from ancient paintings?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:52 engine.py:267] Added request chatcmpl-2d7449f517b54254b9787d516b00d61a.
INFO 12-25 13:22:53 logger.py:37] Received request chatcmpl-22b50608ed734a04a004e1b72c89f7dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At least how many total solar eclipses occurred between 1921 and 1970 according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:53 engine.py:267] Added request chatcmpl-22b50608ed734a04a004e1b72c89f7dc.
INFO 12-25 13:22:53 logger.py:37] Received request chatcmpl-e63f967167b4410bae711f84a4e81627: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times are rocket part separations shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:53 engine.py:267] Added request chatcmpl-e63f967167b4410bae711f84a4e81627.
INFO 12-25 13:22:55 metrics.py:449] Avg prompt throughput: 42.2 tokens/s, Avg generation throughput: 115.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:22:58 logger.py:37] Received request chatcmpl-d9ac64be9f0a44819899a6fc02d1a605: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What indicates if we travel inside a black hole for quite a while?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:22:58 engine.py:267] Added request chatcmpl-d9ac64be9f0a44819899a6fc02d1a605.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:00 logger.py:37] Received request chatcmpl-38c054b668574bc9a581fd7ba4ef8273: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video shows how long it takes to drive from the Earth to the Moon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:00 engine.py:267] Added request chatcmpl-38c054b668574bc9a581fd7ba4ef8273.
INFO 12-25 13:23:00 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 118.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:01 logger.py:37] Received request chatcmpl-528fdeb10f6841d3b4bbf42d88f7cc23: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many protraits at most are shown at one point of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:01 engine.py:267] Added request chatcmpl-528fdeb10f6841d3b4bbf42d88f7cc23.
INFO 12-25 13:23:01 logger.py:37] Received request chatcmpl-3449ce65879e49f2b2b80afcf4702496: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:01 engine.py:267] Added request chatcmpl-3449ce65879e49f2b2b80afcf4702496.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:03 logger.py:37] Received request chatcmpl-510d57b179e146de9dea0d2a7e4a4302: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the speaker mention students in a stressful class?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:03 engine.py:267] Added request chatcmpl-510d57b179e146de9dea0d2a7e4a4302.
INFO 12-25 13:23:05 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:10 logger.py:37] Received request chatcmpl-7c90d9bd6c2540629584fa5058ead14c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the speaker mention water pipes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:10 engine.py:267] Added request chatcmpl-7c90d9bd6c2540629584fa5058ead14c.
INFO 12-25 13:23:10 logger.py:37] Received request chatcmpl-d97e440cb8644b0a9ed55acf960cf261: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the clothes that the speaker is wearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:10 engine.py:267] Added request chatcmpl-d97e440cb8644b0a9ed55acf960cf261.
INFO 12-25 13:23:10 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 105.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:11 logger.py:37] Received request chatcmpl-bc4ed0e1bee24a8c8550951388cdbee3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the location of LIGO Hanford in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:11 logger.py:37] Received request chatcmpl-9f00623347e240bab3db731a571d8bde: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main color of Nuna?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:11 engine.py:267] Added request chatcmpl-bc4ed0e1bee24a8c8550951388cdbee3.
INFO 12-25 13:23:11 engine.py:267] Added request chatcmpl-9f00623347e240bab3db731a571d8bde.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:15 logger.py:37] Received request chatcmpl-8193d79e12064006bb341157ba10d2b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about the water bottle in imagination is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:15 engine.py:267] Added request chatcmpl-8193d79e12064006bb341157ba10d2b3.
INFO 12-25 13:23:15 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 134.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:19 logger.py:37] Received request chatcmpl-f4d7075c876f43deb66bfd7a304fe53d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which one does not exist on the islands west of the Wallace Line?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:19 logger.py:37] Received request chatcmpl-8527e66a0ce64fdc909f16b5b5ba8ecd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is Nuralagus rex doing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:19 logger.py:37] Received request chatcmpl-648a3ea67cec4380a7a239cff968a13e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "For the class of space debris measuring between 1 and 10 centimeters, which cleanup method is proposed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:19 engine.py:267] Added request chatcmpl-f4d7075c876f43deb66bfd7a304fe53d.
INFO 12-25 13:23:19 engine.py:267] Added request chatcmpl-8527e66a0ce64fdc909f16b5b5ba8ecd.
INFO 12-25 13:23:19 engine.py:267] Added request chatcmpl-648a3ea67cec4380a7a239cff968a13e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:20 metrics.py:449] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 104.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:21 logger.py:37] Received request chatcmpl-bc441014adc648418772c03c9a770652: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the speaker introduce the fact that the Mediterranean might disappear for a long while?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:21 engine.py:267] Added request chatcmpl-bc441014adc648418772c03c9a770652.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:25 logger.py:37] Received request chatcmpl-093be5fc47894c23ae3ee7abb88fa270: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the local people ask whether the youtuber brought his oxygen mask?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:25 engine.py:267] Added request chatcmpl-093be5fc47894c23ae3ee7abb88fa270.
INFO 12-25 13:23:25 logger.py:37] Received request chatcmpl-114226946a784eaab893f93e8a57d9ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:25 engine.py:267] Added request chatcmpl-114226946a784eaab893f93e8a57d9ff.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:25 metrics.py:449] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 117.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:27 logger.py:37] Received request chatcmpl-020a0ade07bb4958a0d6626f2c180e9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the clothes that William Smith is wearing in his protrait?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:27 engine.py:267] Added request chatcmpl-020a0ade07bb4958a0d6626f2c180e9a.
INFO 12-25 13:23:27 logger.py:37] Received request chatcmpl-366131eae4904b4ba4b3700a485752e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following elements is not an evidence for the green Sahara?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:27 engine.py:267] Added request chatcmpl-366131eae4904b4ba4b3700a485752e3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:30 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 130.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:32 logger.py:37] Received request chatcmpl-35928b98ef694ab49967a46caedd0437: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens at the end of the Paleozoic Era?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:32 engine.py:267] Added request chatcmpl-35928b98ef694ab49967a46caedd0437.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:33 logger.py:37] Received request chatcmpl-4c9b1871765845c18ef9d9f92df4d8dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the application submitted by the victim in the last part of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:33 engine.py:267] Added request chatcmpl-4c9b1871765845c18ef9d9f92df4d8dc.
INFO 12-25 13:23:33 logger.py:37] Received request chatcmpl-f4096aa7460e4e29bc7945f5b8f67851: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the diameter of the black hole S5 0014+81 compare to other distances in space?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:33 engine.py:267] Added request chatcmpl-f4096aa7460e4e29bc7945f5b8f67851.
INFO 12-25 13:23:34 logger.py:37] Received request chatcmpl-e211448c83e94a1592dbf00e3444b354: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main reason that the period is called Boring Billion?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:34 engine.py:267] Added request chatcmpl-e211448c83e94a1592dbf00e3444b354.
INFO 12-25 13:23:35 metrics.py:449] Avg prompt throughput: 54.9 tokens/s, Avg generation throughput: 96.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:39 logger.py:37] Received request chatcmpl-71c4e845e5714c52bbc63c33eee9b445: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the order of the following types of weathering in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:39 engine.py:267] Added request chatcmpl-71c4e845e5714c52bbc63c33eee9b445.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:40 logger.py:37] Received request chatcmpl-e57eec25a22842a3bb8b50e921b3b329: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different points of views about the amount of continents are mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:40 logger.py:37] Received request chatcmpl-8332bbd0023d4e12943ea81b37919f5c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the third criteria promoted by Nick Mortimer that a continent must meet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:40 engine.py:267] Added request chatcmpl-e57eec25a22842a3bb8b50e921b3b329.
INFO 12-25 13:23:40 engine.py:267] Added request chatcmpl-8332bbd0023d4e12943ea81b37919f5c.
INFO 12-25 13:23:40 metrics.py:449] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 95.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:41 logger.py:37] Received request chatcmpl-9cebd9d0db3c495c9e1cf5c2c47ddc05: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:41 engine.py:267] Added request chatcmpl-9cebd9d0db3c495c9e1cf5c2c47ddc05.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:44 logger.py:37] Received request chatcmpl-ab9e868b3dea400aad98e9aba98c97ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the weather like in the city at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:44 engine.py:267] Added request chatcmpl-ab9e868b3dea400aad98e9aba98c97ea.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:45 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 135.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:46 logger.py:37] Received request chatcmpl-e93a64a6fb8e4d06924bdcc7982a8787: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which AI technology is not featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:46 engine.py:267] Added request chatcmpl-e93a64a6fb8e4d06924bdcc7982a8787.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:47 logger.py:37] Received request chatcmpl-2cea21d17fd646eabf37294551236dc5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the background color of the sign that marks the highest point of Kiribati?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:47 engine.py:267] Added request chatcmpl-2cea21d17fd646eabf37294551236dc5.
INFO 12-25 13:23:48 logger.py:37] Received request chatcmpl-5cd09e5a5bb84b6f855bd98ba2e3c1ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When was Wallace firstly aware of the Wallace line?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:48 engine.py:267] Added request chatcmpl-5cd09e5a5bb84b6f855bd98ba2e3c1ff.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:50 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:52 logger.py:37] Received request chatcmpl-c67f1f89d4894dbeba22aaf94360df6d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who made the call received in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:52 engine.py:267] Added request chatcmpl-c67f1f89d4894dbeba22aaf94360df6d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:23:54 logger.py:37] Received request chatcmpl-fbbcee1c80a54a75b9c08cd36e369ba6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following hypotheses for the disappearance of Mediterranean isn\'t mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:54 engine.py:267] Added request chatcmpl-fbbcee1c80a54a75b9c08cd36e369ba6.
INFO 12-25 13:23:55 logger.py:37] Received request chatcmpl-b9a2fc3f8e88404ca3b9321ed6d8842a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the example of avocados in the video meant to illustrate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:55 engine.py:267] Added request chatcmpl-b9a2fc3f8e88404ca3b9321ed6d8842a.
INFO 12-25 13:23:55 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 103.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:23:56 logger.py:37] Received request chatcmpl-d9cc90d125c844a1a735dbc9d4347863: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the youtuber advise in order to save Kiribati?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:23:56 engine.py:267] Added request chatcmpl-d9cc90d125c844a1a735dbc9d4347863.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:00 logger.py:37] Received request chatcmpl-3b966315e15f4420b147c605d32c2a45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the man in the suit sitting next to the boy in the courtroom in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:00 engine.py:267] Added request chatcmpl-3b966315e15f4420b147c605d32c2a45.
INFO 12-25 13:24:00 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:24:02 logger.py:37] Received request chatcmpl-63527f614ee849c5ba4908661af78222: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the speaker explain after seeing the ancient paintings at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:02 logger.py:37] Received request chatcmpl-d2f91c604d5042c8a2e99cde9d72cbb3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:02 engine.py:267] Added request chatcmpl-63527f614ee849c5ba4908661af78222.
INFO 12-25 13:24:02 engine.py:267] Added request chatcmpl-d2f91c604d5042c8a2e99cde9d72cbb3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:03 logger.py:37] Received request chatcmpl-cfd6b235741848738c857115d59c10e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the fifth sign that is introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:03 engine.py:267] Added request chatcmpl-cfd6b235741848738c857115d59c10e1.
INFO 12-25 13:24:05 metrics.py:449] Avg prompt throughput: 53.1 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:08 logger.py:37] Received request chatcmpl-889d79c2f806492c9450eaebf017b070: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the content of the video, why does the little boy squatting on the ground playing with a toy car run away and hide?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:08 engine.py:267] Added request chatcmpl-889d79c2f806492c9450eaebf017b070.
INFO 12-25 13:24:09 logger.py:37] Received request chatcmpl-9c4322ea2e1a424fa1e5f29aff6e08e4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:09 logger.py:37] Received request chatcmpl-93a40808ad79414aa178dd4506f042b8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the lichens possibly like according to its image in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:09 logger.py:37] Received request chatcmpl-c163a527db784cfebf40e170a616134e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second case in the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:09 engine.py:267] Added request chatcmpl-9c4322ea2e1a424fa1e5f29aff6e08e4.
INFO 12-25 13:24:09 engine.py:267] Added request chatcmpl-93a40808ad79414aa178dd4506f042b8.
INFO 12-25 13:24:09 engine.py:267] Added request chatcmpl-c163a527db784cfebf40e170a616134e.
INFO 12-25 13:24:10 metrics.py:449] Avg prompt throughput: 54.0 tokens/s, Avg generation throughput: 81.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:16 logger.py:37] Received request chatcmpl-292eca866a794a62905a8cd90af8f95f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which codexes are compared in common in the second half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:16 engine.py:267] Added request chatcmpl-292eca866a794a62905a8cd90af8f95f.
INFO 12-25 13:24:16 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 106.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:24:16 logger.py:37] Received request chatcmpl-fa277f39f23248869b76b1d2612c5649: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:16 engine.py:267] Added request chatcmpl-fa277f39f23248869b76b1d2612c5649.
INFO 12-25 13:24:17 logger.py:37] Received request chatcmpl-783cee6a8d0740d2aae1c317d2572278: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about the Eight-Continents theory is true according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:17 logger.py:37] Received request chatcmpl-792e00ed4d0b41a5993a44f3ea5a1713: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was discussed after the introduction to generative AI?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:17 engine.py:267] Added request chatcmpl-783cee6a8d0740d2aae1c317d2572278.
INFO 12-25 13:24:17 engine.py:267] Added request chatcmpl-792e00ed4d0b41a5993a44f3ea5a1713.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:21 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 122.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:22 logger.py:37] Received request chatcmpl-c40672d5c8c548bc9d693d86cf81c767: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the real trial transcript in the second half of the video, how many people raised their right hands during the jury discussion?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:22 logger.py:37] Received request chatcmpl-ef654d228a674a0f80c31b0fb6ca9796: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which option correctly indicates the location of the "psychological tip" written in white on the board when illustrating the third suggestion in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:22 engine.py:267] Added request chatcmpl-c40672d5c8c548bc9d693d86cf81c767.
INFO 12-25 13:24:22 engine.py:267] Added request chatcmpl-ef654d228a674a0f80c31b0fb6ca9796.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:24 logger.py:37] Received request chatcmpl-feb3da192fbf4406ad2bf9bffa68b8e6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following professions does not appear at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:24 logger.py:37] Received request chatcmpl-cd01cc99510d47fa9ba7175f8512e8cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the correct order of these following events?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:24 engine.py:267] Added request chatcmpl-feb3da192fbf4406ad2bf9bffa68b8e6.
INFO 12-25 13:24:24 engine.py:267] Added request chatcmpl-cd01cc99510d47fa9ba7175f8512e8cb.
INFO 12-25 13:24:26 metrics.py:449] Avg prompt throughput: 57.0 tokens/s, Avg generation throughput: 107.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:29 logger.py:37] Received request chatcmpl-c993b4452d074800bd31ce4377d9964c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the phone display at the end of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:29 engine.py:267] Added request chatcmpl-c993b4452d074800bd31ce4377d9964c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:30 logger.py:37] Received request chatcmpl-31746db7d99d4416ac8d506c5cc181a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country is the destination of the plane at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:30 engine.py:267] Added request chatcmpl-31746db7d99d4416ac8d506c5cc181a9.
INFO 12-25 13:24:31 logger.py:37] Received request chatcmpl-efc5ce0f1c2e4834adc1e61b0abd2239: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When discussing which of the following points in this video, there was no page switching? (a) The first. (b) The fourth. (c) The fifth. (d) The eighth. (e) The ninth.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:31 engine.py:267] Added request chatcmpl-efc5ce0f1c2e4834adc1e61b0abd2239.
INFO 12-25 13:24:31 metrics.py:449] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 114.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:35 logger.py:37] Received request chatcmpl-2b9d38506d5743829e7ea53ffcb9484a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is the role of the girl in the yellow top and red trousers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:35 logger.py:37] Received request chatcmpl-5ba2fc5b64d44bd3b335e9e848d40cf8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which question is not included in the frequently asked questions displayed on the website?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:35 engine.py:267] Added request chatcmpl-2b9d38506d5743829e7ea53ffcb9484a.
INFO 12-25 13:24:35 engine.py:267] Added request chatcmpl-5ba2fc5b64d44bd3b335e9e848d40cf8.
INFO 12-25 13:24:36 metrics.py:449] Avg prompt throughput: 47.2 tokens/s, Avg generation throughput: 125.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:39 logger.py:37] Received request chatcmpl-f6fe1a4564f24f0aaddb8b07c569c6e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of cases are cited in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:39 engine.py:267] Added request chatcmpl-f6fe1a4564f24f0aaddb8b07c569c6e0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:40 logger.py:37] Received request chatcmpl-8662eb04c19645e3ba440be23764cc7d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the steps to decorate a Christmas tree? (a) Add Ornaments. (b) Frost with Icicles to finish. (c) Assemble the tree, and add lights if necessary. (d) Fluff the branches according to your liking. (e) Add the nature. (f) Fix the area you want to camouflage.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:40 engine.py:267] Added request chatcmpl-8662eb04c19645e3ba440be23764cc7d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:41 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 119.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:24:41 logger.py:37] Received request chatcmpl-62abf5bd2e7a4d609e8d5e0e105c2c31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is not mentioned in the video that need to pay attention to before entering the court?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:41 engine.py:267] Added request chatcmpl-62abf5bd2e7a4d609e8d5e0e105c2c31.
INFO 12-25 13:24:42 logger.py:37] Received request chatcmpl-04ff18c5306445828346a8c857b79b8a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the last case of the video, what happens when the man divorces with the lady?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:42 engine.py:267] Added request chatcmpl-04ff18c5306445828346a8c857b79b8a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:45 logger.py:37] Received request chatcmpl-5c7b69aa1c0a419cbbdae90addea14fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many photos of the cartoon version of criminals appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:45 engine.py:267] Added request chatcmpl-5c7b69aa1c0a419cbbdae90addea14fd.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:46 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 132.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:47 logger.py:37] Received request chatcmpl-118ad9668ef74810b2a90852499f7846: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What activities are the men in the video not allowed to do while in captivity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:47 engine.py:267] Added request chatcmpl-118ad9668ef74810b2a90852499f7846.
INFO 12-25 13:24:48 logger.py:37] Received request chatcmpl-cea96e78dc7d42919afb99cadb7459f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when a woman crosses the road in the beginning of the video when there are no legal rules?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:48 engine.py:267] Added request chatcmpl-cea96e78dc7d42919afb99cadb7459f4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:51 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 128.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:24:52 logger.py:37] Received request chatcmpl-209c5f166be349c79b7ab4c5f179e1ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the final piece of equipment that the woman adds to her body?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:52 engine.py:267] Added request chatcmpl-209c5f166be349c79b7ab4c5f179e1ab.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:54 logger.py:37] Received request chatcmpl-2fe7a0ad17674acb80d16ab493cb7b76: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the man demonstrate to do a tuck?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:54 engine.py:267] Added request chatcmpl-2fe7a0ad17674acb80d16ab493cb7b76.
INFO 12-25 13:24:54 logger.py:37] Received request chatcmpl-4f9ca701ba6f41c5b3e2c80f539c88f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many judges hear the federal appeals shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:54 engine.py:267] Added request chatcmpl-4f9ca701ba6f41c5b3e2c80f539c88f3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:24:56 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 118.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:24:57 logger.py:37] Received request chatcmpl-c25751d0586d4ff28594dd3e1efb96e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the visualization in the video most closely resemble?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:24:57 engine.py:267] Added request chatcmpl-c25751d0586d4ff28594dd3e1efb96e8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:00 logger.py:37] Received request chatcmpl-f6c8a64d834f4062a7afd1bb4ac276db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the displaying link change after is historically clicked?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:00 logger.py:37] Received request chatcmpl-1c0e1eb03cde4c03a96d65a4cadd68e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:00 engine.py:267] Added request chatcmpl-f6c8a64d834f4062a7afd1bb4ac276db.
INFO 12-25 13:25:00 engine.py:267] Added request chatcmpl-1c0e1eb03cde4c03a96d65a4cadd68e5.
INFO 12-25 13:25:01 metrics.py:449] Avg prompt throughput: 36.9 tokens/s, Avg generation throughput: 109.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:03 logger.py:37] Received request chatcmpl-ebe929ae65d148439e1ebce8002ea47b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many members of the jury are shown in the first half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:03 engine.py:267] Added request chatcmpl-ebe929ae65d148439e1ebce8002ea47b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:05 logger.py:37] Received request chatcmpl-bd7536659c1c4e93ba21b1b789ac33b7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the trick of evolving backward tuck into a backflip in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:05 engine.py:267] Added request chatcmpl-bd7536659c1c4e93ba21b1b789ac33b7.
INFO 12-25 13:25:05 logger.py:37] Received request chatcmpl-a57da37e8e6b4e5596e062d9f706528f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:06 engine.py:267] Added request chatcmpl-a57da37e8e6b4e5596e062d9f706528f.
INFO 12-25 13:25:06 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 123.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:08 logger.py:37] Received request chatcmpl-d03249f182b44e0f92cf2d111be58262: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:08 engine.py:267] Added request chatcmpl-d03249f182b44e0f92cf2d111be58262.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:11 logger.py:37] Received request chatcmpl-79e91f67293c460fa3ade1cf9ec486f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When introducing the eighth point, how many people finally appeared on the screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:11 engine.py:267] Added request chatcmpl-79e91f67293c460fa3ade1cf9ec486f2.
INFO 12-25 13:25:11 metrics.py:449] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 126.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:12 logger.py:37] Received request chatcmpl-cae7392761b64c2a9b853f3e73fc61fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which finger touches the chopsticks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:12 engine.py:267] Added request chatcmpl-cae7392761b64c2a9b853f3e73fc61fb.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:14 logger.py:37] Received request chatcmpl-5c044bad2c7d4097a152a153dc7675da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special about her skate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:14 engine.py:267] Added request chatcmpl-5c044bad2c7d4097a152a153dc7675da.
INFO 12-25 13:25:14 logger.py:37] Received request chatcmpl-88e8ce10a891454ab6ef56b4d259c149: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the red bucket shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:14 engine.py:267] Added request chatcmpl-88e8ce10a891454ab6ef56b4d259c149.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:16 metrics.py:449] Avg prompt throughput: 51.0 tokens/s, Avg generation throughput: 116.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:18 logger.py:37] Received request chatcmpl-5d816ac3ceca4a088fa18ce489aab14b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which year marked the debut of the typewriter introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:18 logger.py:37] Received request chatcmpl-750391bc7fdf4538979dca49a49a933d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options does not appear on the stone tablet carved by the two men at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:18 engine.py:267] Added request chatcmpl-5d816ac3ceca4a088fa18ce489aab14b.
INFO 12-25 13:25:18 engine.py:267] Added request chatcmpl-750391bc7fdf4538979dca49a49a933d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:20 logger.py:37] Received request chatcmpl-e8f740c05ecc4f5bbeb5249867d49fe9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the recommended brand of the shoe cleaner in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:20 engine.py:267] Added request chatcmpl-e8f740c05ecc4f5bbeb5249867d49fe9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:21 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 103.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:25:21 logger.py:37] Received request chatcmpl-c893f38404404fcd96625c98c9761322: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What item is not used to decorate the Christmas tree?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:21 engine.py:267] Added request chatcmpl-c893f38404404fcd96625c98c9761322.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:24 logger.py:37] Received request chatcmpl-4f5f177c7d1e4e328e451a5db7b98b41: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the identity of the cartoon character wearing a hat and raising his right hand in salute in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:24 logger.py:37] Received request chatcmpl-f78848b761134ac6bb85b23db78e0e7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the ad in the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:24 engine.py:267] Added request chatcmpl-4f5f177c7d1e4e328e451a5db7b98b41.
INFO 12-25 13:25:24 engine.py:267] Added request chatcmpl-f78848b761134ac6bb85b23db78e0e7c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:26 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:25:26 logger.py:37] Received request chatcmpl-3b1a2917b9e444b98199fc5851f60a37: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:26 engine.py:267] Added request chatcmpl-3b1a2917b9e444b98199fc5851f60a37.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:29 logger.py:37] Received request chatcmpl-393ba04a19a24cefa42d02b5700cae97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which tool does not the man wearing green hat use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:29 engine.py:267] Added request chatcmpl-393ba04a19a24cefa42d02b5700cae97.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:31 logger.py:37] Received request chatcmpl-1d5356f936ba4da3969192702c979c4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is incorrect?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:31 engine.py:267] Added request chatcmpl-1d5356f936ba4da3969192702c979c4e.
INFO 12-25 13:25:31 metrics.py:449] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:34 logger.py:37] Received request chatcmpl-0423c3d458f44d4b89d8885220d41568: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the pneumatic air gun?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:34 engine.py:267] Added request chatcmpl-0423c3d458f44d4b89d8885220d41568.
INFO 12-25 13:25:34 logger.py:37] Received request chatcmpl-082ea014f0204a6aa05adfba7ec3b712: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of drawing a bifurcated tree when introducing the threading?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:34 engine.py:267] Added request chatcmpl-082ea014f0204a6aa05adfba7ec3b712.
INFO 12-25 13:25:36 metrics.py:449] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 126.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:39 logger.py:37] Received request chatcmpl-c700e34fc4414dadbd5f98def7b07863: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the driving range of Tesla Model X Long Range version on a single charge?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:39 logger.py:37] Received request chatcmpl-a134c3f811e045d3b9096b2aff84efeb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, which food is not used to practice holding chopsticks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:39 engine.py:267] Added request chatcmpl-c700e34fc4414dadbd5f98def7b07863.
INFO 12-25 13:25:39 engine.py:267] Added request chatcmpl-a134c3f811e045d3b9096b2aff84efeb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:41 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:25:41 logger.py:37] Received request chatcmpl-bfa917836dd546509a04168518bee67e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the department on the website?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:41 engine.py:267] Added request chatcmpl-bfa917836dd546509a04168518bee67e.
INFO 12-25 13:25:43 logger.py:37] Received request chatcmpl-4a9839a3f5b54308b037376c7e5d203e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the blue item most likely to be?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:43 engine.py:267] Added request chatcmpl-4a9839a3f5b54308b037376c7e5d203e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:44 logger.py:37] Received request chatcmpl-c08946c4633f4e87b055f58c031099a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the order in the video, what is the fourth GPT introduced (except GPT Finder)?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:44 engine.py:267] Added request chatcmpl-c08946c4633f4e87b055f58c031099a9.
INFO 12-25 13:25:44 logger.py:37] Received request chatcmpl-6a8969dd859a4458b04b3493211d2c91: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct about the typewriter introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:44 engine.py:267] Added request chatcmpl-6a8969dd859a4458b04b3493211d2c91.
INFO 12-25 13:25:46 metrics.py:449] Avg prompt throughput: 54.5 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:48 logger.py:37] Received request chatcmpl-fda6055bb6b74e509a1d3df70954a741: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the difference between the plants before and after being placed in the hole?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:48 engine.py:267] Added request chatcmpl-fda6055bb6b74e509a1d3df70954a741.
INFO 12-25 13:25:49 logger.py:37] Received request chatcmpl-678d501b4a1d45719847b2d0f44401a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which IMAX movie isn\'t in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:49 logger.py:37] Received request chatcmpl-daf964d8beec4706a1321812b17ab0a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not the meaning of the On-device AI technology introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:49 logger.py:37] Received request chatcmpl-91c65dc5b92041cd9f824e3e4f80e91c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:49 engine.py:267] Added request chatcmpl-678d501b4a1d45719847b2d0f44401a7.
INFO 12-25 13:25:49 engine.py:267] Added request chatcmpl-daf964d8beec4706a1321812b17ab0a4.
INFO 12-25 13:25:49 engine.py:267] Added request chatcmpl-91c65dc5b92041cd9f824e3e4f80e91c.
INFO 12-25 13:25:51 metrics.py:449] Avg prompt throughput: 51.9 tokens/s, Avg generation throughput: 105.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:25:57 logger.py:37] Received request chatcmpl-09de436b8903487889340b6c06a25f02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why is IMAX not suitable for filming movies?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:57 engine.py:267] Added request chatcmpl-09de436b8903487889340b6c06a25f02.
INFO 12-25 13:25:57 logger.py:37] Received request chatcmpl-6e4f4b866b0340fa8ff6a5c4673d6d97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, guess how many times more powerful is the PS5 than the PS2?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:57 engine.py:267] Added request chatcmpl-6e4f4b866b0340fa8ff6a5c4673d6d97.
INFO 12-25 13:25:57 metrics.py:449] Avg prompt throughput: 10.8 tokens/s, Avg generation throughput: 104.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:25:58 logger.py:37] Received request chatcmpl-c010861d6ced4674be9530454781dc6e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where are the propellers of the flying car in the video stored?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:58 engine.py:267] Added request chatcmpl-c010861d6ced4674be9530454781dc6e.
INFO 12-25 13:25:59 logger.py:37] Received request chatcmpl-300b1353475a4360968d32e5679bbdb6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the difference of the woman when talking to the camera and when decorating the tree?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:25:59 engine.py:267] Added request chatcmpl-300b1353475a4360968d32e5679bbdb6.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:02 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 135.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:03 logger.py:37] Received request chatcmpl-e59122c425fd4bf29940751490e7ea2c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which transportation is the quantum computer compared to in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:03 engine.py:267] Added request chatcmpl-e59122c425fd4bf29940751490e7ea2c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:04 logger.py:37] Received request chatcmpl-067f7155ee474ed29ed1c73b994c0750: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Shen do for changing his fate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:04 engine.py:267] Added request chatcmpl-067f7155ee474ed29ed1c73b994c0750.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:06 logger.py:37] Received request chatcmpl-2033fb5015904640be5120ea17da8c48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is forbidden when there is a huge red cross on the screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:06 engine.py:267] Added request chatcmpl-2033fb5015904640be5120ea17da8c48.
INFO 12-25 13:26:07 logger.py:37] Received request chatcmpl-6bb30a94050c497e9efdecd357ce414d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:07 engine.py:267] Added request chatcmpl-6bb30a94050c497e9efdecd357ce414d.
INFO 12-25 13:26:07 metrics.py:449] Avg prompt throughput: 49.6 tokens/s, Avg generation throughput: 103.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:10 logger.py:37] Received request chatcmpl-dc7b146ae3534695bb6d3f43c78df456: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the seats in the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:10 engine.py:267] Added request chatcmpl-dc7b146ae3534695bb6d3f43c78df456.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:12 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 146.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:14 logger.py:37] Received request chatcmpl-5e12d07cb0044158a5fbc2a3b1aabcab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the mentor of the Chased black spider-man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:14 logger.py:37] Received request chatcmpl-2d31693800114cb19503b8708d761bc3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why doesn\'t it work to click on a cell phone while wearing gloves?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:14 engine.py:267] Added request chatcmpl-5e12d07cb0044158a5fbc2a3b1aabcab.
INFO 12-25 13:26:14 engine.py:267] Added request chatcmpl-2d31693800114cb19503b8708d761bc3.
INFO 12-25 13:26:15 logger.py:37] Received request chatcmpl-bf4bfe55f4f94f6c801e6f1c4bf099ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens to the drill when it is taken out of the orange bucket?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:15 engine.py:267] Added request chatcmpl-bf4bfe55f4f94f6c801e6f1c4bf099ca.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:16 logger.py:37] Received request chatcmpl-b63ed9f40c024873b5f548b9d44c817f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, guess what device the touch screen was first used on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:16 engine.py:267] Added request chatcmpl-b63ed9f40c024873b5f548b9d44c817f.
INFO 12-25 13:26:17 metrics.py:449] Avg prompt throughput: 53.1 tokens/s, Avg generation throughput: 102.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:20 logger.py:37] Received request chatcmpl-189efd81a8dd421cbdda17bf45395663: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill does the chicken have?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:20 engine.py:267] Added request chatcmpl-189efd81a8dd421cbdda17bf45395663.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:22 logger.py:37] Received request chatcmpl-f25c3244819f42bb8ee707b4e1dcf53f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many groups of people were interviewed in the promotional video at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:22 engine.py:267] Added request chatcmpl-f25c3244819f42bb8ee707b4e1dcf53f.
INFO 12-25 13:26:22 logger.py:37] Received request chatcmpl-7ef8adee734f4a76a63e3b1328d1b6c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sticker does it appear on the screen at the beginning of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:22 engine.py:267] Added request chatcmpl-7ef8adee734f4a76a63e3b1328d1b6c0.
INFO 12-25 13:26:22 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 113.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:25 logger.py:37] Received request chatcmpl-7dd445d1a1cb4a7d8d8466848bca74ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which GPT is introduced after Convert Anything?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:25 engine.py:267] Added request chatcmpl-7dd445d1a1cb4a7d8d8466848bca74ee.
INFO 12-25 13:26:26 logger.py:37] Received request chatcmpl-5abc4d09c5554a4aafb906010749bb91: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when a monster teach math?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:26 engine.py:267] Added request chatcmpl-5abc4d09c5554a4aafb906010749bb91.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:27 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 121.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:28 logger.py:37] Received request chatcmpl-9c1d31f2e60f4a34bfc884fa7fd0d0a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which game is played on each generation of Play Stations in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:28 engine.py:267] Added request chatcmpl-9c1d31f2e60f4a34bfc884fa7fd0d0a4.
INFO 12-25 13:26:29 logger.py:37] Received request chatcmpl-7344d280b6ec49e6a7f6f5b8610d25bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:29 engine.py:267] Added request chatcmpl-7344d280b6ec49e6a7f6f5b8610d25bf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:31 logger.py:37] Received request chatcmpl-b6338754b4af4578a29924aef4598257: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many clips of Mad Men where the typewriter made appearances are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:31 engine.py:267] Added request chatcmpl-b6338754b4af4578a29924aef4598257.
INFO 12-25 13:26:32 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 129.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:34 logger.py:37] Received request chatcmpl-8b92c6999b5e4b52bedffefc54a6e0e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the ship coming here?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:34 engine.py:267] Added request chatcmpl-8b92c6999b5e4b52bedffefc54a6e0e2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:36 logger.py:37] Received request chatcmpl-dc29662b69d34dfcb216077363bcb45b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who owns the bottle containing protists at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:36 engine.py:267] Added request chatcmpl-dc29662b69d34dfcb216077363bcb45b.
INFO 12-25 13:26:37 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 130.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:39 logger.py:37] Received request chatcmpl-bbb50872cc5844e1a6260f477f701dad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:39 engine.py:267] Added request chatcmpl-bbb50872cc5844e1a6260f477f701dad.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:42 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:43 logger.py:37] Received request chatcmpl-644a4b6028394c83adb1328fe6dd6c8d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What story does the video tell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:43 engine.py:267] Added request chatcmpl-644a4b6028394c83adb1328fe6dd6c8d.
INFO 12-25 13:26:44 logger.py:37] Received request chatcmpl-6dc2d344f50b454e9fc5a50363ad9f92: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:44 engine.py:267] Added request chatcmpl-6dc2d344f50b454e9fc5a50363ad9f92.
INFO 12-25 13:26:45 logger.py:37] Received request chatcmpl-6424bb1fdd634e7998d5cc1a58248543: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is incorrect?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:45 logger.py:37] Received request chatcmpl-4114bbf53a4b452ca6cc9ee5d22d3134: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Shen feel when he is going to see a panda?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:45 engine.py:267] Added request chatcmpl-6424bb1fdd634e7998d5cc1a58248543.
INFO 12-25 13:26:45 engine.py:267] Added request chatcmpl-4114bbf53a4b452ca6cc9ee5d22d3134.
INFO 12-25 13:26:47 metrics.py:449] Avg prompt throughput: 49.4 tokens/s, Avg generation throughput: 103.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:50 logger.py:37] Received request chatcmpl-406bcdc53e8b42aaaa29327b75ba4779: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which does not appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:50 logger.py:37] Received request chatcmpl-bbd1500c45e0421f80d9af48a0ace710: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the attitude of the king towards the hero in front of him?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:50 engine.py:267] Added request chatcmpl-406bcdc53e8b42aaaa29327b75ba4779.
INFO 12-25 13:26:50 engine.py:267] Added request chatcmpl-bbd1500c45e0421f80d9af48a0ace710.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:51 logger.py:37] Received request chatcmpl-3b88134c13394c6bbc0496c7322c76c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the chased black spider-man hide at first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:51 engine.py:267] Added request chatcmpl-3b88134c13394c6bbc0496c7322c76c9.
INFO 12-25 13:26:52 logger.py:37] Received request chatcmpl-5cb93fa2a2154295a584a3551cd79dbb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is correct for ranking Tesla models from shortest to longest 0-60 mph acceleration time based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:52 engine.py:267] Added request chatcmpl-5cb93fa2a2154295a584a3551cd79dbb.
INFO 12-25 13:26:53 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 96.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:56 logger.py:37] Received request chatcmpl-192dd66785f64b2e872dccd514cdfc93: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the two girls in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:56 engine.py:267] Added request chatcmpl-192dd66785f64b2e872dccd514cdfc93.
INFO 12-25 13:26:58 metrics.py:449] Avg prompt throughput: 12.7 tokens/s, Avg generation throughput: 144.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:26:59 logger.py:37] Received request chatcmpl-6884ce08af4b4ae38ad75da8b88666d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Puss in Boots feel when he hear the whistle of the man with hat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:26:59 engine.py:267] Added request chatcmpl-6884ce08af4b4ae38ad75da8b88666d5.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:03 metrics.py:449] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 133.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:27:03 logger.py:37] Received request chatcmpl-fb2eadf7e6b04ed695f60d5e21b571bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many penguins play torches when they have a bonfire party?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:03 engine.py:267] Added request chatcmpl-fb2eadf7e6b04ed695f60d5e21b571bf.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:04 logger.py:37] Received request chatcmpl-ab43ee882cb647a699a4cea61d5763ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the yellow turtle monster do after receiving a red book?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:04 engine.py:267] Added request chatcmpl-ab43ee882cb647a699a4cea61d5763ab.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:06 logger.py:37] Received request chatcmpl-50f05ffb2aad4170bbdf63b5fce067fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly orders the types of touch screens according to their order in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:06 engine.py:267] Added request chatcmpl-50f05ffb2aad4170bbdf63b5fce067fe.
INFO 12-25 13:27:07 logger.py:37] Received request chatcmpl-da85ea491c024c39be24841d6406f508: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter half of the video, what are the man and woman drinking during their date?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:07 engine.py:267] Added request chatcmpl-da85ea491c024c39be24841d6406f508.
INFO 12-25 13:27:08 metrics.py:449] Avg prompt throughput: 55.0 tokens/s, Avg generation throughput: 124.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:10 logger.py:37] Received request chatcmpl-d6d8801ed72042fb9e29b0e3088d0886: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the small iceberg shrinking?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:10 engine.py:267] Added request chatcmpl-d6d8801ed72042fb9e29b0e3088d0886.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:11 logger.py:37] Received request chatcmpl-53f85a4b82d54b4791a299d4a91792d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, in the little girl\'s recollection, what is the correct order of the events she experienced? (1) Her paintings were disliked by others. (2) She was pushed down by others. (3) She was forgotten by others when playing hide and seek. (4) She was talked about by others while swinging.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:11 engine.py:267] Added request chatcmpl-53f85a4b82d54b4791a299d4a91792d4.
INFO 12-25 13:27:13 logger.py:37] Received request chatcmpl-6e5ecc0ac0ac449cb6ef63c5355a8ed7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what might the content of the letter be?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:13 engine.py:267] Added request chatcmpl-6e5ecc0ac0ac449cb6ef63c5355a8ed7.
INFO 12-25 13:27:13 metrics.py:449] Avg prompt throughput: 35.6 tokens/s, Avg generation throughput: 114.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:14 logger.py:37] Received request chatcmpl-1bcdeff2540547859c76138110956526: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which GPT can generate a prompt based on the image so that DALLE can generate a similar image?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:14 engine.py:267] Added request chatcmpl-1bcdeff2540547859c76138110956526.
INFO 12-25 13:27:16 logger.py:37] Received request chatcmpl-9c3e967de3784e13b226b45d02517a69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the fox do after meeting the blue baby bird?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:16 engine.py:267] Added request chatcmpl-9c3e967de3784e13b226b45d02517a69.
INFO 12-25 13:27:18 metrics.py:449] Avg prompt throughput: 40.6 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:19 logger.py:37] Received request chatcmpl-3cdf7c7cc53449c9974734db3bb761d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the little iceberg meet first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:19 engine.py:267] Added request chatcmpl-3cdf7c7cc53449c9974734db3bb761d2.
INFO 12-25 13:27:20 logger.py:37] Received request chatcmpl-8ddba5cb4a844c598c7258ae27af648a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is Manny\'s family\'s pet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:20 engine.py:267] Added request chatcmpl-8ddba5cb4a844c598c7258ae27af648a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:22 logger.py:37] Received request chatcmpl-e1bc9d90828e49a883a271b7350cb7ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the hero wait until the last moment to save the princess?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:22 engine.py:267] Added request chatcmpl-e1bc9d90828e49a883a271b7350cb7ff.
INFO 12-25 13:27:23 logger.py:37] Received request chatcmpl-85d06abda9ee4cd697a375511bfa649b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the brand of the TV used with PS2 in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:23 engine.py:267] Added request chatcmpl-85d06abda9ee4cd697a375511bfa649b.
INFO 12-25 13:27:23 metrics.py:449] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 109.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:24 logger.py:37] Received request chatcmpl-2b10bc472bc74efabb766b17643a2245: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what do the dead dinosaurs transform into?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:24 engine.py:267] Added request chatcmpl-2b10bc472bc74efabb766b17643a2245.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:26 logger.py:37] Received request chatcmpl-5c62fb85f77f46ef9773848d444da0a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the female protagonist pay a bum to accompany her for a day at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:26 engine.py:267] Added request chatcmpl-5c62fb85f77f46ef9773848d444da0a0.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:28 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:29 logger.py:37] Received request chatcmpl-ad80e7e25a7f439298c30bba8ac839a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many crystals with cat in boots does Death break?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:29 engine.py:267] Added request chatcmpl-ad80e7e25a7f439298c30bba8ac839a1.
INFO 12-25 13:27:30 logger.py:37] Received request chatcmpl-fe67304674c848d999728cb8a1e63d36: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the baby bird go at last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:30 engine.py:267] Added request chatcmpl-fe67304674c848d999728cb8a1e63d36.
INFO 12-25 13:27:30 logger.py:37] Received request chatcmpl-79a972ecdad94d598a459debdd383812: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Among the examples of using microscopes to help learning life sciences at the end of the video, what are being observed in the example following the demonstration of studying mitosis?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:30 engine.py:267] Added request chatcmpl-79a972ecdad94d598a459debdd383812.
INFO 12-25 13:27:33 metrics.py:449] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:34 logger.py:37] Received request chatcmpl-b198d351275548a582b3d883178445c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is covered on the ground of the castle?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:34 engine.py:267] Added request chatcmpl-b198d351275548a582b3d883178445c0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:36 logger.py:37] Received request chatcmpl-b44d7deed9da4c05bf4bbc64588a1ad5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens to Shen at last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:36 engine.py:267] Added request chatcmpl-b44d7deed9da4c05bf4bbc64588a1ad5.
INFO 12-25 13:27:37 logger.py:37] Received request chatcmpl-cadb32ba86a942c2a886984a7485cfbd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If a cue appears in the bottom left corner when a splice occurs, then how many video clips were used to compose this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:37 engine.py:267] Added request chatcmpl-cadb32ba86a942c2a886984a7485cfbd.
INFO 12-25 13:27:38 metrics.py:449] Avg prompt throughput: 39.8 tokens/s, Avg generation throughput: 101.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:27:38 logger.py:37] Received request chatcmpl-b61ffbf3c84f4e12b7119c2629c6db16: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is Puss in Boots meet Death?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:38 engine.py:267] Added request chatcmpl-b61ffbf3c84f4e12b7119c2629c6db16.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:42 logger.py:37] Received request chatcmpl-95c4165087bf45928884fbe725512d3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many bullets does Rango use to kill the hawl in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:42 engine.py:267] Added request chatcmpl-95c4165087bf45928884fbe725512d3f.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:43 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 131.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:27:43 logger.py:37] Received request chatcmpl-b8c976380d4045b5bb7d99fd568f0c40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when the chicken is bumping fists with a penguin?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:43 engine.py:267] Added request chatcmpl-b8c976380d4045b5bb7d99fd568f0c40.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:45 logger.py:37] Received request chatcmpl-79b3e08a935b4829a666cfe9ac1a373f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the man always speak in a strange way during his date in the latter half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:45 engine.py:267] Added request chatcmpl-79b3e08a935b4829a666cfe9ac1a373f.
INFO 12-25 13:27:45 logger.py:37] Received request chatcmpl-50f468b0dc8049f69143cf2eb3f62408: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, where does young Sheldon find his father?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:45 engine.py:267] Added request chatcmpl-50f468b0dc8049f69143cf2eb3f62408.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:47 logger.py:37] Received request chatcmpl-baf320af712f4cab9f8f7c151d690c22: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the terminator with sunglasses hide his gun?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:47 engine.py:267] Added request chatcmpl-baf320af712f4cab9f8f7c151d690c22.
INFO 12-25 13:27:48 metrics.py:449] Avg prompt throughput: 53.1 tokens/s, Avg generation throughput: 109.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:51 logger.py:37] Received request chatcmpl-2022b2bcc01442378a2e8aaf2f4ff2c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, why does Manny want to be friends with Griffin?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:51 engine.py:267] Added request chatcmpl-2022b2bcc01442378a2e8aaf2f4ff2c2.
INFO 12-25 13:27:51 logger.py:37] Received request chatcmpl-d96e98a697ac4df58cb2c637b13374d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of story does this video record about the little girl?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:51 engine.py:267] Added request chatcmpl-d96e98a697ac4df58cb2c637b13374d6.
INFO 12-25 13:27:53 metrics.py:449] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 127.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:54 logger.py:37] Received request chatcmpl-0909740ed25b44bfb179d41eb9e8436a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What caused the dilapidated scene at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:54 engine.py:267] Added request chatcmpl-0909740ed25b44bfb179d41eb9e8436a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:27:55 logger.py:37] Received request chatcmpl-8e58eed9abf745acb73d7bd29150930f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the laptop the woman is holding at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:55 engine.py:267] Added request chatcmpl-8e58eed9abf745acb73d7bd29150930f.
INFO 12-25 13:27:56 logger.py:37] Received request chatcmpl-6885c20b21ac411ca5258e84f9a92ef4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the smarter one according to the hippo god?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:27:56 engine.py:267] Added request chatcmpl-6885c20b21ac411ca5258e84f9a92ef4.
INFO 12-25 13:27:58 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 118.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:00 logger.py:37] Received request chatcmpl-b0466c1f143d40968feeae008f8446d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who fight versus the black dinosaur at last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:00 engine.py:267] Added request chatcmpl-b0466c1f143d40968feeae008f8446d7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:02 logger.py:37] Received request chatcmpl-fd5ff15f05834379a5455519a6f3553e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, who is Griffin more interested in?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:02 engine.py:267] Added request chatcmpl-fd5ff15f05834379a5455519a6f3553e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:03 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 129.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:04 logger.py:37] Received request chatcmpl-aa37d44a94714bcdb69c7213d34ceab7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a reason why there are many teenage mothers in Brazil every year?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:04 logger.py:37] Received request chatcmpl-b44b1ab969e64e6da737181008a54120: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the dragon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:04 engine.py:267] Added request chatcmpl-aa37d44a94714bcdb69c7213d34ceab7.
INFO 12-25 13:28:04 engine.py:267] Added request chatcmpl-b44b1ab969e64e6da737181008a54120.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:08 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 100.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:08 logger.py:37] Received request chatcmpl-d29adeda020142db87b0517bbfb85b4d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when a star falls on the earth?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:08 logger.py:37] Received request chatcmpl-639124d8fa2b434f962fa8dd10485ab2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When in the video does the female protagonist wear a green dress?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:08 engine.py:267] Added request chatcmpl-d29adeda020142db87b0517bbfb85b4d.
INFO 12-25 13:28:08 engine.py:267] Added request chatcmpl-639124d8fa2b434f962fa8dd10485ab2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:10 logger.py:37] Received request chatcmpl-dd579117f94744e193b04387e2011d61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which part of the video is the woman in the blue top interviewed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:10 engine.py:267] Added request chatcmpl-dd579117f94744e193b04387e2011d61.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:11 logger.py:37] Received request chatcmpl-96305e3c51a943b4b174e2db87f8bce4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the opponent of Rango in the second matchup in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:11 engine.py:267] Added request chatcmpl-96305e3c51a943b4b174e2db87f8bce4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:13 metrics.py:449] Avg prompt throughput: 52.0 tokens/s, Avg generation throughput: 124.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:13 logger.py:37] Received request chatcmpl-849e38b809ff4d299a9b43f66e3fc1fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the mother bird bring a fish to the fox?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:13 engine.py:267] Added request chatcmpl-849e38b809ff4d299a9b43f66e3fc1fb.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:14 logger.py:37] Received request chatcmpl-65b4b67241204651875d339fe7b50088: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the hippo god decide to do?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:14 engine.py:267] Added request chatcmpl-65b4b67241204651875d339fe7b50088.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:16 logger.py:37] Received request chatcmpl-2a98fffb7e8a4828bb04662367ef51b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many persons does superman fight versus?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:16 engine.py:267] Added request chatcmpl-2a98fffb7e8a4828bb04662367ef51b5.
INFO 12-25 13:28:17 logger.py:37] Received request chatcmpl-f17d45e176674d42909f7cada99ebb14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how many cubs is the mother bear with when the filmer encounters her downstream of the river?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:18 engine.py:267] Added request chatcmpl-f17d45e176674d42909f7cada99ebb14.
INFO 12-25 13:28:18 metrics.py:449] Avg prompt throughput: 52.2 tokens/s, Avg generation throughput: 114.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:20 logger.py:37] Received request chatcmpl-ae0e6bfdcd3b49d5aba084c41904dca3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the hero take the last monster back?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:20 engine.py:267] Added request chatcmpl-ae0e6bfdcd3b49d5aba084c41904dca3.
INFO 12-25 13:28:21 logger.py:37] Received request chatcmpl-e344670c63c34b57829163a2b5848634: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal doesn\'t appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:21 engine.py:267] Added request chatcmpl-e344670c63c34b57829163a2b5848634.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:23 logger.py:37] Received request chatcmpl-60a3837654f740c8a5245af6f2ef7710: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the children wearing pink outfits doing at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:23 engine.py:267] Added request chatcmpl-60a3837654f740c8a5245af6f2ef7710.
INFO 12-25 13:28:23 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 118.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:26 logger.py:37] Received request chatcmpl-5d810f6228e042999fb9ebc5843b04c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the woman in the blue and black shirt want to do makeup for the man in the yellow shirt in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:26 engine.py:267] Added request chatcmpl-5d810f6228e042999fb9ebc5843b04c3.
INFO 12-25 13:28:27 logger.py:37] Received request chatcmpl-749a6aaf7e2c428ca190a8154fdd0dad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What ultimately happened to the little penguin that got lost from its parents in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:27 engine.py:267] Added request chatcmpl-749a6aaf7e2c428ca190a8154fdd0dad.
INFO 12-25 13:28:28 metrics.py:449] Avg prompt throughput: 29.3 tokens/s, Avg generation throughput: 127.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:30 logger.py:37] Received request chatcmpl-71e292f228794afa98e4484391d5c24f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, what kind of attitude is reflected in the interview with the young parents?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:30 engine.py:267] Added request chatcmpl-71e292f228794afa98e4484391d5c24f.
INFO 12-25 13:28:30 logger.py:37] Received request chatcmpl-ac92d23f5c4945618a438c38ea17d4bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is protecting the boy?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:30 engine.py:267] Added request chatcmpl-ac92d23f5c4945618a438c38ea17d4bc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:33 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:34 logger.py:37] Received request chatcmpl-0af536042a0b441fa1d5fa838ad2353d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What common element do these clips in the video share?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:34 engine.py:267] Added request chatcmpl-0af536042a0b441fa1d5fa838ad2353d.
INFO 12-25 13:28:35 logger.py:37] Received request chatcmpl-e1ff2e43a1794ad0b6d32655c1f6371f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following sections is not included in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:35 engine.py:267] Added request chatcmpl-e1ff2e43a1794ad0b6d32655c1f6371f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:37 logger.py:37] Received request chatcmpl-dc50158019a247d888a072911ac58676: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which step introduced in this video does not require the collaboration of two excavators?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:37 engine.py:267] Added request chatcmpl-dc50158019a247d888a072911ac58676.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:38 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 112.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:38 logger.py:37] Received request chatcmpl-d7451a8188d04467b7a806f9fdc5c40b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is caught in the air by Superman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:38 engine.py:267] Added request chatcmpl-d7451a8188d04467b7a806f9fdc5c40b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:43 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 127.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:43 logger.py:37] Received request chatcmpl-665651d1b8364267bc490ef2a91a5e4d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main food of the brown bear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:43 engine.py:267] Added request chatcmpl-665651d1b8364267bc490ef2a91a5e4d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:44 logger.py:37] Received request chatcmpl-79259785af6540a798d6d6b01bc6ecc5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did young Sheldon\'s mother not tell him about the contents of the letter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:44 engine.py:267] Added request chatcmpl-79259785af6540a798d6d6b01bc6ecc5.
INFO 12-25 13:28:44 logger.py:37] Received request chatcmpl-847f4c91bbf84639864f62dedf5b8e76: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The problems people encounter in the video are caused by what?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:44 engine.py:267] Added request chatcmpl-847f4c91bbf84639864f62dedf5b8e76.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:46 logger.py:37] Received request chatcmpl-01e3b9fba9f2423b887fb886f0b71112: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how does Vitria make money?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:46 engine.py:267] Added request chatcmpl-01e3b9fba9f2423b887fb886f0b71112.
INFO 12-25 13:28:48 logger.py:37] Received request chatcmpl-7d08481d26ed4f039abe18bff783f057: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video mentions that when penguins huddle together, the temperature in the middle can reach up to how many degrees Celsius?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:48 engine.py:267] Added request chatcmpl-7d08481d26ed4f039abe18bff783f057.
INFO 12-25 13:28:48 metrics.py:449] Avg prompt throughput: 51.7 tokens/s, Avg generation throughput: 112.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:50 logger.py:37] Received request chatcmpl-6d79c09f4ef646b588ca272d882e45f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, the man who leaves with the female protagonist is actually?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:50 engine.py:267] Added request chatcmpl-6d79c09f4ef646b588ca272d882e45f7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:52 logger.py:37] Received request chatcmpl-f4e6eaf2b1394d27b88cea24cf781fac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where in the video is the interview with the woman wearing a mask and a green shirt located?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:52 engine.py:267] Added request chatcmpl-f4e6eaf2b1394d27b88cea24cf781fac.
INFO 12-25 13:28:53 metrics.py:449] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 120.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:28:53 logger.py:37] Received request chatcmpl-f0c918f319a54228a665e87284f6d4a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the direction of movement of the man speaking to the camera at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:53 engine.py:267] Added request chatcmpl-f0c918f319a54228a665e87284f6d4a8.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:55 logger.py:37] Received request chatcmpl-811507f332a14859b1be979abafc035b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:55 engine.py:267] Added request chatcmpl-811507f332a14859b1be979abafc035b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:28:57 logger.py:37] Received request chatcmpl-9e55dc4cd64d4eab8beff900adb935d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the hippo god do with the two men\'s hearts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:28:57 engine.py:267] Added request chatcmpl-9e55dc4cd64d4eab8beff900adb935d8.
INFO 12-25 13:28:58 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 133.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:00 logger.py:37] Received request chatcmpl-504993db9c53452a92a509e706166cbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which part of the video is a man wearing a red jersey interviewed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:00 logger.py:37] Received request chatcmpl-70840049aaf0496f96c30b4b2746a1e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the five black-text lines penned by the man in blue is replicated in red spray paint during the sorting and counting phase?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:00 engine.py:267] Added request chatcmpl-504993db9c53452a92a509e706166cbe.
INFO 12-25 13:29:00 engine.py:267] Added request chatcmpl-70840049aaf0496f96c30b4b2746a1e0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:02 logger.py:37] Received request chatcmpl-b4c226e3684641db8ae218d4ecaddcb0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the person with white hair wearing a black top that appears in the middle of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:02 engine.py:267] Added request chatcmpl-b4c226e3684641db8ae218d4ecaddcb0.
INFO 12-25 13:29:03 metrics.py:449] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 97.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:29:03 logger.py:37] Received request chatcmpl-663e57c2ccd34ade93705a954200f515: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the creature do at last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:03 engine.py:267] Added request chatcmpl-663e57c2ccd34ade93705a954200f515.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:07 logger.py:37] Received request chatcmpl-e8bf7f9a084a4d4d8b59618c6a410603: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of the video, in which direction is the little penguin moving?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:07 engine.py:267] Added request chatcmpl-e8bf7f9a084a4d4d8b59618c6a410603.
INFO 12-25 13:29:07 logger.py:37] Received request chatcmpl-052c8b9277e843bd91b5a85f34ca7c40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a significance of the Ping Pong Parkinson event according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:07 engine.py:267] Added request chatcmpl-052c8b9277e843bd91b5a85f34ca7c40.
INFO 12-25 13:29:08 metrics.py:449] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:10 logger.py:37] Received request chatcmpl-4d9fba1d9c434a7da4803a31927f6fd7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:10 engine.py:267] Added request chatcmpl-4d9fba1d9c434a7da4803a31927f6fd7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:13 metrics.py:449] Avg prompt throughput: 11.6 tokens/s, Avg generation throughput: 128.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:29:14 logger.py:37] Received request chatcmpl-efc0c90cb99a4066a1386491acb8f9e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who could the woman sitting on the bench at the beginning of the video, wearing black and white stripes and speaking, possibly be?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:14 logger.py:37] Received request chatcmpl-93c46e534fcb4c868c989277004c62f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the cause of the chaos depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:14 engine.py:267] Added request chatcmpl-efc0c90cb99a4066a1386491acb8f9e9.
INFO 12-25 13:29:14 engine.py:267] Added request chatcmpl-93c46e534fcb4c868c989277004c62f3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:15 logger.py:37] Received request chatcmpl-87df202666174792b6bc85098fab500d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the live show featured in the first half of this video, what hairstyle does the second member who starts to sing have?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:15 engine.py:267] Added request chatcmpl-87df202666174792b6bc85098fab500d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:17 logger.py:37] Received request chatcmpl-5699a0ee1397419da9f1d095f78cd01a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is not the ability of superman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:17 engine.py:267] Added request chatcmpl-5699a0ee1397419da9f1d095f78cd01a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:18 metrics.py:449] Avg prompt throughput: 55.9 tokens/s, Avg generation throughput: 117.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:29:19 logger.py:37] Received request chatcmpl-67a9cbc10630426897bf6aa4fdc562b6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many Japanese people would feel ashamed for taking paid leave according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:19 engine.py:267] Added request chatcmpl-67a9cbc10630426897bf6aa4fdc562b6.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:21 logger.py:37] Received request chatcmpl-1fa095a0f924466dbadb93720aa32108: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the key focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:21 engine.py:267] Added request chatcmpl-1fa095a0f924466dbadb93720aa32108.
INFO 12-25 13:29:23 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:25 logger.py:37] Received request chatcmpl-9e70950bd84f40f4ac7d9bf51b953647: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle of the video, what are the difficulties of rebuilding after the earthquake?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:25 engine.py:267] Added request chatcmpl-9e70950bd84f40f4ac7d9bf51b953647.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:26 logger.py:37] Received request chatcmpl-83472b34fb0e4cd0a2499f796436ec5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following views is expressed by the interviewee in the green shirt with a white beard in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:26 engine.py:267] Added request chatcmpl-83472b34fb0e4cd0a2499f796436ec5e.
INFO 12-25 13:29:27 logger.py:37] Received request chatcmpl-9460f6c339b447fd86adf42aa3639a6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, which of the following is NOT a reason for the outbreak of protests by European farmers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:27 engine.py:267] Added request chatcmpl-9460f6c339b447fd86adf42aa3639a6a.
INFO 12-25 13:29:27 logger.py:37] Received request chatcmpl-cb09f17c12774b43b33f7a5d04729601: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what has the price of Bitcoin reached in dollars?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:27 engine.py:267] Added request chatcmpl-cb09f17c12774b43b33f7a5d04729601.
INFO 12-25 13:29:28 metrics.py:449] Avg prompt throughput: 57.7 tokens/s, Avg generation throughput: 90.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:33 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 117.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:33 logger.py:37] Received request chatcmpl-2eb8bf2656cc457995f31fef1a9647ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the narration in the latter part of the video, what is the current trend of the global population?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:33 engine.py:267] Added request chatcmpl-2eb8bf2656cc457995f31fef1a9647ad.
INFO 12-25 13:29:33 logger.py:37] Received request chatcmpl-952cf481118548fa8b0e5503410e620f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is "Avenues for Justice" mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:33 engine.py:267] Added request chatcmpl-952cf481118548fa8b0e5503410e620f.
INFO 12-25 13:29:35 logger.py:37] Received request chatcmpl-f6ec0239bc0e4d41acb307adb06c8790: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early part of the video, the interview with the man could likely have been filmed in what location?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:35 logger.py:37] Received request chatcmpl-41b7d2a3577b4ff0aa774caae45a5012: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many years has it been since the disappearance of flight MH370 according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:35 engine.py:267] Added request chatcmpl-f6ec0239bc0e4d41acb307adb06c8790.
INFO 12-25 13:29:35 engine.py:267] Added request chatcmpl-41b7d2a3577b4ff0aa774caae45a5012.
INFO 12-25 13:29:38 metrics.py:449] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 127.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:40 logger.py:37] Received request chatcmpl-6f7cf19c33f247b29cc916041103e5f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following is NOT a difficulty in growing crops in space?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:40 engine.py:267] Added request chatcmpl-6f7cf19c33f247b29cc916041103e5f2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:41 logger.py:37] Received request chatcmpl-477b00b7fad045809166ac7f38626d36: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "During which part of the video is a black-and-white photo shown?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:41 engine.py:267] Added request chatcmpl-477b00b7fad045809166ac7f38626d36.
INFO 12-25 13:29:42 logger.py:37] Received request chatcmpl-0968eeab94c7449f81e55ce1d96b5a59: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the likely liquid contained in the cup on the desk of the news studio?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:42 engine.py:267] Added request chatcmpl-0968eeab94c7449f81e55ce1d96b5a59.
INFO 12-25 13:29:43 logger.py:37] Received request chatcmpl-7a775a2a1da0412d9e89af44a3f71ede: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:43 engine.py:267] Added request chatcmpl-7a775a2a1da0412d9e89af44a3f71ede.
INFO 12-25 13:29:43 metrics.py:449] Avg prompt throughput: 53.2 tokens/s, Avg generation throughput: 96.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:45 logger.py:37] Received request chatcmpl-c5e7d2ee2c5140dcaeb3918aa49dec0b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what are people\'s concerns about artificially manufactured diamonds?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:45 engine.py:267] Added request chatcmpl-c5e7d2ee2c5140dcaeb3918aa49dec0b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:47 logger.py:37] Received request chatcmpl-4f9ae124fc694c75af66443e659d0896: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following countries has the lowest birth rate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:47 engine.py:267] Added request chatcmpl-4f9ae124fc694c75af66443e659d0896.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:48 metrics.py:449] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:29:49 logger.py:37] Received request chatcmpl-6c11597c692b4650ae19034d3e0613c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the mother brown bear in the video make her cubs run to higher ground?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:49 engine.py:267] Added request chatcmpl-6c11597c692b4650ae19034d3e0613c3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:53 metrics.py:449] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 117.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:29:53 logger.py:37] Received request chatcmpl-660919c1ca264ea2b4507cde6d10e8d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different humanoid characters appear in the game shown in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:53 engine.py:267] Added request chatcmpl-660919c1ca264ea2b4507cde6d10e8d7.
INFO 12-25 13:29:54 logger.py:37] Received request chatcmpl-fc7480a41fa840829595708ce8140082: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the game content that appears in the video produced?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:54 logger.py:37] Received request chatcmpl-0fda8e88acba41628900163e00ae5490: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the interviewed man\'s opinion on cryptocurrencies in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:54 engine.py:267] Added request chatcmpl-fc7480a41fa840829595708ce8140082.
INFO 12-25 13:29:54 engine.py:267] Added request chatcmpl-0fda8e88acba41628900163e00ae5490.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:58 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 128.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:29:59 logger.py:37] Received request chatcmpl-42e31902eb9f4b30ada838cdbb3d65a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video end with?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:29:59 engine.py:267] Added request chatcmpl-42e31902eb9f4b30ada838cdbb3d65a9.
INFO 12-25 13:30:00 logger.py:37] Received request chatcmpl-65ef0da50d0d4ce6ab1e4889d1768276: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when Gragas and Akali fight versus Sylas?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:00 engine.py:267] Added request chatcmpl-65ef0da50d0d4ce6ab1e4889d1768276.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:03 logger.py:37] Received request chatcmpl-1196e37e7a1b46dd98ebeee94140b2c8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where was the scene shown at the beginning of the video filmed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:03 engine.py:267] Added request chatcmpl-1196e37e7a1b46dd98ebeee94140b2c8.
INFO 12-25 13:30:03 metrics.py:449] Avg prompt throughput: 38.0 tokens/s, Avg generation throughput: 126.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:06 logger.py:37] Received request chatcmpl-79e7f4255d3e4fb79c2d1de7431030ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times is Vi slain in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:06 engine.py:267] Added request chatcmpl-79e7f4255d3e4fb79c2d1de7431030ad.
INFO 12-25 13:30:06 logger.py:37] Received request chatcmpl-940eae2138ab4964a815cd4fe65a02c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What caused the death of the people reported in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:06 engine.py:267] Added request chatcmpl-940eae2138ab4964a815cd4fe65a02c1.
INFO 12-25 13:30:07 logger.py:37] Received request chatcmpl-bdf5013c13f34f4193957561982017c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:07 engine.py:267] Added request chatcmpl-bdf5013c13f34f4193957561982017c3.
INFO 12-25 13:30:08 metrics.py:449] Avg prompt throughput: 37.3 tokens/s, Avg generation throughput: 115.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:10 logger.py:37] Received request chatcmpl-48edb2a2558442718c5b051a1e965fe5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, why was Google sued?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:10 engine.py:267] Added request chatcmpl-48edb2a2558442718c5b051a1e965fe5.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:12 logger.py:37] Received request chatcmpl-d81ae506fa334fccb041061ef8e44734: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summoner skill does Sion use in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:12 engine.py:267] Added request chatcmpl-d81ae506fa334fccb041061ef8e44734.
INFO 12-25 13:30:12 logger.py:37] Received request chatcmpl-ed5a69ebd8654bf1a5139cd694924a28: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many legends does Rengar slay?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:12 engine.py:267] Added request chatcmpl-ed5a69ebd8654bf1a5139cd694924a28.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:13 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 113.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:30:14 logger.py:37] Received request chatcmpl-3806cfd2b653444497ff0a71697723c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What emotion is the song sung by the woman at the end of the video expressing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:14 engine.py:267] Added request chatcmpl-3806cfd2b653444497ff0a71697723c3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:17 logger.py:37] Received request chatcmpl-a9b9c40663044260a36691b6d36b5db9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the host talking about when the screenshots of the webpage and comments were shown at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:17 engine.py:267] Added request chatcmpl-a9b9c40663044260a36691b6d36b5db9.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:18 metrics.py:449] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 132.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:30:19 logger.py:37] Received request chatcmpl-c2337e16b2594e2f93b2f650ae902086: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the location of the race as shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:19 logger.py:37] Received request chatcmpl-d6c065d07b3c4be3bfd21efea081138f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many skins does Vi have in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:19 engine.py:267] Added request chatcmpl-c2337e16b2594e2f93b2f650ae902086.
INFO 12-25 13:30:19 engine.py:267] Added request chatcmpl-d6c065d07b3c4be3bfd21efea081138f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:23 logger.py:37] Received request chatcmpl-a8f0b66bcfc8449a9b95945157d483f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the people holding candles doing at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:23 engine.py:267] Added request chatcmpl-a8f0b66bcfc8449a9b95945157d483f2.
INFO 12-25 13:30:23 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 127.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:25 logger.py:37] Received request chatcmpl-ea9a743d8ac8413196d035610baa4313: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which news media outlet reported on this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:25 engine.py:267] Added request chatcmpl-ea9a743d8ac8413196d035610baa4313.
INFO 12-25 13:30:25 logger.py:37] Received request chatcmpl-0308841c0bb849d7a8b9f0b675cbdece: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Vayne do at the beginning of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:25 engine.py:267] Added request chatcmpl-0308841c0bb849d7a8b9f0b675cbdece.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:27 logger.py:37] Received request chatcmpl-29553846d10c4639be4e717829cda9a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cars does player use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:27 engine.py:267] Added request chatcmpl-29553846d10c4639be4e717829cda9a3.
INFO 12-25 13:30:28 metrics.py:449] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 118.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:31 logger.py:37] Received request chatcmpl-8883120829ff48058cee9f58eb7df20a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what kind of emotion does the Princess of Wales display?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:31 engine.py:267] Added request chatcmpl-8883120829ff48058cee9f58eb7df20a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:33 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 123.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:30:34 logger.py:37] Received request chatcmpl-d0cad60f4906479d9218cca1456d09c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many taillights does the player\'s car have?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:34 logger.py:37] Received request chatcmpl-f463751814f54a2da88c39d89284717b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning, what is the player\'s rank?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:34 engine.py:267] Added request chatcmpl-d0cad60f4906479d9218cca1456d09c9.
INFO 12-25 13:30:34 engine.py:267] Added request chatcmpl-f463751814f54a2da88c39d89284717b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:35 logger.py:37] Received request chatcmpl-29f8c6720fdb42cab16794301956b5bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was the first to be slain by Vi?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:35 engine.py:267] Added request chatcmpl-29f8c6720fdb42cab16794301956b5bc.
INFO 12-25 13:30:36 logger.py:37] Received request chatcmpl-ea957112923c4daeae3d3b4a65357ff9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, the man speaking to the camera, wearing glasses and a brown coat, is most likely in which role?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:36 engine.py:267] Added request chatcmpl-ea957112923c4daeae3d3b4a65357ff9.
INFO 12-25 13:30:38 metrics.py:449] Avg prompt throughput: 53.0 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:41 logger.py:37] Received request chatcmpl-5bb641e0069e44d4aad98c320278e6e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many sports does the player play?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:41 engine.py:267] Added request chatcmpl-5bb641e0069e44d4aad98c320278e6e3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:43 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 99.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:30:44 logger.py:37] Received request chatcmpl-3da3085cb1134b33999fcde266753ab4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is Sion\'s passive skill?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:44 logger.py:37] Received request chatcmpl-d44707918b7d4e5283af23f5de917b90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the weather like?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:44 logger.py:37] Received request chatcmpl-2aa61cf57d7a43549535ee245f2297a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people were interviewed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:44 engine.py:267] Added request chatcmpl-3da3085cb1134b33999fcde266753ab4.
INFO 12-25 13:30:44 engine.py:267] Added request chatcmpl-d44707918b7d4e5283af23f5de917b90.
INFO 12-25 13:30:44 engine.py:267] Added request chatcmpl-2aa61cf57d7a43549535ee245f2297a9.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:45 logger.py:37] Received request chatcmpl-994f5283e0db44e794f4283c253ee2e5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players jump from a building and die?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:45 engine.py:267] Added request chatcmpl-994f5283e0db44e794f4283c253ee2e5.
INFO 12-25 13:30:48 metrics.py:449] Avg prompt throughput: 48.0 tokens/s, Avg generation throughput: 127.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:50 logger.py:37] Received request chatcmpl-aa6d2e62a11e4ffb801860dafa2b07bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which position is Vayne in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:50 engine.py:267] Added request chatcmpl-aa6d2e62a11e4ffb801860dafa2b07bd.
INFO 12-25 13:30:52 logger.py:37] Received request chatcmpl-def6d26eafed442aa664c78b47da32c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When does the interview with the woman in the green shirt take place in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:52 logger.py:37] Received request chatcmpl-f2dea6be090345889f08fcc6b2ae3bd0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many grenades does the player throw?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:52 engine.py:267] Added request chatcmpl-def6d26eafed442aa664c78b47da32c1.
INFO 12-25 13:30:52 engine.py:267] Added request chatcmpl-f2dea6be090345889f08fcc6b2ae3bd0.
INFO 12-25 13:30:53 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 111.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:56 logger.py:37] Received request chatcmpl-62b3a7d415fb4ff296f89c28ebbabd3d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players completed dunks in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:56 engine.py:267] Added request chatcmpl-62b3a7d415fb4ff296f89c28ebbabd3d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:30:57 logger.py:37] Received request chatcmpl-554eb76118ca4cb0a23c851ff0fe74c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be seen in the sky during the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:57 engine.py:267] Added request chatcmpl-554eb76118ca4cb0a23c851ff0fe74c0.
INFO 12-25 13:30:58 metrics.py:449] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 93.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:30:58 logger.py:37] Received request chatcmpl-0717199deacb46a5ae49846c5b49d80c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the player crash?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:58 engine.py:267] Added request chatcmpl-0717199deacb46a5ae49846c5b49d80c.
INFO 12-25 13:30:59 logger.py:37] Received request chatcmpl-35e86e14ad3340da935af4994fa61260: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early to middle part of the video, there are two women wearing blue clothes. What is their relationship?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:30:59 engine.py:267] Added request chatcmpl-35e86e14ad3340da935af4994fa61260.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:03 metrics.py:449] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 148.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:05 logger.py:37] Received request chatcmpl-622a9ce228d94b4a8dd7139688440a12: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many attempts do it take for Phonzy to hit a 3-pointer in the first game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:05 engine.py:267] Added request chatcmpl-622a9ce228d94b4a8dd7139688440a12.
INFO 12-25 13:31:06 logger.py:37] Received request chatcmpl-07abfed6808f4d54b71774ceb13f7c2d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which brand of car does the player use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:06 engine.py:267] Added request chatcmpl-07abfed6808f4d54b71774ceb13f7c2d.
INFO 12-25 13:31:07 logger.py:37] Received request chatcmpl-b2c55b3361654515bd38ef0beaddd27b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the genre or category of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:07 engine.py:267] Added request chatcmpl-b2c55b3361654515bd38ef0beaddd27b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:08 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 104.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:10 logger.py:37] Received request chatcmpl-934fb0251585422bae1bf87a686878d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What style is the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:10 engine.py:267] Added request chatcmpl-934fb0251585422bae1bf87a686878d4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:13 logger.py:37] Received request chatcmpl-b6a9f46a3b224ef2a413386c5611649c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the conditions under which an offensive player can continue to attack when he scores a goal against someone else\'s defense in the fourth game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:13 logger.py:37] Received request chatcmpl-bd2cdd99575d4cafa2f8ea59c1df6da7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the player\'s sniper rifle?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:13 engine.py:267] Added request chatcmpl-b6a9f46a3b224ef2a413386c5611649c.
INFO 12-25 13:31:13 engine.py:267] Added request chatcmpl-bd2cdd99575d4cafa2f8ea59c1df6da7.
INFO 12-25 13:31:13 metrics.py:449] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:16 logger.py:37] Received request chatcmpl-f07dfb5f8db04a9582efb3e4b6f254b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this news?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:16 engine.py:267] Added request chatcmpl-f07dfb5f8db04a9582efb3e4b6f254b9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:18 logger.py:37] Received request chatcmpl-c1fbb06448704af3b209804bc241d2c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what way is the penultimate goal in the video accomplished?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:18 engine.py:267] Added request chatcmpl-c1fbb06448704af3b209804bc241d2c9.
INFO 12-25 13:31:18 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 137.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:20 logger.py:37] Received request chatcmpl-34491aa0d82f4634bf694fc133b27b82: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many players hold a weapon in their left hand?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:20 engine.py:267] Added request chatcmpl-34491aa0d82f4634bf694fc133b27b82.
INFO 12-25 13:31:21 logger.py:37] Received request chatcmpl-55dc5b7a13d348c19b8974c26fc923d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who slays Azir as shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:21 engine.py:267] Added request chatcmpl-55dc5b7a13d348c19b8974c26fc923d2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:23 logger.py:37] Received request chatcmpl-11bdbda0f1a7445395a08decd0cbb9c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many points does a three-pointer count in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:23 engine.py:267] Added request chatcmpl-11bdbda0f1a7445395a08decd0cbb9c7.
INFO 12-25 13:31:23 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 104.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:24 logger.py:37] Received request chatcmpl-2bddefed705948ada751ea8d8a4bb184: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many free throws does Jamal hit in game 2?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:24 engine.py:267] Added request chatcmpl-2bddefed705948ada751ea8d8a4bb184.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:28 metrics.py:449] Avg prompt throughput: 12.7 tokens/s, Avg generation throughput: 117.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:28 logger.py:37] Received request chatcmpl-37475462b0e24c31bcbcf85bdacd70d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who wins the game in the last match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:28 engine.py:267] Added request chatcmpl-37475462b0e24c31bcbcf85bdacd70d7.
INFO 12-25 13:31:28 logger.py:37] Received request chatcmpl-e09218673f1e4f2a94f37cd4c2fe1320: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When does Sion start proxying?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:28 engine.py:267] Added request chatcmpl-e09218673f1e4f2a94f37cd4c2fe1320.
INFO 12-25 13:31:29 logger.py:37] Received request chatcmpl-ecce50bf55064041a1e9260812012ada: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the two doing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:29 engine.py:267] Added request chatcmpl-ecce50bf55064041a1e9260812012ada.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:33 metrics.py:449] Avg prompt throughput: 36.2 tokens/s, Avg generation throughput: 137.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:35 logger.py:37] Received request chatcmpl-d6b0b0cf08f04e4b87e6dd693b3cf001: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the second game, why is the yellow player docked a point when he gets 12?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:35 engine.py:267] Added request chatcmpl-d6b0b0cf08f04e4b87e6dd693b3cf001.
INFO 12-25 13:31:35 logger.py:37] Received request chatcmpl-606059e3e6774b7cb5cf1fbf99e849ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the narrator\'s "1, 2, 3" stand for when the player in the white undershirt is attacking in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:35 logger.py:37] Received request chatcmpl-d3717a2c960846e988a59218804336cc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many consecutive hits did player #39 in the video have in his first start?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:35 engine.py:267] Added request chatcmpl-606059e3e6774b7cb5cf1fbf99e849ab.
INFO 12-25 13:31:35 engine.py:267] Added request chatcmpl-d3717a2c960846e988a59218804336cc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:37 logger.py:37] Received request chatcmpl-d11139dc97794a7ba8385b7421122711: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which skill is used first by Vayne?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:37 engine.py:267] Added request chatcmpl-d11139dc97794a7ba8385b7421122711.
INFO 12-25 13:31:38 metrics.py:449] Avg prompt throughput: 57.2 tokens/s, Avg generation throughput: 102.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:41 logger.py:37] Received request chatcmpl-4cdd0aabb34c4e349b85493ceab9a4a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the team\'s LAC hitting percentage when the score is 38-29?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:41 engine.py:267] Added request chatcmpl-4cdd0aabb34c4e349b85493ceab9a4a1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:43 metrics.py:449] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 135.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:44 logger.py:37] Received request chatcmpl-9efbe95633f846a8b7e0ed72d106116c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What rank is the player at the end?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:44 engine.py:267] Added request chatcmpl-9efbe95633f846a8b7e0ed72d106116c.
INFO 12-25 13:31:45 logger.py:37] Received request chatcmpl-f1fe6a987cf54cef83d251bcf701312f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score at the end of the half?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:45 engine.py:267] Added request chatcmpl-f1fe6a987cf54cef83d251bcf701312f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:48 logger.py:37] Received request chatcmpl-339fa463ba674cd3b4a2f579e9739061: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who gets the most points in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:48 engine.py:267] Added request chatcmpl-339fa463ba674cd3b4a2f579e9739061.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:48 metrics.py:449] Avg prompt throughput: 36.8 tokens/s, Avg generation throughput: 115.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:50 logger.py:37] Received request chatcmpl-e633c8137ba7437eb57ab59d49135785: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the fourth game, what is the order of appearance for the colors represented by the players?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:50 logger.py:37] Received request chatcmpl-df095fd313384fb99b0f10bb168b539c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is in the sky?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:50 engine.py:267] Added request chatcmpl-e633c8137ba7437eb57ab59d49135785.
INFO 12-25 13:31:50 engine.py:267] Added request chatcmpl-df095fd313384fb99b0f10bb168b539c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:53 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 102.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:31:54 logger.py:37] Received request chatcmpl-cc63f0f55221452c8b6cc57a22e86a9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which significant football event is depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:54 logger.py:37] Received request chatcmpl-9f68d70c6c24483a800b6c82c9d8ef5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do they replace the other side of the layup in the second game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:54 engine.py:267] Added request chatcmpl-cc63f0f55221452c8b6cc57a22e86a9c.
INFO 12-25 13:31:54 engine.py:267] Added request chatcmpl-9f68d70c6c24483a800b6c82c9d8ef5b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:56 logger.py:37] Received request chatcmpl-ed2449d0782d40298620ca21a038ca74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the play die?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:31:56 engine.py:267] Added request chatcmpl-ed2449d0782d40298620ca21a038ca74.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:31:58 metrics.py:449] Avg prompt throughput: 37.9 tokens/s, Avg generation throughput: 139.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:00 logger.py:37] Received request chatcmpl-40747e9f0e584d2c9fc9fedefbf52b37: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many fouls are blown on players in black jerseys in the first game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:00 engine.py:267] Added request chatcmpl-40747e9f0e584d2c9fc9fedefbf52b37.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:02 logger.py:37] Received request chatcmpl-f5b682299ee944c780efcb708ee2f5b0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If you want to confuse your opponent to get rid of him, which move should you use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:02 engine.py:267] Added request chatcmpl-f5b682299ee944c780efcb708ee2f5b0.
INFO 12-25 13:32:03 logger.py:37] Received request chatcmpl-a5149b9e48e445b78b3810dd78ae9fac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the largest run differential in the first inning of the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:03 engine.py:267] Added request chatcmpl-a5149b9e48e445b78b3810dd78ae9fac.
INFO 12-25 13:32:03 metrics.py:449] Avg prompt throughput: 41.6 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:05 logger.py:37] Received request chatcmpl-1223f2c168c44f27868f4dbbb9d03a9e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the hat of player\'s figure?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:05 engine.py:267] Added request chatcmpl-1223f2c168c44f27868f4dbbb9d03a9e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:08 logger.py:37] Received request chatcmpl-fa10091b81c2449496bc33067da512ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens next when the score is 2-1?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:08 engine.py:267] Added request chatcmpl-fa10091b81c2449496bc33067da512ed.
INFO 12-25 13:32:08 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 120.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:09 logger.py:37] Received request chatcmpl-a92a72da270c4bf5bd73f8b4e645287f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the result according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:09 engine.py:267] Added request chatcmpl-a92a72da270c4bf5bd73f8b4e645287f.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:11 logger.py:37] Received request chatcmpl-44ea4297fdd941f0aa48bde41e6e3fdf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are most of the technical moves completed by the players in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:11 engine.py:267] Added request chatcmpl-44ea4297fdd941f0aa48bde41e6e3fdf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:13 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:14 logger.py:37] Received request chatcmpl-310fa402d24b44c48a5d15e0b44c38dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who hit the third ball in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:14 engine.py:267] Added request chatcmpl-310fa402d24b44c48a5d15e0b44c38dc.
INFO 12-25 13:32:15 logger.py:37] Received request chatcmpl-b60ad88434a74a46a1fb0800601d7eb8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which skill are there only three people on the field?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:15 engine.py:267] Added request chatcmpl-b60ad88434a74a46a1fb0800601d7eb8.
INFO 12-25 13:32:15 logger.py:37] Received request chatcmpl-e257aee62c8343ceb1a6997af161a514: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the players doing before the match formally begins, according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:16 engine.py:267] Added request chatcmpl-e257aee62c8343ceb1a6997af161a514.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:17 logger.py:37] Received request chatcmpl-e37058ed689443de967574de17dbab5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first game, what color does the second losing player represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:17 engine.py:267] Added request chatcmpl-e37058ed689443de967574de17dbab5b.
INFO 12-25 13:32:18 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 116.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:21 logger.py:37] Received request chatcmpl-07ed7791520e4827861ad23dcab9e121: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In Germany vs Argentina, Which player scores the first goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:21 engine.py:267] Added request chatcmpl-07ed7791520e4827861ad23dcab9e121.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:22 logger.py:37] Received request chatcmpl-6b4586c279fd49d9a097f519c72139f6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times has LOUISVILLE been ahead in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:22 engine.py:267] Added request chatcmpl-6b4586c279fd49d9a097f519c72139f6.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:23 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:24 logger.py:37] Received request chatcmpl-94ae7f32b0ed457ba22abba03ef0b152: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many games are played in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:24 engine.py:267] Added request chatcmpl-94ae7f32b0ed457ba22abba03ef0b152.
INFO 12-25 13:32:25 logger.py:37] Received request chatcmpl-30eefd92bbd34eebbf8d690dd5e8c97a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:25 engine.py:267] Added request chatcmpl-30eefd92bbd34eebbf8d690dd5e8c97a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:28 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 126.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:29 logger.py:37] Received request chatcmpl-75f29cfd98ad44df8762d17090cc38fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player is replaced in the middle of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:29 logger.py:37] Received request chatcmpl-705b45f003d04954b4b7b55c8c8de18c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is there no winner in Game 3?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:29 engine.py:267] Added request chatcmpl-75f29cfd98ad44df8762d17090cc38fc.
INFO 12-25 13:32:29 engine.py:267] Added request chatcmpl-705b45f003d04954b4b7b55c8c8de18c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:30 logger.py:37] Received request chatcmpl-5baf7326bb8f4a5fa833d52486966858: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the match, which player commits the first foul?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:30 engine.py:267] Added request chatcmpl-5baf7326bb8f4a5fa833d52486966858.
INFO 12-25 13:32:31 logger.py:37] Received request chatcmpl-f298c0a76c9544dc81ee0db18a658738: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who gained the ultimate victory?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:31 engine.py:267] Added request chatcmpl-f298c0a76c9544dc81ee0db18a658738.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:33 metrics.py:449] Avg prompt throughput: 49.0 tokens/s, Avg generation throughput: 116.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:34 logger.py:37] Received request chatcmpl-7ab7aefbc74a4dd19e20f59798779bd1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Extrapolating from the video, what team is the commentator on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:34 engine.py:267] Added request chatcmpl-7ab7aefbc74a4dd19e20f59798779bd1.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:38 logger.py:37] Received request chatcmpl-7cfaac1477d14c03838e773bc7cd8438: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the final score set at in the first game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:38 engine.py:267] Added request chatcmpl-7cfaac1477d14c03838e773bc7cd8438.
INFO 12-25 13:32:38 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:39 logger.py:37] Received request chatcmpl-92b8672bfbad496098822eb881a1ffee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:39 engine.py:267] Added request chatcmpl-92b8672bfbad496098822eb881a1ffee.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:42 logger.py:37] Received request chatcmpl-29516bf67ee843ac8157ca35c0b0604c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When was the first goal scored in the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:42 engine.py:267] Added request chatcmpl-29516bf67ee843ac8157ca35c0b0604c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:43 logger.py:37] Received request chatcmpl-f1a1474004be499c9744a23a59802b43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What country\'s practice game is this?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:43 engine.py:267] Added request chatcmpl-f1a1474004be499c9744a23a59802b43.
INFO 12-25 13:32:43 metrics.py:449] Avg prompt throughput: 36.3 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:44 logger.py:37] Received request chatcmpl-87ecc7289fbd4b91bffd9ec0f59d246c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who scored the third goal in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:44 engine.py:267] Added request chatcmpl-87ecc7289fbd4b91bffd9ec0f59d246c.
INFO 12-25 13:32:45 logger.py:37] Received request chatcmpl-c39fd87de1e5467a8f77eb45c693c8a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which competition is the video related to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:45 engine.py:267] Added request chatcmpl-c39fd87de1e5467a8f77eb45c693c8a7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:48 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:50 logger.py:37] Received request chatcmpl-eb8e95e6943d4bc3b0d2b0f735c05878: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the result of the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:50 engine.py:267] Added request chatcmpl-eb8e95e6943d4bc3b0d2b0f735c05878.
INFO 12-25 13:32:50 logger.py:37] Received request chatcmpl-d6272b04984a4aca9e572dd5d2eb3555: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Brazil score their 5th goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:50 engine.py:267] Added request chatcmpl-d6272b04984a4aca9e572dd5d2eb3555.
INFO 12-25 13:32:51 logger.py:37] Received request chatcmpl-eadc0bc8486d4c73b82cf0e0531624e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "LAL completed the comeback with how much time left in the third quarter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:51 engine.py:267] Added request chatcmpl-eadc0bc8486d4c73b82cf0e0531624e9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:53 metrics.py:449] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:32:54 logger.py:37] Received request chatcmpl-1669c6403eba42b6a625f523ff7aa68d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why were the first two goals in this video invalid?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:54 engine.py:267] Added request chatcmpl-1669c6403eba42b6a625f523ff7aa68d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:32:57 logger.py:37] Received request chatcmpl-e1b6b4ca61be42cf846b15777321988e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video showcasing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:57 engine.py:267] Added request chatcmpl-e1b6b4ca61be42cf846b15777321988e.
INFO 12-25 13:32:58 logger.py:37] Received request chatcmpl-cfc48c12afc8475e8985dd529092f188: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the order of countries that finished first for each leg of the relay race in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:32:58 engine.py:267] Added request chatcmpl-cfc48c12afc8475e8985dd529092f188.
INFO 12-25 13:32:58 metrics.py:449] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 125.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:00 logger.py:37] Received request chatcmpl-8638efc146d2491ea057998b57d1cfa6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first game, when the challenger scores for the first time, how many points has Bugs & Daffy scored?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:00 engine.py:267] Added request chatcmpl-8638efc146d2491ea057998b57d1cfa6.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:01 logger.py:37] Received request chatcmpl-5da8a32aa462430b8dd293b1b7add8d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the performance of Brazil\'s player number 9 in the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:01 engine.py:267] Added request chatcmpl-5da8a32aa462430b8dd293b1b7add8d7.
INFO 12-25 13:33:03 logger.py:37] Received request chatcmpl-cb795f344f664da7b8c2576e801878b8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many goals do the player Number 7 of Tottenham Hotspur score?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:03 engine.py:267] Added request chatcmpl-cb795f344f664da7b8c2576e801878b8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:04 metrics.py:449] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 117.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:33:05 logger.py:37] Received request chatcmpl-b27992ec4f33412e9cf55d2c49883b93: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who hit more threes in Game 1?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:05 engine.py:267] Added request chatcmpl-b27992ec4f33412e9cf55d2c49883b93.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:09 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 130.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:09 logger.py:37] Received request chatcmpl-19eb087d0db749f8a423aa7d49cb624b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first diving event shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:09 engine.py:267] Added request chatcmpl-19eb087d0db749f8a423aa7d49cb624b.
INFO 12-25 13:33:10 logger.py:37] Received request chatcmpl-d7c26ce4bc4e4f3fa70d4b32e162ac47: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the result of the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:10 engine.py:267] Added request chatcmpl-d7c26ce4bc4e4f3fa70d4b32e162ac47.
INFO 12-25 13:33:11 logger.py:37] Received request chatcmpl-1e84850d56c44845a6ec2099d22bae4c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the winning time of the men\'s 100-meter race that was shown first in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:11 engine.py:267] Added request chatcmpl-1e84850d56c44845a6ec2099d22bae4c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:13 logger.py:37] Received request chatcmpl-8865882359b646a99d0236fbdb902530: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the winning team in the video win the FIFA World Cup final?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:13 engine.py:267] Added request chatcmpl-8865882359b646a99d0236fbdb902530.
INFO 12-25 13:33:14 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 106.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:16 logger.py:37] Received request chatcmpl-598516be95e84a1783a0a181e2b86d76: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team in the video reached the finish line first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:16 engine.py:267] Added request chatcmpl-598516be95e84a1783a0a181e2b86d76.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:18 logger.py:37] Received request chatcmpl-1f8ab79693854b63892a5e4ce958aa26: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order do the 2012 London men\'s 100m final, the 2018 Beijing men\'s 100m final, and the 2012 London women\'s 100m final appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:18 logger.py:37] Received request chatcmpl-3307c63853834df084f8752ecab3b0a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When is the second goal scored in the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:18 engine.py:267] Added request chatcmpl-1f8ab79693854b63892a5e4ce958aa26.
INFO 12-25 13:33:18 engine.py:267] Added request chatcmpl-3307c63853834df084f8752ecab3b0a5.
INFO 12-25 13:33:19 metrics.py:449] Avg prompt throughput: 46.7 tokens/s, Avg generation throughput: 95.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:33:19 logger.py:37] Received request chatcmpl-41a442c69d604773a67e62536d8f108f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which competition is being referred to in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:19 engine.py:267] Added request chatcmpl-41a442c69d604773a67e62536d8f108f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:24 metrics.py:449] Avg prompt throughput: 12.3 tokens/s, Avg generation throughput: 145.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:24 logger.py:37] Received request chatcmpl-9c35e7ee946c4b57b809936f831ececc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What were the final placings of the three high jumpers recorded in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:24 engine.py:267] Added request chatcmpl-9c35e7ee946c4b57b809936f831ececc.
INFO 12-25 13:33:25 logger.py:37] Received request chatcmpl-dfc8bdcefa0a48c3b50ce1ecf2f6c2dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What swimming stroke was used for the second leg of the relay race in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:25 engine.py:267] Added request chatcmpl-dfc8bdcefa0a48c3b50ce1ecf2f6c2dc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:27 logger.py:37] Received request chatcmpl-30e959618a1d45f28a255faa02e634cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player scored the 7th goal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:27 engine.py:267] Added request chatcmpl-30e959618a1d45f28a255faa02e634cd.
INFO 12-25 13:33:29 metrics.py:449] Avg prompt throughput: 39.6 tokens/s, Avg generation throughput: 129.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:31 logger.py:37] Received request chatcmpl-7fbb7bdb4d0c42ac8a35782b66e64a9f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the medals won by the athletes recorded in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:31 engine.py:267] Added request chatcmpl-7fbb7bdb4d0c42ac8a35782b66e64a9f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:31 logger.py:37] Received request chatcmpl-88b891ca74a64540adb803bdd95befe1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the last set of diving moves shown by the two female athletes in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:31 engine.py:267] Added request chatcmpl-88b891ca74a64540adb803bdd95befe1.
INFO 12-25 13:33:33 logger.py:37] Received request chatcmpl-68bb205452d24da880996d00800ed016: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which baton handover process in the video did a player fall?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:33 engine.py:267] Added request chatcmpl-68bb205452d24da880996d00800ed016.
INFO 12-25 13:33:34 metrics.py:449] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:36 logger.py:37] Received request chatcmpl-a657eaa3e10946bdbb7a007aaddb0dcf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the match statistics in the bottom left corner of the video indicate at the match time 89:17?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:36 engine.py:267] Added request chatcmpl-a657eaa3e10946bdbb7a007aaddb0dcf.
INFO 12-25 13:33:37 logger.py:37] Received request chatcmpl-263b4faa462d44b696c2ee2d367eb080: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the introductions of the athletes at the beginning of the video, what is the sequence of the French athlete, the American athlete, and the South African athlete?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:37 engine.py:267] Added request chatcmpl-263b4faa462d44b696c2ee2d367eb080.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:39 metrics.py:449] Avg prompt throughput: 32.4 tokens/s, Avg generation throughput: 132.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:41 logger.py:37] Received request chatcmpl-9ac018eee1114223933d11a89681618d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the video show a long jump with a distance of 8 metres 53?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:41 engine.py:267] Added request chatcmpl-9ac018eee1114223933d11a89681618d.
INFO 12-25 13:33:41 logger.py:37] Received request chatcmpl-abbd087ef09f4f778f5422fed6a4e08a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country does the athlete, who was in first place after touching the wall for the third time in the video, represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:41 engine.py:267] Added request chatcmpl-abbd087ef09f4f778f5422fed6a4e08a.
INFO 12-25 13:33:44 metrics.py:449] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 124.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:46 logger.py:37] Received request chatcmpl-45dcb56220ba4ce2b84abb332f0d6861: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the coach of Manchester City described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:46 engine.py:267] Added request chatcmpl-45dcb56220ba4ce2b84abb332f0d6861.
INFO 12-25 13:33:46 logger.py:37] Received request chatcmpl-33bc99e5eaf746bfb8c926450130f994: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which athlete in the video was the first to touch off the crossbar?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:46 engine.py:267] Added request chatcmpl-33bc99e5eaf746bfb8c926450130f994.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:49 logger.py:37] Received request chatcmpl-2d9848c58faf474a8c13ff1ad37747c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, some athletes celebrated by waving their national flags. Which country does the second athlete in the video, who takes out the national flag to celebrate, represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:49 engine.py:267] Added request chatcmpl-2d9848c58faf474a8c13ff1ad37747c7.
INFO 12-25 13:33:49 metrics.py:449] Avg prompt throughput: 43.9 tokens/s, Avg generation throughput: 113.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:51 logger.py:37] Received request chatcmpl-36f6454f9d3647758116faadea982210: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following times and places does not appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:51 engine.py:267] Added request chatcmpl-36f6454f9d3647758116faadea982210.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:52 logger.py:37] Received request chatcmpl-c4f767dd9c7b4df8bca3d190eb960579: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player is injured in the middle of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:52 engine.py:267] Added request chatcmpl-c4f767dd9c7b4df8bca3d190eb960579.
INFO 12-25 13:33:54 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:33:54 logger.py:37] Received request chatcmpl-4b0e97a51f2c4b398561c6cb016b56ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where and when was the longest jump in the video set?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:54 engine.py:267] Added request chatcmpl-4b0e97a51f2c4b398561c6cb016b56ec.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:56 logger.py:37] Received request chatcmpl-0c328b8d3f9f4d41bebf5c0c56a8c0f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many points does Ma Long win on serve in Game 1?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:56 engine.py:267] Added request chatcmpl-0c328b8d3f9f4d41bebf5c0c56a8c0f7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:33:58 logger.py:37] Received request chatcmpl-b07c58688e5b4c16b39f97eaaba28c7f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many strokes did the athlete in the video use during the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:33:58 engine.py:267] Added request chatcmpl-b07c58688e5b4c16b39f97eaaba28c7f.
INFO 12-25 13:33:59 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 128.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:01 logger.py:37] Received request chatcmpl-c5ff83851504482489d31cd38ef791ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the result of the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:01 engine.py:267] Added request chatcmpl-c5ff83851504482489d31cd38ef791ac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:02 logger.py:37] Received request chatcmpl-491b5ff2e41742808258bae828f78838: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order of the swimming strokes used by the athletes in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:02 engine.py:267] Added request chatcmpl-491b5ff2e41742808258bae828f78838.
INFO 12-25 13:34:03 logger.py:37] Received request chatcmpl-38d9627286154d9686340b9a0b2681c5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Japan gets the decisive score to win the championship?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:03 engine.py:267] Added request chatcmpl-38d9627286154d9686340b9a0b2681c5.
INFO 12-25 13:34:04 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 113.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:06 logger.py:37] Received request chatcmpl-c61c30f07a0c4c739cecaa161e9bfe21: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the time of the third athlete to reach the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:06 engine.py:267] Added request chatcmpl-c61c30f07a0c4c739cecaa161e9bfe21.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:09 metrics.py:449] Avg prompt throughput: 13.7 tokens/s, Avg generation throughput: 140.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:11 logger.py:37] Received request chatcmpl-d27fd303b7624b4281d1f08c71c8d2ce: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team won the first men\'s doubles?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:11 engine.py:267] Added request chatcmpl-d27fd303b7624b4281d1f08c71c8d2ce.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:12 logger.py:37] Received request chatcmpl-a780e2f82b1f4172ac9b9b43bbc2eb43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which lane are the Australian athletes competing in the race in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:12 engine.py:267] Added request chatcmpl-a780e2f82b1f4172ac9b9b43bbc2eb43.
INFO 12-25 13:34:12 logger.py:37] Received request chatcmpl-1a250a5f01d14590afa4882e0ede585b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, which country does the athlete positioned on the innermost track represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:12 engine.py:267] Added request chatcmpl-1a250a5f01d14590afa4882e0ede585b.
INFO 12-25 13:34:13 logger.py:37] Received request chatcmpl-d15bd2bebbad49659697126a823298d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what did the staff wearing red hats and red shirts prompt the four American athletes to do?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:13 engine.py:267] Added request chatcmpl-d15bd2bebbad49659697126a823298d5.
INFO 12-25 13:34:14 metrics.py:449] Avg prompt throughput: 54.0 tokens/s, Avg generation throughput: 87.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 134.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:20 logger.py:37] Received request chatcmpl-7195ff63337d4d2aa40cb9c0db4a4880: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where and when was the diving scene in the video taken?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:20 engine.py:267] Added request chatcmpl-7195ff63337d4d2aa40cb9c0db4a4880.
INFO 12-25 13:34:20 logger.py:37] Received request chatcmpl-29cb73c730914885a47c7bd13b2937d1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport are the two athletes playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:20 engine.py:267] Added request chatcmpl-29cb73c730914885a47c7bd13b2937d1.
INFO 12-25 13:34:21 logger.py:37] Received request chatcmpl-3431b080ae0f4956917cc1ef1ba84242: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport are the two athletes playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:21 engine.py:267] Added request chatcmpl-3431b080ae0f4956917cc1ef1ba84242.
INFO 12-25 13:34:21 logger.py:37] Received request chatcmpl-6f7ab8f4d05a48d6b158436957010c3b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Among the four matches, in which order do the two athletes consecutively appear back to the Rio2016 board?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:21 engine.py:267] Added request chatcmpl-6f7ab8f4d05a48d6b158436957010c3b.
INFO 12-25 13:34:24 metrics.py:449] Avg prompt throughput: 52.2 tokens/s, Avg generation throughput: 98.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 117.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:34:29 logger.py:37] Received request chatcmpl-a8b6c16f5cdb40ed9a65b7313a1a9efe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team gets more scores at the second half time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:29 logger.py:37] Received request chatcmpl-8ef0d8c09763402ab4e69fa6089ebfad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the 100m final shown at the end of the video, which country\'s athletes reached the finish line first?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:29 engine.py:267] Added request chatcmpl-a8b6c16f5cdb40ed9a65b7313a1a9efe.
INFO 12-25 13:34:29 engine.py:267] Added request chatcmpl-8ef0d8c09763402ab4e69fa6089ebfad.
INFO 12-25 13:34:30 logger.py:37] Received request chatcmpl-09d15444d9ed44368eb9e487c292dbab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the first match held?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:30 engine.py:267] Added request chatcmpl-09d15444d9ed44368eb9e487c292dbab.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:34 metrics.py:449] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 135.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:35 logger.py:37] Received request chatcmpl-b1ee960efdd94d02a4640794ae26061d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the sequence of appearance for the following throwers on the court? (a) Dark blue 21. (b) White 21. (c) Dark blue 29. (d) Dark blue 26.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:35 engine.py:267] Added request chatcmpl-b1ee960efdd94d02a4640794ae26061d.
INFO 12-25 13:34:35 logger.py:37] Received request chatcmpl-fd8883fe88d34165b7b031b5e689cca7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the player pocket the green ball?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:35 engine.py:267] Added request chatcmpl-fd8883fe88d34165b7b031b5e689cca7.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:38 logger.py:37] Received request chatcmpl-2d28bc6dc1e0451d83f329537763124f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the second athlete performing the high jump at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:38 engine.py:267] Added request chatcmpl-2d28bc6dc1e0451d83f329537763124f.
INFO 12-25 13:34:39 logger.py:37] Received request chatcmpl-d706fb593ee04e5ab73cfe9556b16fab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does JPN team usually win a point in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:39 engine.py:267] Added request chatcmpl-d706fb593ee04e5ab73cfe9556b16fab.
INFO 12-25 13:34:39 metrics.py:449] Avg prompt throughput: 59.5 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:43 logger.py:37] Received request chatcmpl-b71d9366dc6447c6be389c6790f86b53: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score at the half time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:43 engine.py:267] Added request chatcmpl-b71d9366dc6447c6be389c6790f86b53.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:44 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:34:44 logger.py:37] Received request chatcmpl-d275613131c94863befec416d74335bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the first four cars driven out of the garage in this video? (a) The yellow car. (b) The black car. (c) The silver car. (d) The white car.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:44 engine.py:267] Added request chatcmpl-d275613131c94863befec416d74335bf.
INFO 12-25 13:34:45 logger.py:37] Received request chatcmpl-52e085372ff34bbda4c7ea2555af81a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following long jump processes appear in the video?  8.53m Rome 2018  8.53m London 2018  8.56m Shanghai 2018  8.53m Birmingham 2018". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:45 engine.py:267] Added request chatcmpl-52e085372ff34bbda4c7ea2555af81a5.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:49 metrics.py:449] Avg prompt throughput: 44.7 tokens/s, Avg generation throughput: 133.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:34:50 logger.py:37] Received request chatcmpl-0a7d87e8523b4b52a5ec9b2fe56e7d26: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the final score of the player DING?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:50 engine.py:267] Added request chatcmpl-0a7d87e8523b4b52a5ec9b2fe56e7d26.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:54 metrics.py:449] Avg prompt throughput: 12.5 tokens/s, Avg generation throughput: 133.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:34:55 logger.py:37] Received request chatcmpl-627370bb806744e5838d5f0440121160: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the number written on the back of Nishida?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:55 engine.py:267] Added request chatcmpl-627370bb806744e5838d5f0440121160.
INFO 12-25 13:34:55 logger.py:37] Received request chatcmpl-20588865339944b38be03a258977a648: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes successfully finished the game in 2010?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:55 engine.py:267] Added request chatcmpl-20588865339944b38be03a258977a648.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:57 logger.py:37] Received request chatcmpl-5220868c98244496be709f7ba6fb96e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many points does the winner get enough to win the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:34:57 engine.py:267] Added request chatcmpl-5220868c98244496be709f7ba6fb96e3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:34:59 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 118.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:01 logger.py:37] Received request chatcmpl-44d62ae435834d648c7def249e515392: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the score of the silver medalist in the last match shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:01 engine.py:267] Added request chatcmpl-44d62ae435834d648c7def249e515392.
INFO 12-25 13:35:02 logger.py:37] Received request chatcmpl-0a77543757b94dce924e3045ef13794e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport are the two teams of athletes playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:02 engine.py:267] Added request chatcmpl-0a77543757b94dce924e3045ef13794e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:04 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 112.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:04 logger.py:37] Received request chatcmpl-7578fa81986c440fa2cf541f450dde30: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the nationality of the man playing the electronic keyboard?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:04 engine.py:267] Added request chatcmpl-7578fa81986c440fa2cf541f450dde30.
INFO 12-25 13:35:05 logger.py:37] Received request chatcmpl-fc833431c3af4be086f25d5264018015: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in this video, what happened to the last shot in this baseball game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:05 engine.py:267] Added request chatcmpl-fc833431c3af4be086f25d5264018015.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:07 logger.py:37] Received request chatcmpl-943774d272454076aa1300baaa571329: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what direction does the camera move during the introduction of the athletes at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:07 engine.py:267] Added request chatcmpl-943774d272454076aa1300baaa571329.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:09 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 132.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:11 logger.py:37] Received request chatcmpl-fe2def8cfe274a3bb3b5e4ab9b907f3c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sport are the two teams playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:11 engine.py:267] Added request chatcmpl-fe2def8cfe274a3bb3b5e4ab9b907f3c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:11 logger.py:37] Received request chatcmpl-b6071bb29439445597d35785c05975f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Among the games, which winner has the quickest finishing time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:12 engine.py:267] Added request chatcmpl-b6071bb29439445597d35785c05975f4.
INFO 12-25 13:35:12 logger.py:37] Received request chatcmpl-19656ac5b3624bafb9f4978937bc25c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which athlete is the second to reach the finish line in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:12 engine.py:267] Added request chatcmpl-19656ac5b3624bafb9f4978937bc25c6.
INFO 12-25 13:35:13 logger.py:37] Received request chatcmpl-984f4a2a7a044378847e82dbdf9dbcb2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary theme of the high school theatre show featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:13 engine.py:267] Added request chatcmpl-984f4a2a7a044378847e82dbdf9dbcb2.
INFO 12-25 13:35:14 metrics.py:449] Avg prompt throughput: 51.5 tokens/s, Avg generation throughput: 99.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:19 logger.py:37] Received request chatcmpl-20ce1cbcabd348f68b29e47dbc67d08b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the silver medalist?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:19 engine.py:267] Added request chatcmpl-20ce1cbcabd348f68b29e47dbc67d08b.
INFO 12-25 13:35:19 logger.py:37] Received request chatcmpl-f74cf0e15ec249e3abd2c682a9e8d7d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the car that is first to start in the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:19 engine.py:267] Added request chatcmpl-f74cf0e15ec249e3abd2c682a9e8d7d2.
INFO 12-25 13:35:19 metrics.py:449] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:20 logger.py:37] Received request chatcmpl-b78e25fd76b24c6299df175373981160: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many seats are on stage in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:20 engine.py:267] Added request chatcmpl-b78e25fd76b24c6299df175373981160.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:21 logger.py:37] Received request chatcmpl-1e60fa7c67104f98a6f24512a9cdca40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle of the video, why are there scenes of men running by the sea?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:21 engine.py:267] Added request chatcmpl-1e60fa7c67104f98a6f24512a9cdca40.
INFO 12-25 13:35:24 metrics.py:449] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:26 logger.py:37] Received request chatcmpl-8cd33e0ba77644d3a74542b1bac20eaf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many men\'s single matches are included in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:26 engine.py:267] Added request chatcmpl-8cd33e0ba77644d3a74542b1bac20eaf.
INFO 12-25 13:35:26 logger.py:37] Received request chatcmpl-8886b9585fd64fb2beba3cb8338e881c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How are the five moments of champion organized in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:26 engine.py:267] Added request chatcmpl-8886b9585fd64fb2beba3cb8338e881c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:28 logger.py:37] Received request chatcmpl-09ad26529ea04852a19d1c93498ad1e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When do the performers begin a dance routine without microphones?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:28 engine.py:267] Added request chatcmpl-09ad26529ea04852a19d1c93498ad1e3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:29 metrics.py:449] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 108.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:29 logger.py:37] Received request chatcmpl-2dbbfb295df74e0592a6310c3b1344b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about broadcast quality from the video description?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:29 engine.py:267] Added request chatcmpl-2dbbfb295df74e0592a6310c3b1344b9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:33 logger.py:37] Received request chatcmpl-d150a59e330142578670054518461cd2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What action does the judge take when the player pockets the black ball while other balls are still on the table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:33 engine.py:267] Added request chatcmpl-d150a59e330142578670054518461cd2.
INFO 12-25 13:35:34 metrics.py:449] Avg prompt throughput: 27.5 tokens/s, Avg generation throughput: 102.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:34 logger.py:37] Received request chatcmpl-1094a7f6eca148beaff7eb0d0c9493ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video document?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:34 logger.py:37] Received request chatcmpl-8681440240cf43ac884636c672a1763e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the setting of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:34 engine.py:267] Added request chatcmpl-1094a7f6eca148beaff7eb0d0c9493ff.
INFO 12-25 13:35:34 engine.py:267] Added request chatcmpl-8681440240cf43ac884636c672a1763e.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:36 logger.py:37] Received request chatcmpl-b783abc7f41241efb1b300bffe6eb970: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the theme of the performance in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:36 engine.py:267] Added request chatcmpl-b783abc7f41241efb1b300bffe6eb970.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:39 metrics.py:449] Avg prompt throughput: 36.0 tokens/s, Avg generation throughput: 126.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:39 logger.py:37] Received request chatcmpl-e5e5ddd2ccea4f70a5d43f89acbd27e4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two players have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:39 engine.py:267] Added request chatcmpl-e5e5ddd2ccea4f70a5d43f89acbd27e4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:40 logger.py:37] Received request chatcmpl-964aea2ae851442a91eebccfffb01a03: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the band do at the end of this song?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:40 engine.py:267] Added request chatcmpl-964aea2ae851442a91eebccfffb01a03.
INFO 12-25 13:35:41 logger.py:37] Received request chatcmpl-ad0328ada47a461194ea14b7c3598f6b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many buckets are on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:41 engine.py:267] Added request chatcmpl-ad0328ada47a461194ea14b7c3598f6b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:43 logger.py:37] Received request chatcmpl-0eef8543b83a415b9cd2c96458079905: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How are the students dressed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:43 engine.py:267] Added request chatcmpl-0eef8543b83a415b9cd2c96458079905.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:44 metrics.py:449] Avg prompt throughput: 49.1 tokens/s, Avg generation throughput: 105.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:44 logger.py:37] Received request chatcmpl-d11c7af155704c7dafb33d33814e212d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team participates in the first five matches in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:44 engine.py:267] Added request chatcmpl-d11c7af155704c7dafb33d33814e212d.
INFO 12-25 13:35:45 logger.py:37] Received request chatcmpl-a99bc10624c545a6b2694b75368b883a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, how is the group dressed for their performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:45 engine.py:267] Added request chatcmpl-a99bc10624c545a6b2694b75368b883a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:49 metrics.py:449] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 145.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:50 logger.py:37] Received request chatcmpl-bf0cec326904446185b62aa5ad9d7a85: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the likely purpose of the scene being performed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:50 engine.py:267] Added request chatcmpl-bf0cec326904446185b62aa5ad9d7a85.
INFO 12-25 13:35:50 logger.py:37] Received request chatcmpl-f1ff65feec9c485e9d2aa1f7f20d27f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the man demonstrate the shake change?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:50 engine.py:267] Added request chatcmpl-f1ff65feec9c485e9d2aa1f7f20d27f8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:54 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 112.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:35:54 logger.py:37] Received request chatcmpl-968f689a520048b884b867da16a26bbb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the story at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:54 engine.py:267] Added request chatcmpl-968f689a520048b884b867da16a26bbb.
INFO 12-25 13:35:55 logger.py:37] Received request chatcmpl-0bba2eb4a032414eaa5e35194efb6803: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which period is the most time-consuming in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:55 engine.py:267] Added request chatcmpl-0bba2eb4a032414eaa5e35194efb6803.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:35:57 logger.py:37] Received request chatcmpl-6410ee63aa9b400faa566d52ee8b6774: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of event is being depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:57 engine.py:267] Added request chatcmpl-6410ee63aa9b400faa566d52ee8b6774.
INFO 12-25 13:35:57 logger.py:37] Received request chatcmpl-1219074a2c164756b512639b0e59d5e4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happened when the performer made the first two pigeons? (a) He duplicated the pigeon and produced another. (b) He produced a pigeon from a burning leather. (c) He put the pigeons into a cage.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:35:58 engine.py:267] Added request chatcmpl-1219074a2c164756b512639b0e59d5e4.
INFO 12-25 13:35:59 metrics.py:449] Avg prompt throughput: 59.9 tokens/s, Avg generation throughput: 127.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:03 logger.py:37] Received request chatcmpl-26ec74bb7bbf4df087ebc352ff298454: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animals appear in the performance from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:03 engine.py:267] Added request chatcmpl-26ec74bb7bbf4df087ebc352ff298454.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:04 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 138.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:36:05 logger.py:37] Received request chatcmpl-263222f00d7847139d8826a2b7fd31a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, who is the winner of the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:05 engine.py:267] Added request chatcmpl-263222f00d7847139d8826a2b7fd31a0.
INFO 12-25 13:36:05 logger.py:37] Received request chatcmpl-fceaa6f8b7704bdbbda7c06fa289c79a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the ring?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:05 engine.py:267] Added request chatcmpl-fceaa6f8b7704bdbbda7c06fa289c79a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:06 logger.py:37] Received request chatcmpl-a7dccce738a04f13951c4e1fb81ec1ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which institution is associated with Pitch Slapped in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:06 engine.py:267] Added request chatcmpl-a7dccce738a04f13951c4e1fb81ec1ff.
INFO 12-25 13:36:09 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 136.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:11 logger.py:37] Received request chatcmpl-96e9223ecd33400ea03512ac071d3797: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the man playing the keyboard leave his seat during the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:11 engine.py:267] Added request chatcmpl-96e9223ecd33400ea03512ac071d3797.
INFO 12-25 13:36:12 logger.py:37] Received request chatcmpl-d43c63bf97b2460dbd8975553551d961: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of cards does the magician ask the female judge to pick one from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:12 engine.py:267] Added request chatcmpl-d43c63bf97b2460dbd8975553551d961.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:14 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 121.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:36:14 logger.py:37] Received request chatcmpl-ebc1ef8372e444c5a8b7beb26d84ca43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of venue is the man performing according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:14 engine.py:267] Added request chatcmpl-ebc1ef8372e444c5a8b7beb26d84ca43.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:16 logger.py:37] Received request chatcmpl-e5c0fa34f04e40d4a997671b3804b92c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What aspect of Broadway is being saluted by the man\'s opening number at the activity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:16 engine.py:267] Added request chatcmpl-e5c0fa34f04e40d4a997671b3804b92c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:18 logger.py:37] Received request chatcmpl-70d61b00f9a54e5691af80200ab6a43a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which play is featured at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:18 engine.py:267] Added request chatcmpl-70d61b00f9a54e5691af80200ab6a43a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:19 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 123.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:36:20 logger.py:37] Received request chatcmpl-baec9d0aa8c94b5ea3929362ce1327cf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the last magic the magician played?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:20 engine.py:267] Added request chatcmpl-baec9d0aa8c94b5ea3929362ce1327cf.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:23 logger.py:37] Received request chatcmpl-874f4935b983494da2d46229021575cf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is likely the emotional tone of the song being performed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:23 engine.py:267] Added request chatcmpl-874f4935b983494da2d46229021575cf.
INFO 12-25 13:36:23 logger.py:37] Received request chatcmpl-1d70a15ab1d64cc6b5cf82729ed3fec5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the performer produce the fifth pigeon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:23 engine.py:267] Added request chatcmpl-1d70a15ab1d64cc6b5cf82729ed3fec5.
INFO 12-25 13:36:24 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 126.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:26 logger.py:37] Received request chatcmpl-1e7dbb4d1efc40abb28f53bcaf5bc165: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:26 engine.py:267] Added request chatcmpl-1e7dbb4d1efc40abb28f53bcaf5bc165.
INFO 12-25 13:36:26 logger.py:37] Received request chatcmpl-9cc1255396af49e6a057bbf8ea7a977a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what setting is the high school theatre show trying to replicate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:26 engine.py:267] Added request chatcmpl-9cc1255396af49e6a057bbf8ea7a977a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:28 logger.py:37] Received request chatcmpl-fbcacc5bb8204b999436d1f803a5a785: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the event in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:28 engine.py:267] Added request chatcmpl-fbcacc5bb8204b999436d1f803a5a785.
INFO 12-25 13:36:29 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:31 logger.py:37] Received request chatcmpl-3ff9c31ecd8d44399d08b9edb4042e0e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happen? (a) The flower in the mouth turns into a butterfly. (b) The turban turns into a real snake. (c) The spider painting on the arm turns into a real spider.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:31 engine.py:267] Added request chatcmpl-3ff9c31ecd8d44399d08b9edb4042e0e.
INFO 12-25 13:36:32 logger.py:37] Received request chatcmpl-083bbaeec8d444f382c33b5e66894e94: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order are the following items used for magic? (a) Cards. (b) A stick. (c) A ring. (d) Paper money.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:32 engine.py:267] Added request chatcmpl-083bbaeec8d444f382c33b5e66894e94.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:34 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 118.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:36:34 logger.py:37] Received request chatcmpl-ffecf888d1ed48e9b4fdf27a6791d8d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the setting for "Grease The Musical" as mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:34 engine.py:267] Added request chatcmpl-ffecf888d1ed48e9b4fdf27a6791d8d0.
INFO 12-25 13:36:35 logger.py:37] Received request chatcmpl-2b716092db4245e59d89ecda89f73d1b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the chronological order of the following events according to this video? (a) The Pinkie Change. (b) The Shake Change. (c) The Shake Change.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:35 engine.py:267] Added request chatcmpl-2b716092db4245e59d89ecda89f73d1b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:39 metrics.py:449] Avg prompt throughput: 31.1 tokens/s, Avg generation throughput: 142.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:36:39 logger.py:37] Received request chatcmpl-eb66e91e95234afdbc8349aecd562143: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the setting from the lighting and background?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:39 engine.py:267] Added request chatcmpl-eb66e91e95234afdbc8349aecd562143.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:42 logger.py:37] Received request chatcmpl-e3920bcbe6f94dd5adc1c95b84f83721: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the magic the magician playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:42 engine.py:267] Added request chatcmpl-e3920bcbe6f94dd5adc1c95b84f83721.
INFO 12-25 13:36:42 logger.py:37] Received request chatcmpl-0660c78bfc9a4409b039f9152ae452e6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the last magic during the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:42 engine.py:267] Added request chatcmpl-0660c78bfc9a4409b039f9152ae452e6.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:44 logger.py:37] Received request chatcmpl-052d7ff3626c403c9f1f15245fe7c45a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the bonus trick?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:44 engine.py:267] Added request chatcmpl-052d7ff3626c403c9f1f15245fe7c45a.
INFO 12-25 13:36:44 metrics.py:449] Avg prompt throughput: 48.8 tokens/s, Avg generation throughput: 115.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:46 logger.py:37] Received request chatcmpl-a02037150dcc48d7811d5626101b847b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the little magician wear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:46 engine.py:267] Added request chatcmpl-a02037150dcc48d7811d5626101b847b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:49 logger.py:37] Received request chatcmpl-3d9bb41f83764fa9971000ed0ce4bbc5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happen? (a) The magician took the white cloth away from the photo frame. (b) The magician led a self introduction. (c) The magician produced a feather.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:49 engine.py:267] Added request chatcmpl-3d9bb41f83764fa9971000ed0ce4bbc5.
INFO 12-25 13:36:49 metrics.py:449] Avg prompt throughput: 31.5 tokens/s, Avg generation throughput: 122.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:50 logger.py:37] Received request chatcmpl-7a46e546e21d4b689bfd7317ea23155b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how much was the guest off by when guessing the price of the second item?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:50 engine.py:267] Added request chatcmpl-7a46e546e21d4b689bfd7317ea23155b.
INFO 12-25 13:36:51 logger.py:37] Received request chatcmpl-83bdd2b745014589a78189fd2f7ec960: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From the staging and setting in the video, what type of ambiance is suggested for the activity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:51 engine.py:267] Added request chatcmpl-83bdd2b745014589a78189fd2f7ec960.
INFO 12-25 13:36:51 logger.py:37] Received request chatcmpl-e48ca2777a684b6492496ce60c108956: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What magic does the magician first perform on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:51 engine.py:267] Added request chatcmpl-e48ca2777a684b6492496ce60c108956.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:54 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 118.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:56 logger.py:37] Received request chatcmpl-8e0072076015498bbd003d1953ef25b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the disappearing coin gone in the fifth magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:56 engine.py:267] Added request chatcmpl-8e0072076015498bbd003d1953ef25b9.
INFO 12-25 13:36:56 logger.py:37] Received request chatcmpl-14b10c3e51a5409885390b879d2650ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is written on the judge\'s table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:56 engine.py:267] Added request chatcmpl-14b10c3e51a5409885390b879d2650ee.
INFO 12-25 13:36:57 logger.py:37] Received request chatcmpl-ef23b349e4174df6989e0afce7120fc8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sentence best describes the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:36:57 engine.py:267] Added request chatcmpl-ef23b349e4174df6989e0afce7120fc8.
INFO 12-25 13:36:58 logger.py:37] Received request chatcmpl-2611fe05fc874516a7d331777cac2e1a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:36:58 engine.py:267] Added request chatcmpl-2611fe05fc874516a7d331777cac2e1a.
INFO 12-25 13:36:59 metrics.py:449] Avg prompt throughput: 49.5 tokens/s, Avg generation throughput: 102.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:02 logger.py:37] Received request chatcmpl-1c571ae599d249cc870b544dbf28e7af: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the key to the illusion of the basic levitating magic that is performed at home?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:02 engine.py:267] Added request chatcmpl-1c571ae599d249cc870b544dbf28e7af.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:03 logger.py:37] Received request chatcmpl-cc21b3dd1b0a40329a186094ca86caba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:03 engine.py:267] Added request chatcmpl-cc21b3dd1b0a40329a186094ca86caba.
INFO 12-25 13:37:04 metrics.py:449] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:04 logger.py:37] Received request chatcmpl-ef98c03534fe4ede83de8a1f7091a7da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Whose song did the performer sing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:04 engine.py:267] Added request chatcmpl-ef98c03534fe4ede83de8a1f7091a7da.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:09 logger.py:37] Received request chatcmpl-190fde1c64f04ebb870400f1aad4f2f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happen? (a) The magician pulls a card out of his phone. (b) The magician pulls the silk through the middle of the screen. (c) The phone goes inside the bottle. (d) The magician visually removes the torchlight from his phone. (e) The icons fall off the screen onto the magician\'s hand.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:09 logger.py:37] Received request chatcmpl-079399d9680a44a4a23906ed4170a408: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where are most of the magics in this video performed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:09 engine.py:267] Added request chatcmpl-190fde1c64f04ebb870400f1aad4f2f9.
INFO 12-25 13:37:09 engine.py:267] Added request chatcmpl-079399d9680a44a4a23906ed4170a408.
INFO 12-25 13:37:09 logger.py:37] Received request chatcmpl-62dc4574e0874952950345a198a23c3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What significant object is present on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:09 engine.py:267] Added request chatcmpl-62dc4574e0874952950345a198a23c3f.
INFO 12-25 13:37:09 metrics.py:449] Avg prompt throughput: 63.8 tokens/s, Avg generation throughput: 110.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:13 logger.py:37] Received request chatcmpl-b21365cc16054c2c8522abb71a6bb1ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At what time does a man in military uniform appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:13 engine.py:267] Added request chatcmpl-b21365cc16054c2c8522abb71a6bb1ab.
INFO 12-25 13:37:14 logger.py:37] Received request chatcmpl-3e599fe4ac1343d7a476e957415c12a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:14 engine.py:267] Added request chatcmpl-3e599fe4ac1343d7a476e957415c12a8.
INFO 12-25 13:37:14 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 129.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:15 logger.py:37] Received request chatcmpl-bb1b562c2fd840b0b0bb1f7a0d6b4837: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is not common among the three card tricks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:15 engine.py:267] Added request chatcmpl-bb1b562c2fd840b0b0bb1f7a0d6b4837.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:19 logger.py:37] Received request chatcmpl-f55fc56599894ddba623fc3d6b1d6fd7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of flowers are placed on the table between the host and the guest in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:19 engine.py:267] Added request chatcmpl-f55fc56599894ddba623fc3d6b1d6fd7.
INFO 12-25 13:37:19 metrics.py:449] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:20 logger.py:37] Received request chatcmpl-b02782c8a92849e4a10a9e87aad63a02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the content of this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:20 logger.py:37] Received request chatcmpl-437a08d2c0e94490b73975db8ad5b448: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the bike on the stage?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:20 engine.py:267] Added request chatcmpl-b02782c8a92849e4a10a9e87aad63a02.
INFO 12-25 13:37:20 engine.py:267] Added request chatcmpl-437a08d2c0e94490b73975db8ad5b448.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:23 logger.py:37] Received request chatcmpl-01d7f6ffce794a26bdd71b66fb93d8ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many items did the guest accurately guess the prices of, with a margin of error within $1?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:23 engine.py:267] Added request chatcmpl-01d7f6ffce794a26bdd71b66fb93d8ea.
INFO 12-25 13:37:24 metrics.py:449] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 118.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:25 logger.py:37] Received request chatcmpl-349da9d3b95d49859b3e02a8f7d165a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why did the judges on stage cry?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:25 engine.py:267] Added request chatcmpl-349da9d3b95d49859b3e02a8f7d165a8.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:27 logger.py:37] Received request chatcmpl-803e7b3e2dc24314be14b642ec4258e4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What card does the male judge pick?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:27 engine.py:267] Added request chatcmpl-803e7b3e2dc24314be14b642ec4258e4.
INFO 12-25 13:37:28 logger.py:37] Received request chatcmpl-99365f14250046df8a9e0fb194dacbea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, who won the sandwich competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:28 engine.py:267] Added request chatcmpl-99365f14250046df8a9e0fb194dacbea.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:29 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 120.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:30 logger.py:37] Received request chatcmpl-7110ac3093744c4390973bd4cebd89e6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From the perspective of the performer, is the judge wearing black clothes on her left or right side?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:30 engine.py:267] Added request chatcmpl-7110ac3093744c4390973bd4cebd89e6.
INFO 12-25 13:37:31 logger.py:37] Received request chatcmpl-5d3b99cab5ef470592e0d566a05dc662: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, who is less likely to get scared?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:31 engine.py:267] Added request chatcmpl-5d3b99cab5ef470592e0d566a05dc662.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:34 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 107.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:34 logger.py:37] Received request chatcmpl-5942eada63a94e338dd06107f01d3127: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two performances have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:34 logger.py:37] Received request chatcmpl-22c5ad6e4d3c44cdb49de88124eba258: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the Bench Press segment, how many times did the team in white shirts complete the bench press?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:34 engine.py:267] Added request chatcmpl-5942eada63a94e338dd06107f01d3127.
INFO 12-25 13:37:34 engine.py:267] Added request chatcmpl-22c5ad6e4d3c44cdb49de88124eba258.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:36 logger.py:37] Received request chatcmpl-9844f3b42bee4d9e8f99cea1f0118655: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What other instrument is there on the stage besides the piano?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:36 engine.py:267] Added request chatcmpl-9844f3b42bee4d9e8f99cea1f0118655.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:38 logger.py:37] Received request chatcmpl-84ee27e1040e4b33ba46520ec4009cc4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:38 engine.py:267] Added request chatcmpl-84ee27e1040e4b33ba46520ec4009cc4.
INFO 12-25 13:37:39 metrics.py:449] Avg prompt throughput: 51.0 tokens/s, Avg generation throughput: 129.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:42 logger.py:37] Received request chatcmpl-ea80bc84aba14a078980ae78bf53604e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happen? (a) A ring jumps into the finger. (b) A coin jumps from hand to hand. (c) The cigarette disappers and reappears. (d) A coin changes into a card.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:42 logger.py:37] Received request chatcmpl-276728b4eb3f4c0ba9c4e2432cfa9fd7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:42 engine.py:267] Added request chatcmpl-ea80bc84aba14a078980ae78bf53604e.
INFO 12-25 13:37:42 engine.py:267] Added request chatcmpl-276728b4eb3f4c0ba9c4e2432cfa9fd7.
INFO 12-25 13:37:43 logger.py:37] Received request chatcmpl-63af5d0a451149aca95f5c2ca46977b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The receptionist in the video has another identity, which is most likely?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:43 engine.py:267] Added request chatcmpl-63af5d0a451149aca95f5c2ca46977b5.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:44 metrics.py:449] Avg prompt throughput: 46.6 tokens/s, Avg generation throughput: 101.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:45 logger.py:37] Received request chatcmpl-a20e530ccf974bdf8aa3277d1aa05fe5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the order of introduction in the video, which of the following options is introduced last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:45 engine.py:267] Added request chatcmpl-a20e530ccf974bdf8aa3277d1aa05fe5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:47 logger.py:37] Received request chatcmpl-6ecf0d378e23440babbe359ae3fec2a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many yeses does the little girl get?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:47 engine.py:267] Added request chatcmpl-6ecf0d378e23440babbe359ae3fec2a4.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:49 metrics.py:449] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:37:50 logger.py:37] Received request chatcmpl-442b68f70be54e5b97b773fa7fd4153b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the name of the program in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:50 engine.py:267] Added request chatcmpl-442b68f70be54e5b97b773fa7fd4153b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:53 logger.py:37] Received request chatcmpl-02aee59d345d4189ad4601ea3415b391: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the first moment occur?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:53 engine.py:267] Added request chatcmpl-02aee59d345d4189ad4601ea3415b391.
INFO 12-25 13:37:54 logger.py:37] Received request chatcmpl-ac4f63a073eb4c9c9c24b3f9e3299d48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which team ultimately won?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:54 engine.py:267] Added request chatcmpl-ac4f63a073eb4c9c9c24b3f9e3299d48.
INFO 12-25 13:37:54 metrics.py:449] Avg prompt throughput: 36.7 tokens/s, Avg generation throughput: 122.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:56 logger.py:37] Received request chatcmpl-37756bb66ed749e68b00f6e1c8e0a4ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the advanced professional magic performed on television?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:37:56 engine.py:267] Added request chatcmpl-37756bb66ed749e68b00f6e1c8e0a4ca.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:37:59 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 128.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:38:00 logger.py:37] Received request chatcmpl-8dafcafeef6f44cba09b53e32280ea54: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:00 engine.py:267] Added request chatcmpl-8dafcafeef6f44cba09b53e32280ea54.
INFO 12-25 13:38:00 logger.py:37] Received request chatcmpl-f20059b3c2a24c2eadfc813c7dba0a5a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is the order in which the host tastes the sandwiches made by the contestants? (1) Owen; (2) Salt Hank; (3) Albert". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:00 engine.py:267] Added request chatcmpl-f20059b3c2a24c2eadfc813c7dba0a5a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:02 logger.py:37] Received request chatcmpl-d88ccf6abdf548778a740096b2c02ff3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happened? (a) Forming a human pole. (b) Jumping through white hoops. (c) Forming a human cross.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:02 engine.py:267] Added request chatcmpl-d88ccf6abdf548778a740096b2c02ff3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:04 logger.py:37] Received request chatcmpl-e85a66bbd1524cf58dd0c05c35c1c0e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many magics does the magician play?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:04 engine.py:267] Added request chatcmpl-e85a66bbd1524cf58dd0c05c35c1c0e0.
INFO 12-25 13:38:04 metrics.py:449] Avg prompt throughput: 59.8 tokens/s, Avg generation throughput: 120.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:07 logger.py:37] Received request chatcmpl-e3f39572f42547cd8187f04af6ac1721: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which performance is the opening of this video taken?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:07 engine.py:267] Added request chatcmpl-e3f39572f42547cd8187f04af6ac1721.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:09 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 111.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:38:10 logger.py:37] Received request chatcmpl-7605a32070fb4baeaaf8ec2a781ba031: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the final movement of the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:10 logger.py:37] Received request chatcmpl-3510114d347f4c36bc81ce7885111185: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The person wearing a red shirt on stage is what role?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:10 logger.py:37] Received request chatcmpl-24a4aaddad9749c686bb2fcc10212bdd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which team won in the end?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:10 engine.py:267] Added request chatcmpl-7605a32070fb4baeaaf8ec2a781ba031.
INFO 12-25 13:38:10 engine.py:267] Added request chatcmpl-3510114d347f4c36bc81ce7885111185.
INFO 12-25 13:38:10 engine.py:267] Added request chatcmpl-24a4aaddad9749c686bb2fcc10212bdd.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:14 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 115.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:15 logger.py:37] Received request chatcmpl-b0b17126f8af486ea4cfec10207e0f51: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following skills is not included in the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:15 engine.py:267] Added request chatcmpl-b0b17126f8af486ea4cfec10207e0f51.
INFO 12-25 13:38:15 logger.py:37] Received request chatcmpl-07f759420f954716bbac62e47596580f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the actor hanging on the left swing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:15 engine.py:267] Added request chatcmpl-07f759420f954716bbac62e47596580f.
INFO 12-25 13:38:16 logger.py:37] Received request chatcmpl-6ec4cc36cd0d43558e27175dd376ce37: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, is the homeowner satisfied with the renovation results?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:16 engine.py:267] Added request chatcmpl-6ec4cc36cd0d43558e27175dd376ce37.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:19 logger.py:37] Received request chatcmpl-70007f35592a41969a86e8450229dc18: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first tattoo about the female guest written by her boyfriend in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:19 engine.py:267] Added request chatcmpl-70007f35592a41969a86e8450229dc18.
INFO 12-25 13:38:19 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 117.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:23 logger.py:37] Received request chatcmpl-25bd5b392887443ebcf65a72df54f458: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the judges do after the little girl finishes the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:23 logger.py:37] Received request chatcmpl-f1b138ca9baf43018447e9ac19a57678: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many moments are in the opening of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:23 engine.py:267] Added request chatcmpl-25bd5b392887443ebcf65a72df54f458.
INFO 12-25 13:38:23 engine.py:267] Added request chatcmpl-f1b138ca9baf43018447e9ac19a57678.
INFO 12-25 13:38:24 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 107.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:38:24 logger.py:37] Received request chatcmpl-4e165d82939842258fa68ac3f97fe34c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the female performer do after she takes off her white shirt?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:24 engine.py:267] Added request chatcmpl-4e165d82939842258fa68ac3f97fe34c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:27 logger.py:37] Received request chatcmpl-5980c06f1379417e80b67401e322bbf2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:27 engine.py:267] Added request chatcmpl-5980c06f1379417e80b67401e322bbf2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:29 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 128.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:38:30 logger.py:37] Received request chatcmpl-613be5abb33b4d3c8625eddf56acbed1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the type of the last trick?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:30 logger.py:37] Received request chatcmpl-1be1a23209754677ad9edd9481d0c9cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the performers end their performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:30 engine.py:267] Added request chatcmpl-613be5abb33b4d3c8625eddf56acbed1.
INFO 12-25 13:38:30 engine.py:267] Added request chatcmpl-1be1a23209754677ad9edd9481d0c9cb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:33 logger.py:37] Received request chatcmpl-0064b6ffe522436cb8ff015bb5508d50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What name did the man wearing the black shirt use when booking the room according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:33 engine.py:267] Added request chatcmpl-0064b6ffe522436cb8ff015bb5508d50.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:34 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:38:35 logger.py:37] Received request chatcmpl-83e0d7ee6e744717bd56fa7ce1dfcca2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the actress fall into a ball?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:35 engine.py:267] Added request chatcmpl-83e0d7ee6e744717bd56fa7ce1dfcca2.
INFO 12-25 13:38:36 logger.py:37] Received request chatcmpl-7f99c1f9c8d4432e877f1243091cb9d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many yeses do the performers get?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:36 engine.py:267] Added request chatcmpl-7f99c1f9c8d4432e877f1243091cb9d0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:39 logger.py:37] Received request chatcmpl-0e8696d13ac84d26ba733cc7d369d01e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the performers do after they get four yeses?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:39 engine.py:267] Added request chatcmpl-0e8696d13ac84d26ba733cc7d369d01e.
INFO 12-25 13:38:39 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:40 logger.py:37] Received request chatcmpl-3b2db5111d5d4fe2accc30e625fb19a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following obstacles appears last?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:40 logger.py:37] Received request chatcmpl-753c8a64df4e4cc0bd574a2d2b78593e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the performer ride?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:40 engine.py:267] Added request chatcmpl-3b2db5111d5d4fe2accc30e625fb19a1.
INFO 12-25 13:38:40 engine.py:267] Added request chatcmpl-753c8a64df4e4cc0bd574a2d2b78593e.
INFO 12-25 13:38:41 logger.py:37] Received request chatcmpl-4ca00c126366460c8fed4f49b92ff419: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In this video, what is the technique or method used by the woman to perform her paper cutting?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:41 engine.py:267] Added request chatcmpl-4ca00c126366460c8fed4f49b92ff419.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:44 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:46 logger.py:37] Received request chatcmpl-0b1eccb2bc7645d2bbb29995f84e76ba: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the little girl\'s expression after the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:46 logger.py:37] Received request chatcmpl-34699a3fd4e44efb9264c6b2736f5b2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people are there in the "tallest family" as shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:46 engine.py:267] Added request chatcmpl-0b1eccb2bc7645d2bbb29995f84e76ba.
INFO 12-25 13:38:46 engine.py:267] Added request chatcmpl-34699a3fd4e44efb9264c6b2736f5b2e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:48 logger.py:37] Received request chatcmpl-b4897ff78cb54d4d888d60ef824789e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of the last moment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:48 engine.py:267] Added request chatcmpl-b4897ff78cb54d4d888d60ef824789e8.
INFO 12-25 13:38:48 logger.py:37] Received request chatcmpl-0435b81005854e968771a9d5728101d7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the chronological order in which the following actions occur? (a) Weaving in the ends. (b) Crocheting a single crochet. (c) Finishing the handcraft. (d) Making a slip knot. (e) Crocheting a chain.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:48 engine.py:267] Added request chatcmpl-0435b81005854e968771a9d5728101d7.
INFO 12-25 13:38:49 metrics.py:449] Avg prompt throughput: 61.4 tokens/s, Avg generation throughput: 100.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:54 logger.py:37] Received request chatcmpl-a431c3f979ef48f29c2276fd7671f198: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened after the two actresses climbed onto the high board?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:54 engine.py:267] Added request chatcmpl-a431c3f979ef48f29c2276fd7671f198.
INFO 12-25 13:38:54 logger.py:37] Received request chatcmpl-81067e731baa4c8e85ae50d211e8ca84: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first competition conducted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:54 engine.py:267] Added request chatcmpl-81067e731baa4c8e85ae50d211e8ca84.
INFO 12-25 13:38:54 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 134.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:57 logger.py:37] Received request chatcmpl-f5dbf2bd1d1a4944bad29b8a4ca79160: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first step to make the handcraft?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:57 engine.py:267] Added request chatcmpl-f5dbf2bd1d1a4944bad29b8a4ca79160.
INFO 12-25 13:38:58 logger.py:37] Received request chatcmpl-22b8407f1082441b86799e9b565398f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which character is the actress cosplayed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:38:58 engine.py:267] Added request chatcmpl-22b8407f1082441b86799e9b565398f4.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:38:59 metrics.py:449] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 119.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:01 logger.py:37] Received request chatcmpl-99a22d844426480b88e5ec8ce894d0c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject or image that the artist is drawing on the board in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:01 engine.py:267] Added request chatcmpl-99a22d844426480b88e5ec8ce894d0c6.
INFO 12-25 13:39:01 logger.py:37] Received request chatcmpl-c44d9c724549482bac03a8c45c7ab8f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which part of the video does the red parrot appear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:01 engine.py:267] Added request chatcmpl-c44d9c724549482bac03a8c45c7ab8f2.
INFO 12-25 13:39:02 logger.py:37] Received request chatcmpl-e3efe80e274443c89ab1481ec9c05a6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Among the three unicycles the actor rides in the performance, which one has the highest frame?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:02 engine.py:267] Added request chatcmpl-e3efe80e274443c89ab1481ec9c05a6a.
INFO 12-25 13:39:04 metrics.py:449] Avg prompt throughput: 41.3 tokens/s, Avg generation throughput: 116.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:06 logger.py:37] Received request chatcmpl-bd9b7b697e3b425ebcb5eab91602ef58: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is not used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:06 engine.py:267] Added request chatcmpl-bd9b7b697e3b425ebcb5eab91602ef58.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:09 logger.py:37] Received request chatcmpl-c8f561a7efe84376be4895324b7d5acd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following business ideas appear in the video? (a) Wedding invitations. (b) Clothing labels. (c) Book marks. (d) Dried flowers.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:09 logger.py:37] Received request chatcmpl-c77e3da01bdc494caefafb3fcae17458: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the performance held?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:09 engine.py:267] Added request chatcmpl-c8f561a7efe84376be4895324b7d5acd.
INFO 12-25 13:39:09 engine.py:267] Added request chatcmpl-c77e3da01bdc494caefafb3fcae17458.
INFO 12-25 13:39:09 metrics.py:449] Avg prompt throughput: 42.5 tokens/s, Avg generation throughput: 115.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:12 logger.py:37] Received request chatcmpl-ea3daa8ba91b4f7baac258d59eedb0bb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the color of the hook?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:12 engine.py:267] Added request chatcmpl-ea3daa8ba91b4f7baac258d59eedb0bb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:14 logger.py:37] Received request chatcmpl-1bd34bcb762a4ac7984f88d2f51a7bc7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which performance in this video has the least acrobats?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:14 engine.py:267] Added request chatcmpl-1bd34bcb762a4ac7984f88d2f51a7bc7.
INFO 12-25 13:39:14 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 130.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:18 logger.py:37] Received request chatcmpl-ffbe2d91e6ce4bc0adbf69e1425c96e7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the intended use of the pink crochet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:18 engine.py:267] Added request chatcmpl-ffbe2d91e6ce4bc0adbf69e1425c96e7.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:19 logger.py:37] Received request chatcmpl-b892d6a59b2e4aa199db38c626b54bd8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the position of the ring which the woman is wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:19 engine.py:267] Added request chatcmpl-b892d6a59b2e4aa199db38c626b54bd8.
INFO 12-25 13:39:19 metrics.py:449] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 131.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:39:21 logger.py:37] Received request chatcmpl-b30560941e69491a9ae98da37c4139db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the person weave the same colored thread?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:21 engine.py:267] Added request chatcmpl-b30560941e69491a9ae98da37c4139db.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:24 metrics.py:449] Avg prompt throughput: 12.4 tokens/s, Avg generation throughput: 122.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:39:25 logger.py:37] Received request chatcmpl-c660bf33211349138fbe5058d79fe43e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:25 logger.py:37] Received request chatcmpl-2643fc580483400e8ca01e0c72a616e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of this video, how many rounds of yellow thread are wrapped around the fingers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:25 engine.py:267] Added request chatcmpl-c660bf33211349138fbe5058d79fe43e.
INFO 12-25 13:39:25 engine.py:267] Added request chatcmpl-2643fc580483400e8ca01e0c72a616e1.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:28 logger.py:37] Received request chatcmpl-f77df6376cc74322902c5fc8bbe6a688: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:28 engine.py:267] Added request chatcmpl-f77df6376cc74322902c5fc8bbe6a688.
INFO 12-25 13:39:28 logger.py:37] Received request chatcmpl-66162d3fefd14dd8b8d9de99896e3a27: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the sequential order in which the following tools are used? (a) Glue gun. (b) Needle. (c) Scissors.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:28 engine.py:267] Added request chatcmpl-66162d3fefd14dd8b8d9de99896e3a27.
INFO 12-25 13:39:29 metrics.py:449] Avg prompt throughput: 56.2 tokens/s, Avg generation throughput: 128.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:31 logger.py:37] Received request chatcmpl-bded970313324407a294f93d55054031: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do the two performers end their performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:31 engine.py:267] Added request chatcmpl-bded970313324407a294f93d55054031.
INFO 12-25 13:39:32 logger.py:37] Received request chatcmpl-2daf85364d08482da0e72ad1d6bad320: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many candles are shown in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:32 engine.py:267] Added request chatcmpl-2daf85364d08482da0e72ad1d6bad320.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:34 metrics.py:449] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:35 logger.py:37] Received request chatcmpl-5255a817b44b4580b284b2388e414edf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which two people appear at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:35 engine.py:267] Added request chatcmpl-5255a817b44b4580b284b2388e414edf.
INFO 12-25 13:39:37 logger.py:37] Received request chatcmpl-bd3baff36a0145f19299c60dbf2f63c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the performers wear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:37 logger.py:37] Received request chatcmpl-6519e8218e5e4c52855dcb60f2afd3b4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is not used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:37 engine.py:267] Added request chatcmpl-bd3baff36a0145f19299c60dbf2f63c7.
INFO 12-25 13:39:37 engine.py:267] Added request chatcmpl-6519e8218e5e4c52855dcb60f2afd3b4.
INFO 12-25 13:39:39 metrics.py:449] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 119.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:43 logger.py:37] Received request chatcmpl-79d48e9a815a4192a2783ab19e87d6bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of handicraft is made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:43 logger.py:37] Received request chatcmpl-59e1a08bceca461ea384828cb6675f61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of this video, how many different colors of acrylic are being squeezed onto the board?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:43 logger.py:37] Received request chatcmpl-51aa158fb1f64fdfa17a482a72879abb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the waiter in LYNN\'s Table wash the dishes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:43 engine.py:267] Added request chatcmpl-79d48e9a815a4192a2783ab19e87d6bf.
INFO 12-25 13:39:43 engine.py:267] Added request chatcmpl-59e1a08bceca461ea384828cb6675f61.
INFO 12-25 13:39:43 engine.py:267] Added request chatcmpl-51aa158fb1f64fdfa17a482a72879abb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:44 metrics.py:449] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 91.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:39:45 logger.py:37] Received request chatcmpl-7bf4a7a8759941189b58abfc243a8d87: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many female performers are doing this show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:45 engine.py:267] Added request chatcmpl-7bf4a7a8759941189b58abfc243a8d87.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:49 logger.py:37] Received request chatcmpl-2a8c4d8bd311458f9f6971d7102e8e91: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What distinguishes the second unicycle from the others?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:49 engine.py:267] Added request chatcmpl-2a8c4d8bd311458f9f6971d7102e8e91.
INFO 12-25 13:39:50 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 133.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:50 logger.py:37] Received request chatcmpl-a78c86476a0d43169e061c0c9fcbb72c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:50 engine.py:267] Added request chatcmpl-a78c86476a0d43169e061c0c9fcbb72c.
INFO 12-25 13:39:51 logger.py:37] Received request chatcmpl-d0bf272f90294e68b0cd9d855d5fbbdf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following materials is not used in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:51 engine.py:267] Added request chatcmpl-d0bf272f90294e68b0cd9d855d5fbbdf.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:53 logger.py:37] Received request chatcmpl-87ee5da62ee44d2ebe2143c1cefc2f31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What would most likely cause Mimi to eat on the floor?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:53 engine.py:267] Added request chatcmpl-87ee5da62ee44d2ebe2143c1cefc2f31.
INFO 12-25 13:39:55 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 130.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:58 logger.py:37] Received request chatcmpl-3109c0973b8d41709639d5c4c8fbb6fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which moment does the sport turn from freestyle motocross into a car race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:58 logger.py:37] Received request chatcmpl-c7dd063a372749b5a567b8d60bef2210: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following ingredients is not used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:58 engine.py:267] Added request chatcmpl-3109c0973b8d41709639d5c4c8fbb6fb.
INFO 12-25 13:39:58 engine.py:267] Added request chatcmpl-c7dd063a372749b5a567b8d60bef2210.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:39:59 logger.py:37] Received request chatcmpl-fc8ec2228f7b432e8ce316f2ddcf58cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What food in the video is worth $750?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:39:59 engine.py:267] Added request chatcmpl-fc8ec2228f7b432e8ce316f2ddcf58cb.
INFO 12-25 13:40:00 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 92.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:40:00 logger.py:37] Received request chatcmpl-cb2078953f2749c898b9670f19045803: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which food prepared by her grandmother does the granddaughter in the video attempt to try?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:00 engine.py:267] Added request chatcmpl-cb2078953f2749c898b9670f19045803.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:04 logger.py:37] Received request chatcmpl-5bb62554fd5e45e69a8a2f0135c8b160: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order do the following events happen? (a) Showcasing the work. (b) Starting from the center. (c) Mastering curves. (d) Navigating small areas and mistakes. (e) Sharing the creations.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:04 engine.py:267] Added request chatcmpl-5bb62554fd5e45e69a8a2f0135c8b160.
INFO 12-25 13:40:05 metrics.py:449] Avg prompt throughput: 35.0 tokens/s, Avg generation throughput: 139.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:07 logger.py:37] Received request chatcmpl-cdba9c991cb543ff96e2070c8783023f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the Chinese restaurant last seen in the clip of the restaurant Burpin\' Burger close its doors?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:07 logger.py:37] Received request chatcmpl-d5dcf8215f354598bd4ea8e3776f11cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many kinds of earrings are made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:07 engine.py:267] Added request chatcmpl-cdba9c991cb543ff96e2070c8783023f.
INFO 12-25 13:40:07 engine.py:267] Added request chatcmpl-d5dcf8215f354598bd4ea8e3776f11cd.
INFO 12-25 13:40:07 logger.py:37] Received request chatcmpl-12218105c8104766995ff2582bee46c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Of the following foods, what does the protagonist in the video prefer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:07 engine.py:267] Added request chatcmpl-12218105c8104766995ff2582bee46c6.
INFO 12-25 13:40:10 metrics.py:449] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 102.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:13 logger.py:37] Received request chatcmpl-84ea4ccc74d3487c873391a08936ff4c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What food do the people in the video end up eating?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:13 logger.py:37] Received request chatcmpl-5791e074404e4f8c917d17da46957a65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:13 engine.py:267] Added request chatcmpl-84ea4ccc74d3487c873391a08936ff4c.
INFO 12-25 13:40:13 engine.py:267] Added request chatcmpl-5791e074404e4f8c917d17da46957a65.
INFO 12-25 13:40:15 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 100.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:40:15 logger.py:37] Received request chatcmpl-d381c7166eae4383bbbea30c365e5ac6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of food does the main character in the video make successively?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:15 engine.py:267] Added request chatcmpl-d381c7166eae4383bbbea30c365e5ac6.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:16 logger.py:37] Received request chatcmpl-746793fa1dc3445aa8e3577011252f5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the finished handcraft look like?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:16 engine.py:267] Added request chatcmpl-746793fa1dc3445aa8e3577011252f5e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:19 logger.py:37] Received request chatcmpl-8a5e4cc149a141f89a820b01c6b4ec0a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many new McDonald\'s have opened in France from 2018-2023 in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:19 engine.py:267] Added request chatcmpl-8a5e4cc149a141f89a820b01c6b4ec0a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:20 metrics.py:449] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 130.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:21 logger.py:37] Received request chatcmpl-697045bb57134810ae0fb2a4370ac7ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the third restaurant featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:21 engine.py:267] Added request chatcmpl-697045bb57134810ae0fb2a4370ac7ae.
INFO 12-25 13:40:21 logger.py:37] Received request chatcmpl-166586beb8a047e497437c8d5a7ed01f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following food in the video is cheapest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:22 engine.py:267] Added request chatcmpl-166586beb8a047e497437c8d5a7ed01f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:23 logger.py:37] Received request chatcmpl-c2c4fd8c3df948d58cda0ce40a44346b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus or main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:23 engine.py:267] Added request chatcmpl-c2c4fd8c3df948d58cda0ce40a44346b.
INFO 12-25 13:40:25 metrics.py:449] Avg prompt throughput: 37.8 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:28 logger.py:37] Received request chatcmpl-d1118c60ab874e7185d23457982efef1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which cat in the video took the salmon directly from the plate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:28 engine.py:267] Added request chatcmpl-d1118c60ab874e7185d23457982efef1.
INFO 12-25 13:40:29 logger.py:37] Received request chatcmpl-3013228306094e93be86c3c88197664d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the third baked food in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:29 engine.py:267] Added request chatcmpl-3013228306094e93be86c3c88197664d.
INFO 12-25 13:40:30 logger.py:37] Received request chatcmpl-e0ae52c476cc400d860bfb2f8181d088: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, in which order are the following tools used? (a) Cotton swabs. (b) Brush. (c) Iron scrubber. (d) Card.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:30 engine.py:267] Added request chatcmpl-e0ae52c476cc400d860bfb2f8181d088.
INFO 12-25 13:40:30 metrics.py:449] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 108.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:31 logger.py:37] Received request chatcmpl-39acb9202a3c434a8170d510acf24be3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The ad in the video is inserted while the main character is eating what?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:31 engine.py:267] Added request chatcmpl-39acb9202a3c434a8170d510acf24be3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:35 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 139.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:36 logger.py:37] Received request chatcmpl-95a439786a914868b7c75f1a97cbd4fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When is the food made in the video eaten?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:36 logger.py:37] Received request chatcmpl-8b9e2bec37b0422aa949d98e9bac15b6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why are people in the video buying food at the dollar store?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:36 engine.py:267] Added request chatcmpl-95a439786a914868b7c75f1a97cbd4fe.
INFO 12-25 13:40:36 engine.py:267] Added request chatcmpl-8b9e2bec37b0422aa949d98e9bac15b6.
INFO 12-25 13:40:37 logger.py:37] Received request chatcmpl-01f736f8f6f143189018d4683e90cc60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item is not in the makeup bag?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:37 engine.py:267] Added request chatcmpl-01f736f8f6f143189018d4683e90cc60.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:40 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 107.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:40 logger.py:37] Received request chatcmpl-16cf8bbf98e74ea5b6edc7de89294d31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is NOT one of the purposes of red threads?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:40 engine.py:267] Added request chatcmpl-16cf8bbf98e74ea5b6edc7de89294d31.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:42 logger.py:37] Received request chatcmpl-48cf99a60b0346a8b42b904f5eef7726: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first food the main character in the video tried?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:42 engine.py:267] Added request chatcmpl-48cf99a60b0346a8b42b904f5eef7726.
INFO 12-25 13:40:43 logger.py:37] Received request chatcmpl-3a2c11e7815b425aa1771b2d67781c72: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What character is the woman with white hair in the video most likely to be?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:43 engine.py:267] Added request chatcmpl-3a2c11e7815b425aa1771b2d67781c72.
INFO 12-25 13:40:43 logger.py:37] Received request chatcmpl-a03d0ada61784a6da937e3437b28fd0a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which section of the video shows customers uploading videos of themselves making or tasting food on video media?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:43 engine.py:267] Added request chatcmpl-a03d0ada61784a6da937e3437b28fd0a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:45 metrics.py:449] Avg prompt throughput: 54.2 tokens/s, Avg generation throughput: 92.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:40:45 logger.py:37] Received request chatcmpl-63fb475a2f7d44c5b2269330e02467d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the specific text displayed on the neon signs?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:45 engine.py:267] Added request chatcmpl-63fb475a2f7d44c5b2269330e02467d4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:49 logger.py:37] Received request chatcmpl-b4da2a7e94984fef8313c53a44476b91: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people in the video eat insects?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:49 engine.py:267] Added request chatcmpl-b4da2a7e94984fef8313c53a44476b91.
INFO 12-25 13:40:50 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 140.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:52 logger.py:37] Received request chatcmpl-ea165994f85747778918d8a0377de004: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the sequential order in which the following types of jewelry are made? (a) Fairy Wing Earrings. (b) Pastel Necklace. (c) Pearl Earrings. (d) Tiered Necklace.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:52 engine.py:267] Added request chatcmpl-ea165994f85747778918d8a0377de004.
INFO 12-25 13:40:53 logger.py:37] Received request chatcmpl-94355e352d724a36a7bd8cd67a0706d3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the characters appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:53 engine.py:267] Added request chatcmpl-94355e352d724a36a7bd8cd67a0706d3.
INFO 12-25 13:40:53 logger.py:37] Received request chatcmpl-0407689490394c37bb0bf7fd4212e37b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What treat did the little hamster savor at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:53 engine.py:267] Added request chatcmpl-0407689490394c37bb0bf7fd4212e37b.
INFO 12-25 13:40:55 metrics.py:449] Avg prompt throughput: 46.7 tokens/s, Avg generation throughput: 104.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:40:57 logger.py:37] Received request chatcmpl-a2087f9ba90b47229032baf11dd0abab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which dish in the video is made mainly of pork?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:57 engine.py:267] Added request chatcmpl-a2087f9ba90b47229032baf11dd0abab.
INFO 12-25 13:40:58 logger.py:37] Received request chatcmpl-fd18c5ad1ad54e77955b4cad7d091ef7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which city did the video take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:40:58 engine.py:267] Added request chatcmpl-fd18c5ad1ad54e77955b4cad7d091ef7.
INFO 12-25 13:41:00 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 129.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:03 logger.py:37] Received request chatcmpl-98f2de762440400a873ca185a6720d74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many stars can be extracted from one CD?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:03 engine.py:267] Added request chatcmpl-98f2de762440400a873ca185a6720d74.
INFO 12-25 13:41:03 logger.py:37] Received request chatcmpl-83cc0c4b074841b6aad96f1e319eeb49: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When the woman in the video introduces Scrunch socks, which two other pieces of clothing she recommends are mixed in the little video she\'s talking about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:03 engine.py:267] Added request chatcmpl-83cc0c4b074841b6aad96f1e319eeb49.
INFO 12-25 13:41:05 metrics.py:449] Avg prompt throughput: 28.8 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:07 logger.py:37] Received request chatcmpl-3add6207b4f74a75a2058c3f6547d5db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Extrapolating from the video, what does the brand OSMO in the video sell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:07 engine.py:267] Added request chatcmpl-3add6207b4f74a75a2058c3f6547d5db.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:09 logger.py:37] Received request chatcmpl-7f369c8d165340a1898155c32d69ff7d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main story of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:09 engine.py:267] Added request chatcmpl-7f369c8d165340a1898155c32d69ff7d.
INFO 12-25 13:41:10 metrics.py:449] Avg prompt throughput: 26.6 tokens/s, Avg generation throughput: 126.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:41:10 logger.py:37] Received request chatcmpl-915b9ceeb1374f54a0fc121a2e922123: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Cavalli do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:10 engine.py:267] Added request chatcmpl-915b9ceeb1374f54a0fc121a2e922123.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:13 logger.py:37] Received request chatcmpl-546b0fa73bcf4a95a308134ae336ec1a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which year did the main character in the video win his second Emmy?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:13 engine.py:267] Added request chatcmpl-546b0fa73bcf4a95a308134ae336ec1a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:14 logger.py:37] Received request chatcmpl-c4b44c0d91ad4361a002040a8c396f00: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly orders the items according to their order in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:14 engine.py:267] Added request chatcmpl-c4b44c0d91ad4361a002040a8c396f00.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:15 metrics.py:449] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 103.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:41:15 logger.py:37] Received request chatcmpl-e66daf7510b842e0816a33b7b74655ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video depict?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:15 engine.py:267] Added request chatcmpl-e66daf7510b842e0816a33b7b74655ed.
INFO 12-25 13:41:16 logger.py:37] Received request chatcmpl-697e74717a7c4be583888d2e5d16ef35: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cats in the video like mackerel the best?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:16 engine.py:267] Added request chatcmpl-697e74717a7c4be583888d2e5d16ef35.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:20 logger.py:37] Received request chatcmpl-61f431b518b04f58b2bfff2b40c87e81: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What outfit was Cardi B wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:20 engine.py:267] Added request chatcmpl-61f431b518b04f58b2bfff2b40c87e81.
INFO 12-25 13:41:20 metrics.py:449] Avg prompt throughput: 36.4 tokens/s, Avg generation throughput: 128.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:23 logger.py:37] Received request chatcmpl-017ee841c38c44e9b84b63db467ed3ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the model walking behind the one in a casual suit characterized by a rich print in vibrant shades of pink and white wearing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:23 engine.py:267] Added request chatcmpl-017ee841c38c44e9b84b63db467ed3ff.
INFO 12-25 13:41:24 logger.py:37] Received request chatcmpl-01a73bb8a12442df813944de247c0f9a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many days a week does the actress in the video wear sunglasses?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:24 engine.py:267] Added request chatcmpl-01a73bb8a12442df813944de247c0f9a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:25 metrics.py:449] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 130.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:26 logger.py:37] Received request chatcmpl-d2deb57f102d43edad61ab462d4dc422: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When making Chickpea frittata, what condiments are added to give it an egg-like smell and taste?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:26 engine.py:267] Added request chatcmpl-d2deb57f102d43edad61ab462d4dc422.
INFO 12-25 13:41:27 logger.py:37] Received request chatcmpl-e50568b30475454aa5d5ea857845c873: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which music artist does Lil Tjay mention enjoying in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:27 engine.py:267] Added request chatcmpl-e50568b30475454aa5d5ea857845c873.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:30 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 136.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:32 logger.py:37] Received request chatcmpl-ed44dd39f95142698d9337efd53fdd4a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Inferring from the video, why does the man in the video choose the latter between caviar and roasted butter beans?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:32 engine.py:267] Added request chatcmpl-ed44dd39f95142698d9337efd53fdd4a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:33 logger.py:37] Received request chatcmpl-aabafd5ed3c84f699454183c0cb5a7d1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How old is the woman in the video in 2019?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:33 engine.py:267] Added request chatcmpl-aabafd5ed3c84f699454183c0cb5a7d1.
INFO 12-25 13:41:34 logger.py:37] Received request chatcmpl-32f24f0036e4405eaa49d42be61683da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main subject matter of the advertisement featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:34 logger.py:37] Received request chatcmpl-52e06361e53f4410b0609d1d84212a4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When the motorcycle in the video leaves, how many people come out of the door?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:34 engine.py:267] Added request chatcmpl-32f24f0036e4405eaa49d42be61683da.
INFO 12-25 13:41:34 engine.py:267] Added request chatcmpl-52e06361e53f4410b0609d1d84212a4e.
INFO 12-25 13:41:35 metrics.py:449] Avg prompt throughput: 55.7 tokens/s, Avg generation throughput: 87.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 147.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:41:41 logger.py:37] Received request chatcmpl-9ef7a614fbd44bd39104724c9e17264e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the three people in the video most likely discussing as they eat their greens?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:41 logger.py:37] Received request chatcmpl-a316e88d705446ad9062b027ff27f5cf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the woman in the video recommend wearing while running?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:41 engine.py:267] Added request chatcmpl-9ef7a614fbd44bd39104724c9e17264e.
INFO 12-25 13:41:41 engine.py:267] Added request chatcmpl-a316e88d705446ad9062b027ff27f5cf.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:42 logger.py:37] Received request chatcmpl-ecf3fc3471b5475eaf6acc7817e9b842: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the student doing while the athlete is competing in the indoor stadium in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:42 engine.py:267] Added request chatcmpl-ecf3fc3471b5475eaf6acc7817e9b842.
INFO 12-25 13:41:44 logger.py:37] Received request chatcmpl-3c8db0a0810c4696be52c525758362ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which Glambot did Cole Walliser almost miss capturing due to an unexpected eyeroll and movement from the celebrity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:44 engine.py:267] Added request chatcmpl-3c8db0a0810c4696be52c525758362ae.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:45 metrics.py:449] Avg prompt throughput: 55.6 tokens/s, Avg generation throughput: 118.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:41:46 logger.py:37] Received request chatcmpl-cf642fb60ce0472792ee8b8761909bb0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What makes Thursday\'s outfit different from the rest of the year?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:46 engine.py:267] Added request chatcmpl-cf642fb60ce0472792ee8b8761909bb0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:50 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 127.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:51 logger.py:37] Received request chatcmpl-cd4172cd17c34f00bc31463678bbc9d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When making the first dish in the video, what is the second food that is plated?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:51 engine.py:267] Added request chatcmpl-cd4172cd17c34f00bc31463678bbc9d2.
INFO 12-25 13:41:51 logger.py:37] Received request chatcmpl-2e96a2565d5c47d191d7d51a2134632c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At what time does the protagonist in the video typically visit the gym for their workout?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:51 engine.py:267] Added request chatcmpl-2e96a2565d5c47d191d7d51a2134632c.
INFO 12-25 13:41:52 logger.py:37] Received request chatcmpl-6ae4bdbb9afc42c6b24cb14cffe13f68: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the person\'s action in number nine GlamBOT in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:52 engine.py:267] Added request chatcmpl-6ae4bdbb9afc42c6b24cb14cffe13f68.
INFO 12-25 13:41:52 logger.py:37] Received request chatcmpl-b97ccfa22e044448985a5b635aeda71a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video highlights different stages of the design and manufacturing process at Herms. Which sequence best reflects the order of these stages as presented?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:52 engine.py:267] Added request chatcmpl-b97ccfa22e044448985a5b635aeda71a.
INFO 12-25 13:41:55 metrics.py:449] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:41:57 logger.py:37] Received request chatcmpl-9cf28766611c438fb6581837f945a81e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video mentions that about 100 SUBWAYS have been closed in France, what is the most likely reason?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:57 engine.py:267] Added request chatcmpl-9cf28766611c438fb6581837f945a81e.
INFO 12-25 13:41:58 logger.py:37] Received request chatcmpl-70eac85b89fc43cfb1b735f528e36cfa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When expectation having finished brushing teeth and getting dressed, what is the male protagonist doing in reality?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:58 engine.py:267] Added request chatcmpl-70eac85b89fc43cfb1b735f528e36cfa.
INFO 12-25 13:41:58 logger.py:37] Received request chatcmpl-ee543ac0002d4de0998eae5ce703979e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly orders the items according to their order in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:41:58 engine.py:267] Added request chatcmpl-ee543ac0002d4de0998eae5ce703979e.
INFO 12-25 13:42:00 metrics.py:449] Avg prompt throughput: 43.0 tokens/s, Avg generation throughput: 110.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:02 logger.py:37] Received request chatcmpl-44716a19ea8a4094b43b4c152348ff78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first thing the heroine does after the exam in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:02 engine.py:267] Added request chatcmpl-44716a19ea8a4094b43b4c152348ff78.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:05 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 137.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:42:05 logger.py:37] Received request chatcmpl-2e477c7f7a1f40ef9d03cb7c656af13e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the makeup bag in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:05 engine.py:267] Added request chatcmpl-2e477c7f7a1f40ef9d03cb7c656af13e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:07 logger.py:37] Received request chatcmpl-3586172126714bfd88b7cd9badc78289: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options has the correct sequence of events sort of appearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:07 engine.py:267] Added request chatcmpl-3586172126714bfd88b7cd9badc78289.
INFO 12-25 13:42:08 logger.py:37] Received request chatcmpl-6d486143735245609894801f80344711: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Priscilla Alexandra Spring mentions the importance of both "love at first sight" and longevity when purchasing a Herms bag. What aspect of the video best showcases the brand\'s focus on longevity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:08 logger.py:37] Received request chatcmpl-1782aced7cc54356ab0cafc66f12b6f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the hero in the video go to with his roommate when he gets home?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:08 engine.py:267] Added request chatcmpl-6d486143735245609894801f80344711.
INFO 12-25 13:42:08 engine.py:267] Added request chatcmpl-1782aced7cc54356ab0cafc66f12b6f3.
INFO 12-25 13:42:10 metrics.py:449] Avg prompt throughput: 58.3 tokens/s, Avg generation throughput: 102.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:13 logger.py:37] Received request chatcmpl-ab5dc68001b440ce88baf39f12e7f081: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main job of the hero in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:13 engine.py:267] Added request chatcmpl-ab5dc68001b440ce88baf39f12e7f081.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:15 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:16 logger.py:37] Received request chatcmpl-65a08bd2d7f44b17b1dd2552a9e140c5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what did the male protagonist do after giving the presentation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:16 engine.py:267] Added request chatcmpl-65a08bd2d7f44b17b1dd2552a9e140c5.
INFO 12-25 13:42:16 logger.py:37] Received request chatcmpl-f8df407fc9f943a6be61ea16b570ec7a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What pattern does the UAV form at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:16 engine.py:267] Added request chatcmpl-f8df407fc9f943a6be61ea16b570ec7a.
INFO 12-25 13:42:17 logger.py:37] Received request chatcmpl-444dd9f016984a78aee263e0c2ef3810: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When and where did the athlete and student first meet in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:17 engine.py:267] Added request chatcmpl-444dd9f016984a78aee263e0c2ef3810.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:19 logger.py:37] Received request chatcmpl-b251cc211f774123a4613555c955594c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time does the hero in the video get up in real life?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:19 engine.py:267] Added request chatcmpl-b251cc211f774123a4613555c955594c.
INFO 12-25 13:42:20 metrics.py:449] Avg prompt throughput: 52.7 tokens/s, Avg generation throughput: 112.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:21 logger.py:37] Received request chatcmpl-33971a0091c94c67983990538b6f612f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order of the countries involved in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:21 engine.py:267] Added request chatcmpl-33971a0091c94c67983990538b6f612f.
INFO 12-25 13:42:22 logger.py:37] Received request chatcmpl-fea825ecddec44aaa5808b6f8bdd1ebf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the two time periods in the video when the male protagonist is training for swimming?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:22 engine.py:267] Added request chatcmpl-fea825ecddec44aaa5808b6f8bdd1ebf.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:25 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:25 logger.py:37] Received request chatcmpl-900d80ebc9cc4906a1771a3cd7eaffc8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the hero and the other football players do before entering the stadium locker room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:25 engine.py:267] Added request chatcmpl-900d80ebc9cc4906a1771a3cd7eaffc8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:27 logger.py:37] Received request chatcmpl-9ff3bdfc0a3949da91659c0a3fb67b60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which area of the video does the male protagonist stay in for the longest time in the afternoon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:27 engine.py:267] Added request chatcmpl-9ff3bdfc0a3949da91659c0a3fb67b60.
INFO 12-25 13:42:28 logger.py:37] Received request chatcmpl-967994723861494980ec7991970a1615: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time does the male protagonist in the video go out to relax?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:28 engine.py:267] Added request chatcmpl-967994723861494980ec7991970a1615.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:30 logger.py:37] Received request chatcmpl-e8c5075fd29e43b5b9c7ddc454cca41a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct sequence of different products appearing in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:30 engine.py:267] Added request chatcmpl-e8c5075fd29e43b5b9c7ddc454cca41a.
INFO 12-25 13:42:30 metrics.py:449] Avg prompt throughput: 54.1 tokens/s, Avg generation throughput: 99.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:42:31 logger.py:37] Received request chatcmpl-c11ea56ccbe241f5b46706c65976ba33: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order do the following events appear in the video? Participation in online meeting Searching with Google Go to the rooftop to eat". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:31 engine.py:267] Added request chatcmpl-c11ea56ccbe241f5b46706c65976ba33.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:34 logger.py:37] Received request chatcmpl-41f33f29d1e74e16896e246363f9ad80: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does underwater photography appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:34 engine.py:267] Added request chatcmpl-41f33f29d1e74e16896e246363f9ad80.
INFO 12-25 13:42:35 metrics.py:449] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 138.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:37 logger.py:37] Received request chatcmpl-ca6fbb45573749c2a6a2a3af74bcf9e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the high table placed at the back of the classroom in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:37 engine.py:267] Added request chatcmpl-ca6fbb45573749c2a6a2a3af74bcf9e9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:39 logger.py:37] Received request chatcmpl-5a61f2ba65594cb38701b7c8b0752de6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On which day is the actress in the video best dressed for sports?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:39 engine.py:267] Added request chatcmpl-5a61f2ba65594cb38701b7c8b0752de6.
INFO 12-25 13:42:40 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 134.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:44 logger.py:37] Received request chatcmpl-886248ffaaca46beab6ecd9d23c178fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is the correct ordering of events for the male lead?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:44 engine.py:267] Added request chatcmpl-886248ffaaca46beab6ecd9d23c178fe.
INFO 12-25 13:42:44 logger.py:37] Received request chatcmpl-87c4a55cbca747c0a889847915cbe6fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what mode of transportation does the protagonist use to commute to school?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:44 engine.py:267] Added request chatcmpl-87c4a55cbca747c0a889847915cbe6fa.
INFO 12-25 13:42:44 logger.py:37] Received request chatcmpl-aff444a71b8a4d6eb6701b9d4b774629: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where did the author of the video learn that "people can adapt and find happiness"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:44 engine.py:267] Added request chatcmpl-aff444a71b8a4d6eb6701b9d4b774629.
INFO 12-25 13:42:45 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 101.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 133.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:52 logger.py:37] Received request chatcmpl-50587b0afe8e4f4aa4c144a89d1ff272: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct chronological order in which the following looks appeared?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:52 engine.py:267] Added request chatcmpl-50587b0afe8e4f4aa4c144a89d1ff272.
INFO 12-25 13:42:52 logger.py:37] Received request chatcmpl-98d225f988864010975d2694a130d691: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the male protagonist do during the time period between returning to the dormitory after studying outside at night and going out to study again?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:52 logger.py:37] Received request chatcmpl-3dafc9ffd3ef4a51ae47e272dee35b0b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the protagonist in the video think is the worst decision ever?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:52 engine.py:267] Added request chatcmpl-98d225f988864010975d2694a130d691.
INFO 12-25 13:42:52 engine.py:267] Added request chatcmpl-3dafc9ffd3ef4a51ae47e272dee35b0b.
INFO 12-25 13:42:53 logger.py:37] Received request chatcmpl-111c6f4520774ac0b3642636ca38b53c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which food was absent from the hero\'s last meal in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:53 engine.py:267] Added request chatcmpl-111c6f4520774ac0b3642636ca38b53c.
INFO 12-25 13:42:55 metrics.py:449] Avg prompt throughput: 55.2 tokens/s, Avg generation throughput: 96.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:42:58 logger.py:37] Received request chatcmpl-ed4d3771279747c4b5a8933785244e18: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What mode of transport do the people in the video take to get to Horseshoe Bay?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:42:58 engine.py:267] Added request chatcmpl-ed4d3771279747c4b5a8933785244e18.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:00 metrics.py:449] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 95.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:00 logger.py:37] Received request chatcmpl-6250079bb7a34d17aaab78c4b12b08da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When did the boy finally return home ready to rest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:00 logger.py:37] Received request chatcmpl-07c33e8951754edda9f082932d6a2348: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the direction of the person in the video relative to the camera when sliding with the rope?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:00 engine.py:267] Added request chatcmpl-6250079bb7a34d17aaab78c4b12b08da.
INFO 12-25 13:43:00 engine.py:267] Added request chatcmpl-07c33e8951754edda9f082932d6a2348.
INFO 12-25 13:43:01 logger.py:37] Received request chatcmpl-b469b1643d5f438a8a15de2841d4f69a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What brand is the wallet in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:01 engine.py:267] Added request chatcmpl-b469b1643d5f438a8a15de2841d4f69a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:05 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 149.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:07 logger.py:37] Received request chatcmpl-6a9fc1f628fa4e5298585a008afc1f5a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly sorts the sequence of events in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:07 engine.py:267] Added request chatcmpl-6a9fc1f628fa4e5298585a008afc1f5a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:08 logger.py:37] Received request chatcmpl-61f7f10969204e2f943ba2ec6d212770: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the main character at the beginning of the video when she talks to the camera?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:08 engine.py:267] Added request chatcmpl-61f7f10969204e2f943ba2ec6d212770.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:09 logger.py:37] Received request chatcmpl-45f5060d921541319d687aebc897e6c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video emphasizes the importance of craftsmanship and hand-made techniques at Herms. Which statement best reflects the brand\'s dedication to craftsmanship?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:09 engine.py:267] Added request chatcmpl-45f5060d921541319d687aebc897e6c9.
INFO 12-25 13:43:10 metrics.py:449] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 93.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:10 logger.py:37] Received request chatcmpl-8703f981e6854635b04522375fb6b13d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the author of the video feel the need to "appreciate your own nation"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:10 engine.py:267] Added request chatcmpl-8703f981e6854635b04522375fb6b13d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:15 logger.py:37] Received request chatcmpl-354c1a1f695449659cbc7d4ce7e1a443: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the activities appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:15 logger.py:37] Received request chatcmpl-7f8893c95c9e4bb79fb345d9e58a2b33: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main reason for Amtrak\'s failure as shown by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:15 engine.py:267] Added request chatcmpl-354c1a1f695449659cbc7d4ce7e1a443.
INFO 12-25 13:43:15 engine.py:267] Added request chatcmpl-7f8893c95c9e4bb79fb345d9e58a2b33.
INFO 12-25 13:43:15 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:16 logger.py:37] Received request chatcmpl-2410507f5cd44909a1aa9a110a49d903: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order do the following events appear in the video? Receiving a parcel Making bibimbap Cleaning the floor". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:16 engine.py:267] Added request chatcmpl-2410507f5cd44909a1aa9a110a49d903.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:18 logger.py:37] Received request chatcmpl-dd01b6b1d1f84aa9abdb92a7b56fd1b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the main character cry at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:18 engine.py:267] Added request chatcmpl-dd01b6b1d1f84aa9abdb92a7b56fd1b9.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:20 metrics.py:449] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 134.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:21 logger.py:37] Received request chatcmpl-d0bfb6b76e934a459b8fd8238c12ab9c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the main character arrive at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:21 engine.py:267] Added request chatcmpl-d0bfb6b76e934a459b8fd8238c12ab9c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:23 logger.py:37] Received request chatcmpl-9934f477e66d46bb808676990ba3b2e7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first thing the hero does after breakfast in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:23 engine.py:267] Added request chatcmpl-9934f477e66d46bb808676990ba3b2e7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:25 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 118.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:26 logger.py:37] Received request chatcmpl-18c8ee70c1564680b3d143c48c3dbd97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the author feel betrayed at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:26 engine.py:267] Added request chatcmpl-18c8ee70c1564680b3d143c48c3dbd97.
INFO 12-25 13:43:26 logger.py:37] Received request chatcmpl-c2f24d078188492a987846c8547f1eab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the man and woman in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:26 engine.py:267] Added request chatcmpl-c2f24d078188492a987846c8547f1eab.
INFO 12-25 13:43:27 logger.py:37] Received request chatcmpl-7cd7a6ebac7d4d97ade34dbcc3e23459: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What actions does the red-black parrot perform in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:27 engine.py:267] Added request chatcmpl-7cd7a6ebac7d4d97ade34dbcc3e23459.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:29 logger.py:37] Received request chatcmpl-6764de63ad174e848b44acdba7285f90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the hero in the video work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:29 engine.py:267] Added request chatcmpl-6764de63ad174e848b44acdba7285f90.
INFO 12-25 13:43:30 metrics.py:449] Avg prompt throughput: 51.0 tokens/s, Avg generation throughput: 115.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:32 logger.py:37] Received request chatcmpl-4c8dc6b6cc4d44b2a5f07070a97fa351: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reaction of the dog when a person walks towards a black-white dog holding a broken black slipper?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:32 logger.py:37] Received request chatcmpl-b9dd2b052bbc493895a3948fdaabcad8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What animals did the main character not see on the trip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:33 engine.py:267] Added request chatcmpl-4c8dc6b6cc4d44b2a5f07070a97fa351.
INFO 12-25 13:43:33 engine.py:267] Added request chatcmpl-b9dd2b052bbc493895a3948fdaabcad8.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:35 logger.py:37] Received request chatcmpl-b978ab922e034ebcac4aa7e34458f22e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the underlying reason why the main character in the video takes off his shoes when he gets into the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:35 engine.py:267] Added request chatcmpl-b978ab922e034ebcac4aa7e34458f22e.
INFO 12-25 13:43:35 metrics.py:449] Avg prompt throughput: 42.8 tokens/s, Avg generation throughput: 111.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:37 logger.py:37] Received request chatcmpl-3ad75496723644db9fe8ff8ee142264f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the male protagonist in the video not do in reality?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:37 engine.py:267] Added request chatcmpl-3ad75496723644db9fe8ff8ee142264f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:38 logger.py:37] Received request chatcmpl-947d7a50407f4b5385025cae49379a66: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After telling the story about the railroad, where does the main character in the video reach?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:38 engine.py:267] Added request chatcmpl-947d7a50407f4b5385025cae49379a66.
INFO 12-25 13:43:40 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:42 logger.py:37] Received request chatcmpl-7cf2c2a7337243b08d65f2786238058c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the chronological sequence of the following events depicted in the video? eat breakfast gym workout present in class". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:42 engine.py:267] Added request chatcmpl-7cf2c2a7337243b08d65f2786238058c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:43 logger.py:37] Received request chatcmpl-e00c7a4f9a034bfe969e9380ea48c447: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the dog do when a person walks on the floor in socks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:43 engine.py:267] Added request chatcmpl-e00c7a4f9a034bfe969e9380ea48c447.
INFO 12-25 13:43:44 logger.py:37] Received request chatcmpl-e33372276d4f4e899e09cbbc3bc4c7c4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The man in the video ate pancakes after visiting which attraction?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:44 engine.py:267] Added request chatcmpl-e33372276d4f4e899e09cbbc3bc4c7c4.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:45 metrics.py:449] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 109.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:45 logger.py:37] Received request chatcmpl-0e56949515834d63ade6f3844eb489e6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many attractions are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:45 engine.py:267] Added request chatcmpl-0e56949515834d63ade6f3844eb489e6.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:49 logger.py:37] Received request chatcmpl-b24fbc6a3d1f4e6e9755770871810140: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the yellow dog feel when a girl wants to cut its hair?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:50 engine.py:267] Added request chatcmpl-b24fbc6a3d1f4e6e9755770871810140.
INFO 12-25 13:43:50 metrics.py:449] Avg prompt throughput: 25.5 tokens/s, Avg generation throughput: 131.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:51 logger.py:37] Received request chatcmpl-cfa65f9fafa1405da3ce1e34185e2e8b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly orders the sequence of the boy\'s daily itinerary?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:51 engine.py:267] Added request chatcmpl-cfa65f9fafa1405da3ce1e34185e2e8b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:53 logger.py:37] Received request chatcmpl-0d2ed7afdbc04745aac069ce335102a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the animals featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:53 engine.py:267] Added request chatcmpl-0d2ed7afdbc04745aac069ce335102a3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:55 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:43:56 logger.py:37] Received request chatcmpl-4c8ecf2515a944b6b70474ea9aaeb5cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many dogs are there when a black-white dog emerges from a black and white pillow?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:56 engine.py:267] Added request chatcmpl-4c8ecf2515a944b6b70474ea9aaeb5cd.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:43:58 logger.py:37] Received request chatcmpl-0bc6dbc8e84b48248979cbb0f35ea1cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What activities are recorded sequentially in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:43:58 engine.py:267] Added request chatcmpl-0bc6dbc8e84b48248979cbb0f35ea1cb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:00 logger.py:37] Received request chatcmpl-f112389ae32a4cf1a635b9444aba791f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the man in the video do next after finishing his second swim session?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:00 engine.py:267] Added request chatcmpl-f112389ae32a4cf1a635b9444aba791f.
INFO 12-25 13:44:00 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 126.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:02 logger.py:37] Received request chatcmpl-580822e75e274df4880050ab1dea205a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first animal that appears in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:02 engine.py:267] Added request chatcmpl-580822e75e274df4880050ab1dea205a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:05 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 130.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:06 logger.py:37] Received request chatcmpl-258d23a1c05641a4974048aa587c9911: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which country is recorded by the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:06 engine.py:267] Added request chatcmpl-258d23a1c05641a4974048aa587c9911.
INFO 12-25 13:44:06 logger.py:37] Received request chatcmpl-7b103d81e76e4614a78ac88e76cb7b61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the yellow cat with black spots do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:06 engine.py:267] Added request chatcmpl-7b103d81e76e4614a78ac88e76cb7b61.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:10 metrics.py:449] Avg prompt throughput: 24.9 tokens/s, Avg generation throughput: 142.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:12 logger.py:37] Received request chatcmpl-449d7118558b4c3ab788600174a00984: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the house?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:12 engine.py:267] Added request chatcmpl-449d7118558b4c3ab788600174a00984.
INFO 12-25 13:44:14 logger.py:37] Received request chatcmpl-cab6aab7c5e24fdeb12fb2aafc9f1861: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What the color is the parrot that stands on wood?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:14 logger.py:37] Received request chatcmpl-58e160ac1bdd4c40a39bea928c9cb595: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How far does the main character in the video travel in total?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:14 engine.py:267] Added request chatcmpl-cab6aab7c5e24fdeb12fb2aafc9f1861.
INFO 12-25 13:44:14 engine.py:267] Added request chatcmpl-58e160ac1bdd4c40a39bea928c9cb595.
INFO 12-25 13:44:15 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 105.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:17 logger.py:37] Received request chatcmpl-ee4808b222734689867a802f7d4eea3a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the main character in the video on holiday?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:18 engine.py:267] Added request chatcmpl-ee4808b222734689867a802f7d4eea3a.
INFO 12-25 13:44:18 logger.py:37] Received request chatcmpl-dbfb99219393439cb1dd253660351ec0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the white parrot do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:18 engine.py:267] Added request chatcmpl-dbfb99219393439cb1dd253660351ec0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:20 metrics.py:449] Avg prompt throughput: 25.1 tokens/s, Avg generation throughput: 129.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:21 logger.py:37] Received request chatcmpl-284cbe905b5a4a63b648a4d7f011d4b7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Extrapolating from the video, what is most likely carved on the stone next to the highway?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:21 engine.py:267] Added request chatcmpl-284cbe905b5a4a63b648a4d7f011d4b7.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:23 logger.py:37] Received request chatcmpl-ac50b953dfac4d8888d70dbd4f62d483: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many lessons does the author of the video illustrate that she has learned?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:23 engine.py:267] Added request chatcmpl-ac50b953dfac4d8888d70dbd4f62d483.
INFO 12-25 13:44:24 logger.py:37] Received request chatcmpl-818e922af99643c6b32fc73fa9ee4db7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the first panda do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:24 engine.py:267] Added request chatcmpl-818e922af99643c6b32fc73fa9ee4db7.
INFO 12-25 13:44:25 logger.py:37] Received request chatcmpl-6a333d7d8301478f93997d00b8b16d19: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the polar bear do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:25 engine.py:267] Added request chatcmpl-6a333d7d8301478f93997d00b8b16d19.
INFO 12-25 13:44:25 metrics.py:449] Avg prompt throughput: 52.7 tokens/s, Avg generation throughput: 102.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:29 logger.py:37] Received request chatcmpl-2cb46f857a584dbb86d7ae9b1231a106: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where does the video show them spending the night in the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:29 engine.py:267] Added request chatcmpl-2cb46f857a584dbb86d7ae9b1231a106.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:30 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 123.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:30 logger.py:37] Received request chatcmpl-ed86b087afcb42cc9feb6dfc86d928a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why are Shanghai temples so crowded, as inferred by the main character in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:30 engine.py:267] Added request chatcmpl-ed86b087afcb42cc9feb6dfc86d928a8.
INFO 12-25 13:44:31 logger.py:37] Received request chatcmpl-29e9ac83311a4c62840dab6c5d12c1df: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the black dog hold the goose?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:31 engine.py:267] Added request chatcmpl-29e9ac83311a4c62840dab6c5d12c1df.
INFO 12-25 13:44:32 logger.py:37] Received request chatcmpl-630d047a5e734c8697fd590431ff4af5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the monkey do to the woman?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:32 engine.py:267] Added request chatcmpl-630d047a5e734c8697fd590431ff4af5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:35 metrics.py:449] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 133.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:36 logger.py:37] Received request chatcmpl-a1e37b3e918c421c9c9378d802d27d44: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the dog in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:36 engine.py:267] Added request chatcmpl-a1e37b3e918c421c9c9378d802d27d44.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:39 logger.py:37] Received request chatcmpl-c76bbbc3a2894df681e2220abc892024: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the black-white cat doing in the toilet?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:39 engine.py:267] Added request chatcmpl-c76bbbc3a2894df681e2220abc892024.
INFO 12-25 13:44:40 metrics.py:449] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 100.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:40 logger.py:37] Received request chatcmpl-54da6e29a1a9468aa89b90487420bfa8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many running sessions did the athlete who recorded the shoe change in the video perform in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:40 logger.py:37] Received request chatcmpl-a1547f6926974e8ab91863b6051b94ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does a black elephant do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:40 engine.py:267] Added request chatcmpl-54da6e29a1a9468aa89b90487420bfa8.
INFO 12-25 13:44:40 engine.py:267] Added request chatcmpl-a1547f6926974e8ab91863b6051b94ff.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:43 logger.py:37] Received request chatcmpl-48e45d3991d5454692c252eb4c4e3d3c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, what time is it roughly when the main character faces the camera?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:43 engine.py:267] Added request chatcmpl-48e45d3991d5454692c252eb4c4e3d3c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:45 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:44:46 logger.py:37] Received request chatcmpl-f9b8d089154040fd8e66dcab8ff02191: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the next exercise after the burpee training in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:46 engine.py:267] Added request chatcmpl-f9b8d089154040fd8e66dcab8ff02191.
INFO 12-25 13:44:46 logger.py:37] Received request chatcmpl-17f5ca90fa944d67b8d06fa53a40db5c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many hats does the hamster change in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:46 engine.py:267] Added request chatcmpl-17f5ca90fa944d67b8d06fa53a40db5c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:48 logger.py:37] Received request chatcmpl-5eee0d5d0d9c4a98a3da146c7926bf09: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When does the construction of the highway start, as described by the man in his first viewpoint at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:48 engine.py:267] Added request chatcmpl-5eee0d5d0d9c4a98a3da146c7926bf09.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:50 logger.py:37] Received request chatcmpl-54d5a05090304ad7b55bfe9ea7ed4442: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first stage of the workout, what training did the male protagonist in the video not undergo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:50 engine.py:267] Added request chatcmpl-54d5a05090304ad7b55bfe9ea7ed4442.
INFO 12-25 13:44:50 metrics.py:449] Avg prompt throughput: 55.5 tokens/s, Avg generation throughput: 117.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:51 logger.py:37] Received request chatcmpl-1a576ec1842041ff993f16048068549d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how many times does the male protagonist do hanging leg raises per set in the first phase of training?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:51 engine.py:267] Added request chatcmpl-1a576ec1842041ff993f16048068549d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:52 logger.py:37] Received request chatcmpl-59c9b5c7731648fab75687f6760fada6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many babies does the lion mother have in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:52 engine.py:267] Added request chatcmpl-59c9b5c7731648fab75687f6760fada6.
INFO 12-25 13:44:54 logger.py:37] Received request chatcmpl-288e7916da274b1b8069311582ff1b9f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of chess are the old people in the video playing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:54 engine.py:267] Added request chatcmpl-288e7916da274b1b8069311582ff1b9f.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:55 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 114.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:44:56 logger.py:37] Received request chatcmpl-b39d25bb7414446d8352babe835e6bfb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which exercise did the man in the video do that required him to block his nose?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:56 engine.py:267] Added request chatcmpl-b39d25bb7414446d8352babe835e6bfb.
INFO 12-25 13:44:57 logger.py:37] Received request chatcmpl-51fb86e44331433fac0f4ced3926ca23: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the last move the man makes in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:44:57 engine.py:267] Added request chatcmpl-51fb86e44331433fac0f4ced3926ca23.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:00 metrics.py:449] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 128.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:01 logger.py:37] Received request chatcmpl-d9d61147cf224d218ca7aaeea5a46c70: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the squirrel do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:01 engine.py:267] Added request chatcmpl-d9d61147cf224d218ca7aaeea5a46c70.
INFO 12-25 13:45:02 logger.py:37] Received request chatcmpl-7c71077dd49d4108a7e1027493ea41f0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct ordering of the following tips in the order they are presented in the video? fake cut back double touch meg the lift stop and meg". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:02 engine.py:267] Added request chatcmpl-7c71077dd49d4108a7e1027493ea41f0.
INFO 12-25 13:45:02 logger.py:37] Received request chatcmpl-15ddd5e5bd214a46ba8d683a6bf915e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color are the parrots in the video when three of them appear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:02 engine.py:267] Added request chatcmpl-15ddd5e5bd214a46ba8d683a6bf915e3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:05 logger.py:37] Received request chatcmpl-90fbd5a6cd0a48f884c5fab7df4c1e45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, which track\'s runners reached the finish line first in the second group of races?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:05 engine.py:267] Added request chatcmpl-90fbd5a6cd0a48f884c5fab7df4c1e45.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:05 metrics.py:449] Avg prompt throughput: 58.8 tokens/s, Avg generation throughput: 114.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:07 logger.py:37] Received request chatcmpl-8cbd30e1660444488ef3ab62b255f2b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when a boy picks up a mirror?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:07 engine.py:267] Added request chatcmpl-8cbd30e1660444488ef3ab62b255f2b2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:08 logger.py:37] Received request chatcmpl-26fb46602ac04005952eb075275232d9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player will be eliminated at the end of each lap of the first and second games in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:08 engine.py:267] Added request chatcmpl-26fb46602ac04005952eb075275232d9.
INFO 12-25 13:45:09 logger.py:37] Received request chatcmpl-8d4c630d13f441fe8609be921bd44011: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color does the fish turn when fed a sea urchin by a man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:09 engine.py:267] Added request chatcmpl-8d4c630d13f441fe8609be921bd44011.
INFO 12-25 13:45:10 metrics.py:449] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 119.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:14 logger.py:37] Received request chatcmpl-0c02033e2f164d40ab07611526a13045: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the panda that takes a blue bucket do in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:14 engine.py:267] Added request chatcmpl-0c02033e2f164d40ab07611526a13045.
INFO 12-25 13:45:14 logger.py:37] Received request chatcmpl-ba4aabaec567441898714d0c434b67e7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How long did it take the first runner to reach the finish line in the third race in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:14 engine.py:267] Added request chatcmpl-ba4aabaec567441898714d0c434b67e7.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:15 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 115.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:45:16 logger.py:37] Received request chatcmpl-d903aa64ef7f4c3b8ced6162c01d9e87: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when a baby elephant chases a group of ducks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:16 engine.py:267] Added request chatcmpl-d903aa64ef7f4c3b8ced6162c01d9e87.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:19 logger.py:37] Received request chatcmpl-87807e0bfa0841ffa6f16db355b1bdc6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the highest weight that the boys\' group can successfully bench press in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:19 engine.py:267] Added request chatcmpl-87807e0bfa0841ffa6f16db355b1bdc6.
INFO 12-25 13:45:20 logger.py:37] Received request chatcmpl-130f4d4d58034f1ca1174a1f8cb3c9ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does a black dog do in water?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:20 engine.py:267] Added request chatcmpl-130f4d4d58034f1ca1174a1f8cb3c9ff.
INFO 12-25 13:45:20 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 118.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:23 logger.py:37] Received request chatcmpl-cb2e2cee4ade4ec6855c6388274be557: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many ladies participated in the women\'s bench press competition in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:23 engine.py:267] Added request chatcmpl-cb2e2cee4ade4ec6855c6388274be557.
INFO 12-25 13:45:23 logger.py:37] Received request chatcmpl-b1b61165310b4098ba708758f1122c72: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is between the yellow fox and the white fox?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:23 engine.py:267] Added request chatcmpl-b1b61165310b4098ba708758f1122c72.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:25 metrics.py:449] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:45:26 logger.py:37] Received request chatcmpl-1ae9f3fc1f1c4411869320317d3c2092: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the rules of the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:26 engine.py:267] Added request chatcmpl-1ae9f3fc1f1c4411869320317d3c2092.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:28 logger.py:37] Received request chatcmpl-88cb92aeaac943be949a27079d454a11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the animals in this video do?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:28 engine.py:267] Added request chatcmpl-88cb92aeaac943be949a27079d454a11.
INFO 12-25 13:45:29 logger.py:37] Received request chatcmpl-2a9617402af34cf5960887f0be9770c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which athlete\'s run is being recorded on a mobile phone by the coach wearing a white top and black shorts in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:29 engine.py:267] Added request chatcmpl-2a9617402af34cf5960887f0be9770c2.
INFO 12-25 13:45:30 logger.py:37] Received request chatcmpl-e62d8a588af8471c9db0ded648aa0b5f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what is the order in which high knees, jump lunges, A skips, and kneeling jumps appear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:30 engine.py:267] Added request chatcmpl-e62d8a588af8471c9db0ded648aa0b5f.
INFO 12-25 13:45:30 metrics.py:449] Avg prompt throughput: 55.4 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:32 logger.py:37] Received request chatcmpl-da381407fb4a4939a6b633f1824575cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which planet does the boy spend the most time visiting?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:32 engine.py:267] Added request chatcmpl-da381407fb4a4939a6b633f1824575cb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:35 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 133.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:45:36 logger.py:37] Received request chatcmpl-ac8ef416626e48028f0600696b69866c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many pandas are on the swing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:36 engine.py:267] Added request chatcmpl-ac8ef416626e48028f0600696b69866c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:37 logger.py:37] Received request chatcmpl-8e5a0a71e0e140b8aad0982fc9698d06: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animal is a herbivore mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:37 engine.py:267] Added request chatcmpl-8e5a0a71e0e140b8aad0982fc9698d06.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:38 logger.py:37] Received request chatcmpl-ee7aca4d7b4047b3897c71f875eacd6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order do burpees, jump squats and push-ups appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:38 engine.py:267] Added request chatcmpl-ee7aca4d7b4047b3897c71f875eacd6f.
INFO 12-25 13:45:40 logger.py:37] Received request chatcmpl-299c334d5aee4a599c799530d11a320d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times is the little boy on the right side of the planet when he visited the planet in his rocket?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:40 engine.py:267] Added request chatcmpl-299c334d5aee4a599c799530d11a320d.
INFO 12-25 13:45:40 metrics.py:449] Avg prompt throughput: 53.7 tokens/s, Avg generation throughput: 110.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:43 logger.py:37] Received request chatcmpl-341320a34da5499f813b4aa0aea735b9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the brown horse do to the boy with blue costume?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:43 engine.py:267] Added request chatcmpl-341320a34da5499f813b4aa0aea735b9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:45 logger.py:37] Received request chatcmpl-9ad0830b49944a2797aeb85949458407: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color is the woman\'s phone for personal use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:45 engine.py:267] Added request chatcmpl-9ad0830b49944a2797aeb85949458407.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:45 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 128.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:45:46 logger.py:37] Received request chatcmpl-41cb0cd79bea4b3ea58e08d2e289bc8c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animals detailedly introduced in the video are not extinct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:46 engine.py:267] Added request chatcmpl-41cb0cd79bea4b3ea58e08d2e289bc8c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:50 logger.py:37] Received request chatcmpl-f1e912f0ddd24d08af78bb63f36edffe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second yoga pranayama method demonstrated by the man in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:50 engine.py:267] Added request chatcmpl-f1e912f0ddd24d08af78bb63f36edffe.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:50 metrics.py:449] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 137.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:52 logger.py:37] Received request chatcmpl-8eee1ff2e0a1420ba8f60a43876d438c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the coach wearing a white top and black trousers and a hat at the beginning of the video mainly explain to the athlete wearing a black top and grey and white shorts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:52 engine.py:267] Added request chatcmpl-8eee1ff2e0a1420ba8f60a43876d438c.
INFO 12-25 13:45:53 logger.py:37] Received request chatcmpl-95d2a394fa134d3b9e3feccdfd462c54: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how many finishing cars were on the same team as the winning driver?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:53 engine.py:267] Added request chatcmpl-95d2a394fa134d3b9e3feccdfd462c54.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:55 logger.py:37] Received request chatcmpl-41364a11a3fa4c1fa647dd95cfae24de: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which technique described in the video is done by kicking the ball into the air over a defender?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:55 engine.py:267] Added request chatcmpl-41364a11a3fa4c1fa647dd95cfae24de.
INFO 12-25 13:45:55 metrics.py:449] Avg prompt throughput: 45.4 tokens/s, Avg generation throughput: 110.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:45:56 logger.py:37] Received request chatcmpl-7c39d42901304ef7821c9363535e259c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two male judges share in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:56 engine.py:267] Added request chatcmpl-7c39d42901304ef7821c9363535e259c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:45:59 logger.py:37] Received request chatcmpl-8499180e66354db79252721b86059500: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Imagine you are a videographer tasked with filming a corporate presentation that will involve displaying detailed graphs and charts on a large LED screen. What factors would you consider to minimize the risk of moir during the recording?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:45:59 engine.py:267] Added request chatcmpl-8499180e66354db79252721b86059500.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:00 metrics.py:449] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 117.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:01 logger.py:37] Received request chatcmpl-3e8de1221bfd44ba8c66af6b36844418: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not a sponsor of the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:01 engine.py:267] Added request chatcmpl-3e8de1221bfd44ba8c66af6b36844418.
INFO 12-25 13:46:01 logger.py:37] Received request chatcmpl-a9388d2f5d0c48198c8b7c69a57ed251: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who won the championship in the women\'s competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:02 engine.py:267] Added request chatcmpl-a9388d2f5d0c48198c8b7c69a57ed251.
INFO 12-25 13:46:03 logger.py:37] Received request chatcmpl-a0fdf28332d345a9b7395e0aafd415ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many sets of shadowboxing training were performed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:03 engine.py:267] Added request chatcmpl-a0fdf28332d345a9b7395e0aafd415ea.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:05 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 114.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:05 logger.py:37] Received request chatcmpl-4c4423d485174f8eb36d7af76e3730e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the video demonstrate the concept of "aliasing" in relation to the formation of moir?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:05 engine.py:267] Added request chatcmpl-4c4423d485174f8eb36d7af76e3730e9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:08 logger.py:37] Received request chatcmpl-bab4abd481ac4603b3f7748a8ea37c7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main idea of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:08 engine.py:267] Added request chatcmpl-bab4abd481ac4603b3f7748a8ea37c7c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:09 logger.py:37] Received request chatcmpl-42a18c45779943ff8b188b5ae85d0e25: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What weight did the first girl in the video\'s female group attempt to bench press before failing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:09 engine.py:267] Added request chatcmpl-42a18c45779943ff8b188b5ae85d0e25.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:10 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:11 logger.py:37] Received request chatcmpl-3da29035279243dc8557c9a908dc7a89: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the second super set in the weight training introduced in the video mainly consist of?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:11 engine.py:267] Added request chatcmpl-3da29035279243dc8557c9a908dc7a89.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:15 metrics.py:449] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 146.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:17 logger.py:37] Received request chatcmpl-f89ce754f5bc43a190dceef18f41d4f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly sorts the events of the following heroines in chronological order?  Study  Make the bed  Eat breakfast  Exercise at home". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:17 engine.py:267] Added request chatcmpl-f89ce754f5bc43a190dceef18f41d4f2.
INFO 12-25 13:46:17 logger.py:37] Received request chatcmpl-0c180930497149bea873ea8d98795913: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the animal flying in sky?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:17 engine.py:267] Added request chatcmpl-0c180930497149bea873ea8d98795913.
INFO 12-25 13:46:18 logger.py:37] Received request chatcmpl-2bab4e8397414805a797a4b4c6ccdc69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many of the tricks presented in the video involve drilling the ball through a defender\'s crotch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:18 engine.py:267] Added request chatcmpl-2bab4e8397414805a797a4b4c6ccdc69.
INFO 12-25 13:46:18 logger.py:37] Received request chatcmpl-fb2b25968d6d4927bb3455a42e842ba8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the workout that follows after the tuck jumps workout in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:18 engine.py:267] Added request chatcmpl-fb2b25968d6d4927bb3455a42e842ba8.
INFO 12-25 13:46:20 metrics.py:449] Avg prompt throughput: 58.1 tokens/s, Avg generation throughput: 86.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:23 logger.py:37] Received request chatcmpl-e31c6812cf184304a6916c5584da12b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How to replicate the penalty kick of the person wearing a teddy bear headgear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:23 engine.py:267] Added request chatcmpl-e31c6812cf184304a6916c5584da12b5.
INFO 12-25 13:46:24 logger.py:37] Received request chatcmpl-3db8aaf1556f4afca61adcc68d1237b0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main product introduced by the male protagonist in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:24 engine.py:267] Added request chatcmpl-3db8aaf1556f4afca61adcc68d1237b0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:25 metrics.py:449] Avg prompt throughput: 27.5 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:26 logger.py:37] Received request chatcmpl-38252d9796614362b77efdffec4d37b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time did the heroine in the video turn off her alarm clock?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:26 engine.py:267] Added request chatcmpl-38252d9796614362b77efdffec4d37b2.
INFO 12-25 13:46:27 logger.py:37] Received request chatcmpl-3900f5c7adfd4721b95696b1b2bcbdcd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not the home country of the four women in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:27 engine.py:267] Added request chatcmpl-3900f5c7adfd4721b95696b1b2bcbdcd.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:30 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 132.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:31 logger.py:37] Received request chatcmpl-0f97055793db4dc19fe3c1d042f0917c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was the second contestant eliminated during the final match in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:31 engine.py:267] Added request chatcmpl-0f97055793db4dc19fe3c1d042f0917c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:32 logger.py:37] Received request chatcmpl-a0277b40d05e4de1b78e53c7a909c71f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:32 engine.py:267] Added request chatcmpl-a0277b40d05e4de1b78e53c7a909c71f.
INFO 12-25 13:46:33 logger.py:37] Received request chatcmpl-771f485bfff74249a360d4c1992f48d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What aspect of Italy does Carola Ordenes dislike?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:33 engine.py:267] Added request chatcmpl-771f485bfff74249a360d4c1992f48d8.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:35 logger.py:37] Received request chatcmpl-0f00035c7e27476f9e03a3bb0aef2de0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animals are introduced in sequence in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:35 engine.py:267] Added request chatcmpl-0f00035c7e27476f9e03a3bb0aef2de0.
INFO 12-25 13:46:35 metrics.py:449] Avg prompt throughput: 51.1 tokens/s, Avg generation throughput: 101.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:36 logger.py:37] Received request chatcmpl-cc5dadcca3894722bbab2cb54ac4a630: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options describes the first exercise shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:36 engine.py:267] Added request chatcmpl-cc5dadcca3894722bbab2cb54ac4a630.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:39 logger.py:37] Received request chatcmpl-e1136b78853a46b2b32a36eed16f2692: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the event that put an end to the romanticization of TB in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:39 engine.py:267] Added request chatcmpl-e1136b78853a46b2b32a36eed16f2692.
INFO 12-25 13:46:40 logger.py:37] Received request chatcmpl-aa5fed0b95294d01924ef23edf66783e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:40 engine.py:267] Added request chatcmpl-aa5fed0b95294d01924ef23edf66783e.
INFO 12-25 13:46:40 metrics.py:449] Avg prompt throughput: 40.0 tokens/s, Avg generation throughput: 116.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:40 logger.py:37] Received request chatcmpl-9a7beb3821934f17adc42b4c78f6bd0c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player in the video successfully copied a penalty kick?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:40 engine.py:267] Added request chatcmpl-9a7beb3821934f17adc42b4c78f6bd0c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:45 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 134.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:46 logger.py:37] Received request chatcmpl-a6027ee8a5b347eba27b300a6875a42a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is not correct according to what is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:46 engine.py:267] Added request chatcmpl-a6027ee8a5b347eba27b300a6875a42a.
INFO 12-25 13:46:47 logger.py:37] Received request chatcmpl-0f215493b60d4984be4ab958f4c83444: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which of the following diseases causes the most deaths?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:47 engine.py:267] Added request chatcmpl-0f215493b60d4984be4ab958f4c83444.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:47 logger.py:37] Received request chatcmpl-e6ab6b2b4be9431ab822b3657dd23bc9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most likely role of the woman in yellow in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:47 engine.py:267] Added request chatcmpl-e6ab6b2b4be9431ab822b3657dd23bc9.
INFO 12-25 13:46:49 logger.py:37] Received request chatcmpl-60d95e0224a24b74bcf1a84e014163dc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What decision did the judges reach?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:49 engine.py:267] Added request chatcmpl-60d95e0224a24b74bcf1a84e014163dc.
INFO 12-25 13:46:50 metrics.py:449] Avg prompt throughput: 52.6 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:54 logger.py:37] Received request chatcmpl-215fceaff1aa4f3994ade7a8e71d749d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the performance, what captivating element draws the audience\'s attention?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:54 engine.py:267] Added request chatcmpl-215fceaff1aa4f3994ade7a8e71d749d.
INFO 12-25 13:46:54 logger.py:37] Received request chatcmpl-3bdf53ea1c334e5c8626ed7bedbe06d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the first minute of the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:54 engine.py:267] Added request chatcmpl-3bdf53ea1c334e5c8626ed7bedbe06d4.
INFO 12-25 13:46:55 logger.py:37] Received request chatcmpl-ccff9c18856b496fa7aa59c4651fa733: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what happened when the Gypsies migrated to Europe?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:55 engine.py:267] Added request chatcmpl-ccff9c18856b496fa7aa59c4651fa733.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:46:56 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 106.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:46:57 logger.py:37] Received request chatcmpl-30fae6069bbb462c849b17754594a99b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many items did the woman take out of her bag?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:46:57 engine.py:267] Added request chatcmpl-30fae6069bbb462c849b17754594a99b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:01 metrics.py:449] Avg prompt throughput: 12.7 tokens/s, Avg generation throughput: 129.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:01 logger.py:37] Received request chatcmpl-bd3a29f7ce6648bea7c588902525de57: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the woman\'s favorite drink, and why?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:01 engine.py:267] Added request chatcmpl-bd3a29f7ce6648bea7c588902525de57.
INFO 12-25 13:47:02 logger.py:37] Received request chatcmpl-101439769cf54b4db0b175e9a657b096: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which of the following statements is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:02 engine.py:267] Added request chatcmpl-101439769cf54b4db0b175e9a657b096.
INFO 12-25 13:47:03 logger.py:37] Received request chatcmpl-2e50581dd482485880e205bcd1db2213: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle of the video a shield appears on a mountain in Central Europe, what does this stand for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:03 engine.py:267] Added request chatcmpl-2e50581dd482485880e205bcd1db2213.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:04 logger.py:37] Received request chatcmpl-c51b7b703e2a42a38d7870c664e4a792: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the proposed solution presented in the video to minimize moir during the Taylor Swift concert?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:04 engine.py:267] Added request chatcmpl-c51b7b703e2a42a38d7870c664e4a792.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:06 metrics.py:449] Avg prompt throughput: 55.4 tokens/s, Avg generation throughput: 104.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:07 logger.py:37] Received request chatcmpl-aa81e6b9f40d43ba84f403d391ea3e32: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cars finished the race in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:07 engine.py:267] Added request chatcmpl-aa81e6b9f40d43ba84f403d391ea3e32.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:10 logger.py:37] Received request chatcmpl-a240da49566a44808f7187fbe518cdd3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the usage of the thing that the girl take out from envelop?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:10 engine.py:267] Added request chatcmpl-a240da49566a44808f7187fbe518cdd3.
INFO 12-25 13:47:11 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 116.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:11 logger.py:37] Received request chatcmpl-eb69f6bcfa464d1d8908249e5c3c2b97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, which is the most important element that makes it difficult to dive into Lake Nasser to find the lost fort?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:11 engine.py:267] Added request chatcmpl-eb69f6bcfa464d1d8908249e5c3c2b97.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:12 logger.py:37] Received request chatcmpl-5e8b4be32da442f2a8d721967519e07b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which are the primary themes explored in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:12 engine.py:267] Added request chatcmpl-5e8b4be32da442f2a8d721967519e07b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:15 logger.py:37] Received request chatcmpl-16a0037489e147e5b6a75c38184c3527: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the girl take out from the envelop?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:15 engine.py:267] Added request chatcmpl-16a0037489e147e5b6a75c38184c3527.
INFO 12-25 13:47:15 logger.py:37] Received request chatcmpl-39fb96500770484aa724cd6cedeb3f8b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the best title for this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:15 engine.py:267] Added request chatcmpl-39fb96500770484aa724cd6cedeb3f8b.
INFO 12-25 13:47:16 metrics.py:449] Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 125.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:17 logger.py:37] Received request chatcmpl-eb5f6c06314e4bee8ffd5ab37be2f352: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where may the images in the video mainly come from(except for map)?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:17 engine.py:267] Added request chatcmpl-eb5f6c06314e4bee8ffd5ab37be2f352.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:21 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 122.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:21 logger.py:37] Received request chatcmpl-97c6c30fb84c49f99f0568b7642ec6a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following statements about the Lighthouse of Alexandria is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:21 engine.py:267] Added request chatcmpl-97c6c30fb84c49f99f0568b7642ec6a1.
INFO 12-25 13:47:21 logger.py:37] Received request chatcmpl-11b25b48fed44783bb07be0dac715078: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, in what order does the author present Bernini\'s four masterpieces created for Borghese in a single scene?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:21 engine.py:267] Added request chatcmpl-11b25b48fed44783bb07be0dac715078.
INFO 12-25 13:47:22 logger.py:37] Received request chatcmpl-c02a9d7e5c57496ea4f96378fe4cb3a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is a fact?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:22 engine.py:267] Added request chatcmpl-c02a9d7e5c57496ea4f96378fe4cb3a0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:25 logger.py:37] Received request chatcmpl-93e1fd1d90eb419281fc7df52e9aa887: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which woman works as a chef?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:25 engine.py:267] Added request chatcmpl-93e1fd1d90eb419281fc7df52e9aa887.
INFO 12-25 13:47:26 metrics.py:449] Avg prompt throughput: 54.7 tokens/s, Avg generation throughput: 123.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:28 logger.py:37] Received request chatcmpl-278f30312c474fd89f4e08f206136936: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How much money can you save by purchasing the course through the link and promo code shared by the heroine in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:28 logger.py:37] Received request chatcmpl-68bfeada88c045eb9e5ffde8237639dd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, which of the following statements about the painting "Altropos (the Fates)" is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:28 engine.py:267] Added request chatcmpl-278f30312c474fd89f4e08f206136936.
INFO 12-25 13:47:28 engine.py:267] Added request chatcmpl-68bfeada88c045eb9e5ffde8237639dd.
INFO 12-25 13:47:29 logger.py:37] Received request chatcmpl-c6785334402e4934be908c2c6e74f8e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what happened after the Crusaders conques Antioch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:29 engine.py:267] Added request chatcmpl-c6785334402e4934be908c2c6e74f8e2.
INFO 12-25 13:47:31 metrics.py:449] Avg prompt throughput: 45.6 tokens/s, Avg generation throughput: 110.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:32 logger.py:37] Received request chatcmpl-7dc2a7284a62406b92cf54f1798f64ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the folllowing persons or institudes believes that the first motorized flight was invented by Whitehead?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:32 engine.py:267] Added request chatcmpl-7dc2a7284a62406b92cf54f1798f64ea.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:35 logger.py:37] Received request chatcmpl-d2fecb96d4c74628bbb70556e8a6617d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:35 engine.py:267] Added request chatcmpl-d2fecb96d4c74628bbb70556e8a6617d.
INFO 12-25 13:47:36 metrics.py:449] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 122.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:36 logger.py:37] Received request chatcmpl-a385f60c6b624b96b205b9839a963536: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is not true about the artwork "Apollo and Daphne"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:36 engine.py:267] Added request chatcmpl-a385f60c6b624b96b205b9839a963536.
INFO 12-25 13:47:37 logger.py:37] Received request chatcmpl-48be25e7120e402cb6af98174cde2dea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the standing man in the black shirt doing in the first minute of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:37 engine.py:267] Added request chatcmpl-48be25e7120e402cb6af98174cde2dea.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:40 logger.py:37] Received request chatcmpl-4a6aa40933914ecdbebd720375d311b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which of the following statements about the world\'s longest railway line is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:40 engine.py:267] Added request chatcmpl-4a6aa40933914ecdbebd720375d311b3.
INFO 12-25 13:47:41 metrics.py:449] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 111.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:41 logger.py:37] Received request chatcmpl-2e15022eaec0403e83387d8d5dd0a087: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, which of the following events happened before 1613?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:41 engine.py:267] Added request chatcmpl-2e15022eaec0403e83387d8d5dd0a087.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:46 metrics.py:449] Avg prompt throughput: 14.8 tokens/s, Avg generation throughput: 128.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:46 logger.py:37] Received request chatcmpl-d802c7a08b324f4ebef1776a711807c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following statements about Goya and the historical background is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:46 logger.py:37] Received request chatcmpl-59849ca926724566942966235d4a9cc7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what is not true about the design for local people after the disaster?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:46 engine.py:267] Added request chatcmpl-d802c7a08b324f4ebef1776a711807c2.
INFO 12-25 13:47:46 engine.py:267] Added request chatcmpl-59849ca926724566942966235d4a9cc7.
INFO 12-25 13:47:47 logger.py:37] Received request chatcmpl-a32343e3d0024d708c60a8cdb6047979: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:47 engine.py:267] Added request chatcmpl-a32343e3d0024d708c60a8cdb6047979.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:49 logger.py:37] Received request chatcmpl-67ab004ae73849eb975f44259ec07f4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following statements is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:49 engine.py:267] Added request chatcmpl-67ab004ae73849eb975f44259ec07f4e.
INFO 12-25 13:47:51 metrics.py:449] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:53 logger.py:37] Received request chatcmpl-626b0a197c84473caedce5b968e1bcc4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following things mentioned in the video was not the cause of the split of the country?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:53 engine.py:267] Added request chatcmpl-626b0a197c84473caedce5b968e1bcc4.
INFO 12-25 13:47:54 logger.py:37] Received request chatcmpl-984aecfd996648dc87416d2b4c00d29f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following knowledge and techniques doesn\'t contribute to Mona Lisa\'s mysterious smile?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:54 engine.py:267] Added request chatcmpl-984aecfd996648dc87416d2b4c00d29f.
INFO 12-25 13:47:54 logger.py:37] Received request chatcmpl-27ab1e6f29b84250a8c083298cf0bb50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After introducing Tofu making, what kind of traditional technique or scenic spot did the youtuber introduce according to what is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:54 engine.py:267] Added request chatcmpl-27ab1e6f29b84250a8c083298cf0bb50.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:56 metrics.py:449] Avg prompt throughput: 45.6 tokens/s, Avg generation throughput: 103.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:47:57 logger.py:37] Received request chatcmpl-b0bbe51d14f54c399edb67fb638f37c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main idea of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:57 engine.py:267] Added request chatcmpl-b0bbe51d14f54c399edb67fb638f37c7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:47:58 logger.py:37] Received request chatcmpl-640e5dcb368e4ee7af21150d24c873f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Throughout the video, how many scholars in total show up in the video and comment on Napoleon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:47:58 engine.py:267] Added request chatcmpl-640e5dcb368e4ee7af21150d24c873f8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:01 logger.py:37] Received request chatcmpl-05fa1544226b450ba2762f15a2f6edd9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Paula Scher often do when she sits down at her desk as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:01 engine.py:267] Added request chatcmpl-05fa1544226b450ba2762f15a2f6edd9.
INFO 12-25 13:48:01 metrics.py:449] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 106.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:01 logger.py:37] Received request chatcmpl-a59b9527cf154117a30842b6a3611a74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the expanding red lines on the map in the first few minutes of the video stand for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:01 engine.py:267] Added request chatcmpl-a59b9527cf154117a30842b6a3611a74.
INFO 12-25 13:48:02 logger.py:37] Received request chatcmpl-de1edcd6bd7d4f9c9e02b3da68e25462: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which of the following statements about Napoleon is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:02 engine.py:267] Added request chatcmpl-de1edcd6bd7d4f9c9e02b3da68e25462.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:05 logger.py:37] Received request chatcmpl-211c5c7931844b0a9bed4d608e02cc25: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following statements about the seven wonders of the ancient world is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:05 engine.py:267] Added request chatcmpl-211c5c7931844b0a9bed4d608e02cc25.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:06 metrics.py:449] Avg prompt throughput: 43.1 tokens/s, Avg generation throughput: 126.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:48:07 logger.py:37] Received request chatcmpl-65375ff658794f33b352f08b733c9d2d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "To introduce Kyoto\'s traditional culture, where has the youtuber not been in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:07 engine.py:267] Added request chatcmpl-65375ff658794f33b352f08b733c9d2d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:09 logger.py:37] Received request chatcmpl-c892ffaef68e4ffd856b86765129e130: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the statements is not correct about the the metal ingots in the drained wreck?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:10 engine.py:267] Added request chatcmpl-c892ffaef68e4ffd856b86765129e130.
INFO 12-25 13:48:11 metrics.py:449] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 132.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:12 logger.py:37] Received request chatcmpl-a4719e36a01143b9973e8fd7753117be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what color does a ceramic object look like before it is burned in a furnace?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:12 engine.py:267] Added request chatcmpl-a4719e36a01143b9973e8fd7753117be.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:13 logger.py:37] Received request chatcmpl-8d68a35bde9742efbf1519f6447fb71e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements is correct according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:13 engine.py:267] Added request chatcmpl-8d68a35bde9742efbf1519f6447fb71e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:14 logger.py:37] Received request chatcmpl-6f58f8119c7144c5a96967af6beccb0d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following things can not be found in Ellora Caves?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:14 engine.py:267] Added request chatcmpl-6f58f8119c7144c5a96967af6beccb0d.
INFO 12-25 13:48:15 logger.py:37] Received request chatcmpl-1a2caf4db534444783c9f7e99d11e455: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:15 engine.py:267] Added request chatcmpl-1a2caf4db534444783c9f7e99d11e455.
INFO 12-25 13:48:16 metrics.py:449] Avg prompt throughput: 53.1 tokens/s, Avg generation throughput: 105.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:18 logger.py:37] Received request chatcmpl-a6f263b34ce748238669b3f0560af6fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what does the cocked elbow in Copley\'s work reveal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:18 engine.py:267] Added request chatcmpl-a6f263b34ce748238669b3f0560af6fe.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:21 metrics.py:449] Avg prompt throughput: 14.3 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:48:21 logger.py:37] Received request chatcmpl-513a9b3b14234465858d687f80b5b359: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which of the following events happened after the battle at Standford Bridge?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:21 engine.py:267] Added request chatcmpl-513a9b3b14234465858d687f80b5b359.
INFO 12-25 13:48:22 logger.py:37] Received request chatcmpl-94524774e7dc4004b039dbcfe36c8992: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many colors of glaze are used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:22 logger.py:37] Received request chatcmpl-ff85a0d36366488ba24a5a835ef259e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about William the Conquer is true based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:22 engine.py:267] Added request chatcmpl-94524774e7dc4004b039dbcfe36c8992.
INFO 12-25 13:48:22 engine.py:267] Added request chatcmpl-ff85a0d36366488ba24a5a835ef259e2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:25 logger.py:37] Received request chatcmpl-344126b2fa1b4f0db3723e98fb3a1bcc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video primarily about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:25 engine.py:267] Added request chatcmpl-344126b2fa1b4f0db3723e98fb3a1bcc.
INFO 12-25 13:48:26 metrics.py:449] Avg prompt throughput: 52.8 tokens/s, Avg generation throughput: 117.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:29 logger.py:37] Received request chatcmpl-b4ce68ce8649429989d876b929e97668: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How was his life journey according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:29 engine.py:267] Added request chatcmpl-b4ce68ce8649429989d876b929e97668.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:30 logger.py:37] Received request chatcmpl-492d751ac8f7420d85ffc7f914a422b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, what is not true about the portraits?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:30 logger.py:37] Received request chatcmpl-df6ed2f7bce3479e91314719db04dcc5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is true about Bernini\'s David as described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:30 engine.py:267] Added request chatcmpl-492d751ac8f7420d85ffc7f914a422b5.
INFO 12-25 13:48:30 engine.py:267] Added request chatcmpl-df6ed2f7bce3479e91314719db04dcc5.
INFO 12-25 13:48:31 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 89.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:48:31 logger.py:37] Received request chatcmpl-735599ca1542482fa4802a2bbc25746e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  The concept of the personal fat threshold.  How to grow fat cells.  The relationship between insulin and diet.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:31 engine.py:267] Added request chatcmpl-735599ca1542482fa4802a2bbc25746e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:36 metrics.py:449] Avg prompt throughput: 19.0 tokens/s, Avg generation throughput: 139.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:37 logger.py:37] Received request chatcmpl-95a499f3b69e45a983707aa604ae3030: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is not true about the painting based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:37 engine.py:267] Added request chatcmpl-95a499f3b69e45a983707aa604ae3030.
INFO 12-25 13:48:37 logger.py:37] Received request chatcmpl-a640233adf0e4e7b959a0661a74d88a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main idea of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:37 engine.py:267] Added request chatcmpl-a640233adf0e4e7b959a0661a74d88a9.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:38 logger.py:37] Received request chatcmpl-f9d498d596f445aeaaf492fb4155fd15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What treatment is universally implemented in all the case studies featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:38 engine.py:267] Added request chatcmpl-f9d498d596f445aeaaf492fb4155fd15.
INFO 12-25 13:48:39 logger.py:37] Received request chatcmpl-1fe0606e8ab64a68a9a0146ee63e35e8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What could we do in our daily life to help prevent the disease that the video mainly talks about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:39 engine.py:267] Added request chatcmpl-1fe0606e8ab64a68a9a0146ee63e35e8.
INFO 12-25 13:48:41 metrics.py:449] Avg prompt throughput: 52.7 tokens/s, Avg generation throughput: 103.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:42 logger.py:37] Received request chatcmpl-74302c8accbe4e768ec3b9bbd034eac9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what might be the relationship between the old man in a white shirt and the standing man in a black shirt?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:42 engine.py:267] Added request chatcmpl-74302c8accbe4e768ec3b9bbd034eac9.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:44 logger.py:37] Received request chatcmpl-0dac72676b2145d9be3a725f56b5b93f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which of the following suggestions is not given by the old man?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:44 engine.py:267] Added request chatcmpl-0dac72676b2145d9be3a725f56b5b93f.
INFO 12-25 13:48:45 logger.py:37] Received request chatcmpl-e2436058fa0a41e5a26719dabfc746b0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the focus of standard thyroid treatment according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:45 engine.py:267] Added request chatcmpl-e2436058fa0a41e5a26719dabfc746b0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:46 metrics.py:449] Avg prompt throughput: 43.9 tokens/s, Avg generation throughput: 117.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:48:47 logger.py:37] Received request chatcmpl-e71df8b1f1814d01aa0b37e86c653105: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the speaker\'s presentation in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:47 engine.py:267] Added request chatcmpl-e71df8b1f1814d01aa0b37e86c653105.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:49 logger.py:37] Received request chatcmpl-3c7c31d77dd24e99ae31bd31898b5029: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which of the following features can not describe Paula Scher?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:49 engine.py:267] Added request chatcmpl-3c7c31d77dd24e99ae31bd31898b5029.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:51 metrics.py:449] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 122.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:48:52 logger.py:37] Received request chatcmpl-0132e7053e2f45bdaf89b05d242b65f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is not true about Kyo-yuzen technique based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:52 engine.py:267] Added request chatcmpl-0132e7053e2f45bdaf89b05d242b65f8.
INFO 12-25 13:48:52 logger.py:37] Received request chatcmpl-3fe0e9d07eeb45f69ba87d1018c15595: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  Sleepwalking and the Brain.  How Much Control Do We Have of Our Brain?  Emotions and the Brain.  Creativity and the Brain.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:52 engine.py:267] Added request chatcmpl-3fe0e9d07eeb45f69ba87d1018c15595.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:54 logger.py:37] Received request chatcmpl-9eee96354c084a10a798eb8c3de42a08: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  Insulin Resistance Explained.  Case studies.  How to Reverse Type 2 Diabetes.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:54 engine.py:267] Added request chatcmpl-9eee96354c084a10a798eb8c3de42a08.
INFO 12-25 13:48:56 metrics.py:449] Avg prompt throughput: 52.6 tokens/s, Avg generation throughput: 124.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:48:59 logger.py:37] Received request chatcmpl-203ffefb0bff40c7aae15799a58e3cc3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, why does the author mention Cambodia Angkor Wat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:59 logger.py:37] Received request chatcmpl-a9974b11874e44739d7896868b5f7b0c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which of the following statements about the caves is not correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:48:59 engine.py:267] Added request chatcmpl-203ffefb0bff40c7aae15799a58e3cc3.
INFO 12-25 13:48:59 engine.py:267] Added request chatcmpl-a9974b11874e44739d7896868b5f7b0c.
INFO 12-25 13:49:00 logger.py:37] Received request chatcmpl-df195446891347e2bfdbdba324494dbd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What event is shared by two families as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:00 engine.py:267] Added request chatcmpl-df195446891347e2bfdbdba324494dbd.
INFO 12-25 13:49:01 metrics.py:449] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 102.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:03 logger.py:37] Received request chatcmpl-1238b443411a404399326ce104521eac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What components are the cause of inflammation in the nutritional model developed by the speaker?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:03 engine.py:267] Added request chatcmpl-1238b443411a404399326ce104521eac.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:06 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 112.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:49:06 logger.py:37] Received request chatcmpl-9eee97faf99d474c9378c20d0125b9b0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the verse "The red lacquered gates wine is left to sour meat to rot, outside the gates lie the bones of the frozen and starved" imply according to what is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:06 engine.py:267] Added request chatcmpl-9eee97faf99d474c9378c20d0125b9b0.
INFO 12-25 13:49:07 logger.py:37] Received request chatcmpl-008fa126a02e4dc19323ce7f06320264: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, when did Du Fu write the verse "In the city in spring grass and weeds grow everywhere grieving for the times, even the blossom sheds tears"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:07 engine.py:267] Added request chatcmpl-008fa126a02e4dc19323ce7f06320264.
INFO 12-25 13:49:07 logger.py:37] Received request chatcmpl-ab2a2df5504d44ed8d24728832fb94aa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What central theme is explored in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:07 engine.py:267] Added request chatcmpl-ab2a2df5504d44ed8d24728832fb94aa.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:09 logger.py:37] Received request chatcmpl-e9ff94fd0e4e4cff902719b62e3a2be2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which subject is NOT involved in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:09 engine.py:267] Added request chatcmpl-e9ff94fd0e4e4cff902719b62e3a2be2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:11 metrics.py:449] Avg prompt throughput: 60.5 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:49:12 logger.py:37] Received request chatcmpl-1e9d26b161bb4f0fb3e6ada3e19aee90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times did Joeri appear when explaining the situation in the 1990s as described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:12 engine.py:267] Added request chatcmpl-1e9d26b161bb4f0fb3e6ada3e19aee90.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:15 logger.py:37] Received request chatcmpl-0a0647bd8ea34618a3c49441530543ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what did the blogger do to these ceramic products after they were put into the furnace and burned?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:15 engine.py:267] Added request chatcmpl-0a0647bd8ea34618a3c49441530543ec.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:16 metrics.py:449] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 126.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:49:16 logger.py:37] Received request chatcmpl-8ea68b5dfd7d444e89be7c268c049743: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:16 engine.py:267] Added request chatcmpl-8ea68b5dfd7d444e89be7c268c049743.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:18 logger.py:37] Received request chatcmpl-66b6be2571ea4769b7011ed45c31c9f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following sections most closely relates to the theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:18 engine.py:267] Added request chatcmpl-66b6be2571ea4769b7011ed45c31c9f1.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:19 logger.py:37] Received request chatcmpl-9a324e68762d4b129fa868330cc7a526: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order are the following introduced in the video?  Resilience training program.  The relationship between genetics and stress.  The stress\'s influence on the brain.  What does resilient behavior look like.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:19 engine.py:267] Added request chatcmpl-9a324e68762d4b129fa868330cc7a526.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:21 metrics.py:449] Avg prompt throughput: 45.5 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:49:21 logger.py:37] Received request chatcmpl-ba85ea175c2a4d4c85baf357032f56a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What could be the key to truly combating and even preventing the disease that the video mainly talks about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:21 logger.py:37] Received request chatcmpl-c1b1fcfc1f474da3aaf673862eeef441: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:21 engine.py:267] Added request chatcmpl-ba85ea175c2a4d4c85baf357032f56a1.
INFO 12-25 13:49:21 engine.py:267] Added request chatcmpl-c1b1fcfc1f474da3aaf673862eeef441.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:23 logger.py:37] Received request chatcmpl-79324aa47b3041ccbd2f8b0a4cf605d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does a thorough comprehension of the first method introduced in the video aid in navigating economic downturns?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:23 engine.py:267] Added request chatcmpl-79324aa47b3041ccbd2f8b0a4cf605d2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:26 metrics.py:449] Avg prompt throughput: 40.8 tokens/s, Avg generation throughput: 126.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:27 logger.py:37] Received request chatcmpl-9b41198ad977445483689f11e6454587: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are some of the health issues that can arise from consuming too much sugar according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:27 engine.py:267] Added request chatcmpl-9b41198ad977445483689f11e6454587.
INFO 12-25 13:49:27 logger.py:37] Received request chatcmpl-7f2b32ea8e654476b34560e3c096b57f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which small animal appears most frequently in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:27 engine.py:267] Added request chatcmpl-7f2b32ea8e654476b34560e3c096b57f.
INFO 12-25 13:49:28 logger.py:37] Received request chatcmpl-fb57b0a605b74dfc9cc0ef0df431b17b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What approach does the video suggest is needed to combat the rising numbers of obesity and diabetes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:28 engine.py:267] Added request chatcmpl-fb57b0a605b74dfc9cc0ef0df431b17b.
INFO 12-25 13:49:31 metrics.py:449] Avg prompt throughput: 40.7 tokens/s, Avg generation throughput: 115.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:33 logger.py:37] Received request chatcmpl-ebd46d25c04f457f9570189b4a31676a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a criticism of the current credit scoring system in the US mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:33 engine.py:267] Added request chatcmpl-ebd46d25c04f457f9570189b4a31676a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:34 logger.py:37] Received request chatcmpl-03fc7e15cb7b42d9a7343ea0aca8dd55: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which scientists are mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:34 engine.py:267] Added request chatcmpl-03fc7e15cb7b42d9a7343ea0aca8dd55.
INFO 12-25 13:49:35 logger.py:37] Received request chatcmpl-79993b9718c14f0597bd65707c85aaf2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the speaker\'s opinion on reversing type 2 diabetes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:35 engine.py:267] Added request chatcmpl-79993b9718c14f0597bd65707c85aaf2.
INFO 12-25 13:49:36 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 118.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:38 logger.py:37] Received request chatcmpl-af0f1ae2591249bdb0eec7ba96615213: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did Yen\'s appreciation against the US Dollar after the Plaza Accord impact the Japanese economy in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:38 engine.py:267] Added request chatcmpl-af0f1ae2591249bdb0eec7ba96615213.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:41 logger.py:37] Received request chatcmpl-d9ec4b149add4ee7ba8d5a8942aa9e82: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:41 logger.py:37] Received request chatcmpl-984458fc551f48c0ab0d1c94d6df3148: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the speaker\'s opinion on preventing inflammation and sickness?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:41 engine.py:267] Added request chatcmpl-d9ec4b149add4ee7ba8d5a8942aa9e82.
INFO 12-25 13:49:41 engine.py:267] Added request chatcmpl-984458fc551f48c0ab0d1c94d6df3148.
INFO 12-25 13:49:41 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 118.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:43 logger.py:37] Received request chatcmpl-e30ae006f22644afb1ac1797c3db4ac0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:43 engine.py:267] Added request chatcmpl-e30ae006f22644afb1ac1797c3db4ac0.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:46 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 128.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:49:47 logger.py:37] Received request chatcmpl-8544c92686494175b1eee7b81ef2efae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT one of the primary methods to reach the theme introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:47 logger.py:37] Received request chatcmpl-1b9f455f1cbb4e4d9324a1809f29a7b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video focus on in the "Free?" chapter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:47 logger.py:37] Received request chatcmpl-a2510e840a1e4c3596a8c48c380779fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  How to cure thyroid when you have auto-immune.  Stress influence on the production of TSH.  Standard Thyroid Treatment.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:47 engine.py:267] Added request chatcmpl-8544c92686494175b1eee7b81ef2efae.
INFO 12-25 13:49:47 engine.py:267] Added request chatcmpl-1b9f455f1cbb4e4d9324a1809f29a7b2.
INFO 12-25 13:49:47 engine.py:267] Added request chatcmpl-a2510e840a1e4c3596a8c48c380779fb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:50 logger.py:37] Received request chatcmpl-d402745babd24ecbbd96e1d6c634b631: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the suggested treatment for goiter as mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:50 engine.py:267] Added request chatcmpl-d402745babd24ecbbd96e1d6c634b631.
INFO 12-25 13:49:51 metrics.py:449] Avg prompt throughput: 60.2 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:49:54 logger.py:37] Received request chatcmpl-61f4591895b24d1085936d9bfe2eb638: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the phenomenon mainly introduced in the video happen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:54 logger.py:37] Received request chatcmpl-e36c396d02094b998f73c9b2900ba4f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main argument presented by Jordi Visser regarding the volatility of Bitcoin in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:54 engine.py:267] Added request chatcmpl-61f4591895b24d1085936d9bfe2eb638.
INFO 12-25 13:49:54 engine.py:267] Added request chatcmpl-e36c396d02094b998f73c9b2900ba4f3.
INFO 12-25 13:49:55 logger.py:37] Received request chatcmpl-b633be9129d64cab8be4cc5db3b5b85f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who\'s in control of our brains in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:55 logger.py:37] Received request chatcmpl-71d0f696d338463cb64b73d889efd3f8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is not mentioned in the video as influencing their mental resilience?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:49:55 engine.py:267] Added request chatcmpl-b633be9129d64cab8be4cc5db3b5b85f.
INFO 12-25 13:49:55 engine.py:267] Added request chatcmpl-71d0f696d338463cb64b73d889efd3f8.
INFO 12-25 13:49:56 metrics.py:449] Avg prompt throughput: 53.4 tokens/s, Avg generation throughput: 80.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:00 logger.py:37] Received request chatcmpl-41a804e226d24bbf9105db094243e897: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:00 engine.py:267] Added request chatcmpl-41a804e226d24bbf9105db094243e897.
INFO 12-25 13:50:01 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:50:01 logger.py:37] Received request chatcmpl-f56f5e8767c64cceb5d60d6fe6a346de: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the core distinction between American Express and companies like Visa and Mastercard as described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:01 engine.py:267] Added request chatcmpl-f56f5e8767c64cceb5d60d6fe6a346de.
INFO 12-25 13:50:01 logger.py:37] Received request chatcmpl-285308a82b7445a2b2c52f152bb4f646: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:01 engine.py:267] Added request chatcmpl-285308a82b7445a2b2c52f152bb4f646.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:03 logger.py:37] Received request chatcmpl-14479346ad434b8d8fa31d59a9b9c9cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order for introducing content in the video? (a) The excretion process of plants. (b) Plant adaptability. (c) The structure of a plant. (d) The special way of eating of plants. (e) Photosynthesis.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:04 engine.py:267] Added request chatcmpl-14479346ad434b8d8fa31d59a9b9c9cd.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:06 metrics.py:449] Avg prompt throughput: 47.4 tokens/s, Avg generation throughput: 139.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:08 logger.py:37] Received request chatcmpl-1a54f4661de54774a7661ae93482acc9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What subject is central to the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:08 engine.py:267] Added request chatcmpl-1a54f4661de54774a7661ae93482acc9.
INFO 12-25 13:50:10 logger.py:37] Received request chatcmpl-94dff0986fe24071855f7c3f7b73e576: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of experts does Kmele consult in sequence in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:10 logger.py:37] Received request chatcmpl-85569e91f0144f52b1f5efa5c7c954f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is Kemle\'s attitude towards the explanation of consciousness by the experts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:10 logger.py:37] Received request chatcmpl-f0151302666c49278166c0a4b8d6dee9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is one reason why the relationship between inflation and wage inflation has weakened in recent decades?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:10 engine.py:267] Added request chatcmpl-94dff0986fe24071855f7c3f7b73e576.
INFO 12-25 13:50:10 engine.py:267] Added request chatcmpl-85569e91f0144f52b1f5efa5c7c954f7.
INFO 12-25 13:50:10 engine.py:267] Added request chatcmpl-f0151302666c49278166c0a4b8d6dee9.
INFO 12-25 13:50:11 metrics.py:449] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 75.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:16 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 146.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:50:17 logger.py:37] Received request chatcmpl-5831d75cdc18461d906eb759132dc617: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following subjects is not discussed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:17 engine.py:267] Added request chatcmpl-5831d75cdc18461d906eb759132dc617.
INFO 12-25 13:50:17 logger.py:37] Received request chatcmpl-6f0f77461afa409cb4588aba6fd6e1af: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the collapse of Long Term Capital Management (LTCM) affect Goldman Sachs in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:17 engine.py:267] Added request chatcmpl-6f0f77461afa409cb4588aba6fd6e1af.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:19 logger.py:37] Received request chatcmpl-7d1c1769f9684759b62bc28469dd5ed9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Here are a few sub-titles about this video, what should be the correct order in which they appear in the video? (1) The money problem. (2) The Acqusition. (3) Intermission. (4) Present day and future.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:19 engine.py:267] Added request chatcmpl-7d1c1769f9684759b62bc28469dd5ed9.
INFO 12-25 13:50:20 logger.py:37] Received request chatcmpl-6f2f810e49d8453baf5eaab9f8f63d00: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What explanation is given for the fact that the country mainly featured in the video continued to experience deflation in the early 2000s?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:20 engine.py:267] Added request chatcmpl-6f2f810e49d8453baf5eaab9f8f63d00.
INFO 12-25 13:50:21 metrics.py:449] Avg prompt throughput: 64.6 tokens/s, Avg generation throughput: 116.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:24 logger.py:37] Received request chatcmpl-06cb18f7f8614afc92a80031bfe63cfc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When will we likely discover alien life, as anticipated by the white-haired speaker in the video\'s opening and closing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:24 engine.py:267] Added request chatcmpl-06cb18f7f8614afc92a80031bfe63cfc.
INFO 12-25 13:50:24 logger.py:37] Received request chatcmpl-585437276dc14b30b0137951daf155db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:24 engine.py:267] Added request chatcmpl-585437276dc14b30b0137951daf155db.
INFO 12-25 13:50:26 metrics.py:449] Avg prompt throughput: 27.2 tokens/s, Avg generation throughput: 127.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:28 logger.py:37] Received request chatcmpl-7074a423752e4a5fafd24f19d7ed9afb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central conflict regarding the main theme of the video presentation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:28 engine.py:267] Added request chatcmpl-7074a423752e4a5fafd24f19d7ed9afb.
INFO 12-25 13:50:28 logger.py:37] Received request chatcmpl-cc6ced0255fd4f2190a195f61bccba67: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best summarizes the core difference between the contrasting viewpoints on the future of Bitcoin in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:28 engine.py:267] Added request chatcmpl-cc6ced0255fd4f2190a195f61bccba67.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:31 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:32 logger.py:37] Received request chatcmpl-cda09bf23c4241158392ccf6a17e58da: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  Lambda-Cold Dark Matter Model  The Bullet Cluster  Annihilation Detection  Dark Energy". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:32 engine.py:267] Added request chatcmpl-cda09bf23c4241158392ccf6a17e58da.
INFO 12-25 13:50:32 logger.py:37] Received request chatcmpl-a65d0c3285744d1281ce133d64f88fea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What concern did Terri Duhon and her team have regarding the expanding credit derivatives market, particularly in the context of mortgages in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:32 engine.py:267] Added request chatcmpl-a65d0c3285744d1281ce133d64f88fea.
INFO 12-25 13:50:33 logger.py:37] Received request chatcmpl-ae064f683a8b445f9eef6f8df3e83592: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is NOT introduced between the way "learn to read financial news critically" and "utilize gamified learning apps" in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:33 engine.py:267] Added request chatcmpl-ae064f683a8b445f9eef6f8df3e83592.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:35 logger.py:37] Received request chatcmpl-c14be8aef823496289560b8228392037: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What makes influential financial podcasts a valuable tool for financial education in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:35 engine.py:267] Added request chatcmpl-c14be8aef823496289560b8228392037.
INFO 12-25 13:50:36 metrics.py:449] Avg prompt throughput: 64.7 tokens/s, Avg generation throughput: 114.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:39 logger.py:37] Received request chatcmpl-79107454a202466bb40068c9be90f846: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the "Great Attractor" according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:39 engine.py:267] Added request chatcmpl-79107454a202466bb40068c9be90f846.
INFO 12-25 13:50:40 logger.py:37] Received request chatcmpl-052d1354fbe54e66a6ba8e2d999aa0bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a significant factor that cause Discover\'s success in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:40 engine.py:267] Added request chatcmpl-052d1354fbe54e66a6ba8e2d999aa0bd.
INFO 12-25 13:50:40 logger.py:37] Received request chatcmpl-9705f4a87fb944008d399ec58b1db35c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the planets that Dr.David Grinspoon and Dr. Heidi B. Hammel research?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:40 engine.py:267] Added request chatcmpl-9705f4a87fb944008d399ec58b1db35c.
INFO 12-25 13:50:41 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 108.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:43 logger.py:37] Received request chatcmpl-b38f991eaab74eb0a3fb472c0f27dfcf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following best summarizes the main concern of those who advocate for a reduction in the balance sheet in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:43 engine.py:267] Added request chatcmpl-b38f991eaab74eb0a3fb472c0f27dfcf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:45 logger.py:37] Received request chatcmpl-76d39f866bf246fd9d4e02a9226efdbf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the given video, what is the main focus of it?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:45 engine.py:267] Added request chatcmpl-76d39f866bf246fd9d4e02a9226efdbf.
INFO 12-25 13:50:46 logger.py:37] Received request chatcmpl-b32fe00c3f0443dfb5305b888dbf6ceb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video state about the total area of the universe?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:46 engine.py:267] Added request chatcmpl-b32fe00c3f0443dfb5305b888dbf6ceb.
INFO 12-25 13:50:46 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 116.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:49 logger.py:37] Received request chatcmpl-e61cd5b06b0e465da8b5c4dda3ae57f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do the companies featured in the video face challenges when entering the IPO underwriting business?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:49 engine.py:267] Added request chatcmpl-e61cd5b06b0e465da8b5c4dda3ae57f1.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:50 logger.py:37] Received request chatcmpl-7d36b1546ae9449aa0a6d9db838f5b2d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the core focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:50 engine.py:267] Added request chatcmpl-7d36b1546ae9449aa0a6d9db838f5b2d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:50 logger.py:37] Received request chatcmpl-143bc6048acc40b28e3f2066eecf92ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:50 engine.py:267] Added request chatcmpl-143bc6048acc40b28e3f2066eecf92ec.
INFO 12-25 13:50:51 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 109.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:50:52 logger.py:37] Received request chatcmpl-0e7719eb375a4c6ab2d068d8ea4398fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What milestone was described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:52 engine.py:267] Added request chatcmpl-0e7719eb375a4c6ab2d068d8ea4398fc.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:50:56 logger.py:37] Received request chatcmpl-346ed690448245f08bd9a29101ec52fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the views of the individuals interviewed regarding the potential existence of extraterrestrial life in the universe?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:56 engine.py:267] Added request chatcmpl-346ed690448245f08bd9a29101ec52fb.
INFO 12-25 13:50:56 logger.py:37] Received request chatcmpl-4f5fe98e22724142b110319eb793dd34: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video identify as a significant consequence of central bank interventions like quantitative easing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:56 logger.py:37] Received request chatcmpl-a317efa0d8e340a9b26471f9186549ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the primary factor that distinguishes a recession from a deleveraging?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:56 engine.py:267] Added request chatcmpl-4f5fe98e22724142b110319eb793dd34.
INFO 12-25 13:50:56 engine.py:267] Added request chatcmpl-a317efa0d8e340a9b26471f9186549ee.
INFO 12-25 13:50:56 metrics.py:449] Avg prompt throughput: 24.6 tokens/s, Avg generation throughput: 83.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:50:57 logger.py:37] Received request chatcmpl-b9ef2c27852c4174afec6c7465f7466c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main idea of Dr. Sam Ohhugan\'s words?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:50:57 engine.py:267] Added request chatcmpl-b9ef2c27852c4174afec6c7465f7466c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:01 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 139.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:02 logger.py:37] Received request chatcmpl-45e91c0de96d46faa3b58f448e341f63: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the primary purpose of the gathering in Boca Raton, Florida in 1994, highlighted at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:02 engine.py:267] Added request chatcmpl-45e91c0de96d46faa3b58f448e341f63.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:03 logger.py:37] Received request chatcmpl-85c37e73eb0f44949cfeab27e35222ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the view of the white interviewee in the video wearing sunglasses on whether there are parallel universes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:03 engine.py:267] Added request chatcmpl-85c37e73eb0f44949cfeab27e35222ae.
INFO 12-25 13:51:04 logger.py:37] Received request chatcmpl-95f2bffc97d04cb0989bbcdec910d55b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What future human activity does the video discuss?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:04 logger.py:37] Received request chatcmpl-621daf17b01f4898a3a16e3fc9b40143: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to Green\'s research, what is the benefit that lightning brings to us?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:04 engine.py:267] Added request chatcmpl-95f2bffc97d04cb0989bbcdec910d55b.
INFO 12-25 13:51:04 engine.py:267] Added request chatcmpl-621daf17b01f4898a3a16e3fc9b40143.
INFO 12-25 13:51:07 metrics.py:449] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 102.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:09 logger.py:37] Received request chatcmpl-2522f7b23eaa4074a3d1706751d6e297: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what order are the following planets introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:09 engine.py:267] Added request chatcmpl-2522f7b23eaa4074a3d1706751d6e297.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:10 logger.py:37] Received request chatcmpl-7f9f1c61f32545ddb9f5a9835a752c77: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  Our Local Universe  The Zone of Avoidance  Dark Flow  The Vela Supercluster". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:10 engine.py:267] Added request chatcmpl-7f9f1c61f32545ddb9f5a9835a752c77.
INFO 12-25 13:51:11 logger.py:37] Received request chatcmpl-a34083e56d594006b47cd82ecddd8776: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, which of the following elements takes part in the formation of the Yamal Crater?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:11 engine.py:267] Added request chatcmpl-a34083e56d594006b47cd82ecddd8776.
INFO 12-25 13:51:12 metrics.py:449] Avg prompt throughput: 46.8 tokens/s, Avg generation throughput: 109.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:14 logger.py:37] Received request chatcmpl-cce0d13a642e49579c303e458930373b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  SN-1987A  Type 1a Supernova  Kilonova". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:14 engine.py:267] Added request chatcmpl-cce0d13a642e49579c303e458930373b.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:17 metrics.py:449] Avg prompt throughput: 18.2 tokens/s, Avg generation throughput: 136.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:51:17 logger.py:37] Received request chatcmpl-b552ff52b2e64aaa9478e77a0cac2b77: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which of the following elements was not one of the causes of such a great loss in Hilo island in 1960?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:17 engine.py:267] Added request chatcmpl-b552ff52b2e64aaa9478e77a0cac2b77.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:20 logger.py:37] Received request chatcmpl-5ec2b9e4ddf74fd4a487de548920557d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which sequence are the following introduced in the video?  The Big Bang  The Hubble Telescope  Redshift  Dark Energy". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:20 engine.py:267] Added request chatcmpl-5ec2b9e4ddf74fd4a487de548920557d.
INFO 12-25 13:51:20 logger.py:37] Received request chatcmpl-3b7844eef65544beaaaa9a238bd90737: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was Fritz Zwicky\'s significant contribution as highlighted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:20 engine.py:267] Added request chatcmpl-3b7844eef65544beaaaa9a238bd90737.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:21 logger.py:37] Received request chatcmpl-c88d738c4c6941949ce66ef902a082f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the following is introduced in the video?  How to supply oxygen  The motion of ISS  Fireflies on ISS  The communication between ISS and The Earth". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:21 engine.py:267] Added request chatcmpl-c88d738c4c6941949ce66ef902a082f2.
INFO 12-25 13:51:22 metrics.py:449] Avg prompt throughput: 66.8 tokens/s, Avg generation throughput: 96.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 13:51:22 logger.py:37] Received request chatcmpl-0c3e514682bc43d683dd739467f45b31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:22 engine.py:267] Added request chatcmpl-0c3e514682bc43d683dd739467f45b31.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:27 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 136.7 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:51:27 logger.py:37] Received request chatcmpl-e77f0b896d834cb2b1669fc5e67d81bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What topic is discussed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:27 engine.py:267] Added request chatcmpl-e77f0b896d834cb2b1669fc5e67d81bc.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:28 logger.py:37] Received request chatcmpl-cbb60a4cfbbe447e8a90a0eeee7f98ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what occurred within the lava as its outer layer solidified into rock?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:28 logger.py:37] Received request chatcmpl-9fd5d579e243489fa4a3e13580340a76: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what can be inferred about astronomers\' reactions to the observations?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:28 engine.py:267] Added request chatcmpl-cbb60a4cfbbe447e8a90a0eeee7f98ed.
INFO 12-25 13:51:28 engine.py:267] Added request chatcmpl-9fd5d579e243489fa4a3e13580340a76.
INFO 12-25 13:51:29 logger.py:37] Received request chatcmpl-5a3d2d58bd5d40f7abe9fd2b41dd7d96: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:29 engine.py:267] Added request chatcmpl-5a3d2d58bd5d40f7abe9fd2b41dd7d96.
INFO 12-25 13:51:32 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 101.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:35 logger.py:37] Received request chatcmpl-05f729500f88421cac65e91b2dee0a25: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is mentioned in the video as the second line of evidence for dark matter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:35 engine.py:267] Added request chatcmpl-05f729500f88421cac65e91b2dee0a25.
INFO 12-25 13:51:35 logger.py:37] Received request chatcmpl-ad65eac4c66d471faf38eb986191a835: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the video describe the methods being used by physicists to support the theory of parallel universes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:35 engine.py:267] Added request chatcmpl-ad65eac4c66d471faf38eb986191a835.
INFO 12-25 13:51:36 logger.py:37] Received request chatcmpl-afa1d8951f4e4c62b6670963e2e2305d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which of the following reasons does not lead humpback whales to come to Hawaii to breed and nurse the young?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:36 engine.py:267] Added request chatcmpl-afa1d8951f4e4c62b6670963e2e2305d.
INFO 12-25 13:51:36 logger.py:37] Received request chatcmpl-06d23135fc6d4de58fdb95c17dbc3fe6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is the primary reason for the appearance of giraffe images on the rocks in the deep desert?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:36 engine.py:267] Added request chatcmpl-06d23135fc6d4de58fdb95c17dbc3fe6.
INFO 12-25 13:51:37 metrics.py:449] Avg prompt throughput: 59.5 tokens/s, Avg generation throughput: 87.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:42 logger.py:37] Received request chatcmpl-debb5632260545de94d1334bd86749ca: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What aspect is NOT described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:42 engine.py:267] Added request chatcmpl-debb5632260545de94d1334bd86749ca.
INFO 12-25 13:51:42 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 111.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:51:43 logger.py:37] Received request chatcmpl-583a9b11facd435994e71522ecbf83f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the rocket\'s main function according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:43 logger.py:37] Received request chatcmpl-75e0b6080d76404387f90e2722b175f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following topics is not discussed in detail in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:43 logger.py:37] Received request chatcmpl-b6c080a770d84c01bab142a8dff5a661: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the discovery of the feathered serpent carvings at the city of Uxmal suggest about the Maya civilization of the Yucatan?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:43 engine.py:267] Added request chatcmpl-583a9b11facd435994e71522ecbf83f4.
INFO 12-25 13:51:43 engine.py:267] Added request chatcmpl-75e0b6080d76404387f90e2722b175f9.
INFO 12-25 13:51:43 engine.py:267] Added request chatcmpl-b6c080a770d84c01bab142a8dff5a661.
INFO 12-25 13:51:47 metrics.py:449] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 120.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:49 logger.py:37] Received request chatcmpl-5ccf1b99706b47bea914060e2526a9f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What event is the video primarily discussing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:49 engine.py:267] Added request chatcmpl-5ccf1b99706b47bea914060e2526a9f9.
INFO 12-25 13:51:49 logger.py:37] Received request chatcmpl-758eb1de64cb4758a1d721d2b5303103: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which concept is not described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:49 engine.py:267] Added request chatcmpl-758eb1de64cb4758a1d721d2b5303103.
INFO 12-25 13:51:51 logger.py:37] Received request chatcmpl-ff09390164954a3da1982fc4b41b288c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, how do the fractures form?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:51 logger.py:37] Received request chatcmpl-7ad966bd9b2e4e339378b39bd1d55e3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:51 engine.py:267] Added request chatcmpl-ff09390164954a3da1982fc4b41b288c.
INFO 12-25 13:51:51 engine.py:267] Added request chatcmpl-7ad966bd9b2e4e339378b39bd1d55e3f.
INFO 12-25 13:51:52 metrics.py:449] Avg prompt throughput: 49.5 tokens/s, Avg generation throughput: 82.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:56 logger.py:37] Received request chatcmpl-b66cccc4a048420ead9f8a3d45465ed2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What missions have encountered the failures detailed in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:56 engine.py:267] Added request chatcmpl-b66cccc4a048420ead9f8a3d45465ed2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:57 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 138.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:51:58 logger.py:37] Received request chatcmpl-d4b75bbff30a44898aa6f13115e79045: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What conclusions can be made about the special machine\'s impact on astronomical measurements from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:58 engine.py:267] Added request chatcmpl-d4b75bbff30a44898aa6f13115e79045.
INFO 12-25 13:51:59 logger.py:37] Received request chatcmpl-00b9b79e8ee04782932fdcc1f3778c29: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the lady in the first case in the video do?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:59 logger.py:37] Received request chatcmpl-76a0972cc91c4c2fa99fab0bc704e10b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did Masu misunderstand according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:51:59 engine.py:267] Added request chatcmpl-00b9b79e8ee04782932fdcc1f3778c29.
INFO 12-25 13:51:59 engine.py:267] Added request chatcmpl-76a0972cc91c4c2fa99fab0bc704e10b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:02 metrics.py:449] Avg prompt throughput: 39.3 tokens/s, Avg generation throughput: 114.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:52:03 logger.py:37] Received request chatcmpl-15486d682dda4244a79ac82392f7d90a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How was Nahuku formed according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:03 engine.py:267] Added request chatcmpl-15486d682dda4244a79ac82392f7d90a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:04 logger.py:37] Received request chatcmpl-1c87ed56c781460e9dd33d62fdb81954: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After the first successful moon landing, what challenge did NASA\'s Apollo Program face?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:04 engine.py:267] Added request chatcmpl-1c87ed56c781460e9dd33d62fdb81954.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:06 logger.py:37] Received request chatcmpl-9857ea5f7713421ea387845cb445158f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the view held by the female witness present in the first case in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:06 engine.py:267] Added request chatcmpl-9857ea5f7713421ea387845cb445158f.
INFO 12-25 13:52:06 logger.py:37] Received request chatcmpl-ffab243a9b8b4d1cbd11c5900433c18f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the metaphor for a double-barreled shotgun according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:06 engine.py:267] Added request chatcmpl-ffab243a9b8b4d1cbd11c5900433c18f.
INFO 12-25 13:52:07 metrics.py:449] Avg prompt throughput: 53.4 tokens/s, Avg generation throughput: 106.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:09 logger.py:37] Received request chatcmpl-832da63f76734f9dae70ff1913bc8366: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people does the Ross Ice Shelf team consist of?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:09 engine.py:267] Added request chatcmpl-832da63f76734f9dae70ff1913bc8366.
INFO 12-25 13:52:10 logger.py:37] Received request chatcmpl-6223f2ffa4f340619499a254da596e20: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why did the scientist mention the way a star explodes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:10 engine.py:267] Added request chatcmpl-6223f2ffa4f340619499a254da596e20.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:12 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 124.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:12 logger.py:37] Received request chatcmpl-e3d2ad96554b4544b5bc61d1ea0d13fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not discussed by the presenter in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:12 engine.py:267] Added request chatcmpl-e3d2ad96554b4544b5bc61d1ea0d13fa.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:14 logger.py:37] Received request chatcmpl-f47bae61e1e9474fa9165f5b39a65b64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what potential changes might occur over tens of millions of years?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:14 engine.py:267] Added request chatcmpl-f47bae61e1e9474fa9165f5b39a65b64.
INFO 12-25 13:52:15 logger.py:37] Received request chatcmpl-5640a5abea184638850a6e5116018239: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many cases are cited in the video to illustrate the craters caused by excessive methane in permafrost?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:15 logger.py:37] Received request chatcmpl-a71e80a04f7a4deebcf429156ea299ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why was the team so cautious upon the helicopter\'s landing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:15 engine.py:267] Added request chatcmpl-5640a5abea184638850a6e5116018239.
INFO 12-25 13:52:15 engine.py:267] Added request chatcmpl-a71e80a04f7a4deebcf429156ea299ec.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:17 metrics.py:449] Avg prompt throughput: 54.4 tokens/s, Avg generation throughput: 102.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:52:17 logger.py:37] Received request chatcmpl-335ad05421604a98bf4f243296dd51ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which case is the main story about in the plot of the movie explained by the host in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:17 engine.py:267] Added request chatcmpl-335ad05421604a98bf4f243296dd51ff.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:21 logger.py:37] Received request chatcmpl-be475910f6bf442aa5b61cf9e2abdf92: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what is Chimeya famous for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:21 logger.py:37] Received request chatcmpl-d64c68f32c334d55846082aaa8abf6e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following techniques was not used in the research of Esieh Lake?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:21 engine.py:267] Added request chatcmpl-be475910f6bf442aa5b61cf9e2abdf92.
INFO 12-25 13:52:21 engine.py:267] Added request chatcmpl-d64c68f32c334d55846082aaa8abf6e0.
INFO 12-25 13:52:22 metrics.py:449] Avg prompt throughput: 41.4 tokens/s, Avg generation throughput: 110.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:22 logger.py:37] Received request chatcmpl-72c1b5b0022446dcaab77dc5af3ac431: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What triggered the 1958 tsunami in Lituya Bay according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:22 engine.py:267] Added request chatcmpl-72c1b5b0022446dcaab77dc5af3ac431.
INFO 12-25 13:52:24 logger.py:37] Received request chatcmpl-d840a44c7ffa426e989e125a111ec1b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly sorts the order in which events appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:24 engine.py:267] Added request chatcmpl-d840a44c7ffa426e989e125a111ec1b2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:26 logger.py:37] Received request chatcmpl-b5eca33b45504a26ac57eacaa7188f51: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What evidence suggests that the Maya at "Stairway to Heaven" were wealthy plantation owners?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:26 engine.py:267] Added request chatcmpl-b5eca33b45504a26ac57eacaa7188f51.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:27 metrics.py:449] Avg prompt throughput: 41.8 tokens/s, Avg generation throughput: 120.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:28 logger.py:37] Received request chatcmpl-12afc30f0f114196891a615336718f26: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is true about the theory of the formation of the earth that NASA believes in?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:28 engine.py:267] Added request chatcmpl-12afc30f0f114196891a615336718f26.
INFO 12-25 13:52:29 logger.py:37] Received request chatcmpl-3bd53dbe8ecf4d5c99e3e6dba1adb7d1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How were the Sawtooth ranges formed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:29 engine.py:267] Added request chatcmpl-3bd53dbe8ecf4d5c99e3e6dba1adb7d1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:32 metrics.py:449] Avg prompt throughput: 26.0 tokens/s, Avg generation throughput: 135.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:34 logger.py:37] Received request chatcmpl-07e99a90b6aa457ea14eafc05a098115: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order in which the restrictions on the use of weapons under international law are introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:34 logger.py:37] Received request chatcmpl-1ac3137f0d264061a70bbad37193f8e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What evidence indicates that the mountain is still growing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:34 engine.py:267] Added request chatcmpl-07e99a90b6aa457ea14eafc05a098115.
INFO 12-25 13:52:34 engine.py:267] Added request chatcmpl-1ac3137f0d264061a70bbad37193f8e3.
INFO 12-25 13:52:34 logger.py:37] Received request chatcmpl-fafd9c713050455fbead0d434216c497: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main case presented in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:35 engine.py:267] Added request chatcmpl-fafd9c713050455fbead0d434216c497.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:36 logger.py:37] Received request chatcmpl-f2a9bfad5c0244108044cbcafa261ffe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which element has the highest peak in the spectra of sample token by Dr. Rudy Reimer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:36 engine.py:267] Added request chatcmpl-f2a9bfad5c0244108044cbcafa261ffe.
INFO 12-25 13:52:37 metrics.py:449] Avg prompt throughput: 53.6 tokens/s, Avg generation throughput: 82.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:40 logger.py:37] Received request chatcmpl-cbf1be00392b48ebba37df5298c64500: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man in the first case in the video go to jail for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:40 engine.py:267] Added request chatcmpl-cbf1be00392b48ebba37df5298c64500.
INFO 12-25 13:52:41 logger.py:37] Received request chatcmpl-8877915ee16b4a2ea977fa59adad44f6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following steps introduced in this video? (a) Removing a washing machine door seal. (b) Astonishing Results of the beach on the washing machine door seal. (c) Washing machine hoses to clean to remove Mold Mildew fungus. (d) Cleaning mold out of soap draw.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:41 logger.py:37] Received request chatcmpl-0ade611ec2434d4c96417c43ebad15d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following statements regarding the algae sample token near a volcanic hot spring is false?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:41 engine.py:267] Added request chatcmpl-8877915ee16b4a2ea977fa59adad44f6.
INFO 12-25 13:52:41 engine.py:267] Added request chatcmpl-0ade611ec2434d4c96417c43ebad15d4.
INFO 12-25 13:52:42 metrics.py:449] Avg prompt throughput: 51.2 tokens/s, Avg generation throughput: 104.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:46 logger.py:37] Received request chatcmpl-0c07e8475ea842618a5cb823727ce111: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, why does the caravan drop off hay along the way?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:46 engine.py:267] Added request chatcmpl-0c07e8475ea842618a5cb823727ce111.
INFO 12-25 13:52:47 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:52:47 logger.py:37] Received request chatcmpl-e9b4ef2527c5449ebddb9db157668b14: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the biological father of the girl in the second case in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:47 engine.py:267] Added request chatcmpl-e9b4ef2527c5449ebddb9db157668b14.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:49 logger.py:37] Received request chatcmpl-d79644932de54939b06ed556c6898df0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What specific evidence is presented to support the claim that the Maya in the Yucatan were more advanced than previously believed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:49 engine.py:267] Added request chatcmpl-d79644932de54939b06ed556c6898df0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:52 metrics.py:449] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 128.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:52:52 logger.py:37] Received request chatcmpl-aa710e8d4bfe4acb97335354dae149bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content introduced in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:52 engine.py:267] Added request chatcmpl-aa710e8d4bfe4acb97335354dae149bf.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:53 logger.py:37] Received request chatcmpl-c617dc8c640745d39b17542f82681808: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which two people are the main focus of conflict in the film\'s plot in the second half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:54 engine.py:267] Added request chatcmpl-c617dc8c640745d39b17542f82681808.
INFO 12-25 13:52:56 logger.py:37] Received request chatcmpl-966fdfa04f2d4478a63b1ed80ba4ac7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what circumstances was the museum depicted in the video bombed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:56 logger.py:37] Received request chatcmpl-ed15606e364e47a69b7108adbe2f34fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From which pose does there come a cat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:56 engine.py:267] Added request chatcmpl-966fdfa04f2d4478a63b1ed80ba4ac7c.
INFO 12-25 13:52:56 engine.py:267] Added request chatcmpl-ed15606e364e47a69b7108adbe2f34fa.
INFO 12-25 13:52:57 metrics.py:449] Avg prompt throughput: 52.1 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:52:59 logger.py:37] Received request chatcmpl-e11d76c6b8d446b5ac7812531fa83ca5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the bar scene of the movie, what item does the policeman present as evidence of the arrested person\'s suspicion, found in the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:52:59 engine.py:267] Added request chatcmpl-e11d76c6b8d446b5ac7812531fa83ca5.
INFO 12-25 13:53:00 logger.py:37] Received request chatcmpl-c746f07813d545adacc08374f8ec8fbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main message of the caller in the 911 recordings that appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:00 engine.py:267] Added request chatcmpl-c746f07813d545adacc08374f8ec8fbe.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:02 metrics.py:449] Avg prompt throughput: 30.6 tokens/s, Avg generation throughput: 114.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:53:02 logger.py:37] Received request chatcmpl-66048d3ab55e4027b3dc0f8a2d5543b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Under what circumstances can Chad Doerman be sentenced to death?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:02 engine.py:267] Added request chatcmpl-66048d3ab55e4027b3dc0f8a2d5543b3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:05 logger.py:37] Received request chatcmpl-29471c6c24ec4120861a045b1827e7c8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the point of the video trying to discuss about the NFT by purchasing the example of Ford signing a purchase contract with an athlete?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:05 engine.py:267] Added request chatcmpl-29471c6c24ec4120861a045b1827e7c8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:06 logger.py:37] Received request chatcmpl-fcd84aedd6054d95812d0805b78b0cb1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the argument in the second case based on the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:06 engine.py:267] Added request chatcmpl-fcd84aedd6054d95812d0805b78b0cb1.
INFO 12-25 13:53:06 logger.py:37] Received request chatcmpl-b910ea40bc254b48a7c9abf0ae514cb1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:07 engine.py:267] Added request chatcmpl-b910ea40bc254b48a7c9abf0ae514cb1.
INFO 12-25 13:53:07 metrics.py:449] Avg prompt throughput: 55.2 tokens/s, Avg generation throughput: 111.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:09 logger.py:37] Received request chatcmpl-6d6834154fe04582aa56027eb2223071: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:09 engine.py:267] Added request chatcmpl-6d6834154fe04582aa56027eb2223071.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:11 logger.py:37] Received request chatcmpl-2c5307ee096347f8b0df00e3e05e65a6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following types of coffee made in this video? (a) Espresso, Manual. (b) Piccolo Latte. (c) Dirty Chai. (d) Vienna Coffee.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:11 engine.py:267] Added request chatcmpl-2c5307ee096347f8b0df00e3e05e65a6.
INFO 12-25 13:53:12 metrics.py:449] Avg prompt throughput: 30.4 tokens/s, Avg generation throughput: 131.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:14 logger.py:37] Received request chatcmpl-39ad21c7a50a4eff9b8936ac67c221c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does code red refer to in the film plot in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:14 engine.py:267] Added request chatcmpl-39ad21c7a50a4eff9b8936ac67c221c3.
INFO 12-25 13:53:14 logger.py:37] Received request chatcmpl-2ab34a94c2e44199bce4aa9be29f3c02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the issue that the prosecution and defence sit down to discuss in the episode of the film at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:14 engine.py:267] Added request chatcmpl-2ab34a94c2e44199bce4aa9be29f3c02.
INFO 12-25 13:53:15 logger.py:37] Received request chatcmpl-aa414bce58ed46c7bdc193dd2051feaf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central focus of the main plot discussed by the two hosts in the video about the film?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:15 engine.py:267] Added request chatcmpl-aa414bce58ed46c7bdc193dd2051feaf.
INFO 12-25 13:53:17 metrics.py:449] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:20 logger.py:37] Received request chatcmpl-e1d2c3ce6f6a49dc87637be1be1e0987: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following steps has the most scenarios during the demonstration according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:20 engine.py:267] Added request chatcmpl-e1d2c3ce6f6a49dc87637be1be1e0987.
INFO 12-25 13:53:22 logger.py:37] Received request chatcmpl-7a69458f3673457aaa4327a788f80a41: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, how did the defense lawyer prove that there was something wrong with the surveillance video in the movie plot?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:22 logger.py:37] Received request chatcmpl-8fbfcdb203344b1f9fbdfc85fa695093: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What efforts were made by the defence lawyers in the last trial in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:22 logger.py:37] Received request chatcmpl-5e1383f62e2f486cadaa4f0416cc5780: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:22 engine.py:267] Added request chatcmpl-7a69458f3673457aaa4327a788f80a41.
INFO 12-25 13:53:22 engine.py:267] Added request chatcmpl-8fbfcdb203344b1f9fbdfc85fa695093.
INFO 12-25 13:53:22 engine.py:267] Added request chatcmpl-5e1383f62e2f486cadaa4f0416cc5780.
INFO 12-25 13:53:22 metrics.py:449] Avg prompt throughput: 54.4 tokens/s, Avg generation throughput: 78.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:27 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 146.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:30 logger.py:37] Received request chatcmpl-969f880332744910a1dfab90f8429b47: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the correct order of events in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:30 engine.py:267] Added request chatcmpl-969f880332744910a1dfab90f8429b47.
INFO 12-25 13:53:30 logger.py:37] Received request chatcmpl-7ce64e838fd14db48b5820db8ae34ade: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following poses introduced in this video? (a) Reclining butterfly pose. (b) Downward facing dog. (c) Camel pose. (d) Seated chair twist.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:30 engine.py:267] Added request chatcmpl-7ce64e838fd14db48b5820db8ae34ade.
INFO 12-25 13:53:32 logger.py:37] Received request chatcmpl-c9460a26725041b8a30e5bfcc9f093c4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What content does the video mainly focus on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:32 logger.py:37] Received request chatcmpl-3ab4b4cd06a142c4b539bf987aaabc70: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic about the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:32 engine.py:267] Added request chatcmpl-c9460a26725041b8a30e5bfcc9f093c4.
INFO 12-25 13:53:32 engine.py:267] Added request chatcmpl-3ab4b4cd06a142c4b539bf987aaabc70.
INFO 12-25 13:53:32 metrics.py:449] Avg prompt throughput: 56.3 tokens/s, Avg generation throughput: 58.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:37 logger.py:37] Received request chatcmpl-cb397a96848f443384fd60e31224ed0c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following functions can not the app provide according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:37 engine.py:267] Added request chatcmpl-cb397a96848f443384fd60e31224ed0c.
INFO 12-25 13:53:37 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 144.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:39 logger.py:37] Received request chatcmpl-aae7bfe3475441fe81830053397e6dbf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the main content of the video presented?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:39 engine.py:267] Added request chatcmpl-aae7bfe3475441fe81830053397e6dbf.
INFO 12-25 13:53:40 logger.py:37] Received request chatcmpl-5e40d9538ebb4cbe9c4ed6d3f2d439ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What character in the courtroom is the man with the gun trying to assassinate the prosecutor in the film clip at the very beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:40 engine.py:267] Added request chatcmpl-5e40d9538ebb4cbe9c4ed6d3f2d439ad.
INFO 12-25 13:53:41 logger.py:37] Received request chatcmpl-ecd9b3d6544f40258d3f93663e3cfcbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order do the following steps are introduced when manipulating the first image in this video? (a) Adding more control points. (b) Global adjustments (c) Launching Nik Viveza. (d) Adjusting green". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:41 engine.py:267] Added request chatcmpl-ecd9b3d6544f40258d3f93663e3cfcbe.
INFO 12-25 13:53:42 metrics.py:449] Avg prompt throughput: 48.2 tokens/s, Avg generation throughput: 100.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:47 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 137.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:48 logger.py:37] Received request chatcmpl-a45eb016e49846bfbbe9aa9ea715962c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the motivation behind Ruby Frank\'s unsolicited plea as mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:48 engine.py:267] Added request chatcmpl-a45eb016e49846bfbbe9aa9ea715962c.
INFO 12-25 13:53:49 logger.py:37] Received request chatcmpl-68252685e2c543ed8d1b66728ea45117: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who were the individuals in the video who were subsequently arrested for child abuse?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:49 logger.py:37] Received request chatcmpl-b87d3c8771dc4daeb7e04fca82a24597: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic about the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:49 engine.py:267] Added request chatcmpl-68252685e2c543ed8d1b66728ea45117.
INFO 12-25 13:53:49 engine.py:267] Added request chatcmpl-b87d3c8771dc4daeb7e04fca82a24597.
INFO 12-25 13:53:52 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 118.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:54 logger.py:37] Received request chatcmpl-172d33995681490eaf3e1eb4a80e2941: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary subject matter of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:54 engine.py:267] Added request chatcmpl-172d33995681490eaf3e1eb4a80e2941.
INFO 12-25 13:53:56 logger.py:37] Received request chatcmpl-79f99e962b0d4d379577d8c6acb09a04: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, what can people do if they lose their important files on the computers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:56 engine.py:267] Added request chatcmpl-79f99e962b0d4d379577d8c6acb09a04.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:53:57 metrics.py:449] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 118.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:53:58 logger.py:37] Received request chatcmpl-448fb43508d24b1e928b8ac7332d5c4b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following steps introduced in this video? (a) Solving the middle layer. (b) Matching corner pieces with the center. (c) Solving the yellow. (d) Solving the white. (e) Solving the cube.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:58 engine.py:267] Added request chatcmpl-448fb43508d24b1e928b8ac7332d5c4b.
INFO 12-25 13:53:59 logger.py:37] Received request chatcmpl-5b847dc7316c40bf99c03c3bbbbb30c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How and why does the water filled in the drum change color?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:53:59 engine.py:267] Added request chatcmpl-5b847dc7316c40bf99c03c3bbbbb30c1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:01 logger.py:37] Received request chatcmpl-28010edf5cd14d23b8666d3c1787d301: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Assuming different models such as the S6 and S6 Edge are considered one generation, how many generations of Samsung Galaxy S series phones are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:01 logger.py:37] Received request chatcmpl-f000f0820b9e47cbb734b55090e77076: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following tips introduced in this video? (a) Tracking daily data of the body (b) Emphasizing the importance of time and priority. (c) Building a personalised meal plan. (d) Creating a caloric deficit.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:01 engine.py:267] Added request chatcmpl-28010edf5cd14d23b8666d3c1787d301.
INFO 12-25 13:54:02 engine.py:267] Added request chatcmpl-f000f0820b9e47cbb734b55090e77076.
INFO 12-25 13:54:02 metrics.py:449] Avg prompt throughput: 71.5 tokens/s, Avg generation throughput: 102.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:05 logger.py:37] Received request chatcmpl-b6ec5be106fd4c0fae9047008755b01c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:05 engine.py:267] Added request chatcmpl-b6ec5be106fd4c0fae9047008755b01c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:06 logger.py:37] Received request chatcmpl-7c9ce148981d41e391646ab1259f3c55: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What configuration type is the demonstration of Decton after the professor introduces the topic of materials?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:07 engine.py:267] Added request chatcmpl-7c9ce148981d41e391646ab1259f3c55.
INFO 12-25 13:54:07 metrics.py:449] Avg prompt throughput: 26.3 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:09 logger.py:37] Received request chatcmpl-3d469d9be5204355a872c36d8530469f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following yaku does the example round one have according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:09 engine.py:267] Added request chatcmpl-3d469d9be5204355a872c36d8530469f.
INFO 12-25 13:54:09 logger.py:37] Received request chatcmpl-b39a1187071d46efbb3c72994df0b8ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can you do with GPT-4 Turbo as described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:09 engine.py:267] Added request chatcmpl-b39a1187071d46efbb3c72994df0b8ed.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:12 logger.py:37] Received request chatcmpl-492f727276064620ac08808a930ba1c8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what sequence are the following contents introduced in this video? (a) Different types of yaku. (b) Different types of tiles. (c) The strategies to complete a winning hand quickly. (d) How to create a winning hand.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:12 engine.py:267] Added request chatcmpl-492f727276064620ac08808a930ba1c8.
INFO 12-25 13:54:12 metrics.py:449] Avg prompt throughput: 47.7 tokens/s, Avg generation throughput: 122.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:15 logger.py:37] Received request chatcmpl-c3dfab03dfa14f489ac02c49a7b90c38: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:15 engine.py:267] Added request chatcmpl-c3dfab03dfa14f489ac02c49a7b90c38.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:17 logger.py:37] Received request chatcmpl-7902c4e61d324584950517218685c667: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How were the recurring short video clips captured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:17 engine.py:267] Added request chatcmpl-7902c4e61d324584950517218685c667.
INFO 12-25 13:54:17 metrics.py:449] Avg prompt throughput: 25.0 tokens/s, Avg generation throughput: 114.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:54:17 logger.py:37] Received request chatcmpl-22898ce1b63b4e94acdba7899f91c731: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary subject matter of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:17 engine.py:267] Added request chatcmpl-22898ce1b63b4e94acdba7899f91c731.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:21 logger.py:37] Received request chatcmpl-072205c016134d11a8ef1414ad636cfe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what sequence are the following topics introduced in this video? (a) Internet Safety: Your Browser\'s Security Features. (b) Basic Parts of a Computer. (c) Mac OS X Basics: Getting Started with the Desktop (d) Understanding Operating Systems". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:21 engine.py:267] Added request chatcmpl-072205c016134d11a8ef1414ad636cfe.
INFO 12-25 13:54:22 metrics.py:449] Avg prompt throughput: 33.2 tokens/s, Avg generation throughput: 141.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:25 logger.py:37] Received request chatcmpl-dafff5d988554b909d378f767c332681: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which component in the chassis has the most distinct color from the others?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:25 logger.py:37] Received request chatcmpl-88b269fd4db44a2d87ea9ec390c802bb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following item is not the difference when making Macchiato and Latte Macchiato according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:25 logger.py:37] Received request chatcmpl-4bb4ad4056cf4979b27301b0b7d7fe0c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what sequence are the following topics introduced in this video? (a) Different types of grills. (b) Venting. (c) Lighting considerations. (d) Cooking options. (e) Outdoor kitchen configurations.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:25 engine.py:267] Added request chatcmpl-dafff5d988554b909d378f767c332681.
INFO 12-25 13:54:25 engine.py:267] Added request chatcmpl-88b269fd4db44a2d87ea9ec390c802bb.
INFO 12-25 13:54:25 engine.py:267] Added request chatcmpl-4bb4ad4056cf4979b27301b0b7d7fe0c.
INFO 12-25 13:54:27 metrics.py:449] Avg prompt throughput: 47.9 tokens/s, Avg generation throughput: 99.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:31 logger.py:37] Received request chatcmpl-f8c76138f87e4af6a5d0eaf82682e2f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:31 engine.py:267] Added request chatcmpl-f8c76138f87e4af6a5d0eaf82682e2f7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:32 logger.py:37] Received request chatcmpl-5156ab864a8f431dbf06e035fd1e539b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of Bugatti does the video devote the most space to?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:32 engine.py:267] Added request chatcmpl-5156ab864a8f431dbf06e035fd1e539b.
INFO 12-25 13:54:32 metrics.py:449] Avg prompt throughput: 25.3 tokens/s, Avg generation throughput: 117.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:54:33 logger.py:37] Received request chatcmpl-699bcbee17044b84b7193431b6c74114: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in this video, which of the following websites can help promote selling?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:33 engine.py:267] Added request chatcmpl-699bcbee17044b84b7193431b6c74114.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:36 logger.py:37] Received request chatcmpl-1f800ffb65cf4a45848c47086e8d2831: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When was the first blue LED created in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:36 engine.py:267] Added request chatcmpl-1f800ffb65cf4a45848c47086e8d2831.
INFO 12-25 13:54:36 logger.py:37] Received request chatcmpl-ed7ff200947e4ac68e5e23c820091efa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What tech product presented in the video is not a combination of software and hardware?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:36 engine.py:267] Added request chatcmpl-ed7ff200947e4ac68e5e23c820091efa.
INFO 12-25 13:54:37 metrics.py:449] Avg prompt throughput: 39.7 tokens/s, Avg generation throughput: 127.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:39 logger.py:37] Received request chatcmpl-b9d0128f905247abb879e2b5413d8371: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following topics introduced in this video? (a) How to design clothing. (b) How to create a logo. (c) How to start an online store or website for free. (d) How to market and get sales.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:39 engine.py:267] Added request chatcmpl-b9d0128f905247abb879e2b5413d8371.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:40 logger.py:37] Received request chatcmpl-f62ecfc93c44442799f11febbf496371: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic about the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:40 engine.py:267] Added request chatcmpl-f62ecfc93c44442799f11febbf496371.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:42 metrics.py:449] Avg prompt throughput: 32.9 tokens/s, Avg generation throughput: 129.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:54:43 logger.py:37] Received request chatcmpl-b373eb0e92f04e8891a6eb3348291e94: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following statements about the first cilp of the video presented by the speaker is incorrect?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:43 engine.py:267] Added request chatcmpl-b373eb0e92f04e8891a6eb3348291e94.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:47 logger.py:37] Received request chatcmpl-31270d73525240b5a305838488ce0558: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many different pictures are edited in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:47 logger.py:37] Received request chatcmpl-0d4197c7b53f4f0d8282416fafd97d3a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s a video writer\'s least favorite product?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:47 engine.py:267] Added request chatcmpl-31270d73525240b5a305838488ce0558.
INFO 12-25 13:54:47 engine.py:267] Added request chatcmpl-0d4197c7b53f4f0d8282416fafd97d3a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:47 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 115.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:54:48 logger.py:37] Received request chatcmpl-696e09ecb66f415890cc9987dbb7db78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which statement is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:48 engine.py:267] Added request chatcmpl-696e09ecb66f415890cc9987dbb7db78.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:50 logger.py:37] Received request chatcmpl-b27e2132a9da4ca9acbf20288c0f411c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which direction is the narrator in the red facing in relation to the narrator in green?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:50 engine.py:267] Added request chatcmpl-b27e2132a9da4ca9acbf20288c0f411c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:52 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 128.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:54:53 logger.py:37] Received request chatcmpl-f98524e0ca9e4e87bff5010b53e8f587: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between Dante and his family according to what is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:53 engine.py:267] Added request chatcmpl-f98524e0ca9e4e87bff5010b53e8f587.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:56 logger.py:37] Received request chatcmpl-e62516f7efec40b99a260d9fa8b046cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can\'t you learn from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:56 engine.py:267] Added request chatcmpl-e62516f7efec40b99a260d9fa8b046cd.
INFO 12-25 13:54:56 logger.py:37] Received request chatcmpl-b8ae1ffd87ef40a3a53211638811646b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What color was the back cover of the previous generation Galaxy S phone of the phone with the most expensive starting price shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:56 engine.py:267] Added request chatcmpl-b8ae1ffd87ef40a3a53211638811646b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:57 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:54:58 logger.py:37] Received request chatcmpl-7e6b4f1fbc7241128f773562d8af4642: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of video game was not mentioned in the introduction of the NVIDIA V1?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:58 engine.py:267] Added request chatcmpl-7e6b4f1fbc7241128f773562d8af4642.
INFO 12-25 13:54:59 logger.py:37] Received request chatcmpl-fbf1b134be2b45759ca54de69fbc04c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, what does the story entail?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:54:59 engine.py:267] Added request chatcmpl-fbf1b134be2b45759ca54de69fbc04c2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:01 logger.py:37] Received request chatcmpl-3039c64e4a3541ccb72fa491ecfc6b6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:01 engine.py:267] Added request chatcmpl-3039c64e4a3541ccb72fa491ecfc6b6a.
INFO 12-25 13:55:02 logger.py:37] Received request chatcmpl-5a9844c0bbba4893bc7e67d2ca1fff76: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which phone characteristic and model pairing is incorrect from the following options?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:02 engine.py:267] Added request chatcmpl-5a9844c0bbba4893bc7e67d2ca1fff76.
INFO 12-25 13:55:02 metrics.py:449] Avg prompt throughput: 51.2 tokens/s, Avg generation throughput: 110.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:06 logger.py:37] Received request chatcmpl-8dbd878fbdea4a31922bcb056c288514: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which car was the first to be designed with an automobile roof?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:06 engine.py:267] Added request chatcmpl-8dbd878fbdea4a31922bcb056c288514.
INFO 12-25 13:55:07 logger.py:37] Received request chatcmpl-7d45528fa4f04e30acca45e0641b973e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, what is the stickman animation about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:07 logger.py:37] Received request chatcmpl-88ae2610652a46bd9c75a4b9fb31dca2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following can best summarize the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:07 engine.py:267] Added request chatcmpl-7d45528fa4f04e30acca45e0641b973e.
INFO 12-25 13:55:07 engine.py:267] Added request chatcmpl-88ae2610652a46bd9c75a4b9fb31dca2.
INFO 12-25 13:55:07 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 106.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:09 logger.py:37] Received request chatcmpl-6efc56d6c9514fa480bf036125031847: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order of the video to explain the following events? (a) History. (b) Alexnet. (c) CUDA. (d) Team Management.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:09 engine.py:267] Added request chatcmpl-6efc56d6c9514fa480bf036125031847.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:11 logger.py:37] Received request chatcmpl-a286b3aca04f45908230db4881bfd5ef: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which tech product in the video is not music-related?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:11 engine.py:267] Added request chatcmpl-a286b3aca04f45908230db4881bfd5ef.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:12 metrics.py:449] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 127.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:12 logger.py:37] Received request chatcmpl-4554be1978dd49aea8164a958df561ed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do Joker and Harley escape when their car is caught by Batman\'s car in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:12 engine.py:267] Added request chatcmpl-4554be1978dd49aea8164a958df561ed.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:14 logger.py:37] Received request chatcmpl-cf9d56ed32574896ae1042b6f87811d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the main thing this video documents?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:14 engine.py:267] Added request chatcmpl-cf9d56ed32574896ae1042b6f87811d2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:17 logger.py:37] Received request chatcmpl-6b43cded19b44c6bad9339530111e52e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which section of the video is the rocket recovery told?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:17 engine.py:267] Added request chatcmpl-6b43cded19b44c6bad9339530111e52e.
INFO 12-25 13:55:17 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 129.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:19 logger.py:37] Received request chatcmpl-37271d06a9a44a1b871606e6bbe676c2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the author playing a video game at the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:19 engine.py:267] Added request chatcmpl-37271d06a9a44a1b871606e6bbe676c2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:20 logger.py:37] Received request chatcmpl-96ce81b98bfd419895d7e0ef059bc607: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the installation order for the following components in the video? (a) Motherboard. (b) Water cooling. (c) Power supply. (d) Bus.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:20 engine.py:267] Added request chatcmpl-96ce81b98bfd419895d7e0ef059bc607.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:21 logger.py:37] Received request chatcmpl-9b7d4548c833444781df00cfb6f95dde: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:21 engine.py:267] Added request chatcmpl-9b7d4548c833444781df00cfb6f95dde.
INFO 12-25 13:55:22 logger.py:37] Received request chatcmpl-a937d94e691e47f889564cceaee4214d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, why is the teacher still in the museum after the security alarm?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:22 engine.py:267] Added request chatcmpl-a937d94e691e47f889564cceaee4214d.
INFO 12-25 13:55:22 metrics.py:449] Avg prompt throughput: 56.8 tokens/s, Avg generation throughput: 96.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:27 logger.py:37] Received request chatcmpl-5a7e1ad5bfbd41bd8aa02b06f46286be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many cars have broken 300 mph top speed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:27 logger.py:37] Received request chatcmpl-06a0c25058234eb696c383e2180f8697: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:27 engine.py:267] Added request chatcmpl-5a7e1ad5bfbd41bd8aa02b06f46286be.
INFO 12-25 13:55:27 engine.py:267] Added request chatcmpl-06a0c25058234eb696c383e2180f8697.
INFO 12-25 13:55:27 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 109.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:27 logger.py:37] Received request chatcmpl-7457f61c862f4d3a819d96f6c917a0b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the meeting scene at the beginning of the video, who didn\'t quit the Justice League?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:27 engine.py:267] Added request chatcmpl-7457f61c862f4d3a819d96f6c917a0b5.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:29 logger.py:37] Received request chatcmpl-6ce44c0fa95d4be0b95373177e4d0b81: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the black stickman and the red stickman in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:29 engine.py:267] Added request chatcmpl-6ce44c0fa95d4be0b95373177e4d0b81.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:31 logger.py:37] Received request chatcmpl-8c7615b862cb454896254f219bbb19a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the man who wear a T-shirt with the words "BLUE GHOST" on it?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:31 engine.py:267] Added request chatcmpl-8c7615b862cb454896254f219bbb19a3.
INFO 12-25 13:55:32 metrics.py:449] Avg prompt throughput: 43.2 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:33 logger.py:37] Received request chatcmpl-a3837c41d647485eb30d2847e93baf4e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, who protects the mermaid?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:33 engine.py:267] Added request chatcmpl-a3837c41d647485eb30d2847e93baf4e.
INFO 12-25 13:55:34 logger.py:37] Received request chatcmpl-2593d738b42b44c6a8097b64272e3e50: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video tell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:34 engine.py:267] Added request chatcmpl-2593d738b42b44c6a8097b64272e3e50.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:36 logger.py:37] Received request chatcmpl-84fbe076ba8745bda71b3aa59e192a15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what is the final story\'s theme?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:36 engine.py:267] Added request chatcmpl-84fbe076ba8745bda71b3aa59e192a15.
INFO 12-25 13:55:37 metrics.py:449] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 126.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:40 logger.py:37] Received request chatcmpl-b5bde8cb985e4983bccedd27b801f003: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many audio-like products are shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:40 engine.py:267] Added request chatcmpl-b5bde8cb985e4983bccedd27b801f003.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:41 logger.py:37] Received request chatcmpl-1b3c5c4d5a45470e8d918bb53726d088: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What factors may not be pertinent to an author\'s assessment of a technology product?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:41 engine.py:267] Added request chatcmpl-1b3c5c4d5a45470e8d918bb53726d088.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:42 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 112.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:43 logger.py:37] Received request chatcmpl-c06a2a35684a4bdd86bbf6e401407494: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the man with a laughing face do at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:43 engine.py:267] Added request chatcmpl-c06a2a35684a4bdd86bbf6e401407494.
INFO 12-25 13:55:44 logger.py:37] Received request chatcmpl-b41a9abab9d5425396ab1dcc7f6728a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what is the weakness of the villain?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:44 engine.py:267] Added request chatcmpl-b41a9abab9d5425396ab1dcc7f6728a3.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:47 logger.py:37] Received request chatcmpl-fd7d1ce797e44c51a10d0ffbea437afc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what is the function of the necklace that the girl stole from the museum?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:47 engine.py:267] Added request chatcmpl-fd7d1ce797e44c51a10d0ffbea437afc.
INFO 12-25 13:55:47 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:48 logger.py:37] Received request chatcmpl-cf9a3b5f40e14b66a9d5578564cffacd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do heroes of legend use to defeat the enemy based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:48 engine.py:267] Added request chatcmpl-cf9a3b5f40e14b66a9d5578564cffacd.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:51 logger.py:37] Received request chatcmpl-30a10e3c6c474594907612e95dbd433a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens to the computer in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:51 engine.py:267] Added request chatcmpl-30a10e3c6c474594907612e95dbd433a.
INFO 12-25 13:55:51 logger.py:37] Received request chatcmpl-0508c8ea73904372a83bb8b5db904571: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, how did the man, who was wearing a bandage and holding an envelope, sustain his injury?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:52 engine.py:267] Added request chatcmpl-0508c8ea73904372a83bb8b5db904571.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:52 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 119.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:55:53 logger.py:37] Received request chatcmpl-7a7490f4ef4e4f82a72b2823f8bd063f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:53 engine.py:267] Added request chatcmpl-7a7490f4ef4e4f82a72b2823f8bd063f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:55:56 logger.py:37] Received request chatcmpl-f55482aa0b0645e5b8289dfb7a74415e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the people in the village do according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:56 engine.py:267] Added request chatcmpl-f55482aa0b0645e5b8289dfb7a74415e.
INFO 12-25 13:55:57 logger.py:37] Received request chatcmpl-edf5fa5a00e84f2aa21899cc610ed57b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, why do the two people in the moving giant castle get out?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:55:57 engine.py:267] Added request chatcmpl-edf5fa5a00e84f2aa21899cc610ed57b.
INFO 12-25 13:55:57 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 123.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:00 logger.py:37] Received request chatcmpl-e855185980f5496ab189eebdffc54313: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Kevin hug and apologize to the boy named Holden in the middle of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:00 engine.py:267] Added request chatcmpl-e855185980f5496ab189eebdffc54313.
INFO 12-25 13:56:01 logger.py:37] Received request chatcmpl-99d1d37d35fd41ef85f36c4b120964a4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what does the team do in the first story?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:01 engine.py:267] Added request chatcmpl-99d1d37d35fd41ef85f36c4b120964a4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:02 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 110.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:03 logger.py:37] Received request chatcmpl-70d6a4bcc28047d8a465dd8aa41445ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, why does the orange stickman want to destroy the Minecraft world?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:03 engine.py:267] Added request chatcmpl-70d6a4bcc28047d8a465dd8aa41445ff.
INFO 12-25 13:56:03 logger.py:37] Received request chatcmpl-aa77c2e62b0c4acda9dfad81dcd42673: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, why does the orange stick man stop destroying?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:03 engine.py:267] Added request chatcmpl-aa77c2e62b0c4acda9dfad81dcd42673.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:07 metrics.py:449] Avg prompt throughput: 28.0 tokens/s, Avg generation throughput: 111.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:08 logger.py:37] Received request chatcmpl-e19e429c58d349cbabec70332c781336: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do Tom and Jerry share a similarity as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:08 logger.py:37] Received request chatcmpl-63018f3aafab4548b937c944b27b2974: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Throughout the video, why does the woman named Jane undergo a personality change?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:08 engine.py:267] Added request chatcmpl-e19e429c58d349cbabec70332c781336.
INFO 12-25 13:56:08 engine.py:267] Added request chatcmpl-63018f3aafab4548b937c944b27b2974.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:11 logger.py:37] Received request chatcmpl-d230920630cc4a71b2019a45d46ed934: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video entail?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:11 engine.py:267] Added request chatcmpl-d230920630cc4a71b2019a45d46ed934.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:12 logger.py:37] Received request chatcmpl-42fb42c4c6eb45c599f14430fd28ad67: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "During the 39th to 43rd minute of the film, why does Mike Ross give Nathan a check?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:12 engine.py:267] Added request chatcmpl-42fb42c4c6eb45c599f14430fd28ad67.
INFO 12-25 13:56:12 metrics.py:449] Avg prompt throughput: 53.5 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:15 logger.py:37] Received request chatcmpl-96905e74190b458996318397c18103aa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is Arya Stark when she was a child?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:15 engine.py:267] Added request chatcmpl-96905e74190b458996318397c18103aa.
INFO 12-25 13:56:16 logger.py:37] Received request chatcmpl-eeb1535028f4400582d4500eee3993d3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the power of the song according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:16 engine.py:267] Added request chatcmpl-eeb1535028f4400582d4500eee3993d3.
INFO 12-25 13:56:17 metrics.py:449] Avg prompt throughput: 25.4 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:19 logger.py:37] Received request chatcmpl-03a012aaa6ab49a1a5398b4c0e1d2f2a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, how is the relationship between the rabbit and human?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:19 engine.py:267] Added request chatcmpl-03a012aaa6ab49a1a5398b4c0e1d2f2a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:22 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 114.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:23 logger.py:37] Received request chatcmpl-6a1268c43f8a439e80730914daf455ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first half of the video, why did the big boy wearing a striped shirt refuse the request of the little boy wearing swimming goggles to watch TV together?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:23 logger.py:37] Received request chatcmpl-78678abbc2654a7087ddcaf92c740189: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the greatest fighter according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:23 engine.py:267] Added request chatcmpl-6a1268c43f8a439e80730914daf455ff.
INFO 12-25 13:56:23 engine.py:267] Added request chatcmpl-78678abbc2654a7087ddcaf92c740189.
INFO 12-25 13:56:24 logger.py:37] Received request chatcmpl-ef32f8b36195459eb7e46b73cf1c8a8d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the impression of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:24 engine.py:267] Added request chatcmpl-ef32f8b36195459eb7e46b73cf1c8a8d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:27 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 124.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:27 logger.py:37] Received request chatcmpl-578c40334413417090c074da363c3970: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how was Victor ultimately healed and able to control his new abilities?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:27 engine.py:267] Added request chatcmpl-578c40334413417090c074da363c3970.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:29 logger.py:37] Received request chatcmpl-f0b666d47ad84466b1f8be91819d5dbc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Joker give bomb controler to both people of boats respectively?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:29 engine.py:267] Added request chatcmpl-f0b666d47ad84466b1f8be91819d5dbc.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:31 logger.py:37] Received request chatcmpl-a8552ec946d14553b7c67a9762eb3291: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When Jane saw Grayson in the office, she shed tears. What was Jane\'s mood at this moment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:31 engine.py:267] Added request chatcmpl-a8552ec946d14553b7c67a9762eb3291.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:32 logger.py:37] Received request chatcmpl-7a561e8ef1834c27aa80118075349f9f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times do news segments appear in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:32 engine.py:267] Added request chatcmpl-7a561e8ef1834c27aa80118075349f9f.
INFO 12-25 13:56:32 metrics.py:449] Avg prompt throughput: 54.6 tokens/s, Avg generation throughput: 107.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:33 logger.py:37] Received request chatcmpl-401b79d2c9f2414db33ec8428673baf6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when the figures in the video are electrocuted?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:33 engine.py:267] Added request chatcmpl-401b79d2c9f2414db33ec8428673baf6.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:36 logger.py:37] Received request chatcmpl-61028f2469ad464cae95eba0fcb0e930: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the speaker\'s attitude to the new version movie?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:36 engine.py:267] Added request chatcmpl-61028f2469ad464cae95eba0fcb0e930.
INFO 12-25 13:56:37 metrics.py:449] Avg prompt throughput: 25.7 tokens/s, Avg generation throughput: 140.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:40 logger.py:37] Received request chatcmpl-32b0154314df4a90a81427a44087ad88: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, when Claire says "This means" to Luke, the man in a suit, what does this statement imply?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:40 engine.py:267] Added request chatcmpl-32b0154314df4a90a81427a44087ad88.
INFO 12-25 13:56:41 logger.py:37] Received request chatcmpl-b7d3de1abb73465aad7f0d8db26bc679: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did Jessica Pearson send Harvey a text message saying "I need you" in the first six minutes of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:41 engine.py:267] Added request chatcmpl-b7d3de1abb73465aad7f0d8db26bc679.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:42 metrics.py:449] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 123.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:43 logger.py:37] Received request chatcmpl-2f5ad6f6a09e439bbd021aa0561a9857: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What research did Oliver Niebuhr conduct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:43 engine.py:267] Added request chatcmpl-2f5ad6f6a09e439bbd021aa0561a9857.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:47 logger.py:37] Received request chatcmpl-6da2b74549c44a49848ed0d9a5190da4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what is the relationship of Tom and Jerry when they meet the witch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:47 engine.py:267] Added request chatcmpl-6da2b74549c44a49848ed0d9a5190da4.
INFO 12-25 13:56:47 metrics.py:449] Avg prompt throughput: 26.4 tokens/s, Avg generation throughput: 99.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:48 logger.py:37] Received request chatcmpl-8a2525ae1e964010a8a17a3fd4e4089b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the man in the suit and tie caution Wayne against following in his family\'s footsteps early in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:48 logger.py:37] Received request chatcmpl-8f4f5b30b51c4889af3f0a99cd41a7d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:48 engine.py:267] Added request chatcmpl-8a2525ae1e964010a8a17a3fd4e4089b.
INFO 12-25 13:56:48 engine.py:267] Added request chatcmpl-8f4f5b30b51c4889af3f0a99cd41a7d8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:51 logger.py:37] Received request chatcmpl-4e02df0f2f6e41198e0cd0e039668602: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, why does Tony say, "We had a great day today"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:51 engine.py:267] Added request chatcmpl-4e02df0f2f6e41198e0cd0e039668602.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:52 metrics.py:449] Avg prompt throughput: 41.2 tokens/s, Avg generation throughput: 129.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:53 logger.py:37] Received request chatcmpl-5ff49cbecb144c85a8e33e298008e123: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Between the 6th and 13th minutes of the video, why does Jessica Pearson specifically invite Mike Ross to have dinner together?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:53 engine.py:267] Added request chatcmpl-5ff49cbecb144c85a8e33e298008e123.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:55 logger.py:37] Received request chatcmpl-7d696a2a1d1d428cb7404385745b200f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does bat-man stop the truck Joker drives?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:55 engine.py:267] Added request chatcmpl-7d696a2a1d1d428cb7404385745b200f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:56:57 logger.py:37] Received request chatcmpl-67327fe3426d47f6b32a0a435eb8eb9b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Kevin show a nervous state when answering the phone in the second half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:57 engine.py:267] Added request chatcmpl-67327fe3426d47f6b32a0a435eb8eb9b.
INFO 12-25 13:56:57 metrics.py:449] Avg prompt throughput: 42.4 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:56:58 logger.py:37] Received request chatcmpl-200006530b7b458ebae90b60e5ebd844: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the video introduce a family who raises two children, showcasing conflicting points within the family? And what problem does it elaborate on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:56:58 engine.py:267] Added request chatcmpl-200006530b7b458ebae90b60e5ebd844.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:01 logger.py:37] Received request chatcmpl-cb2dd9dfbe57429db6db3c6ffd6b2de4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early part of the video, the man whose window was smashed by Wayne, and the woman wearing a pattern with white triangles, who is chatting with Wayne\'s father in the middle part of the video, what is their relationship?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:01 engine.py:267] Added request chatcmpl-cb2dd9dfbe57429db6db3c6ffd6b2de4.
INFO 12-25 13:57:02 logger.py:37] Received request chatcmpl-600e33a708754722bccea787b92aa032: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When Penny enters the laundry room, what color clothes is Leonard folding?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:02 engine.py:267] Added request chatcmpl-600e33a708754722bccea787b92aa032.
INFO 12-25 13:57:02 metrics.py:449] Avg prompt throughput: 48.6 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:06 logger.py:37] Received request chatcmpl-c660ad6dc928442f81bb9145d7be9661: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is Theresa Woo\'s profession?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:06 logger.py:37] Received request chatcmpl-27310f08a3ec4861bb97e4c074769bb6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following impacts of water scarcity was NOT mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:06 engine.py:267] Added request chatcmpl-c660ad6dc928442f81bb9145d7be9661.
INFO 12-25 13:57:06 engine.py:267] Added request chatcmpl-27310f08a3ec4861bb97e4c074769bb6.
INFO 12-25 13:57:07 metrics.py:449] Avg prompt throughput: 25.2 tokens/s, Avg generation throughput: 127.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:10 logger.py:37] Received request chatcmpl-88c28360ee754c4db391c906b8e8bf64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the experiment in which a man with a ponytail invited volunteers to assess the accuracy of determining COVID-19 infection based on voice, aiming to explore?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:10 engine.py:267] Added request chatcmpl-88c28360ee754c4db391c906b8e8bf64.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:11 logger.py:37] Received request chatcmpl-e625d9f588324438be969eeebbe6d5f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the girl most important quality?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:11 engine.py:267] Added request chatcmpl-e625d9f588324438be969eeebbe6d5f1.
INFO 12-25 13:57:11 logger.py:37] Received request chatcmpl-def86092ac0e4eecb4bdf3968effda60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can\'t be inferred from the interview with an Amish woman is shown in the latter part of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:11 engine.py:267] Added request chatcmpl-def86092ac0e4eecb4bdf3968effda60.
INFO 12-25 13:57:12 metrics.py:449] Avg prompt throughput: 43.8 tokens/s, Avg generation throughput: 104.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:14 logger.py:37] Received request chatcmpl-38ab73a892014c24ad0997a5786fe22e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Before Jane spills the nail polish, why does Grayson, who is wearing a black suit and a red tie, sit on the couch with a grim expression?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:14 engine.py:267] Added request chatcmpl-38ab73a892014c24ad0997a5786fe22e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:17 metrics.py:449] Avg prompt throughput: 16.8 tokens/s, Avg generation throughput: 123.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:18 logger.py:37] Received request chatcmpl-9589bc03ea194494a18c1bf11dc585e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Jon Snow use to fight with Ramsay Bolton?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:18 engine.py:267] Added request chatcmpl-9589bc03ea194494a18c1bf11dc585e2.
INFO 12-25 13:57:18 logger.py:37] Received request chatcmpl-51953261cff14a4a948421aea3c0a1a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the early part of the video, what can we infer as the reason for the sudden surge in popularity of crystals and gemstones?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:18 engine.py:267] Added request chatcmpl-51953261cff14a4a948421aea3c0a1a0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:20 logger.py:37] Received request chatcmpl-61e4dbaed6f4469e9c893481bb563819: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of work did the man named Tony engage in?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:20 engine.py:267] Added request chatcmpl-61e4dbaed6f4469e9c893481bb563819.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:22 logger.py:37] Received request chatcmpl-a589e282ffac4e33ae751aa7736cf21b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which episode do Penny and Leonard get married in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:22 engine.py:267] Added request chatcmpl-a589e282ffac4e33ae751aa7736cf21b.
INFO 12-25 13:57:22 metrics.py:449] Avg prompt throughput: 54.5 tokens/s, Avg generation throughput: 126.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:26 logger.py:37] Received request chatcmpl-c65aee0b899e4683936c114a13b2fceb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which country\'s drug trafficking group was responsible for the death of crime journalist De Vries?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:26 engine.py:267] Added request chatcmpl-c65aee0b899e4683936c114a13b2fceb.
INFO 12-25 13:57:27 logger.py:37] Received request chatcmpl-6ce633fe81c84da59de8bcb47bf9cf13: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why was Theresa Woo murdered?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:27 logger.py:37] Received request chatcmpl-a5c06f74c0a345fdbcb2434e5c32c343: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What motivated Taylor to make up her mind to change her and Harry\'s dietary habits?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:27 engine.py:267] Added request chatcmpl-6ce633fe81c84da59de8bcb47bf9cf13.
INFO 12-25 13:57:27 engine.py:267] Added request chatcmpl-a5c06f74c0a345fdbcb2434e5c32c343.
INFO 12-25 13:57:27 metrics.py:449] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 100.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:29 logger.py:37] Received request chatcmpl-e5fe3315b7f5409f978a0e7d69358bcc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the speaker think about the David Suchet\'s version movie?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:29 engine.py:267] Added request chatcmpl-e5fe3315b7f5409f978a0e7d69358bcc.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:33 metrics.py:449] Avg prompt throughput: 13.1 tokens/s, Avg generation throughput: 125.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:33 logger.py:37] Received request chatcmpl-6b69b5f61bed4bf293c542c94e915b57: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the order of companies mentioned in the first half of the video related to water scarcity?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:33 logger.py:37] Received request chatcmpl-b0077d3372124c719c3bd8cd8238d302: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video tell us?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:33 engine.py:267] Added request chatcmpl-6b69b5f61bed4bf293c542c94e915b57.
INFO 12-25 13:57:33 engine.py:267] Added request chatcmpl-b0077d3372124c719c3bd8cd8238d302.
INFO 12-25 13:57:34 logger.py:37] Received request chatcmpl-244307344b8e42c08afc9811a6b72570: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which company\'s management did Jamie Dimon not serve on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:34 engine.py:267] Added request chatcmpl-244307344b8e42c08afc9811a6b72570.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:36 logger.py:37] Received request chatcmpl-897e5fc67d9f464cab159e69941293bb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the later segment of the video, it was noted that "Jon is currently investigating a training method for enduring effectiveness." What is the focus of Jon Freeman\'s research?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:36 engine.py:267] Added request chatcmpl-897e5fc67d9f464cab159e69941293bb.
INFO 12-25 13:57:38 metrics.py:449] Avg prompt throughput: 56.9 tokens/s, Avg generation throughput: 127.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:42 logger.py:37] Received request chatcmpl-a82e206d89d64ae4a083e44bc21f23e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, does the male interviewee wearing a black suit have a stance that is more in favor of men or women?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:42 engine.py:267] Added request chatcmpl-a82e206d89d64ae4a083e44bc21f23e3.
INFO 12-25 13:57:43 metrics.py:449] Avg prompt throughput: 15.8 tokens/s, Avg generation throughput: 119.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:43 logger.py:37] Received request chatcmpl-4c4e72c952c7494e804bb08d55520ac3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, the price at which Jonas and Max sell drugs is approximately how many times the price in the origin country, Colombia?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:43 logger.py:37] Received request chatcmpl-0ff3a806f29e41c68d465673bbd2ab60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Joker kill his accomplices?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:43 engine.py:267] Added request chatcmpl-4c4e72c952c7494e804bb08d55520ac3.
INFO 12-25 13:57:43 engine.py:267] Added request chatcmpl-0ff3a806f29e41c68d465673bbd2ab60.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:47 logger.py:37] Received request chatcmpl-693f9b636562427cb9ffa2d47060f6a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, what mode of transportation do you think the Amish use?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:47 engine.py:267] Added request chatcmpl-693f9b636562427cb9ffa2d47060f6a8.
INFO 12-25 13:57:48 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 135.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:49 logger.py:37] Received request chatcmpl-2c0f28256c2643f0b433ec5e6cbfaf86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Leonard convince Penny to go on a date with him?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:49 engine.py:267] Added request chatcmpl-2c0f28256c2643f0b433ec5e6cbfaf86.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:51 logger.py:37] Received request chatcmpl-ad98d6e7ad8b4866b304fd9c1973da82: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the focus of the imagined world in 2050 that is introduced in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:51 engine.py:267] Added request chatcmpl-ad98d6e7ad8b4866b304fd9c1973da82.
INFO 12-25 13:57:51 logger.py:37] Received request chatcmpl-2c39dcef7f5c46f29175d29b16693423: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which conclusion cannot be drawn in the middle section, which features interviews with Australian women in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:51 engine.py:267] Added request chatcmpl-2c39dcef7f5c46f29175d29b16693423.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:53 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 106.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:53 logger.py:37] Received request chatcmpl-35538b2e38a747f9a26db94e2cbd08d6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how did the debate between Einstein and Bohr about quantum mechanics turn out?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:53 engine.py:267] Added request chatcmpl-35538b2e38a747f9a26db94e2cbd08d6.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:54 logger.py:37] Received request chatcmpl-95fce6f2df9d4acd9fb8522df7a6d126: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Poirot lead person to death in David Suchet\'s version?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:54 engine.py:267] Added request chatcmpl-95fce6f2df9d4acd9fb8522df7a6d126.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:57:58 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 123.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 13:57:59 logger.py:37] Received request chatcmpl-322e52c035914da8939ea9938c4daaad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a reason for water scarcity mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:59 logger.py:37] Received request chatcmpl-47230ca58a0c44f8afad4788a0053615: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the fourth-to-last news item in this news video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:59 engine.py:267] Added request chatcmpl-322e52c035914da8939ea9938c4daaad.
INFO 12-25 13:57:59 engine.py:267] Added request chatcmpl-47230ca58a0c44f8afad4788a0053615.
INFO 12-25 13:57:59 logger.py:37] Received request chatcmpl-9a961e859e4442a7923a57758d7bd2ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the differing motivations for buying unhealthy food in the early part of the video between Cuba\'s family and Michael\'s family?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:57:59 engine.py:267] Added request chatcmpl-9a961e859e4442a7923a57758d7bd2ae.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:01 logger.py:37] Received request chatcmpl-cc8a5c19a9a04a728d3d1f0fb8efddfa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After receiving a one-time benefit of 26,000, what transformation did the three families experience?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:01 engine.py:267] Added request chatcmpl-cc8a5c19a9a04a728d3d1f0fb8efddfa.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:03 metrics.py:449] Avg prompt throughput: 56.9 tokens/s, Avg generation throughput: 113.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:03 logger.py:37] Received request chatcmpl-e1b08d8690c746d0a3d65781686dfb53: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what inconsistency in quantum mechanics was discovered by Einstein and published in a paper?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:03 engine.py:267] Added request chatcmpl-e1b08d8690c746d0a3d65781686dfb53.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:05 logger.py:37] Received request chatcmpl-745f8e286b134301a444d5d7c9f2a668: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the use of spinal cord stimulators to treat Teresa Burbery and Gordon Myers indicate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:05 engine.py:267] Added request chatcmpl-745f8e286b134301a444d5d7c9f2a668.
INFO 12-25 13:58:06 logger.py:37] Received request chatcmpl-1e5837e9bba843f989a1a680c4181740: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following was not a factor in Sandy Weill\'s decision to dismiss Jamie Dimon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:06 engine.py:267] Added request chatcmpl-1e5837e9bba843f989a1a680c4181740.
INFO 12-25 13:58:08 metrics.py:449] Avg prompt throughput: 42.9 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:09 logger.py:37] Received request chatcmpl-42ff256f17724db28b253c51d0f1d3fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the content of the video, why did the local government send an entourage to follow the reporter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:09 engine.py:267] Added request chatcmpl-42ff256f17724db28b253c51d0f1d3fe.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:11 logger.py:37] Received request chatcmpl-bc7e925343c54f5aa108a4978f5ff565: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many people interviewed in the video are unwilling to show their faces?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:11 engine.py:267] Added request chatcmpl-bc7e925343c54f5aa108a4978f5ff565.
INFO 12-25 13:58:11 logger.py:37] Received request chatcmpl-b8f4e1a3bb40404eb909691ee2acb5ee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle section of the video, regarding the news about a ship colliding with a bridge, how do the news anchor and the guest judge when the first power outage occurred on the ship in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:11 engine.py:267] Added request chatcmpl-b8f4e1a3bb40404eb909691ee2acb5ee.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:13 metrics.py:449] Avg prompt throughput: 46.7 tokens/s, Avg generation throughput: 103.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:13 logger.py:37] Received request chatcmpl-3dee9b71fda6471298eba517095e9c4a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, how many low-income individuals affected by housing issues were interviewed in total?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:13 engine.py:267] Added request chatcmpl-3dee9b71fda6471298eba517095e9c4a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:17 logger.py:37] Received request chatcmpl-030ef6003cc6411a85713f9853db03c8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the entire video, what kind of transformation occurred with the child named Cuba?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:17 engine.py:267] Added request chatcmpl-030ef6003cc6411a85713f9853db03c8.
INFO 12-25 13:58:18 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:18 logger.py:37] Received request chatcmpl-02f1baf542434ed9ad133a6229f4b87a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of the first section in the video, imagine the sections are separated by an opening frame?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:18 engine.py:267] Added request chatcmpl-02f1baf542434ed9ad133a6229f4b87a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:20 logger.py:37] Received request chatcmpl-8205f8620d824a7993c61e706496887a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the beginning of the video, what do the red-marked countries on the world map represent?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:20 engine.py:267] Added request chatcmpl-8205f8620d824a7993c61e706496887a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:21 logger.py:37] Received request chatcmpl-b85849ff96bc41908bfd8ede82d68d75: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, what is the sentiment of the four Russian defectors towards a woman named Judy Tulk?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:21 engine.py:267] Added request chatcmpl-b85849ff96bc41908bfd8ede82d68d75.
INFO 12-25 13:58:23 metrics.py:449] Avg prompt throughput: 44.4 tokens/s, Avg generation throughput: 127.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:25 logger.py:37] Received request chatcmpl-0944b129818748a4b3ca9c57d00043a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What religion can we infer from the video that the Amish practice?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:25 engine.py:267] Added request chatcmpl-0944b129818748a4b3ca9c57d00043a7.
INFO 12-25 13:58:25 logger.py:37] Received request chatcmpl-09af8c0940ce469fb72070ff122551c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following contents was NOT mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:25 engine.py:267] Added request chatcmpl-09af8c0940ce469fb72070ff122551c6.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:28 metrics.py:449] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:29 logger.py:37] Received request chatcmpl-86ea19ee0e004ee2a147e740a9547dec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, a woman believed her son had died due to a hospital\'s mistake with information. What impact did this incident have on her family relationships?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:29 logger.py:37] Received request chatcmpl-ff3d71af74cb41e89892e5cbf39ed431: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item is not used in the video where the guest demonstrates making a solar eclipse observing tool?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:29 engine.py:267] Added request chatcmpl-86ea19ee0e004ee2a147e740a9547dec.
INFO 12-25 13:58:29 engine.py:267] Added request chatcmpl-ff3d71af74cb41e89892e5cbf39ed431.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:31 logger.py:37] Received request chatcmpl-d0f918c1a919433591c5170fb2e98e6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video repeatedly shows a person at a table, lifting a cup and another cup also floating up, with two light balls under each cup. What is this segment trying to show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:31 engine.py:267] Added request chatcmpl-d0f918c1a919433591c5170fb2e98e6f.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:33 metrics.py:449] Avg prompt throughput: 48.3 tokens/s, Avg generation throughput: 121.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:33 logger.py:37] Received request chatcmpl-4925b8f38fbc4fd092430855995c548f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, the male interviewee wearing a tight black shirt told a joke about his experience in a popular culture class. He said if there\'s a movie that more than half of the class has seen, he would buy everyone pizza. Many years have passed, and he hasn\'t found such a movie yet. What does he imply with this joke?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:33 engine.py:267] Added request chatcmpl-4925b8f38fbc4fd092430855995c548f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:35 logger.py:37] Received request chatcmpl-a02948e443fd49019852a5299fa828d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the interviewees in the video, which of the following is not a benefit of delaying aging?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:35 logger.py:37] Received request chatcmpl-52e038cbc0ac4fea94276b4cb452bd36: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What should team T1 do if they want to win this game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:35 engine.py:267] Added request chatcmpl-a02948e443fd49019852a5299fa828d5.
INFO 12-25 13:58:35 engine.py:267] Added request chatcmpl-52e038cbc0ac4fea94276b4cb452bd36.
INFO 12-25 13:58:38 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 120.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:42 logger.py:37] Received request chatcmpl-c26683a8f2ad45ac9f560495b3000c16: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the final battle unfold?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:42 engine.py:267] Added request chatcmpl-c26683a8f2ad45ac9f560495b3000c16.
INFO 12-25 13:58:43 metrics.py:449] Avg prompt throughput: 11.8 tokens/s, Avg generation throughput: 80.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:43 logger.py:37] Received request chatcmpl-4e4b5991cb2f4ecd9e9c4e08410b0dfb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the content of the video, what does the word "dirty" most likely refer to in the video title "The dirty business of beauty"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:43 logger.py:37] Received request chatcmpl-210d84024418431e9d511b1dc3a53162: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the final part of the video, an interview was conducted with a white woman and a black man. What is the relevance of this interview to the theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:43 logger.py:37] Received request chatcmpl-6241087891ed4b518abe07b91f6bfba8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "From the initial section of the video, which of the following is NOT a factor contributing to Jessica\'s unstable housing situation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:43 engine.py:267] Added request chatcmpl-4e4b5991cb2f4ecd9e9c4e08410b0dfb.
INFO 12-25 13:58:43 engine.py:267] Added request chatcmpl-210d84024418431e9d511b1dc3a53162.
INFO 12-25 13:58:43 engine.py:267] Added request chatcmpl-6241087891ed4b518abe07b91f6bfba8.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:48 metrics.py:449] Avg prompt throughput: 48.8 tokens/s, Avg generation throughput: 123.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:48 logger.py:37] Received request chatcmpl-7f1a9796f2db4dc39a0d61c4d1a742e6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do the hosts talk about lemon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:48 logger.py:37] Received request chatcmpl-94d8d7351417400792901392b111a926: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following is NOT a reason for the surge in the number of private commercial DNA laboratories?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:48 engine.py:267] Added request chatcmpl-7f1a9796f2db4dc39a0d61c4d1a742e6.
INFO 12-25 13:58:48 engine.py:267] Added request chatcmpl-94d8d7351417400792901392b111a926.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:50 logger.py:37] Received request chatcmpl-17a0dbe8759b44a38dbe4deddb40f81e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which person\'s anti-aging research did not mention biological clinical trials?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:50 engine.py:267] Added request chatcmpl-17a0dbe8759b44a38dbe4deddb40f81e.
INFO 12-25 13:58:51 logger.py:37] Received request chatcmpl-adf26e1c8141485b91fd261059436528: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did Jamie Dimon turn down numerous job offers from famous Wall Street investment banks to work for Sandy Weill?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:51 engine.py:267] Added request chatcmpl-adf26e1c8141485b91fd261059436528.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:53 metrics.py:449] Avg prompt throughput: 55.3 tokens/s, Avg generation throughput: 116.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:54 logger.py:37] Received request chatcmpl-90c9866e91854c37a9eb03b972a97c3e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does team WBG win the battle at the time of 17:10?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:54 engine.py:267] Added request chatcmpl-90c9866e91854c37a9eb03b972a97c3e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:57 logger.py:37] Received request chatcmpl-80fdfd4a53f948319e660b53f1c84ba1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the content of the video, what is the initial intention of B.C. having safer-supply drugs?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:57 engine.py:267] Added request chatcmpl-80fdfd4a53f948319e660b53f1c84ba1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:58:58 metrics.py:449] Avg prompt throughput: 29.1 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:58:58 logger.py:37] Received request chatcmpl-3dfcef2f0a3649eb9f83f288a92993d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the content of the video, what position does Marineland\'s statement aim to express?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:58 engine.py:267] Added request chatcmpl-3dfcef2f0a3649eb9f83f288a92993d4.
INFO 12-25 13:58:59 logger.py:37] Received request chatcmpl-3c09c0cd6ee3485fb5e57c409681247c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many patients were harmed by medical accidents in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:58:59 engine.py:267] Added request chatcmpl-3c09c0cd6ee3485fb5e57c409681247c.
INFO 12-25 13:59:03 metrics.py:449] Avg prompt throughput: 26.9 tokens/s, Avg generation throughput: 142.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:05 logger.py:37] Received request chatcmpl-68e501689e8647dd861230bdb7cbb800: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How about the pick strategy of team T1 as shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:05 engine.py:267] Added request chatcmpl-68e501689e8647dd861230bdb7cbb800.
INFO 12-25 13:59:05 logger.py:37] Received request chatcmpl-06e9f0833b004eed8156a3a8bdf63493: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who will lead their team to victory in this game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:05 engine.py:267] Added request chatcmpl-06e9f0833b004eed8156a3a8bdf63493.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:07 logger.py:37] Received request chatcmpl-8b318c39e5154e7db48e6d76f42d7146: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the content of the video, whose viewpoint is relatively the most radical?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:07 engine.py:267] Added request chatcmpl-8b318c39e5154e7db48e6d76f42d7146.
INFO 12-25 13:59:07 logger.py:37] Received request chatcmpl-53a423bee7234789ba5c2ac11cbc2f12: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which one is a condition for successfully applying for housing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:07 engine.py:267] Added request chatcmpl-53a423bee7234789ba5c2ac11cbc2f12.
INFO 12-25 13:59:08 metrics.py:449] Avg prompt throughput: 52.1 tokens/s, Avg generation throughput: 93.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:13 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 107.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:13 logger.py:37] Received request chatcmpl-101cb291951249fb92bc9e1667f30848: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, how do the jungles of two teams start?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:13 logger.py:37] Received request chatcmpl-303936e68e0e42498f7d27a4a857204d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events did not appear in the news?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:13 engine.py:267] Added request chatcmpl-101cb291951249fb92bc9e1667f30848.
INFO 12-25 13:59:13 engine.py:267] Added request chatcmpl-303936e68e0e42498f7d27a4a857204d.
INFO 12-25 13:59:13 logger.py:37] Received request chatcmpl-915aafe09a5d4e479cd64af0f3f8d54c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following news items did NOT appear in this news segment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:13 engine.py:267] Added request chatcmpl-915aafe09a5d4e479cd64af0f3f8d54c.
INFO 12-25 13:59:15 logger.py:37] Received request chatcmpl-7f7ca5a9ec63444bac9d9f392d3c18c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the player take the five cards at the beginning of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:15 engine.py:267] Added request chatcmpl-7f7ca5a9ec63444bac9d9f392d3c18c0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:18 metrics.py:449] Avg prompt throughput: 53.9 tokens/s, Avg generation throughput: 125.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:19 logger.py:37] Received request chatcmpl-0742858ea5944020bba83c33442efdad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Steve Horvath consider a viable solution for reversing aging?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:19 engine.py:267] Added request chatcmpl-0742858ea5944020bba83c33442efdad.
INFO 12-25 13:59:20 logger.py:37] Received request chatcmpl-04ce90e7cf60450baf51e927da6d1bd5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following events was not reported in this news video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:20 logger.py:37] Received request chatcmpl-bef2f14496344354bfa1a0c4d731306e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team has the most significant advantage in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:20 engine.py:267] Added request chatcmpl-04ce90e7cf60450baf51e927da6d1bd5.
INFO 12-25 13:59:20 engine.py:267] Added request chatcmpl-bef2f14496344354bfa1a0c4d731306e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:23 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 108.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:25 logger.py:37] Received request chatcmpl-073e3d6d385d4909974304d9267569a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the occupation of the character the player controls?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:25 engine.py:267] Added request chatcmpl-073e3d6d385d4909974304d9267569a9.
INFO 12-25 13:59:26 logger.py:37] Received request chatcmpl-74f10d1a93c145e49c93f7ff2199f090: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions of neurosurgeon Tom Morris mentioned in the video is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:26 logger.py:37] Received request chatcmpl-dfbb59874bb443a0a721ad1838dd9743: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Weiwei go to the tower of enemy at the time of 15:00?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:26 logger.py:37] Received request chatcmpl-6d93f41cb29e43deb7bab19dd8ec15db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which position of team WBG is stronger at the beginning of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:26 engine.py:267] Added request chatcmpl-74f10d1a93c145e49c93f7ff2199f090.
INFO 12-25 13:59:26 engine.py:267] Added request chatcmpl-dfbb59874bb443a0a721ad1838dd9743.
INFO 12-25 13:59:26 engine.py:267] Added request chatcmpl-6d93f41cb29e43deb7bab19dd8ec15db.
INFO 12-25 13:59:28 metrics.py:449] Avg prompt throughput: 54.5 tokens/s, Avg generation throughput: 81.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:30 logger.py:37] Received request chatcmpl-3630debf10034d73a6ff7431a52fd4fb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the strategy of the player?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:30 engine.py:267] Added request chatcmpl-3630debf10034d73a6ff7431a52fd4fb.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:33 logger.py:37] Received request chatcmpl-a61ac4b544464ddea642a05a749c8bc5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the successful appeal by a group of Swiss women on health and climate as a fundamental human right signify?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:33 engine.py:267] Added request chatcmpl-a61ac4b544464ddea642a05a749c8bc5.
INFO 12-25 13:59:33 metrics.py:449] Avg prompt throughput: 11.9 tokens/s, Avg generation throughput: 132.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:35 logger.py:37] Received request chatcmpl-0c7bf82a3a4e4402beca6d8e1ec4de8c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did Rookie flash over the wall at the beginning of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:35 engine.py:267] Added request chatcmpl-0c7bf82a3a4e4402beca6d8e1ec4de8c.
INFO 12-25 13:59:35 logger.py:37] Received request chatcmpl-db92ca2442d248aaa165126fdca5af9f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What strategy should team FLY take?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:35 engine.py:267] Added request chatcmpl-db92ca2442d248aaa165126fdca5af9f.
INFO 12-25 13:59:36 logger.py:37] Received request chatcmpl-82a2730583be4bdbb52f57ad377ea3a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the man on the sidelines wearing a gray top with studs talking to the camera after the game starts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:36 engine.py:267] Added request chatcmpl-82a2730583be4bdbb52f57ad377ea3a7.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:38 metrics.py:449] Avg prompt throughput: 55.4 tokens/s, Avg generation throughput: 105.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 13:59:39 logger.py:37] Received request chatcmpl-78836855246744e1b3b8c56a4176c7e9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second to last news item in this segment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:39 engine.py:267] Added request chatcmpl-78836855246744e1b3b8c56a4176c7e9.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:42 logger.py:37] Received request chatcmpl-3bf7a27542544452b9eba829a078af69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which lane of the blue team has the biggest advantage in the first ten minutes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:42 logger.py:37] Received request chatcmpl-e933298893f94940984657306e7e3d9e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, which team gets the final victory?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:42 engine.py:267] Added request chatcmpl-3bf7a27542544452b9eba829a078af69.
INFO 12-25 13:59:42 engine.py:267] Added request chatcmpl-e933298893f94940984657306e7e3d9e.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:43 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 112.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 13:59:44 logger.py:37] Received request chatcmpl-77044484db2e4a38ab4b0997b55e848f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the second news item reported in this news video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:44 logger.py:37] Received request chatcmpl-b439bbf96adf427fa5b5f011ab542fed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many valid goals does Jesse score in the final one-two session?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:44 engine.py:267] Added request chatcmpl-77044484db2e4a38ab4b0997b55e848f.
INFO 12-25 13:59:44 engine.py:267] Added request chatcmpl-b439bbf96adf427fa5b5f011ab542fed.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:47 logger.py:37] Received request chatcmpl-7433166ba45a44a1b5c823a30b5de76e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the player send a message of well met?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:47 engine.py:267] Added request chatcmpl-7433166ba45a44a1b5c823a30b5de76e.
INFO 12-25 13:59:48 metrics.py:449] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 122.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:52 logger.py:37] Received request chatcmpl-703bd8a2ea214a12a6a05aaa803dec08: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On which day after Jesse\'s tryout does the Ignite suffer a crushing defeat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:52 engine.py:267] Added request chatcmpl-703bd8a2ea214a12a6a05aaa803dec08.
INFO 12-25 13:59:52 logger.py:37] Received request chatcmpl-5615e7b34da046cdaf6db8a7337fec3b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the atmosphere in team WBG according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:52 engine.py:267] Added request chatcmpl-5615e7b34da046cdaf6db8a7337fec3b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:53 logger.py:37] Received request chatcmpl-7077ed3702fb4f42a49071672a0465aa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is the position that is banned mostly from the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:53 engine.py:267] Added request chatcmpl-7077ed3702fb4f42a49071672a0465aa.
INFO 12-25 13:59:53 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 97.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 13:59:54 logger.py:37] Received request chatcmpl-dc030eb0483e4d73bb79ef945bc16932: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the player first die?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:54 engine.py:267] Added request chatcmpl-dc030eb0483e4d73bb79ef945bc16932.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:58 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 140.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 13:59:58 logger.py:37] Received request chatcmpl-3ef52314966e48fb8b70183fb05c5db0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the comparative strengths of each team?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 13:59:58 engine.py:267] Added request chatcmpl-3ef52314966e48fb8b70183fb05c5db0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:00 logger.py:37] Received request chatcmpl-066714ac288344c78f68941d628cc091: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After buying a cup of coffee, how many challenges does the man complete?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:00 logger.py:37] Received request chatcmpl-41eb87bd6aa346159153d86cadd1e2c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many 3-pointers does the college freshman protagonist in the video hit in a practice game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:00 engine.py:267] Added request chatcmpl-066714ac288344c78f68941d628cc091.
INFO 12-25 14:00:00 engine.py:267] Added request chatcmpl-41eb87bd6aa346159153d86cadd1e2c1.
INFO 12-25 14:00:01 logger.py:37] Received request chatcmpl-e9ae3c99ac3b4e7ea4dcc220926e0d67: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How about the bottom lane at an early time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:01 engine.py:267] Added request chatcmpl-e9ae3c99ac3b4e7ea4dcc220926e0d67.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:03 metrics.py:449] Avg prompt throughput: 52.3 tokens/s, Avg generation throughput: 101.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:04 logger.py:37] Received request chatcmpl-54cb1d1fea904b7a8f2b97dee7110e40: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What type of cards does the play require at the start of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:04 engine.py:267] Added request chatcmpl-54cb1d1fea904b7a8f2b97dee7110e40.
INFO 12-25 14:00:05 logger.py:37] Received request chatcmpl-daaddfa2c3f649c780c0ec83e658a19d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletic goals did LIT score from the last technical statistic on shooting percentage before halftime to the end of the half?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:05 engine.py:267] Added request chatcmpl-daaddfa2c3f649c780c0ec83e658a19d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:07 logger.py:37] Received request chatcmpl-7e5b7986d6fc4c70a8a8581ca92ddd8b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the least flattering of the gadgets featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:07 engine.py:267] Added request chatcmpl-7e5b7986d6fc4c70a8a8581ca92ddd8b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:08 metrics.py:449] Avg prompt throughput: 41.7 tokens/s, Avg generation throughput: 112.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:00:09 logger.py:37] Received request chatcmpl-814c35f477d741d4a4791389e3fab3b8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which cost of card has the fewest number?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:09 logger.py:37] Received request chatcmpl-f8a48599e2974c0a8e8dafdbfe9cf77c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who has the maximum kill streak according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:09 engine.py:267] Added request chatcmpl-814c35f477d741d4a4791389e3fab3b8.
INFO 12-25 14:00:09 engine.py:267] Added request chatcmpl-f8a48599e2974c0a8e8dafdbfe9cf77c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:13 logger.py:37] Received request chatcmpl-7313b8f62f7245339f9ed1cefeb1848c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did Pau Gasol say he was willing to break his leg?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:13 engine.py:267] Added request chatcmpl-7313b8f62f7245339f9ed1cefeb1848c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:13 metrics.py:449] Avg prompt throughput: 38.3 tokens/s, Avg generation throughput: 100.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:00:13 logger.py:37] Received request chatcmpl-9fd997c3601b408f9a32d5a89a1ce9cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why doesn\'t Jesse make it past the Ignite team to the tryouts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:13 engine.py:267] Added request chatcmpl-9fd997c3601b408f9a32d5a89a1ce9cd.
INFO 12-25 14:00:14 logger.py:37] Received request chatcmpl-b8b6cf6e3a724ff1b6f8c227ef19fb69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video document?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:14 engine.py:267] Added request chatcmpl-b8b6cf6e3a724ff1b6f8c227ef19fb69.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:16 logger.py:37] Received request chatcmpl-1c46f1a50bd849a18b0030594195e5d4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happens when it is at ban/pick time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:16 engine.py:267] Added request chatcmpl-1c46f1a50bd849a18b0030594195e5d4.
INFO 12-25 14:00:18 metrics.py:449] Avg prompt throughput: 37.7 tokens/s, Avg generation throughput: 129.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:20 logger.py:37] Received request chatcmpl-37c42c1511b143e9b48b06bdf6898026: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions best summarizes Cameron?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:20 engine.py:267] Added request chatcmpl-37c42c1511b143e9b48b06bdf6898026.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:21 logger.py:37] Received request chatcmpl-7b34095416d344abbcabd10421533da0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What game do they play to discover that Wiggins shoots 44.8% from the field in the game of Wiggins guessing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:21 engine.py:267] Added request chatcmpl-7b34095416d344abbcabd10421533da0.
INFO 12-25 14:00:23 logger.py:37] Received request chatcmpl-8007c046ddcb4fd5a92688622fa2570a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which type of grenade was not featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:23 logger.py:37] Received request chatcmpl-fdb8862ed6ae42cda686ff4954cb7afa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the home team\'s top scorer?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:23 engine.py:267] Added request chatcmpl-8007c046ddcb4fd5a92688622fa2570a.
INFO 12-25 14:00:23 engine.py:267] Added request chatcmpl-fdb8862ed6ae42cda686ff4954cb7afa.
INFO 12-25 14:00:23 metrics.py:449] Avg prompt throughput: 52.9 tokens/s, Avg generation throughput: 93.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:25 logger.py:37] Received request chatcmpl-3bb602619b0943f2bd014dc6a4495284: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the team on the counterattack after Sabonis\' first steal?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:25 engine.py:267] Added request chatcmpl-3bb602619b0943f2bd014dc6a4495284.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:27 logger.py:37] Received request chatcmpl-5c8a027c24e24129a28e51c84a4baa6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What tool in the video had the least impact on the player\'s ability to complete the challenge?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:27 engine.py:267] Added request chatcmpl-5c8a027c24e24129a28e51c84a4baa6f.
INFO 12-25 14:00:28 metrics.py:449] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 120.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:00:28 logger.py:37] Received request chatcmpl-c2282dd0d5b34b93bf4e73e908062367: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the occupation of the character that the player uses?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:28 engine.py:267] Added request chatcmpl-c2282dd0d5b34b93bf4e73e908062367.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:31 logger.py:37] Received request chatcmpl-193ceeb7c1304d81a21f4a518ba1c9d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What led to the decline of the Soviet men\'s basketball team\'s dominance after 1990?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:31 logger.py:37] Received request chatcmpl-077d43c735864bedb448e86e599a02e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many timeout substitutions were there during the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:31 engine.py:267] Added request chatcmpl-193ceeb7c1304d81a21f4a518ba1c9d2.
INFO 12-25 14:00:31 engine.py:267] Added request chatcmpl-077d43c735864bedb448e86e599a02e2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:33 metrics.py:449] Avg prompt throughput: 40.3 tokens/s, Avg generation throughput: 111.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:00:33 logger.py:37] Received request chatcmpl-3dee6405348846e9b3434dac3ac20e06: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which lane does the player start in at the beginning of the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:33 engine.py:267] Added request chatcmpl-3dee6405348846e9b3434dac3ac20e06.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:35 logger.py:37] Received request chatcmpl-69af02e4c94647d084321eb9bd4b504d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does Cameron achieve in his debut practice game in Las Vegas?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:35 engine.py:267] Added request chatcmpl-69af02e4c94647d084321eb9bd4b504d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:38 logger.py:37] Received request chatcmpl-b4a8b4f615ca47c1a1b3b8937bf3740d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did Florentino Perez fail to create a well-rounded team capable of competing?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:38 engine.py:267] Added request chatcmpl-b4a8b4f615ca47c1a1b3b8937bf3740d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:38 metrics.py:449] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 122.4 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:40 logger.py:37] Received request chatcmpl-fb2df15f238d4871828cba066369bc45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What character is the person speaking to the group at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:40 logger.py:37] Received request chatcmpl-c718e310db9745d98fb955b1335aa382: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the rules for the initial 2v2 basketball mini-game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:40 engine.py:267] Added request chatcmpl-fb2df15f238d4871828cba066369bc45.
INFO 12-25 14:00:40 engine.py:267] Added request chatcmpl-c718e310db9745d98fb955b1335aa382.
INFO 12-25 14:00:40 logger.py:37] Received request chatcmpl-e7be838da9be4d6899241b07267c840a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is presented successively in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:40 engine.py:267] Added request chatcmpl-e7be838da9be4d6899241b07267c840a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:43 logger.py:37] Received request chatcmpl-9527d9247d864758a9a94458cb962e09: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the video featuring Ronaldo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:43 engine.py:267] Added request chatcmpl-9527d9247d864758a9a94458cb962e09.
INFO 12-25 14:00:43 metrics.py:449] Avg prompt throughput: 51.7 tokens/s, Avg generation throughput: 96.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:46 logger.py:37] Received request chatcmpl-788ce1d0561348e4a6f749d4a3be444d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many timeouts does the HUN actively consume throughout the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:46 engine.py:267] Added request chatcmpl-788ce1d0561348e4a6f749d4a3be444d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:48 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 134.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:00:49 logger.py:37] Received request chatcmpl-ed5431a11f83482b8500eb529fec0e8b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What evaluation does the video provide of the introduced football club\'s performance in the 2019/20 Premier League season?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:49 engine.py:267] Added request chatcmpl-ed5431a11f83482b8500eb529fec0e8b.
INFO 12-25 14:00:50 logger.py:37] Received request chatcmpl-8f3a8c5cdc014fffb6062c682c3a3e43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which period does the home team overtake the guest team?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:50 engine.py:267] Added request chatcmpl-8f3a8c5cdc014fffb6062c682c3a3e43.
INFO 12-25 14:00:53 metrics.py:449] Avg prompt throughput: 28.7 tokens/s, Avg generation throughput: 133.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:55 logger.py:37] Received request chatcmpl-9ce368252d0142e1a6fb0f7c5fb9404a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many goals did the number 9 of the blue team score in the match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:56 engine.py:267] Added request chatcmpl-9ce368252d0142e1a6fb0f7c5fb9404a.
INFO 12-25 14:00:56 logger.py:37] Received request chatcmpl-1c07e30e02a64b8e965a12cf24b35ad1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is Rakija introduced at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:56 engine.py:267] Added request chatcmpl-1c07e30e02a64b8e965a12cf24b35ad1.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:00:57 logger.py:37] Received request chatcmpl-acc194ea8e9940a1b778cd76880cbada: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How would you describe the number 11 in the red shirt\'s performance in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:57 engine.py:267] Added request chatcmpl-acc194ea8e9940a1b778cd76880cbada.
INFO 12-25 14:00:57 logger.py:37] Received request chatcmpl-318a384f79ef48ab8ce5cacee550982b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is Jesse absent from the first game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:00:57 engine.py:267] Added request chatcmpl-318a384f79ef48ab8ce5cacee550982b.
INFO 12-25 14:00:58 metrics.py:449] Avg prompt throughput: 53.0 tokens/s, Avg generation throughput: 88.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:02 logger.py:37] Received request chatcmpl-88163b98e6244f07b3b71652cfc80bc1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why was the man with glass selected as the president of the club according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:02 engine.py:267] Added request chatcmpl-88163b98e6244f07b3b71652cfc80bc1.
INFO 12-25 14:01:03 logger.py:37] Received request chatcmpl-f79cf438589b498ba2c0e76ec5e417ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the Guess Nash matchup, which game has similar rules to the third game in Guess Wiggins?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:03 engine.py:267] Added request chatcmpl-f79cf438589b498ba2c0e76ec5e417ff.
INFO 12-25 14:01:03 metrics.py:449] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 109.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:04 logger.py:37] Received request chatcmpl-206dff3a65f34faa815d6fdf4dbdcbfa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:04 engine.py:267] Added request chatcmpl-206dff3a65f34faa815d6fdf4dbdcbfa.
INFO 12-25 14:01:05 logger.py:37] Received request chatcmpl-2ac395e5658b4ee8acdc653f6401b4a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What story does this documentary tell?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:05 engine.py:267] Added request chatcmpl-2ac395e5658b4ee8acdc653f6401b4a0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:08 metrics.py:449] Avg prompt throughput: 23.9 tokens/s, Avg generation throughput: 118.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:01:09 logger.py:37] Received request chatcmpl-8271773866e0441f9583beabeab440b7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did the match in the video progress in terms of scoring, leading up to its conclusion?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:09 engine.py:267] Added request chatcmpl-8271773866e0441f9583beabeab440b7.
INFO 12-25 14:01:10 logger.py:37] Received request chatcmpl-63fbeced75604890a1eeb2f014f9bcdd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the winner win the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:10 logger.py:37] Received request chatcmpl-9ff274244a104be4a897018a8e46d1e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video\'s assessment of the main character based on the details provided in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:10 engine.py:267] Added request chatcmpl-63fbeced75604890a1eeb2f014f9bcdd.
INFO 12-25 14:01:10 engine.py:267] Added request chatcmpl-9ff274244a104be4a897018a8e46d1e2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:13 logger.py:37] Received request chatcmpl-3cab7af38f3b4e919c2cde7c78b5bb5b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which task does the man continue to do from day one to day two?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:13 engine.py:267] Added request chatcmpl-3cab7af38f3b4e919c2cde7c78b5bb5b.
INFO 12-25 14:01:13 metrics.py:449] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 108.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:15 logger.py:37] Received request chatcmpl-bf7b4d38de304753aa5d0bf48d839b21: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How would you assess the passing skills as suggested in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:15 engine.py:267] Added request chatcmpl-bf7b4d38de304753aa5d0bf48d839b21.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:16 logger.py:37] Received request chatcmpl-13e434b07d1145b9a03a35bfa59172fe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:16 engine.py:267] Added request chatcmpl-13e434b07d1145b9a03a35bfa59172fe.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:18 metrics.py:449] Avg prompt throughput: 24.7 tokens/s, Avg generation throughput: 130.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:01:19 logger.py:37] Received request chatcmpl-206cbf513a904523a15254c083044d3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:19 engine.py:267] Added request chatcmpl-206cbf513a904523a15254c083044d3f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:23 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 111.3 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:01:23 logger.py:37] Received request chatcmpl-cf48242f192148cfb14546b958b9905b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the start of the race, why do the athletes line up as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:23 logger.py:37] Received request chatcmpl-51702800507b4e438ffaef60229fedc6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:23 engine.py:267] Added request chatcmpl-cf48242f192148cfb14546b958b9905b.
INFO 12-25 14:01:23 engine.py:267] Added request chatcmpl-51702800507b4e438ffaef60229fedc6.
INFO 12-25 14:01:24 logger.py:37] Received request chatcmpl-d25e80f099c347e595590e4dd284f0d9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the main character\'s 25m straight-line sprint ability considered inferior to that of a professional sprinter in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:24 engine.py:267] Added request chatcmpl-d25e80f099c347e595590e4dd284f0d9.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:26 logger.py:37] Received request chatcmpl-d207cf2cd4624615b51fe17370839664: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the video narrator think Kresimir Cosic\'s traits sound familiar?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:26 engine.py:267] Added request chatcmpl-d207cf2cd4624615b51fe17370839664.
INFO 12-25 14:01:28 metrics.py:449] Avg prompt throughput: 55.5 tokens/s, Avg generation throughput: 130.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:30 logger.py:37] Received request chatcmpl-047166cb638343928ecfd2fdbbb9fa6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many of Liverpool\'s number 11, Salah\'s goals are featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:30 engine.py:267] Added request chatcmpl-047166cb638343928ecfd2fdbbb9fa6f.
INFO 12-25 14:01:31 logger.py:37] Received request chatcmpl-654e4251afd94f2497ce085db2ac26d9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the impact of player number 10 on the red team according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:31 engine.py:267] Added request chatcmpl-654e4251afd94f2497ce085db2ac26d9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:33 metrics.py:449] Avg prompt throughput: 28.3 tokens/s, Avg generation throughput: 120.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:35 logger.py:37] Received request chatcmpl-3ee4c020e8f64777b4ce2cf3fbce9b1f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How would you describe the team in red\'s performance in the game at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:35 engine.py:267] Added request chatcmpl-3ee4c020e8f64777b4ce2cf3fbce9b1f.
INFO 12-25 14:01:35 logger.py:37] Received request chatcmpl-87a87862ba3e4d88b1ab34964522196e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times did champions break world records in the matches shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:35 engine.py:267] Added request chatcmpl-87a87862ba3e4d88b1ab34964522196e.
INFO 12-25 14:01:36 logger.py:37] Received request chatcmpl-6cbb307b75d844adbad12b5fc966ffd4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s the difference between guessing Doni\'s game and guessing other players?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:36 engine.py:267] Added request chatcmpl-6cbb307b75d844adbad12b5fc966ffd4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:37 logger.py:37] Received request chatcmpl-382361e34be346c8919c700d1274f099: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the topic of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:37 engine.py:267] Added request chatcmpl-382361e34be346c8919c700d1274f099.
INFO 12-25 14:01:38 metrics.py:449] Avg prompt throughput: 53.4 tokens/s, Avg generation throughput: 102.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:41 logger.py:37] Received request chatcmpl-93b98afe69c64694a2d67946df19108b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video featuring?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:41 engine.py:267] Added request chatcmpl-93b98afe69c64694a2d67946df19108b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:43 logger.py:37] Received request chatcmpl-556a1120db484e59a20bf02eafe21cdf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:43 engine.py:267] Added request chatcmpl-556a1120db484e59a20bf02eafe21cdf.
INFO 12-25 14:01:43 metrics.py:449] Avg prompt throughput: 23.8 tokens/s, Avg generation throughput: 108.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:01:44 logger.py:37] Received request chatcmpl-2944094fafbc414a81b398aacc44a110: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many meters did they approximately complete in 25 minutes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:44 engine.py:267] Added request chatcmpl-2944094fafbc414a81b398aacc44a110.
INFO 12-25 14:01:44 logger.py:37] Received request chatcmpl-9564ce1900684371a9354c83b06f2406: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the critical factors contributing to the success of the player featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:44 engine.py:267] Added request chatcmpl-9564ce1900684371a9354c83b06f2406.
INFO 12-25 14:01:48 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 145.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:51 logger.py:37] Received request chatcmpl-d0b96d13f0104440ab65c67ba6f99bcd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player is lying on the ground receiving treatment in the first half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:51 logger.py:37] Received request chatcmpl-cf9929aa145e403c87bf2b839756d3ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The video mentions the goal-scoring contributions of which players?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:51 logger.py:37] Received request chatcmpl-0f3d87d557b24a71a24e235bc1ddf4f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video\'s evaluation of the main character\'s performance as a football coach?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:51 engine.py:267] Added request chatcmpl-d0b96d13f0104440ab65c67ba6f99bcd.
INFO 12-25 14:01:51 engine.py:267] Added request chatcmpl-cf9929aa145e403c87bf2b839756d3ae.
INFO 12-25 14:01:51 engine.py:267] Added request chatcmpl-0f3d87d557b24a71a24e235bc1ddf4f5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:52 logger.py:37] Received request chatcmpl-fca965a167cd44ef947f4a69e986d7b2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How would you evaluate the FA Cup final match between Chelsea and Liverpool according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:52 engine.py:267] Added request chatcmpl-fca965a167cd44ef947f4a69e986d7b2.
INFO 12-25 14:01:53 metrics.py:449] Avg prompt throughput: 54.4 tokens/s, Avg generation throughput: 94.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:01:57 logger.py:37] Received request chatcmpl-c9e0da728184464e929abddf4b740e31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What underlies the main character\'s ability to make rapid decisions on the field, according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:01:57 engine.py:267] Added request chatcmpl-c9e0da728184464e929abddf4b740e31.
INFO 12-25 14:01:58 metrics.py:449] Avg prompt throughput: 14.6 tokens/s, Avg generation throughput: 145.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:01 logger.py:37] Received request chatcmpl-c269dfe10b6646748615c815beb0e860: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many athletes in the video were eliminated while jumping a height of 2 metres 27?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:01 logger.py:37] Received request chatcmpl-54784d68c0c24ae0bd9c9af58392dc87: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the French team have no results in the second group of games in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:01 engine.py:267] Added request chatcmpl-c269dfe10b6646748615c815beb0e860.
INFO 12-25 14:02:01 engine.py:267] Added request chatcmpl-54784d68c0c24ae0bd9c9af58392dc87.
INFO 12-25 14:02:02 logger.py:37] Received request chatcmpl-21ce8ae2acff448bae51b74a82dbcf74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which countries do the top three in the competition come from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:02 engine.py:267] Added request chatcmpl-21ce8ae2acff448bae51b74a82dbcf74.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:03 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 99.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:03 logger.py:37] Received request chatcmpl-38beb09dc0c34a63bb8d1c0017815bac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:03 engine.py:267] Added request chatcmpl-38beb09dc0c34a63bb8d1c0017815bac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:07 logger.py:37] Received request chatcmpl-2d144edd02ef40119703deb10b88f44d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Assuming the order of the matches is arranged in the order of appearance in the video, with the first match being the first one played in the video. Which of the following description of the champions\' performances in several matches in the video is inappropriate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:07 engine.py:267] Added request chatcmpl-2d144edd02ef40119703deb10b88f44d.
INFO 12-25 14:02:07 logger.py:37] Received request chatcmpl-ddcf7420faa04ed9b1f23c4b3689bab2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the medal awarded to the first runner to reach the finish line in the 1500m run in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:07 engine.py:267] Added request chatcmpl-ddcf7420faa04ed9b1f23c4b3689bab2.
INFO 12-25 14:02:08 metrics.py:449] Avg prompt throughput: 48.0 tokens/s, Avg generation throughput: 129.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:10 logger.py:37] Received request chatcmpl-855c3dc67e484b8586dcf660ed9bd7a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, why does a person suddenly appear in front of the leading team of runners when it is already 7,600 meters?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:10 engine.py:267] Added request chatcmpl-855c3dc67e484b8586dcf660ed9bd7a9.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:12 logger.py:37] Received request chatcmpl-c0a46d3875ca40728c371f16d8cfd12a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the main reason for the success of the club represented by the white team at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:12 engine.py:267] Added request chatcmpl-c0a46d3875ca40728c371f16d8cfd12a.
INFO 12-25 14:02:13 metrics.py:449] Avg prompt throughput: 31.4 tokens/s, Avg generation throughput: 120.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:13 logger.py:37] Received request chatcmpl-22b6fb4ca4444ce4b2c5dbd1804c3268: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the opening section of the video, what is the sequence in which the pairs of men\'s 10m platform divers appear?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:13 engine.py:267] Added request chatcmpl-22b6fb4ca4444ce4b2c5dbd1804c3268.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:17 logger.py:37] Received request chatcmpl-edb6a7203fe04ac99b90c2a9f7e25d75: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After how many minutes is it no longer possible to see two athletes side by side?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:17 engine.py:267] Added request chatcmpl-edb6a7203fe04ac99b90c2a9f7e25d75.
INFO 12-25 14:02:18 logger.py:37] Received request chatcmpl-4986c350bbbc4826922b4c0545872f78: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How has the player\'s playing style evolved during his tenure at Manchester United in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:18 engine.py:267] Added request chatcmpl-4986c350bbbc4826922b4c0545872f78.
INFO 12-25 14:02:18 metrics.py:449] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 131.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:21 logger.py:37] Received request chatcmpl-035ee85f3df446f9b92bbbbd9a76d4fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which event did the oldest individual Olympic swimming gold medallist in the video win gold?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:21 engine.py:267] Added request chatcmpl-035ee85f3df446f9b92bbbbd9a76d4fa.
INFO 12-25 14:02:23 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 138.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:26 logger.py:37] Received request chatcmpl-0a1836eceaf84c12b2cc55578c192b02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which jump did the silver medalist in the video perform best?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:26 engine.py:267] Added request chatcmpl-0a1836eceaf84c12b2cc55578c192b02.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:28 logger.py:37] Received request chatcmpl-d840db0a230e426ab1b77cdec510ad26: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason why the referee raised the red flag during the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:28 engine.py:267] Added request chatcmpl-d840db0a230e426ab1b77cdec510ad26.
INFO 12-25 14:02:28 logger.py:37] Received request chatcmpl-e697d40aa68e4343aae39aae5e7d1f46: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:28 engine.py:267] Added request chatcmpl-e697d40aa68e4343aae39aae5e7d1f46.
INFO 12-25 14:02:28 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 87.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:29 logger.py:37] Received request chatcmpl-90d98aa935cb4abb9b49e48e4de05199: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which game is Fan Z.D. closest to winning?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:29 engine.py:267] Added request chatcmpl-90d98aa935cb4abb9b49e48e4de05199.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:31 logger.py:37] Received request chatcmpl-4038243c65a34848bf448c4f2627a8e3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the players of the Polish team feel down after the first set of games in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:31 engine.py:267] Added request chatcmpl-4038243c65a34848bf448c4f2627a8e3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:33 metrics.py:449] Avg prompt throughput: 27.0 tokens/s, Avg generation throughput: 130.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:34 logger.py:37] Received request chatcmpl-1f4d562acdd448bea8e3da8409d4867b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What caused the German athlete in the video to encounter difficulties when attempting to clear the height of 2 meters 27?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:34 engine.py:267] Added request chatcmpl-1f4d562acdd448bea8e3da8409d4867b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:35 logger.py:37] Received request chatcmpl-6026b010bffd4b4ebdd6aa328e41a892: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the problem with Tosin OKE\'s presence in the game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:35 engine.py:267] Added request chatcmpl-6026b010bffd4b4ebdd6aa328e41a892.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:38 logger.py:37] Received request chatcmpl-6a6c24ccc3de4a70968e81b42496723c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the Canadian athlete suddenly collapse during the game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:38 engine.py:267] Added request chatcmpl-6a6c24ccc3de4a70968e81b42496723c.
INFO 12-25 14:02:38 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 118.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:39 logger.py:37] Received request chatcmpl-8f87e4cc4f3d42d1a92787a906a63d6a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the function of the whiteboard?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:39 engine.py:267] Added request chatcmpl-8f87e4cc4f3d42d1a92787a906a63d6a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:42 logger.py:37] Received request chatcmpl-b48533bca84a40c28cc305698de6ac97: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which team in the video has the best performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:42 engine.py:267] Added request chatcmpl-b48533bca84a40c28cc305698de6ac97.
INFO 12-25 14:02:43 metrics.py:449] Avg prompt throughput: 24.5 tokens/s, Avg generation throughput: 123.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:02:43 logger.py:37] Received request chatcmpl-8f899ff890fd413c85c4050f13dfe2cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened to the championship-winning athlete in the video during the last 400 meters of the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:44 engine.py:267] Added request chatcmpl-8f899ff890fd413c85c4050f13dfe2cb.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:45 logger.py:37] Received request chatcmpl-db7935b705cb41f4bbfcf3bc06b2cb7a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the Swiss athlete in the yellow top so happy near the end of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:45 engine.py:267] Added request chatcmpl-db7935b705cb41f4bbfcf3bc06b2cb7a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:48 logger.py:37] Received request chatcmpl-0514b2a10eaa4f169a133081085ebcbe: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:48 engine.py:267] Added request chatcmpl-0514b2a10eaa4f169a133081085ebcbe.
INFO 12-25 14:02:48 metrics.py:449] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 128.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:50 logger.py:37] Received request chatcmpl-955a347dc2ea4bd9bbd4872f3081f4bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the height of the first attempt of the championship-winning athlete in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:50 engine.py:267] Added request chatcmpl-955a347dc2ea4bd9bbd4872f3081f4bf.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:51 logger.py:37] Received request chatcmpl-1606eb9d56c446afa4bab20d377403f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement about this video is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:51 engine.py:267] Added request chatcmpl-1606eb9d56c446afa4bab20d377403f2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:52 logger.py:37] Received request chatcmpl-686a1cd3b3c747ccb9b9438bb3cb3c8d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between Fan Z.D. and Wang C.Q. that can be inferred from this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:52 engine.py:267] Added request chatcmpl-686a1cd3b3c747ccb9b9438bb3cb3c8d.
INFO 12-25 14:02:53 logger.py:37] Received request chatcmpl-18600e40bf9843d4ba5f9252efc0608b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:53 engine.py:267] Added request chatcmpl-18600e40bf9843d4ba5f9252efc0608b.
INFO 12-25 14:02:53 metrics.py:449] Avg prompt throughput: 52.6 tokens/s, Avg generation throughput: 102.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:02:57 logger.py:37] Received request chatcmpl-adf60c58e3944a73b806455b259447f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the identity of the athlete in the video who committed fouls on all attempts except the first one?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:57 engine.py:267] Added request chatcmpl-adf60c58e3944a73b806455b259447f1.
INFO 12-25 14:02:58 logger.py:37] Received request chatcmpl-61b52b3828114bb6960de0ccd424a711: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what is the problem with the German team\'s third jump in the women\'s synchronized 10m high platform diving competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:02:58 engine.py:267] Added request chatcmpl-61b52b3828114bb6960de0ccd424a711.
INFO 12-25 14:02:58 metrics.py:449] Avg prompt throughput: 30.9 tokens/s, Avg generation throughput: 126.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:02 logger.py:37] Received request chatcmpl-8fde7714e99b471b85fcdb997f42c00e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many scores does Fiji get at the very end of the first half?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:02 engine.py:267] Added request chatcmpl-8fde7714e99b471b85fcdb997f42c00e.
INFO 12-25 14:03:03 logger.py:37] Received request chatcmpl-c5b22f6e7cbb477eab05f00c4b10f0c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many balls does the woman in pink pitch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:03 engine.py:267] Added request chatcmpl-c5b22f6e7cbb477eab05f00c4b10f0c3.
INFO 12-25 14:03:03 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 123.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:07 logger.py:37] Received request chatcmpl-3065cbf9dea84f9a806eef261fb912cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, which of the following sentences best describes this match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:07 engine.py:267] Added request chatcmpl-3065cbf9dea84f9a806eef261fb912cd.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:08 logger.py:37] Received request chatcmpl-e511f9b807e64fdfaab13d5085dd6dee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which player in the video is always in the lead?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:08 engine.py:267] Added request chatcmpl-e511f9b807e64fdfaab13d5085dd6dee.
INFO 12-25 14:03:08 metrics.py:449] Avg prompt throughput: 13.3 tokens/s, Avg generation throughput: 110.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:10 logger.py:37] Received request chatcmpl-9b6ca3bf4f4c4830b7e19a25a754f3c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the key events or topics covered in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:10 logger.py:37] Received request chatcmpl-359e27bfad14494d87be2490d1b674a5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:10 engine.py:267] Added request chatcmpl-9b6ca3bf4f4c4830b7e19a25a754f3c3.
INFO 12-25 14:03:10 engine.py:267] Added request chatcmpl-359e27bfad14494d87be2490d1b674a5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:14 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 124.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:14 logger.py:37] Received request chatcmpl-9bf96dcddba84f2798919ee2e89f4f22: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what does it mean when there appears a badminton icon near the team name on the scoreboard, leftmost of the screen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:14 engine.py:267] Added request chatcmpl-9bf96dcddba84f2798919ee2e89f4f22.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:16 logger.py:37] Received request chatcmpl-4c36abf0201e4e0bbf371dde037ff6a1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly sequences the order in which the competition items appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:16 engine.py:267] Added request chatcmpl-4c36abf0201e4e0bbf371dde037ff6a1.
INFO 12-25 14:03:17 logger.py:37] Received request chatcmpl-5abb83ceb93d451e88615a12ea643329: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is interviewed both before and after the race based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:17 engine.py:267] Added request chatcmpl-5abb83ceb93d451e88615a12ea643329.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:19 metrics.py:449] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 114.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:20 logger.py:37] Received request chatcmpl-c1fa50547be14cc080a090e04cb5c580: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, how many match points and set points does the winner have before the last rally to win this match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:20 engine.py:267] Added request chatcmpl-c1fa50547be14cc080a090e04cb5c580.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:23 logger.py:37] Received request chatcmpl-8cdcaa6156474b8caf896f7edda53e2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred from this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:23 engine.py:267] Added request chatcmpl-8cdcaa6156474b8caf896f7edda53e2e.
INFO 12-25 14:03:24 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 129.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:26 logger.py:37] Received request chatcmpl-e535214a4c524dbc8229abfbb74624ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the American Nelson athlete in the video fail in his second trial jump of 5m95?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:26 engine.py:267] Added request chatcmpl-e535214a4c524dbc8229abfbb74624ac.
INFO 12-25 14:03:26 logger.py:37] Received request chatcmpl-9478e6112ed0493b980efd1442b02575: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:26 engine.py:267] Added request chatcmpl-9478e6112ed0493b980efd1442b02575.
INFO 12-25 14:03:26 logger.py:37] Received request chatcmpl-ddff4866b5cb4b029bd1e422ba356fee: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what do the sportsmen do before the match gets started?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:27 engine.py:267] Added request chatcmpl-ddff4866b5cb4b029bd1e422ba356fee.
INFO 12-25 14:03:29 metrics.py:449] Avg prompt throughput: 41.1 tokens/s, Avg generation throughput: 111.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:31 logger.py:37] Received request chatcmpl-05aba08ef4214c0ba1af4908d65292c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the volunteer squatting next to the middle line do after each rally in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:31 engine.py:267] Added request chatcmpl-05aba08ef4214c0ba1af4908d65292c7.
INFO 12-25 14:03:32 logger.py:37] Received request chatcmpl-c386605c208640a2a698fa3e46a1a6a8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be read from the scoreboard before halftime in the fourth set?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:32 logger.py:37] Received request chatcmpl-39b50f6b6e2642d98820eaddbf52672a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video primarily about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:32 engine.py:267] Added request chatcmpl-c386605c208640a2a698fa3e46a1a6a8.
INFO 12-25 14:03:32 engine.py:267] Added request chatcmpl-39b50f6b6e2642d98820eaddbf52672a.
INFO 12-25 14:03:34 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 108.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:36 logger.py:37] Received request chatcmpl-79dd8aab536b411abf7cc29aa824ad81: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, which jump earned the highest score for the champion pair in the women\'s synchronized ten-meter high platform diving competition?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:36 engine.py:267] Added request chatcmpl-79dd8aab536b411abf7cc29aa824ad81.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:38 logger.py:37] Received request chatcmpl-5b4a3a53a2744da2b169213868d6e56a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what grave actions does the king unknowingly commit?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:38 logger.py:37] Received request chatcmpl-a87607c1aeb84846990c48d7f937e267: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:38 engine.py:267] Added request chatcmpl-5b4a3a53a2744da2b169213868d6e56a.
INFO 12-25 14:03:38 engine.py:267] Added request chatcmpl-a87607c1aeb84846990c48d7f937e267.
INFO 12-25 14:03:39 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 93.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:39 logger.py:37] Received request chatcmpl-9be3ccc7b6004223be04f03c1726e854: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the timer after the race, in which lag does Jake Gagne drive fastest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:39 engine.py:267] Added request chatcmpl-9be3ccc7b6004223be04f03c1726e854.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:44 metrics.py:449] Avg prompt throughput: 13.9 tokens/s, Avg generation throughput: 123.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:44 logger.py:37] Received request chatcmpl-a15dd47048724112b41792ef1b5ff679: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What inference can be made from the video about life after death?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:44 logger.py:37] Received request chatcmpl-1e603e71e6d941eb8a86455a5dadb7ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is there a penalty shootout in this game in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:44 engine.py:267] Added request chatcmpl-a15dd47048724112b41792ef1b5ff679.
INFO 12-25 14:03:44 engine.py:267] Added request chatcmpl-1e603e71e6d941eb8a86455a5dadb7ff.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:46 logger.py:37] Received request chatcmpl-168570fce2a9444eb2b73b84c974f629: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special to their homemade baseball game when compared to a usual baseball game?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:46 logger.py:37] Received request chatcmpl-3707865d0c6f4d3eadf91bddb0d2d3bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who wins the women\'s A final?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:46 engine.py:267] Added request chatcmpl-168570fce2a9444eb2b73b84c974f629.
INFO 12-25 14:03:46 engine.py:267] Added request chatcmpl-3707865d0c6f4d3eadf91bddb0d2d3bd.
INFO 12-25 14:03:49 metrics.py:449] Avg prompt throughput: 51.5 tokens/s, Avg generation throughput: 121.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:52 logger.py:37] Received request chatcmpl-3759b3b3c1cc4acdba74c1c726af44ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:52 logger.py:37] Received request chatcmpl-4c9de7edef0e4640b030eaf383d25b52: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the blue team win the match point?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:52 engine.py:267] Added request chatcmpl-3759b3b3c1cc4acdba74c1c726af44ec.
INFO 12-25 14:03:52 engine.py:267] Added request chatcmpl-4c9de7edef0e4640b030eaf383d25b52.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:53 logger.py:37] Received request chatcmpl-1ce54e881d8c495686dcd366ddc4a9c9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Snow White come to meet the seven miners?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:53 engine.py:267] Added request chatcmpl-1ce54e881d8c495686dcd366ddc4a9c9.
INFO 12-25 14:03:54 metrics.py:449] Avg prompt throughput: 37.1 tokens/s, Avg generation throughput: 100.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:54 logger.py:37] Received request chatcmpl-86a28226d23a4bfba1ae9cf4ecc7151a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video primarily about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:54 engine.py:267] Added request chatcmpl-86a28226d23a4bfba1ae9cf4ecc7151a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:57 logger.py:37] Received request chatcmpl-412158fea6a44efaaf9ebfdabb61e083: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the performances in the video is a solo?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:57 engine.py:267] Added request chatcmpl-412158fea6a44efaaf9ebfdabb61e083.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:03:58 logger.py:37] Received request chatcmpl-df86e190700941a2aa76722259e4e7ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the actions of the friar in the video, what can be inferred about his beliefs?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:58 engine.py:267] Added request chatcmpl-df86e190700941a2aa76722259e4e7ab.
INFO 12-25 14:03:59 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 129.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:03:59 logger.py:37] Received request chatcmpl-a6d0f71bd2fe477382ba220a55f578cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the king endeavoring to accomplish?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:03:59 engine.py:267] Added request chatcmpl-a6d0f71bd2fe477382ba220a55f578cb.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:01 logger.py:37] Received request chatcmpl-438c4b0af7f54a029b418098919d30d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is the correct characteristic of Shaw, the player from Britain who is wearing black shirts and pants?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:01 engine.py:267] Added request chatcmpl-438c4b0af7f54a029b418098919d30d2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:04 metrics.py:449] Avg prompt throughput: 26.5 tokens/s, Avg generation throughput: 123.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:04:04 logger.py:37] Received request chatcmpl-1fbdd3e8988e4b85bf3c84ff01f34fdc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the series "Working In The Theatre" from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:04 logger.py:37] Received request chatcmpl-a4ae40b8f2a24b98b84685f26a1a7b15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do Everyman\'s friend Fellowship and his Kindred respond to his request for them to accompany him on his journey to face judgment?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:04 engine.py:267] Added request chatcmpl-1fbdd3e8988e4b85bf3c84ff01f34fdc.
INFO 12-25 14:04:04 engine.py:267] Added request chatcmpl-a4ae40b8f2a24b98b84685f26a1a7b15.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:06 logger.py:37] Received request chatcmpl-943ad83d38f346609befb1d322c6cfcf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about how the video\'s protagonist initially treated her powers and her kingdom?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:06 engine.py:267] Added request chatcmpl-943ad83d38f346609befb1d322c6cfcf.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:09 metrics.py:449] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 122.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:09 logger.py:37] Received request chatcmpl-65a65097fedb446f9edc9d1c4aadde94: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:09 engine.py:267] Added request chatcmpl-65a65097fedb446f9edc9d1c4aadde94.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:11 logger.py:37] Received request chatcmpl-52c569dbbfbc49e58c8347e397517704: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the man dressed in a formal suit and dark hat\'s attitude towards the woman in the white skirt and his employees?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:11 engine.py:267] Added request chatcmpl-52c569dbbfbc49e58c8347e397517704.
INFO 12-25 14:04:12 logger.py:37] Received request chatcmpl-6a5b06fbc0724a9287ec2b0feff51435: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the king\'s response upon discovering the truth about his actions in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:12 engine.py:267] Added request chatcmpl-6a5b06fbc0724a9287ec2b0feff51435.
INFO 12-25 14:04:13 logger.py:37] Received request chatcmpl-4d36f284e0fc477babbb99f43538abb0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:13 engine.py:267] Added request chatcmpl-4d36f284e0fc477babbb99f43538abb0.
INFO 12-25 14:04:14 metrics.py:449] Avg prompt throughput: 54.2 tokens/s, Avg generation throughput: 103.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:17 logger.py:37] Received request chatcmpl-980f2ca86ca843d382d79288aa4cef23: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What would happen if Nebraska won the fourth set?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:17 engine.py:267] Added request chatcmpl-980f2ca86ca843d382d79288aa4cef23.
INFO 12-25 14:04:18 logger.py:37] Received request chatcmpl-6792825a597f4b339af781143bc03686: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central conflict involving the woman dressed in a black top and white skirt in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:18 engine.py:267] Added request chatcmpl-6792825a597f4b339af781143bc03686.
INFO 12-25 14:04:19 metrics.py:449] Avg prompt throughput: 26.8 tokens/s, Avg generation throughput: 133.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:21 logger.py:37] Received request chatcmpl-4423f2f386cf462db2470cf62ad85741: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most possible reason why a bearded dragon can speak in the second magic performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:21 engine.py:267] Added request chatcmpl-4423f2f386cf462db2470cf62ad85741.
INFO 12-25 14:04:22 logger.py:37] Received request chatcmpl-4a9f0ec3366d48799734775b2bf7bd47: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main plot of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:22 engine.py:267] Added request chatcmpl-4a9f0ec3366d48799734775b2bf7bd47.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:24 logger.py:37] Received request chatcmpl-abb418f13d2842ab892390baf7c47cff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many periods do they play for and how many photos are taken?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:24 engine.py:267] Added request chatcmpl-abb418f13d2842ab892390baf7c47cff.
INFO 12-25 14:04:24 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 117.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:27 logger.py:37] Received request chatcmpl-423c910446554e82b91a3bb2b4cd6c9d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the Queen\'s fate in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:27 engine.py:267] Added request chatcmpl-423c910446554e82b91a3bb2b4cd6c9d.
INFO 12-25 14:04:27 logger.py:37] Received request chatcmpl-4ad04552706244bbabf12209428392fd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What motivates the main character to flee her hometown?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:27 engine.py:267] Added request chatcmpl-4ad04552706244bbabf12209428392fd.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:29 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 112.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:04:29 logger.py:37] Received request chatcmpl-dfe6f75e09af4eaa9c7f597dd51946c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the magic tricks about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:29 engine.py:267] Added request chatcmpl-dfe6f75e09af4eaa9c7f597dd51946c3.
INFO 12-25 14:04:30 logger.py:37] Received request chatcmpl-9c3da2eac6d94971b1189a591e7e9fa3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many games are hosted in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:30 engine.py:267] Added request chatcmpl-9c3da2eac6d94971b1189a591e7e9fa3.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:32 logger.py:37] Received request chatcmpl-7c85c8a0faa244a4aa3da7f2decc1ba5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the decision of the two main characters in the video to get married tell us about their characters?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:33 engine.py:267] Added request chatcmpl-7c85c8a0faa244a4aa3da7f2decc1ba5.
INFO 12-25 14:04:33 logger.py:37] Received request chatcmpl-901a50cf98964a49aef3b5e7b86fd69d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the overall quality of the play\'s production?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:33 engine.py:267] Added request chatcmpl-901a50cf98964a49aef3b5e7b86fd69d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:34 metrics.py:449] Avg prompt throughput: 51.6 tokens/s, Avg generation throughput: 115.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:35 logger.py:37] Received request chatcmpl-18f840a2221044f7bbf6156f129b84ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:35 engine.py:267] Added request chatcmpl-18f840a2221044f7bbf6156f129b84ad.
INFO 12-25 14:04:36 logger.py:37] Received request chatcmpl-ffcb5d9edb1340ada9020b5c7ff48bdb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the performance from the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:36 engine.py:267] Added request chatcmpl-ffcb5d9edb1340ada9020b5c7ff48bdb.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:39 metrics.py:449] Avg prompt throughput: 24.8 tokens/s, Avg generation throughput: 123.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:04:40 logger.py:37] Received request chatcmpl-bc486e8d145d4fc7924b67f3bfb42546: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following magics performed in this video? (a) Finding words in a dictionary. (b) Drawing a diamond using a match. (c) Producing a popcoin from eyes. (d) Seeing things through a bearded dragon. (e) Inducing judges to choose the cards that they get.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:40 engine.py:267] Added request chatcmpl-bc486e8d145d4fc7924b67f3bfb42546.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:42 logger.py:37] Received request chatcmpl-20b358141bc24ccdae104db145d01490: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video primarily focused on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:42 engine.py:267] Added request chatcmpl-20b358141bc24ccdae104db145d01490.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:43 logger.py:37] Received request chatcmpl-63f3971b661c493686add43224dfaf29: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following magics performed in this video? (a) Bend the straw with spirits. (b) Two kinds of snacks are poured out of the packaging bag. (c) Two coins on the plate turn into seven. (d) Coins drilled into the cup from the bottom.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:43 engine.py:267] Added request chatcmpl-63f3971b661c493686add43224dfaf29.
INFO 12-25 14:04:44 metrics.py:449] Avg prompt throughput: 58.0 tokens/s, Avg generation throughput: 118.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:04:44 logger.py:37] Received request chatcmpl-e45cd387a2e245109bead3547a8554d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the professional relationship between William Ivey Long and Willa Kim as described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:44 engine.py:267] Added request chatcmpl-e45cd387a2e245109bead3547a8554d0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:47 logger.py:37] Received request chatcmpl-7598586203b54340b11f1db9630e1621: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the story of the wolf conclude in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:47 engine.py:267] Added request chatcmpl-7598586203b54340b11f1db9630e1621.
INFO 12-25 14:04:49 metrics.py:449] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 142.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:51 logger.py:37] Received request chatcmpl-4ba17b305e9147ce83cd79af193d6c5f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the first and the fifth segments of magic in this video have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:51 engine.py:267] Added request chatcmpl-4ba17b305e9147ce83cd79af193d6c5f.
INFO 12-25 14:04:51 logger.py:37] Received request chatcmpl-edc1bf8cda0b423f9e743a10fd0ad2ec: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the central theme of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:51 engine.py:267] Added request chatcmpl-edc1bf8cda0b423f9e743a10fd0ad2ec.
INFO 12-25 14:04:52 logger.py:37] Received request chatcmpl-63ec3e9d187244a09cb7bd2026fb08d8: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which summarizes the main content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:52 engine.py:267] Added request chatcmpl-63ec3e9d187244a09cb7bd2026fb08d8.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:54 metrics.py:449] Avg prompt throughput: 38.2 tokens/s, Avg generation throughput: 97.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:56 logger.py:37] Received request chatcmpl-ffee4a704d68429db0593fc0233d6632: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special about the second magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:56 engine.py:267] Added request chatcmpl-ffee4a704d68429db0593fc0233d6632.
INFO 12-25 14:04:58 logger.py:37] Received request chatcmpl-f81fc65532ad4773a0e5c75ae35f145a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:58 logger.py:37] Received request chatcmpl-aaea252406334669bdbeb310dfb11f62: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the character of the woman dressed in a white skirt and black top perceived at the beginning of the play?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:04:58 engine.py:267] Added request chatcmpl-f81fc65532ad4773a0e5c75ae35f145a.
INFO 12-25 14:04:58 engine.py:267] Added request chatcmpl-aaea252406334669bdbeb310dfb11f62.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:04:59 metrics.py:449] Avg prompt throughput: 39.1 tokens/s, Avg generation throughput: 102.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:05:00 logger.py:37] Received request chatcmpl-79c45dad588b441087c4e54afa7d83dd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:00 engine.py:267] Added request chatcmpl-79c45dad588b441087c4e54afa7d83dd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:03 logger.py:37] Received request chatcmpl-eff0d555c04249839c6883ffdf154bea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many tricks are revealed in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:03 engine.py:267] Added request chatcmpl-eff0d555c04249839c6883ffdf154bea.
INFO 12-25 14:05:04 metrics.py:449] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 134.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:07 logger.py:37] Received request chatcmpl-123723b184f04452a1aa6fadb79ad4a0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order do the following events happen in this video? (a) Mr. Bean falls in love with the beautiful singer Roxy and has a wish to get an autograph from her. His attempts are mostly foiled by the bodyguard until he manages to get a kiss mark from Roxy using her handkerchief and Bean is happy. (b) Whilst digging for treasure, Mr. Bean builds his own metal detector and goes to hunt for treasure but fails. When he manages to get the treasure and bring it to his flat. (c) Mr. Bean and Irma are off for a day at the seaside, where his trunk gets accidentally swapped with that of a stage magician. (d) Bean attends a hypnotism show. He unwittingly volunteers to be hypnotised; when the hypnotist makes him think he\'s a dog, he runs away and then back at home chases Scrapper around the garden and the house.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:07 logger.py:37] Received request chatcmpl-8bed2260cc114b89ad12e3d6369df6b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What inference can be made about the actress on her interactions in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:07 logger.py:37] Received request chatcmpl-2f676bba95164b02bf043cb85b56668e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the key to the illusion of bending a teaspoon with his mind?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:07 engine.py:267] Added request chatcmpl-123723b184f04452a1aa6fadb79ad4a0.
INFO 12-25 14:05:07 engine.py:267] Added request chatcmpl-8bed2260cc114b89ad12e3d6369df6b5.
INFO 12-25 14:05:07 engine.py:267] Added request chatcmpl-2f676bba95164b02bf043cb85b56668e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:09 logger.py:37] Received request chatcmpl-487f3787cb454e34b4fd8672a620ac61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:09 engine.py:267] Added request chatcmpl-487f3787cb454e34b4fd8672a620ac61.
INFO 12-25 14:05:09 metrics.py:449] Avg prompt throughput: 86.5 tokens/s, Avg generation throughput: 83.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:13 logger.py:37] Received request chatcmpl-e7e254326b3a493c88243d6f6148506e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which tool is used in the first magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:13 engine.py:267] Added request chatcmpl-e7e254326b3a493c88243d6f6148506e.
INFO 12-25 14:05:14 logger.py:37] Received request chatcmpl-d11f529e7bd54d2db2d9886a6a1ea168: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What overarching story is told in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:14 engine.py:267] Added request chatcmpl-d11f529e7bd54d2db2d9886a6a1ea168.
INFO 12-25 14:05:14 metrics.py:449] Avg prompt throughput: 24.4 tokens/s, Avg generation throughput: 116.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:05:14 logger.py:37] Received request chatcmpl-f308d6ed3e7a4008be9dd02f3485fe12: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following tools is not used in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:14 engine.py:267] Added request chatcmpl-f308d6ed3e7a4008be9dd02f3485fe12.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:19 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 140.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:20 logger.py:37] Received request chatcmpl-1ba598489dab4c469ae1f308f8aabf7a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many magics are performed in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:20 logger.py:37] Received request chatcmpl-50905debe4d74881833650dc17e1ef8f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which magic trick has a tutorial?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:20 engine.py:267] Added request chatcmpl-1ba598489dab4c469ae1f308f8aabf7a.
INFO 12-25 14:05:20 engine.py:267] Added request chatcmpl-50905debe4d74881833650dc17e1ef8f.
INFO 12-25 14:05:21 logger.py:37] Received request chatcmpl-81be03e71fdd44759028a2f6061053b6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What aspect of theatre production is highlighted according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:21 engine.py:267] Added request chatcmpl-81be03e71fdd44759028a2f6061053b6.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:23 logger.py:37] Received request chatcmpl-4e6e3215d894428ab90d2c1ed4aeca86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which action is not included in the third magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:23 engine.py:267] Added request chatcmpl-4e6e3215d894428ab90d2c1ed4aeca86.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:24 metrics.py:449] Avg prompt throughput: 50.4 tokens/s, Avg generation throughput: 111.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:25 logger.py:37] Received request chatcmpl-98fee82254ff4f15874837837b179419: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What kind of transformation does William Holmes undergo throughout the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:26 engine.py:267] Added request chatcmpl-98fee82254ff4f15874837837b179419.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:26 logger.py:37] Received request chatcmpl-02f1c69ea2ce4f6986c3a0d708bc7637: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What can be inferred about the storyline of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:26 engine.py:267] Added request chatcmpl-02f1c69ea2ce4f6986c3a0d708bc7637.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:28 logger.py:37] Received request chatcmpl-3f4a59464c4443489657f27d84800418: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the magician fail in the first episode?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:28 engine.py:267] Added request chatcmpl-3f4a59464c4443489657f27d84800418.
INFO 12-25 14:05:29 logger.py:37] Received request chatcmpl-155b9bc14e4f4f5982e54587c61e220b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What similarities exist between the first two magic tricks?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:29 engine.py:267] Added request chatcmpl-155b9bc14e4f4f5982e54587c61e220b.
INFO 12-25 14:05:29 metrics.py:449] Avg prompt throughput: 50.2 tokens/s, Avg generation throughput: 102.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:34 logger.py:37] Received request chatcmpl-5c15a3c7f8a24154ba9ae855588c2397: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many magic shows are included in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:34 engine.py:267] Added request chatcmpl-5c15a3c7f8a24154ba9ae855588c2397.
INFO 12-25 14:05:34 metrics.py:449] Avg prompt throughput: 11.3 tokens/s, Avg generation throughput: 104.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:05:34 logger.py:37] Received request chatcmpl-8f3f1680887b4c139eea173f19ccba1e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle part of the video, why does the girl named Danielle Walker, with golden hair and blue clothes, use a huge bat to hit the ball?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:34 engine.py:267] Added request chatcmpl-8f3f1680887b4c139eea173f19ccba1e.
INFO 12-25 14:05:35 logger.py:37] Received request chatcmpl-0b4150ef59f24b07835ab290f82e1c13: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main focus of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:35 engine.py:267] Added request chatcmpl-0b4150ef59f24b07835ab290f82e1c13.
INFO 12-25 14:05:35 logger.py:37] Received request chatcmpl-2ea658d1187d4fca9c01a53a39c4f1f0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does Mr. Bean get off the plane when he finds the island is right down?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:35 engine.py:267] Added request chatcmpl-2ea658d1187d4fca9c01a53a39c4f1f0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:39 metrics.py:449] Avg prompt throughput: 42.8 tokens/s, Avg generation throughput: 135.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:05:40 logger.py:37] Received request chatcmpl-b59cb9c943a44e43834550e94c4c972a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main purpose of Tim K bending down from the grass, standing up, walking back to the bathtub, and bending down again?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:40 engine.py:267] Added request chatcmpl-b59cb9c943a44e43834550e94c4c972a.
INFO 12-25 14:05:41 logger.py:37] Received request chatcmpl-c7de46392078429a88a81b986ab0982f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does this video reveal each magic trick?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:41 engine.py:267] Added request chatcmpl-c7de46392078429a88a81b986ab0982f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:43 logger.py:37] Received request chatcmpl-7205a747d5844b05a6ecf0447119dd45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "At the end of the video, why does James Corden sing a song with tears in his eyes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:43 engine.py:267] Added request chatcmpl-7205a747d5844b05a6ecf0447119dd45.
INFO 12-25 14:05:44 logger.py:37] Received request chatcmpl-13484d88c2b447b5803b96d9886f4dbc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the beginning of the video, who used a tool to open the watermelon?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:44 engine.py:267] Added request chatcmpl-13484d88c2b447b5803b96d9886f4dbc.
INFO 12-25 14:05:44 metrics.py:449] Avg prompt throughput: 56.6 tokens/s, Avg generation throughput: 114.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:47 logger.py:37] Received request chatcmpl-5ed15006615f459cbd91260f457d1b65: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early part of the video, how was the flip-flop that traveled the farthest thrown?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:47 engine.py:267] Added request chatcmpl-5ed15006615f459cbd91260f457d1b65.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:49 logger.py:37] Received request chatcmpl-1c1b1dcd42b146f8ae2728029fce3889: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the mirrors in the last magic?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:49 engine.py:267] Added request chatcmpl-1c1b1dcd42b146f8ae2728029fce3889.
INFO 12-25 14:05:49 metrics.py:449] Avg prompt throughput: 27.4 tokens/s, Avg generation throughput: 131.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:52 logger.py:37] Received request chatcmpl-170f8ed773634300a540fc2d92afefa2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do the five members of the Feb 5 team want to help William Holmes change?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:52 engine.py:267] Added request chatcmpl-170f8ed773634300a540fc2d92afefa2.
INFO 12-25 14:05:52 logger.py:37] Received request chatcmpl-83acefc286c54eaa996e69a1364fab64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In James Corden\'s dream, what does it mean when the man sitting to his left in a black suit and black tie and the man sitting to his right in a dark blue top suddenly burst into laughter?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:52 logger.py:37] Received request chatcmpl-28ee705d79034533be79e6b1ef663f2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the first game of the video\'s early part, what is the key to winning this game of building the tallest tower?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:52 engine.py:267] Added request chatcmpl-83acefc286c54eaa996e69a1364fab64.
INFO 12-25 14:05:52 engine.py:267] Added request chatcmpl-28ee705d79034533be79e6b1ef663f2e.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:54 metrics.py:449] Avg prompt throughput: 48.1 tokens/s, Avg generation throughput: 93.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:05:54 logger.py:37] Received request chatcmpl-f7c2a57255be41cd847867c3f74f6e63: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:54 engine.py:267] Added request chatcmpl-f7c2a57255be41cd847867c3f74f6e63.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:05:57 logger.py:37] Received request chatcmpl-47d9874019ca44d0a3146908d3cf4185: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, when Luke says, "We probably have no time.", what does this statement express about Luke\'s thoughts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:57 engine.py:267] Added request chatcmpl-47d9874019ca44d0a3146908d3cf4185.
INFO 12-25 14:05:59 logger.py:37] Received request chatcmpl-aeefc9a4c5d448749d6daa8dcb3a723d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which reality show is NOT ranked first in its respective category based on the order of the three guests in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:05:59 engine.py:267] Added request chatcmpl-aeefc9a4c5d448749d6daa8dcb3a723d.
INFO 12-25 14:05:59 metrics.py:449] Avg prompt throughput: 43.2 tokens/s, Avg generation throughput: 130.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:02 logger.py:37] Received request chatcmpl-af19bff537064e9884e6efe70e31e6f4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the first two magics performed in the video have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:02 engine.py:267] Added request chatcmpl-af19bff537064e9884e6efe70e31e6f4.
INFO 12-25 14:06:03 logger.py:37] Received request chatcmpl-b71fd35272f44aad98cfa58b1362c9e0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, during the "Who\'d you rather" segment, what is the relationship between the man wearing a black jacket and Rihanna?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:03 engine.py:267] Added request chatcmpl-b71fd35272f44aad98cfa58b1362c9e0.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:04 metrics.py:449] Avg prompt throughput: 30.1 tokens/s, Avg generation throughput: 121.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:05 logger.py:37] Received request chatcmpl-a7f0de610abc42b088fe63ca5b543925: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early part of the video, during the One-Eyed Monster quiz task, how many questions did the team with the boy with dark skin answer correctly?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:05 engine.py:267] Added request chatcmpl-a7f0de610abc42b088fe63ca5b543925.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:08 logger.py:37] Received request chatcmpl-31365e935c5b44f99639c8b03c5c4847: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the magician and the audience with striped shirts and brown hair?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:08 logger.py:37] Received request chatcmpl-f348289727424ac4a19fd1226e65a4a6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, why is Brian Quinn, a man wearing a baseball cap, booed by the audience at the band\'s live performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:08 engine.py:267] Added request chatcmpl-31365e935c5b44f99639c8b03c5c4847.
INFO 12-25 14:06:08 engine.py:267] Added request chatcmpl-f348289727424ac4a19fd1226e65a4a6.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:09 metrics.py:449] Avg prompt throughput: 47.4 tokens/s, Avg generation throughput: 101.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:10 logger.py:37] Received request chatcmpl-97bd37bb3b534dd2b8ea6da505bc134a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When the three hosts discuss the ranking of musical competition shows, why do they think "X Factor" ranks the highest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:10 engine.py:267] Added request chatcmpl-97bd37bb3b534dd2b8ea6da505bc134a.
INFO 12-25 14:06:10 logger.py:37] Received request chatcmpl-64bf0983853242f6855495d98469ed1d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, which method did the contestant with the shortest time used to send inflatable ducks into the lake?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:11 engine.py:267] Added request chatcmpl-64bf0983853242f6855495d98469ed1d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:14 metrics.py:449] Avg prompt throughput: 30.7 tokens/s, Avg generation throughput: 133.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:15 logger.py:37] Received request chatcmpl-cc2ce82d41284e52983d99268de9fc3f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the sequence in which the following magic tricks are performed in this video? (a) Joker inside the black Jacks sandwich is mysteriously replaced with the randomly chosen card. (b) The positions of Aces and random cards are swapped. (c) After a full circle of mixing up, the piles go back to where they started. (d) The order of cards is recovered from chaos.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:15 engine.py:267] Added request chatcmpl-cc2ce82d41284e52983d99268de9fc3f.
INFO 12-25 14:06:17 logger.py:37] Received request chatcmpl-885a97131f124af290e126a549d1efac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, what is the relationship between the shows "Flavor of Love" and "To Be Her Best Friend" as discussed by the three hosts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:17 logger.py:37] Received request chatcmpl-c3e3bcf6af6a4599a8b428459b1baa66: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle part of the video, why does Joe, the man wearing a blue shirt and yellow pants, pounce on the customer\'s table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:17 logger.py:37] Received request chatcmpl-bc089c06e88a45dda5edbce2766cb69f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle part of the video, which rule did Bailey, the girl, break on her first day of school?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:17 engine.py:267] Added request chatcmpl-885a97131f124af290e126a549d1efac.
INFO 12-25 14:06:17 engine.py:267] Added request chatcmpl-c3e3bcf6af6a4599a8b428459b1baa66.
INFO 12-25 14:06:17 engine.py:267] Added request chatcmpl-bc089c06e88a45dda5edbce2766cb69f.
INFO 12-25 14:06:19 metrics.py:449] Avg prompt throughput: 75.6 tokens/s, Avg generation throughput: 94.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:23 logger.py:37] Received request chatcmpl-517e02214a10472abdb061e9bb46b5f9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT a reason why 100 women think Steve Harvey is a good kisser?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:23 engine.py:267] Added request chatcmpl-517e02214a10472abdb061e9bb46b5f9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:24 metrics.py:449] Avg prompt throughput: 14.9 tokens/s, Avg generation throughput: 133.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:25 logger.py:37] Received request chatcmpl-8e8e2cde0292414d92dead4e844c0f6f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do not the two male performers have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:25 engine.py:267] Added request chatcmpl-8e8e2cde0292414d92dead4e844c0f6f.
INFO 12-25 14:06:26 logger.py:37] Received request chatcmpl-47da79b6c9bb4aab98a8d13c054330b5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, how is the show scoring the answers given by Kim Kardashian?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:26 engine.py:267] Added request chatcmpl-47da79b6c9bb4aab98a8d13c054330b5.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:29 logger.py:37] Received request chatcmpl-1509416a35ad4331b0a73fa65c089155: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, while evaluating five paintings, the man with platinum blonde hair and a pure black top contends that the highest-scoring painting was created by whom?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:29 engine.py:267] Added request chatcmpl-1509416a35ad4331b0a73fa65c089155.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:29 metrics.py:449] Avg prompt throughput: 43.7 tokens/s, Avg generation throughput: 117.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:32 logger.py:37] Received request chatcmpl-5969cd190dd54446970ade272cb1168b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many of the shows in the video are solo acts?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:32 logger.py:37] Received request chatcmpl-cb15847e4fa441f5be14dea1b94dd06e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between Jono and Portia, who comforting the sad Jono?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:32 engine.py:267] Added request chatcmpl-5969cd190dd54446970ade272cb1168b.
INFO 12-25 14:06:32 engine.py:267] Added request chatcmpl-cb15847e4fa441f5be14dea1b94dd06e.
INFO 12-25 14:06:32 logger.py:37] Received request chatcmpl-685b72bd80bf4566a8dc013e1ab44eb3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In how many instances does archery make an appearance during these performances?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:32 engine.py:267] Added request chatcmpl-685b72bd80bf4566a8dc013e1ab44eb3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:34 metrics.py:449] Avg prompt throughput: 39.9 tokens/s, Avg generation throughput: 95.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:35 logger.py:37] Received request chatcmpl-feb19458edd9451aa64b1ee9b9ec113d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, which aspect of William Holmes do the five members of the Feb 5 team not change?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:35 engine.py:267] Added request chatcmpl-feb19458edd9451aa64b1ee9b9ec113d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:41 logger.py:37] Received request chatcmpl-07be216a6f5141a6a9c7bf180cc17e62: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the third and fourth programs have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:41 engine.py:267] Added request chatcmpl-07be216a6f5141a6a9c7bf180cc17e62.
INFO 12-25 14:06:41 metrics.py:449] Avg prompt throughput: 20.6 tokens/s, Avg generation throughput: 105.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:42 logger.py:37] Received request chatcmpl-728bdcb4b73b437bb59cb713f482813c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many guests were invited to participate in the interview in this segment of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:42 logger.py:37] Received request chatcmpl-16ed4210e9df43168ff6bd0cac1f0d05: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which acrobatics skill is absent from this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:42 engine.py:267] Added request chatcmpl-728bdcb4b73b437bb59cb713f482813c.
INFO 12-25 14:06:42 engine.py:267] Added request chatcmpl-16ed4210e9df43168ff6bd0cac1f0d05.
INFO 12-25 14:06:43 logger.py:37] Received request chatcmpl-67a5458fe65f44ae95e12633961648a9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The result of which performance remains unknown based on this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:43 engine.py:267] Added request chatcmpl-67a5458fe65f44ae95e12633961648a9.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:46 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 120.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:46 logger.py:37] Received request chatcmpl-a1b95d20beec49efa49b0c7452008941: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is unique about the last performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:46 engine.py:267] Added request chatcmpl-a1b95d20beec49efa49b0c7452008941.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:48 logger.py:37] Received request chatcmpl-8f695d194aec4ef4a08cf8506d782a0d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the five items, guessed by the man in the red top during the price-guessing segment in the middle of the video, deviated the least from its actual price?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:48 engine.py:267] Added request chatcmpl-8f695d194aec4ef4a08cf8506d782a0d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:50 logger.py:37] Received request chatcmpl-08efb4781d7e49b897565806f58bc988: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which two programs have similarities in the use of the ring?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:50 logger.py:37] Received request chatcmpl-ca74cb797afb40d2a47337c102d72f06: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which acrobatic skill is absent from this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:50 engine.py:267] Added request chatcmpl-08efb4781d7e49b897565806f58bc988.
INFO 12-25 14:06:50 engine.py:267] Added request chatcmpl-ca74cb797afb40d2a47337c102d72f06.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:51 metrics.py:449] Avg prompt throughput: 54.9 tokens/s, Avg generation throughput: 105.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:52 logger.py:37] Received request chatcmpl-313277e8f8a64723887dd7d2c36e1d1e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the first five programs have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:52 engine.py:267] Added request chatcmpl-313277e8f8a64723887dd7d2c36e1d1e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:56 metrics.py:449] Avg prompt throughput: 12.3 tokens/s, Avg generation throughput: 138.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO 12-25 14:06:57 logger.py:37] Received request chatcmpl-a84bf3ea0eed455cad6b358ea349a77c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is true about this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:57 engine.py:267] Added request chatcmpl-a84bf3ea0eed455cad6b358ea349a77c.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:58 logger.py:37] Received request chatcmpl-523f5045555f4760920905a0da469fe0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the spectators do after the performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:58 engine.py:267] Added request chatcmpl-523f5045555f4760920905a0da469fe0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:06:59 logger.py:37] Received request chatcmpl-9567c3589e3e47a692247acba7a30917: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sequence of actions followed after they stepped on the stilts? (a) They unfurled a banner from their mouths. (b) They tumbled down from the high platform. (c) They caught the balls thrown by the ground staff.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:06:59 engine.py:267] Added request chatcmpl-9567c3589e3e47a692247acba7a30917.
INFO 12-25 14:07:00 logger.py:37] Received request chatcmpl-68906881e7c8416798f657204818f308: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the latter part of the video, which prize can Sam Campbell not obtain?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:00 engine.py:267] Added request chatcmpl-68906881e7c8416798f657204818f308.
INFO 12-25 14:07:01 metrics.py:449] Avg prompt throughput: 57.8 tokens/s, Avg generation throughput: 109.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:05 logger.py:37] Received request chatcmpl-b49c0a4f2a44455caeb219fbf7092e61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special about the circus?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:05 engine.py:267] Added request chatcmpl-b49c0a4f2a44455caeb219fbf7092e61.
INFO 12-25 14:07:05 logger.py:37] Received request chatcmpl-cc23a47fbad84a7f83a25c3446d9b0d0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How is the seventh performance different from the others?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:05 engine.py:267] Added request chatcmpl-cc23a47fbad84a7f83a25c3446d9b0d0.
INFO 12-25 14:07:06 logger.py:37] Received request chatcmpl-2253a40bb5934fb9880b1db18b170381: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the early part of the video, when Sal, the man wearing a black suit and a yellow tie, gives a speech, what is the relationship between Crystal and Gary he mentioned?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:06 engine.py:267] Added request chatcmpl-2253a40bb5934fb9880b1db18b170381.
INFO 12-25 14:07:06 metrics.py:449] Avg prompt throughput: 41.9 tokens/s, Avg generation throughput: 75.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:07 logger.py:37] Received request chatcmpl-2f7cc9a72f174eedbf4de2f2f42f0561: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:07 engine.py:267] Added request chatcmpl-2f7cc9a72f174eedbf4de2f2f42f0561.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:11 logger.py:37] Received request chatcmpl-3f4f0a9dda93414cb730f70590659f47: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which acrobatic skill is featured in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:11 engine.py:267] Added request chatcmpl-3f4f0a9dda93414cb730f70590659f47.
INFO 12-25 14:07:11 metrics.py:449] Avg prompt throughput: 24.2 tokens/s, Avg generation throughput: 121.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:12 logger.py:37] Received request chatcmpl-936aa7c074184393a708496026e02ba4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement about this video is true?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:12 engine.py:267] Added request chatcmpl-936aa7c074184393a708496026e02ba4.
INFO 12-25 14:07:12 logger.py:37] Received request chatcmpl-5d1d26bc0e6f4328a2645fa8d956ca12: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the middle part of the video, when Kim Kardashian and Khlo Kardashian come on stage, Khlo Kardashian shakes her head and says "No" to Kim Kardashian. What does this indicate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:12 engine.py:267] Added request chatcmpl-5d1d26bc0e6f4328a2645fa8d956ca12.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:14 logger.py:37] Received request chatcmpl-74e796412e8f44fa854796feea4dbaa4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the man doing when the carousel starts spinning for the first time?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:14 engine.py:267] Added request chatcmpl-74e796412e8f44fa854796feea4dbaa4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:16 metrics.py:449] Avg prompt throughput: 43.9 tokens/s, Avg generation throughput: 127.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:18 logger.py:37] Received request chatcmpl-95b53fa966a34553b8c6179d8a1adb15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the performances does the woman participate in?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:18 engine.py:267] Added request chatcmpl-95b53fa966a34553b8c6179d8a1adb15.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:19 logger.py:37] Received request chatcmpl-c2cade8b7fab4eb9a8fc32149565cc86: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which two performances incorporate the use of light strips?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:19 engine.py:267] Added request chatcmpl-c2cade8b7fab4eb9a8fc32149565cc86.
INFO 12-25 14:07:20 logger.py:37] Received request chatcmpl-11f66a24546143d883e6bb9008d7e0ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is a common characteristic among these auditions?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:20 engine.py:267] Added request chatcmpl-11f66a24546143d883e6bb9008d7e0ac.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:21 metrics.py:449] Avg prompt throughput: 37.0 tokens/s, Avg generation throughput: 102.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:23 logger.py:37] Received request chatcmpl-b0fe109e9ad048b3ad1a22fd9e83b9c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the entire video, what kind of transformation occurs between Jono and Bailey?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:23 engine.py:267] Added request chatcmpl-b0fe109e9ad048b3ad1a22fd9e83b9c0.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:26 metrics.py:449] Avg prompt throughput: 13.8 tokens/s, Avg generation throughput: 87.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:27 logger.py:37] Received request chatcmpl-0a77168c19784ed586a844ff557af485: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:27 logger.py:37] Received request chatcmpl-fabaaf3c61444913894eef9ef105b042: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is most likely to have filmed this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:27 logger.py:37] Received request chatcmpl-09b63d88e53b4538abf536f63a12f2cf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order do the following topics are introduced in this video ? (a) Spring pocket DIY. (b) Easter bucket floral DIY. (c) Farmhouse bunny in a bucket DIY. (d) Spring tin bucket floral DIY. (e) Bunny hop decor.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:27 engine.py:267] Added request chatcmpl-0a77168c19784ed586a844ff557af485.
INFO 12-25 14:07:27 engine.py:267] Added request chatcmpl-fabaaf3c61444913894eef9ef105b042.
INFO 12-25 14:07:27 engine.py:267] Added request chatcmpl-09b63d88e53b4538abf536f63a12f2cf.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:31 metrics.py:449] Avg prompt throughput: 45.7 tokens/s, Avg generation throughput: 119.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:32 logger.py:37] Received request chatcmpl-95ef4c15e7804b93a626ddf36466591e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the actor in the video achieve the jump upwards in the first clip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:32 engine.py:267] Added request chatcmpl-95ef4c15e7804b93a626ddf36466591e.
INFO 12-25 14:07:32 logger.py:37] Received request chatcmpl-27ff163409ef4183b92c1a149b492e7a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is the characteristic of the first wool craft with spoons?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:32 engine.py:267] Added request chatcmpl-27ff163409ef4183b92c1a149b492e7a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:35 logger.py:37] Received request chatcmpl-e1b0be7a06ec492fac461af56b6ce35f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is not used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:35 engine.py:267] Added request chatcmpl-e1b0be7a06ec492fac461af56b6ce35f.
INFO 12-25 14:07:36 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 131.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:40 logger.py:37] Received request chatcmpl-5cffd6556b5b401c8f3b4e8884188f69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the correct steps to make the adorable rabbit? (a) Making a white tail from a microfiber duster mop pad. (b) Cutting off the tinsel from the original rabbit. (c) Wrapping the brown yarn across the rabbit. (d) Making a cute little lace bow and tie it to the rabbit.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:40 engine.py:267] Added request chatcmpl-5cffd6556b5b401c8f3b4e8884188f69.
INFO 12-25 14:07:41 logger.py:37] Received request chatcmpl-6a05a02b1cae4975bd76290ad948f285: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which option correctly describes the second performance?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:41 logger.py:37] Received request chatcmpl-77d5cd17d8e44f44b5232938933e90ff: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the two wall sconces made in this video have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:41 engine.py:267] Added request chatcmpl-6a05a02b1cae4975bd76290ad948f285.
INFO 12-25 14:07:41 engine.py:267] Added request chatcmpl-77d5cd17d8e44f44b5232938933e90ff.
INFO 12-25 14:07:41 metrics.py:449] Avg prompt throughput: 49.4 tokens/s, Avg generation throughput: 81.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:42 logger.py:37] Received request chatcmpl-518f876b13a0440fa4f1dc69f79deab6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the best caption for this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:42 engine.py:267] Added request chatcmpl-518f876b13a0440fa4f1dc69f79deab6.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:46 logger.py:37] Received request chatcmpl-9f582ae00b364fb18ef7c059104fbe11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is not used in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:46 engine.py:267] Added request chatcmpl-9f582ae00b364fb18ef7c059104fbe11.
INFO 12-25 14:07:46 metrics.py:449] Avg prompt throughput: 24.3 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:47 logger.py:37] Received request chatcmpl-66792996ca07413fbd101f2d87320465: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:47 logger.py:37] Received request chatcmpl-57339836a51e406e80aaddd78d243b36: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:47 engine.py:267] Added request chatcmpl-66792996ca07413fbd101f2d87320465.
INFO 12-25 14:07:47 engine.py:267] Added request chatcmpl-57339836a51e406e80aaddd78d243b36.
INFO 12-25 14:07:49 logger.py:37] Received request chatcmpl-75f03a78882f471bb9746786580ebc69: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If one lives in this house, what cannot he do according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:49 engine.py:267] Added request chatcmpl-75f03a78882f471bb9746786580ebc69.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:51 metrics.py:449] Avg prompt throughput: 37.4 tokens/s, Avg generation throughput: 108.9 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:52 logger.py:37] Received request chatcmpl-e70b7c6ce359478bbacab2e8a9b6d24b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:52 logger.py:37] Received request chatcmpl-4751fea791ff4ccda33a3032e40bb38c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following steps does not the woman do on her own?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:52 engine.py:267] Added request chatcmpl-e70b7c6ce359478bbacab2e8a9b6d24b.
INFO 12-25 14:07:52 engine.py:267] Added request chatcmpl-4751fea791ff4ccda33a3032e40bb38c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:55 logger.py:37] Received request chatcmpl-1cd46f0aabf84d2eb246575952111ae2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "If the woman in this video wears and changes one piece of clothes every day, then at least how many days is the video shot for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:55 engine.py:267] Added request chatcmpl-1cd46f0aabf84d2eb246575952111ae2.
INFO 12-25 14:07:55 logger.py:37] Received request chatcmpl-ed835cbd22ff4b81ba1c2984f963b4cb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What distinguishes the yellow lion from the red lion?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:55 engine.py:267] Added request chatcmpl-ed835cbd22ff4b81ba1c2984f963b4cb.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:07:56 metrics.py:449] Avg prompt throughput: 53.7 tokens/s, Avg generation throughput: 108.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:07:58 logger.py:37] Received request chatcmpl-65278b41eb224a1d99ccb05e387a427e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which ingredient is most used in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:58 logger.py:37] Received request chatcmpl-d61943fc3d5f490fa534da10e4468711: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, which handmade electronic device is the most commonly manufactured among the following options?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:07:58 engine.py:267] Added request chatcmpl-65278b41eb224a1d99ccb05e387a427e.
INFO 12-25 14:07:58 engine.py:267] Added request chatcmpl-d61943fc3d5f490fa534da10e4468711.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:00 logger.py:37] Received request chatcmpl-9b062432e5704b33b737bcae908dee17: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement is true about this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:00 engine.py:267] Added request chatcmpl-9b062432e5704b33b737bcae908dee17.
INFO 12-25 14:08:01 logger.py:37] Received request chatcmpl-7505e2388a1e4367b555230bcfbc8344: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:01 engine.py:267] Added request chatcmpl-7505e2388a1e4367b555230bcfbc8344.
INFO 12-25 14:08:01 metrics.py:449] Avg prompt throughput: 50.5 tokens/s, Avg generation throughput: 103.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:04 logger.py:37] Received request chatcmpl-fd8d49d90bab4cdea299d85aa2a31c3d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following steps introduced in this video? (a) A pair of slippers. (b) A pair of pillows. (c) A Starbucks cup. (d) A Windows computer.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:04 engine.py:267] Added request chatcmpl-fd8d49d90bab4cdea299d85aa2a31c3d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:05 logger.py:37] Received request chatcmpl-ce071b9a3267411c8599c7176c7dc51c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:06 engine.py:267] Added request chatcmpl-ce071b9a3267411c8599c7176c7dc51c.
INFO 12-25 14:08:06 logger.py:37] Received request chatcmpl-a6e3e9f8062a4d95a294513c5e80735b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to this video, what can you do if wanting to draw multiple neat lines using only one marker pen?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:06 engine.py:267] Added request chatcmpl-a6e3e9f8062a4d95a294513c5e80735b.
INFO 12-25 14:08:06 metrics.py:449] Avg prompt throughput: 45.7 tokens/s, Avg generation throughput: 116.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:10 logger.py:37] Received request chatcmpl-90a477fe8b764c47a175046b082b552f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:10 engine.py:267] Added request chatcmpl-90a477fe8b764c47a175046b082b552f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:11 logger.py:37] Received request chatcmpl-964c77e0c0e448fbb050e8541f06afed: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video show?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:11 engine.py:267] Added request chatcmpl-964c77e0c0e448fbb050e8541f06afed.
INFO 12-25 14:08:11 metrics.py:449] Avg prompt throughput: 24.0 tokens/s, Avg generation throughput: 109.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:12 logger.py:37] Received request chatcmpl-398f2e51f44f4e3d9ab8f57ed3737335: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Could you please indicate the specific time in the video when the minor kitchen mishap occurs while cooking?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:12 logger.py:37] Received request chatcmpl-1f7a2db48884487b863a3e33829889a3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:12 engine.py:267] Added request chatcmpl-398f2e51f44f4e3d9ab8f57ed3737335.
INFO 12-25 14:08:12 engine.py:267] Added request chatcmpl-1f7a2db48884487b863a3e33829889a3.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:17 logger.py:37] Received request chatcmpl-3251e24c94894018bdf7baeb9fb103bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many dance group auditions are included in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:17 engine.py:267] Added request chatcmpl-3251e24c94894018bdf7baeb9fb103bc.
INFO 12-25 14:08:17 metrics.py:449] Avg prompt throughput: 35.8 tokens/s, Avg generation throughput: 104.0 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:18 logger.py:37] Received request chatcmpl-29249b4e6f364147ac90aa0356021156: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How do they typically determine the final food rating in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:18 engine.py:267] Added request chatcmpl-29249b4e6f364147ac90aa0356021156.
INFO 12-25 14:08:18 logger.py:37] Received request chatcmpl-2c9959e5f8174c47aff29abee7934780: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the first and last made planters have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:18 engine.py:267] Added request chatcmpl-2c9959e5f8174c47aff29abee7934780.
INFO 12-25 14:08:19 logger.py:37] Received request chatcmpl-c8d3a9bfd0324e36a4e77ed85422bd0d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do the Wisconsin cheese cubes receive an A rating?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:19 engine.py:267] Added request chatcmpl-c8d3a9bfd0324e36a4e77ed85422bd0d.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:22 metrics.py:449] Avg prompt throughput: 38.5 tokens/s, Avg generation throughput: 115.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:23 logger.py:37] Received request chatcmpl-7b2abb379ae34e17b192e053204f29ad: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What do the two handmade crafts have in common?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:23 engine.py:267] Added request chatcmpl-7b2abb379ae34e17b192e053204f29ad.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:25 logger.py:37] Received request chatcmpl-365b3274ec5b4256a26528aa441a0915: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does this video focus on?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:25 logger.py:37] Received request chatcmpl-4c2d525c153a448386172c71680b59fc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the primary factor that determined the sequence in which the children appeared in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:25 engine.py:267] Added request chatcmpl-365b3274ec5b4256a26528aa441a0915.
INFO 12-25 14:08:25 engine.py:267] Added request chatcmpl-4c2d525c153a448386172c71680b59fc.
INFO 12-25 14:08:26 logger.py:37] Received request chatcmpl-fc7665f9a7c14b7f9b6be5598425337c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is not the function a clip can provide in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:26 engine.py:267] Added request chatcmpl-fc7665f9a7c14b7f9b6be5598425337c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:27 metrics.py:449] Avg prompt throughput: 51.8 tokens/s, Avg generation throughput: 98.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:28 logger.py:37] Received request chatcmpl-6eee3b0f4daa4710aec21bbf27fd34f2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the best caption for this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:28 engine.py:267] Added request chatcmpl-6eee3b0f4daa4710aec21bbf27fd34f2.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:30 logger.py:37] Received request chatcmpl-7281b540137c46ea9b7164f937d1671e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video the main character goes to five different restaurants, which restaurant is frequented by the main character\'s brother-in-law?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:30 engine.py:267] Added request chatcmpl-7281b540137c46ea9b7164f937d1671e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:32 metrics.py:449] Avg prompt throughput: 27.8 tokens/s, Avg generation throughput: 128.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:33 logger.py:37] Received request chatcmpl-efd9dadef8a742a4abe1b962909c9ed3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, the main character delivers food to someone on Wednesday. What is the nature of their relationship?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:33 engine.py:267] Added request chatcmpl-efd9dadef8a742a4abe1b962909c9ed3.
INFO 12-25 14:08:34 logger.py:37] Received request chatcmpl-56ff5d3d3288479abc65bdd39ef2f1a2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main food sold at the restaurant that the main character in the video thinks has the most historical flavor?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:34 engine.py:267] Added request chatcmpl-56ff5d3d3288479abc65bdd39ef2f1a2.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:36 logger.py:37] Received request chatcmpl-80de09aa7bac480aa74e26f4e74dd0f6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many DIYs have been made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:36 engine.py:267] Added request chatcmpl-80de09aa7bac480aa74e26f4e74dd0f6.
INFO 12-25 14:08:37 metrics.py:449] Avg prompt throughput: 42.3 tokens/s, Avg generation throughput: 125.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:39 logger.py:37] Received request chatcmpl-199817095527424181f0385b3cf26d23: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video hero\'s favorite food before he eats the roast suckling pig?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:39 engine.py:267] Added request chatcmpl-199817095527424181f0385b3cf26d23.
INFO 12-25 14:08:41 logger.py:37] Received request chatcmpl-4f0fb990351a482dbcb80f9e8a2a2fc6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be inferred from the video, why does the video dedicates a significant amount of time to the roast suckling pig?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:41 logger.py:37] Received request chatcmpl-d79d83153d6d4f229732b5e3c629baac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which dish at Restaurant Kalamansi best embodies the rich history and essence of Filipino cuisine?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:41 engine.py:267] Added request chatcmpl-4f0fb990351a482dbcb80f9e8a2a2fc6.
INFO 12-25 14:08:41 engine.py:267] Added request chatcmpl-d79d83153d6d4f229732b5e3c629baac.
INFO 12-25 14:08:42 metrics.py:449] Avg prompt throughput: 43.3 tokens/s, Avg generation throughput: 104.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:44 logger.py:37] Received request chatcmpl-f66555651cfe4dbaa894436b2eb35644: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In which order are the following steps introduced in this video? (a) Cardboard Apple MacBook. (b) Cardboard Apple Watch. (c) Apple iPad. (d) Apple iPhone 13.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:44 engine.py:267] Added request chatcmpl-f66555651cfe4dbaa894436b2eb35644.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:46 logger.py:37] Received request chatcmpl-76623c0318de462397ae2559b8b94ade: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does Sadie have a countdown?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:46 engine.py:267] Added request chatcmpl-76623c0318de462397ae2559b8b94ade.
INFO 12-25 14:08:47 metrics.py:449] Avg prompt throughput: 30.8 tokens/s, Avg generation throughput: 113.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:47 logger.py:37] Received request chatcmpl-1fcc2e7761d14f28b59a2fc1a2ab0100: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most significant difference between the first clip in the video and the other two?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:47 engine.py:267] Added request chatcmpl-1fcc2e7761d14f28b59a2fc1a2ab0100.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:50 logger.py:37] Received request chatcmpl-142ebff8ce4b4aed8ec4bc61f850b42c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Extrapolating from the video, what does it suggest if chunky fries are served?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:50 engine.py:267] Added request chatcmpl-142ebff8ce4b4aed8ec4bc61f850b42c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:52 logger.py:37] Received request chatcmpl-b438282ea00240c6a717e1bdf440d47e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the flavor that the main character tastes the most in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:52 engine.py:267] Added request chatcmpl-b438282ea00240c6a717e1bdf440d47e.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:52 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 127.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:53 logger.py:37] Received request chatcmpl-c00588403e7142f3a87b814d52f83bbb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many calories has the person in the video, who consumed a $100 golden burger, already eaten when he meets his teammate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:53 engine.py:267] Added request chatcmpl-c00588403e7142f3a87b814d52f83bbb.
INFO 12-25 14:08:55 logger.py:37] Received request chatcmpl-1b7ea985e6194a7c857e33ccbc440762: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the best caption for this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:55 engine.py:267] Added request chatcmpl-1b7ea985e6194a7c857e33ccbc440762.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:57 logger.py:37] Received request chatcmpl-2ac3608b9a2f4731986168a0d95fa4d2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following food combinations is the favorite of the two people in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:57 engine.py:267] Added request chatcmpl-2ac3608b9a2f4731986168a0d95fa4d2.
INFO 12-25 14:08:57 metrics.py:449] Avg prompt throughput: 42.0 tokens/s, Avg generation throughput: 114.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:08:58 logger.py:37] Received request chatcmpl-0195da0b4ae349eaa2136135b8180c91: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the person documenting his fitness at the beginning of the video and the main curator of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:58 engine.py:267] Added request chatcmpl-0195da0b4ae349eaa2136135b8180c91.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:08:59 logger.py:37] Received request chatcmpl-99c749e3f20a483690ea457631f2219a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What letter of the alphabet does the two teams choose to eat differently when it comes to food?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:08:59 engine.py:267] Added request chatcmpl-99c749e3f20a483690ea457631f2219a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:02 metrics.py:449] Avg prompt throughput: 29.3 tokens/s, Avg generation throughput: 140.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:03 logger.py:37] Received request chatcmpl-470298dc96ad4e5797eafd64616512f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the handcraft made seventh in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:03 engine.py:267] Added request chatcmpl-470298dc96ad4e5797eafd64616512f5.
INFO 12-25 14:09:04 logger.py:37] Received request chatcmpl-3a575b0086084841bf00ab78ced45de2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was significant about Chanel\'s embrace of tanned skin?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:04 engine.py:267] Added request chatcmpl-3a575b0086084841bf00ab78ced45de2.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:05 logger.py:37] Received request chatcmpl-50a054d1f7124f5bb54c3e526764dbb1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As one team enjoys pizza, how many tasks has the other team completed?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:05 engine.py:267] Added request chatcmpl-50a054d1f7124f5bb54c3e526764dbb1.
INFO 12-25 14:09:07 metrics.py:449] Avg prompt throughput: 38.7 tokens/s, Avg generation throughput: 128.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:09 logger.py:37] Received request chatcmpl-7601220a1a4045aa85e0f1a1baa7bd43: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order for processing cod in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:09 engine.py:267] Added request chatcmpl-7601220a1a4045aa85e0f1a1baa7bd43.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:10 logger.py:37] Received request chatcmpl-7ad5ea7a98e145e9936000ab4f8da4b3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many kinds of planters are made in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:10 engine.py:267] Added request chatcmpl-7ad5ea7a98e145e9936000ab4f8da4b3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:12 logger.py:37] Received request chatcmpl-f5355568e5c24546863c1c98c5ab0d42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which category has the highest number of outfits?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:12 engine.py:267] Added request chatcmpl-f5355568e5c24546863c1c98c5ab0d42.
INFO 12-25 14:09:12 metrics.py:449] Avg prompt throughput: 37.6 tokens/s, Avg generation throughput: 102.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:09:13 logger.py:37] Received request chatcmpl-4dd3c80ceb144287a0df651b53026d4b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many grandsons does the founder of Gucci have?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:13 engine.py:267] Added request chatcmpl-4dd3c80ceb144287a0df651b53026d4b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:14 logger.py:37] Received request chatcmpl-21a24685396649528b090a0bb56f099a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who in the video accomplished the calorie goal set?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:14 engine.py:267] Added request chatcmpl-21a24685396649528b090a0bb56f099a.
INFO 12-25 14:09:15 logger.py:37] Received request chatcmpl-7bfdfbb3bb3646f384b8777bed3ee7c3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main topic about this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:15 engine.py:267] Added request chatcmpl-7bfdfbb3bb3646f384b8777bed3ee7c3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:17 metrics.py:449] Avg prompt throughput: 38.4 tokens/s, Avg generation throughput: 126.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:18 logger.py:37] Received request chatcmpl-1277537488334aa282d7fecbd189a17d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most distinctive feature that sets "Nothing new" apart from the other categories?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:18 engine.py:267] Added request chatcmpl-1277537488334aa282d7fecbd189a17d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:19 logger.py:37] Received request chatcmpl-20f7bcff204a4770aa847655122d3ea0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What would happen if the daughter didn\'t assume control of Prada?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:19 engine.py:267] Added request chatcmpl-20f7bcff204a4770aa847655122d3ea0.
INFO 12-25 14:09:20 logger.py:37] Received request chatcmpl-fb0a555229f4472ba8459da01039e4a7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How did World War I affect the businesses of the people profiled in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:20 engine.py:267] Added request chatcmpl-fb0a555229f4472ba8459da01039e4a7.
INFO 12-25 14:09:22 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 121.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:24 logger.py:37] Received request chatcmpl-f08e799dda804fbcb1dedacb5c7d3358: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which state\'s cuisine is consistently highly praised by the three people in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:24 engine.py:267] Added request chatcmpl-f08e799dda804fbcb1dedacb5c7d3358.
INFO 12-25 14:09:25 logger.py:37] Received request chatcmpl-935239da7a5b4f3c988c7437e7fa7cf1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which item is not being displayed on the product showcase interface?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:25 logger.py:37] Received request chatcmpl-6cc6d107971b433fb3916b98973a6206: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which jewellery piece is being introduced when she takes off her coat?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:25 engine.py:267] Added request chatcmpl-935239da7a5b4f3c988c7437e7fa7cf1.
INFO 12-25 14:09:25 engine.py:267] Added request chatcmpl-6cc6d107971b433fb3916b98973a6206.
INFO 12-25 14:09:27 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:30 logger.py:37] Received request chatcmpl-2c1067d1cce94a6a82558ca05319cb3e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, which of the following statements is accurate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:30 engine.py:267] Added request chatcmpl-2c1067d1cce94a6a82558ca05319cb3e.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:32 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 132.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:09:32 logger.py:37] Received request chatcmpl-ae9773a83f7245308ed203a9866a1b98: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the video\'s main character and the lady sitting next to him at the table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:32 engine.py:267] Added request chatcmpl-ae9773a83f7245308ed203a9866a1b98.
INFO 12-25 14:09:33 logger.py:37] Received request chatcmpl-df7e7f5fc3c44615b6f33393f04cd465: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the woman\'s outfit today in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:33 engine.py:267] Added request chatcmpl-df7e7f5fc3c44615b6f33393f04cd465.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:36 logger.py:37] Received request chatcmpl-cc1550201775402cad868ca90213b26c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video documenting?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:36 engine.py:267] Added request chatcmpl-cc1550201775402cad868ca90213b26c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:37 metrics.py:449] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 112.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:09:37 logger.py:37] Received request chatcmpl-fc82e597e8924e8b9c1212cb45f33590: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:37 engine.py:267] Added request chatcmpl-fc82e597e8924e8b9c1212cb45f33590.
INFO 12-25 14:09:38 logger.py:37] Received request chatcmpl-e5a51d5a7f4c4be38c01825462ab660a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Could you please specify the order for food preparation as shown in the video? Which of the following sequences is accurate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:38 engine.py:267] Added request chatcmpl-e5a51d5a7f4c4be38c01825462ab660a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:41 logger.py:37] Received request chatcmpl-c81f205ed66643289a1d886921819921: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where might this walkout take place?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:41 engine.py:267] Added request chatcmpl-c81f205ed66643289a1d886921819921.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:42 metrics.py:449] Avg prompt throughput: 38.8 tokens/s, Avg generation throughput: 117.1 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:09:43 logger.py:37] Received request chatcmpl-3cb5d94f7a06410daa83755cce1a6400: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what sequence are the following jewelry pieces arranged to be displayed in this video? (a) Engagement ring. (b) Cartier bracelets. (c) Tabayer earrings. (d) Missoma hoops.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:43 engine.py:267] Added request chatcmpl-3cb5d94f7a06410daa83755cce1a6400.
INFO 12-25 14:09:43 logger.py:37] Received request chatcmpl-3d5dc3743216440dbae7a382610dfe84: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many major setbacks in Nike\'s development were mentioned in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:43 engine.py:267] Added request chatcmpl-3d5dc3743216440dbae7a382610dfe84.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:47 logger.py:37] Received request chatcmpl-00fffbcede664b6e91b03a5a27a3604e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What food is sampled by the main character when meeting a modeling agent for the first time in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:47 engine.py:267] Added request chatcmpl-00fffbcede664b6e91b03a5a27a3604e.
INFO 12-25 14:09:47 metrics.py:449] Avg prompt throughput: 46.4 tokens/s, Avg generation throughput: 124.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:50 logger.py:37] Received request chatcmpl-357a5d1cfa784fe4b97de835ed903c57: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What was the trigger for the company\'s name change to Nike in 1971?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:50 engine.py:267] Added request chatcmpl-357a5d1cfa784fe4b97de835ed903c57.
INFO 12-25 14:09:50 logger.py:37] Received request chatcmpl-13fadf791e554b1aaa989f6af2d63d7e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not a common characteristic of these perfumes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:50 engine.py:267] Added request chatcmpl-13fadf791e554b1aaa989f6af2d63d7e.
INFO 12-25 14:09:52 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 128.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:09:55 logger.py:37] Received request chatcmpl-b4e1a1734b274e3cab5c296cbc9e8c30: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many stores has she visited in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:55 engine.py:267] Added request chatcmpl-b4e1a1734b274e3cab5c296cbc9e8c30.
INFO 12-25 14:09:55 logger.py:37] Received request chatcmpl-40bd19ed611040cf88f9a8fa22eab1c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do they throw food in a big bowl?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:55 engine.py:267] Added request chatcmpl-40bd19ed611040cf88f9a8fa22eab1c6.
INFO 12-25 14:09:55 logger.py:37] Received request chatcmpl-378b7ce02a4d4e748bdf0a02687dbda6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the place with the green tin door and the sign that says "GAYOSO"?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:55 engine.py:267] Added request chatcmpl-378b7ce02a4d4e748bdf0a02687dbda6.
INFO 12-25 14:09:56 logger.py:37] Received request chatcmpl-b905c40eac3646658f0300ba4e660b7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the heroine in the video like to wear makeup?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:09:56 engine.py:267] Added request chatcmpl-b905c40eac3646658f0300ba4e660b7c.
INFO 12-25 14:09:57 metrics.py:449] Avg prompt throughput: 51.9 tokens/s, Avg generation throughput: 81.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:00 logger.py:37] Received request chatcmpl-bc69373689334dbf81326ffb2d76b06a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which aspect does this video emphasize?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:00 engine.py:267] Added request chatcmpl-bc69373689334dbf81326ffb2d76b06a.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:02 logger.py:37] Received request chatcmpl-db6d1bc6175648d18462a32ee9bc7126: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the last model gathering, at what time does the green model in the lower left corner of the square appear in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:02 engine.py:267] Added request chatcmpl-db6d1bc6175648d18462a32ee9bc7126.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:02 metrics.py:449] Avg prompt throughput: 27.3 tokens/s, Avg generation throughput: 122.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:10:03 logger.py:37] Received request chatcmpl-16624815e8424b7ea5c08d31a6a1364b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, when introducing her bedroom, why did the author say that she wanted to take a large photo and hang it on the wall?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:03 engine.py:267] Added request chatcmpl-16624815e8424b7ea5c08d31a6a1364b.
INFO 12-25 14:10:04 logger.py:37] Received request chatcmpl-47a2272cb0bf477e83d708f8917d7687: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions about the author\'s use of Bluetooth headsets is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:04 engine.py:267] Added request chatcmpl-47a2272cb0bf477e83d708f8917d7687.
INFO 12-25 14:10:07 metrics.py:449] Avg prompt throughput: 29.9 tokens/s, Avg generation throughput: 136.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:10 logger.py:37] Received request chatcmpl-08feb86d8c33451b8616a48eb8e095d5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the heroine in the dancing sequence in the second half of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:10 engine.py:267] Added request chatcmpl-08feb86d8c33451b8616a48eb8e095d5.
INFO 12-25 14:10:10 logger.py:37] Received request chatcmpl-16a8431fcc2a4b0ab177c478fba2f54a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which food did the team that chose bananas also select from the following options?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:10 logger.py:37] Received request chatcmpl-e1887f3c4f6a485785dc44a12ff32acc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the male protagonist in the video do immediately after finishing his personal report at the meeting?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:10 engine.py:267] Added request chatcmpl-16a8431fcc2a4b0ab177c478fba2f54a.
INFO 12-25 14:10:10 engine.py:267] Added request chatcmpl-e1887f3c4f6a485785dc44a12ff32acc.
INFO 12-25 14:10:12 logger.py:37] Received request chatcmpl-011cf6ff1bf0488b8668a6c74ac5f12b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the following fragrances appear in the video? (a) OUD LEATHER. (b) OUD WOOD. (c) GREY VETIVER. (d) LAVENDRE EXTREME.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:12 engine.py:267] Added request chatcmpl-011cf6ff1bf0488b8668a6c74ac5f12b.
INFO 12-25 14:10:12 metrics.py:449] Avg prompt throughput: 62.2 tokens/s, Avg generation throughput: 77.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:15 logger.py:37] Received request chatcmpl-a598aa3f39214c31a00f35decbf95539: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What factors contributed to the success of Chanel No. 5 and the little black dress?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:15 engine.py:267] Added request chatcmpl-a598aa3f39214c31a00f35decbf95539.
INFO 12-25 14:10:17 logger.py:37] Received request chatcmpl-10f08054e19d436ba63b1d98821310cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:17 engine.py:267] Added request chatcmpl-10f08054e19d436ba63b1d98821310cd.
INFO 12-25 14:10:17 logger.py:37] Received request chatcmpl-12b4fba265de4adfbe7435fde3df3abb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the process of boiling leaves in a pot that the girl introduces at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:17 engine.py:267] Added request chatcmpl-12b4fba265de4adfbe7435fde3df3abb.
INFO 12-25 14:10:17 metrics.py:449] Avg prompt throughput: 26.2 tokens/s, Avg generation throughput: 112.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:21 logger.py:37] Received request chatcmpl-2b333ac1f5384f24a9b5d30a1aa7352e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What clothing was not copied in the clip showing the plagiarism against Zara?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:21 engine.py:267] Added request chatcmpl-2b333ac1f5384f24a9b5d30a1aa7352e.
INFO 12-25 14:10:21 logger.py:37] Received request chatcmpl-2a40eb8c0e374210a89e4a8a9626aa5e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the main content of this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:21 engine.py:267] Added request chatcmpl-2a40eb8c0e374210a89e4a8a9626aa5e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:22 metrics.py:449] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:22 logger.py:37] Received request chatcmpl-3f4e606e02624e4dabfc3c415cd11ac9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After organizing the clutter in the cabinet in the video, what is the main topic that the heroine discusses while sitting in front of the camera?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:23 engine.py:267] Added request chatcmpl-3f4e606e02624e4dabfc3c415cd11ac9.
INFO 12-25 14:10:24 logger.py:37] Received request chatcmpl-5085b4f6ae5b4b999486121c353f318b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following tasks did the heroine not complete while her baby was sleeping?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:24 engine.py:267] Added request chatcmpl-5085b4f6ae5b4b999486121c353f318b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:27 metrics.py:449] Avg prompt throughput: 29.5 tokens/s, Avg generation throughput: 128.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:28 logger.py:37] Received request chatcmpl-1c8173e9a4ba4a46adb5b91db20b548e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In what chronological order did the following events take place? (a) The Prada brand was almost ceasing to exist. (b) The launch of the label Miu Miu. (c) Prada gained connections to royal families. (d) The arrival of Miuccia Prada.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:28 engine.py:267] Added request chatcmpl-1c8173e9a4ba4a46adb5b91db20b548e.
INFO 12-25 14:10:29 logger.py:37] Received request chatcmpl-75a458e5c35c4e579482fa621fe62034: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is correct in chronological order of the male protagonist\'s daily life trajectory?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:29 engine.py:267] Added request chatcmpl-75a458e5c35c4e579482fa621fe62034.
INFO 12-25 14:10:29 logger.py:37] Received request chatcmpl-5c66669f58c44fdc9d1a30b98c9eb592: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions of the heroine\'s daily activities in a day is correct in chronological order?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:29 engine.py:267] Added request chatcmpl-5c66669f58c44fdc9d1a30b98c9eb592.
INFO 12-25 14:10:29 logger.py:37] Received request chatcmpl-f25b0993007d415b93897432f8243682: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, where will the lamp be hung in the package that the heroine takes home from the gym?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:29 engine.py:267] Added request chatcmpl-f25b0993007d415b93897432f8243682.
INFO 12-25 14:10:32 metrics.py:449] Avg prompt throughput: 65.8 tokens/s, Avg generation throughput: 105.0 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:34 logger.py:37] Received request chatcmpl-d298f761954042ff826ac87364fbe34c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What makes the dual diamond ring from Leon Diamond unique or special?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:34 engine.py:267] Added request chatcmpl-d298f761954042ff826ac87364fbe34c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:36 logger.py:37] Received request chatcmpl-2db07b8842624a8b82108147cff46c2f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following things is not what the host and hostess are talking about in the car at the beginning of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:36 engine.py:267] Added request chatcmpl-2db07b8842624a8b82108147cff46c2f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:37 metrics.py:449] Avg prompt throughput: 28.6 tokens/s, Avg generation throughput: 126.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:38 logger.py:37] Received request chatcmpl-a2ee56833133472eb75e79cd6fc58532: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following things was not discussed by the heroine while driving to work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:38 engine.py:267] Added request chatcmpl-a2ee56833133472eb75e79cd6fc58532.
INFO 12-25 14:10:39 logger.py:37] Received request chatcmpl-8985327984c34aa0a893e751b39f14ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which statement is true according to this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:39 logger.py:37] Received request chatcmpl-90156d3edb0d4e2e887291784adbb15c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On which day in the video did the female lead barely speak during daytime working hours?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:39 engine.py:267] Added request chatcmpl-8985327984c34aa0a893e751b39f14ae.
INFO 12-25 14:10:39 engine.py:267] Added request chatcmpl-90156d3edb0d4e2e887291784adbb15c.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:42 metrics.py:449] Avg prompt throughput: 39.5 tokens/s, Avg generation throughput: 108.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:43 logger.py:37] Received request chatcmpl-86364318d6874a3e96a9b2a4524cc5ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What food items are common in both the hero\'s breakfast and lunch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:43 engine.py:267] Added request chatcmpl-86364318d6874a3e96a9b2a4524cc5ea.
INFO 12-25 14:10:44 logger.py:37] Received request chatcmpl-a5516d6fadc14692bc9354f15f9ea231: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not what the heroine said while lying in bed on Friday morning in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:44 engine.py:267] Added request chatcmpl-a5516d6fadc14692bc9354f15f9ea231.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:46 logger.py:37] Received request chatcmpl-28143d9efddd4cfcb09e1c03a937c4bf: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Here are the names of some of the chapters, and what is the order in which they occur? (a) Scaling Up: One Plus One. (b) The Public Eye. (c) Broken Trust. (d) Revenge.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:46 engine.py:267] Added request chatcmpl-28143d9efddd4cfcb09e1c03a937c4bf.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:47 metrics.py:449] Avg prompt throughput: 47.4 tokens/s, Avg generation throughput: 121.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:48 logger.py:37] Received request chatcmpl-0ce44cb0b9a047b3ae0a60460168ae56: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is inside the Amazon package received by the female protagonist in the video used for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:48 engine.py:267] Added request chatcmpl-0ce44cb0b9a047b3ae0a60460168ae56.
INFO 12-25 14:10:49 logger.py:37] Received request chatcmpl-5ed8d9c051db4d1bb10b1e285735dbcd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who was in control during the landing process of the plane in the video\'s return journey?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:49 engine.py:267] Added request chatcmpl-5ed8d9c051db4d1bb10b1e285735dbcd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:52 metrics.py:449] Avg prompt throughput: 27.7 tokens/s, Avg generation throughput: 137.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:10:54 logger.py:37] Received request chatcmpl-7a743bd440004025988fa58edc383d03: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the correct chronological order of what Bart does on his first day in the video after arriving in Salt Lake City?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:54 engine.py:267] Added request chatcmpl-7a743bd440004025988fa58edc383d03.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:10:56 logger.py:37] Received request chatcmpl-8a35167dd5f14b6295e77ea232fd500c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video after feeding the ducks, what did the male protagonist do after riding his bike?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:56 engine.py:267] Added request chatcmpl-8a35167dd5f14b6295e77ea232fd500c.
INFO 12-25 14:10:57 logger.py:37] Received request chatcmpl-8e646aca07b64a8cb9c0b969096d8e3d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the two travelers in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:57 engine.py:267] Added request chatcmpl-8e646aca07b64a8cb9c0b969096d8e3d.
INFO 12-25 14:10:57 metrics.py:449] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 86.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:10:57 logger.py:37] Received request chatcmpl-3cffc9798d6945b18cf3cb698f93524e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What makes ROSE PRICK different from other perfumes?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:10:57 engine.py:267] Added request chatcmpl-3cffc9798d6945b18cf3cb698f93524e.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:02 logger.py:37] Received request chatcmpl-85528f0755ab496ba0dfffe37b5c5fd4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What time does the heroine in the video get home from get off work?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:02 engine.py:267] Added request chatcmpl-85528f0755ab496ba0dfffe37b5c5fd4.
INFO 12-25 14:11:02 metrics.py:449] Avg prompt throughput: 26.1 tokens/s, Avg generation throughput: 146.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:06 logger.py:37] Received request chatcmpl-f2075da4b5b84b5ba387f27cd1eef48c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do travelers think Moldova isn\'t the worst city to visit?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:06 logger.py:37] Received request chatcmpl-39a4e4aa9bf948459a741a30a960e1bd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is the man named Niko yelling at the mountain?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:06 engine.py:267] Added request chatcmpl-f2075da4b5b84b5ba387f27cd1eef48c.
INFO 12-25 14:11:06 engine.py:267] Added request chatcmpl-39a4e4aa9bf948459a741a30a960e1bd.
INFO 12-25 14:11:07 logger.py:37] Received request chatcmpl-b2170ea0f35542b7bf77e5715a554e3d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order of presentation of the following events in the video? (a) Zara was plagiarized. (b) Toxic dyes. (c) Zara owner\'s birthday.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:07 engine.py:267] Added request chatcmpl-b2170ea0f35542b7bf77e5715a554e3d.
INFO 12-25 14:11:07 metrics.py:449] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 102.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:09 logger.py:37] Received request chatcmpl-aa1fc50ae9384afe8def36b3959c4edd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, does the heroine show the panoramic view outside the window of her rented place? If not, why?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:09 engine.py:267] Added request chatcmpl-aa1fc50ae9384afe8def36b3959c4edd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:12 metrics.py:449] Avg prompt throughput: 15.2 tokens/s, Avg generation throughput: 142.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:14 logger.py:37] Received request chatcmpl-c0d01e1fda66490a832d00aa39419b9e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the role of the man named AJ in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:14 engine.py:267] Added request chatcmpl-c0d01e1fda66490a832d00aa39419b9e.
INFO 12-25 14:11:14 logger.py:37] Received request chatcmpl-e2a3eb0850a447aba44d99a68ad6f4c4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the accurate sequence of their destinations?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:14 engine.py:267] Added request chatcmpl-e2a3eb0850a447aba44d99a68ad6f4c4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:16 logger.py:37] Received request chatcmpl-bbd800408d0f499999566a05bae3b374: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly sorts the sequence of events in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:16 engine.py:267] Added request chatcmpl-bbd800408d0f499999566a05bae3b374.
INFO 12-25 14:11:16 logger.py:37] Received request chatcmpl-e11350af6e4e4d068bc45e5c0a0ebf35: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who is the grandfather in the video with the injured right hand?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:17 engine.py:267] Added request chatcmpl-e11350af6e4e4d068bc45e5c0a0ebf35.
INFO 12-25 14:11:17 metrics.py:449] Avg prompt throughput: 51.5 tokens/s, Avg generation throughput: 107.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:19 logger.py:37] Received request chatcmpl-217167d12b004bf787c9de28bc778191: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options does the video not give an explanation for?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:19 engine.py:267] Added request chatcmpl-217167d12b004bf787c9de28bc778191.
INFO 12-25 14:11:22 metrics.py:449] Avg prompt throughput: 13.2 tokens/s, Avg generation throughput: 144.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:25 logger.py:37] Received request chatcmpl-9fc254a0cd0f46279da5236345ced48f: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What did the people in the video do on the third day of their trip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:25 engine.py:267] Added request chatcmpl-9fc254a0cd0f46279da5236345ced48f.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:26 logger.py:37] Received request chatcmpl-88ab4cff6a7f49ea9c7325a599e4b1d1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is there no record of the heroine\'s daily life from 5:00 to 7:20 in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:26 engine.py:267] Added request chatcmpl-88ab4cff6a7f49ea9c7325a599e4b1d1.
INFO 12-25 14:11:27 logger.py:37] Received request chatcmpl-c300376960e6455b920aaad8eeb6e209: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The main character of the video gets the money in a plastic bag, where does it come from?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:27 engine.py:267] Added request chatcmpl-c300376960e6455b920aaad8eeb6e209.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:27 metrics.py:449] Avg prompt throughput: 43.6 tokens/s, Avg generation throughput: 107.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:11:28 logger.py:37] Received request chatcmpl-b3af6612f43948cfa87bd43716ee12e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, how many buildings were built in less than 110 years?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:28 engine.py:267] Added request chatcmpl-b3af6612f43948cfa87bd43716ee12e2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:32 logger.py:37] Received request chatcmpl-f8dd9b26496945e0bccf8bc1467b5c5d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is this video mainly about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:32 engine.py:267] Added request chatcmpl-f8dd9b26496945e0bccf8bc1467b5c5d.
INFO 12-25 14:11:32 metrics.py:449] Avg prompt throughput: 25.9 tokens/s, Avg generation throughput: 134.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:35 logger.py:37] Received request chatcmpl-42106b070c6d43e4adc5f61d2da1968c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the team in the SUV in the video and the owner of the van company?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:35 engine.py:267] Added request chatcmpl-42106b070c6d43e4adc5f61d2da1968c.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:37 logger.py:37] Received request chatcmpl-197ac9205dd94be98ec19c2c5fa06104: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the final mode of transportation used by the team that successfully finishes the second challenge?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:37 engine.py:267] Added request chatcmpl-197ac9205dd94be98ec19c2c5fa06104.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:37 logger.py:37] Received request chatcmpl-62e799ca9ac34a268b5925dd2f6498e2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the theme of the video that the male protagonist made after finishing his workout?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:37 engine.py:267] Added request chatcmpl-62e799ca9ac34a268b5925dd2f6498e2.
INFO 12-25 14:11:37 metrics.py:449] Avg prompt throughput: 28.5 tokens/s, Avg generation throughput: 102.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:11:38 logger.py:37] Received request chatcmpl-f14baa1b0f0145d49ff345e4e5957994: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the following places are introduced in the video? (a) Minaki Aman Temple. (b) Alhamra. (c) Burj Khalifa. (d) Machu Picchu. (e) Coliseum.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:38 engine.py:267] Added request chatcmpl-f14baa1b0f0145d49ff345e4e5957994.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:42 metrics.py:449] Avg prompt throughput: 34.7 tokens/s, Avg generation throughput: 138.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:43 logger.py:37] Received request chatcmpl-84c0497b287649a39215e62cc6cd12cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "When the people in the video saw the turtles for the first time, how many days into their journey was it?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:43 engine.py:267] Added request chatcmpl-84c0497b287649a39215e62cc6cd12cd.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:44 logger.py:37] Received request chatcmpl-5ef08557407a49a28514b0be472070c6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the protagonist of the video record?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:44 engine.py:267] Added request chatcmpl-5ef08557407a49a28514b0be472070c6.
INFO 12-25 14:11:46 logger.py:37] Received request chatcmpl-2ee5388337ac4a73960905bc2c85a22a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the main character of the video think of the people of Bandung?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:46 engine.py:267] Added request chatcmpl-2ee5388337ac4a73960905bc2c85a22a.
INFO 12-25 14:11:46 logger.py:37] Received request chatcmpl-020f6dfc12434c98a30a41b82b258c42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what happened in the car when the heroine came home from shopping in the supermarket?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:46 engine.py:267] Added request chatcmpl-020f6dfc12434c98a30a41b82b258c42.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:47 metrics.py:449] Avg prompt throughput: 55.2 tokens/s, Avg generation throughput: 93.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:11:48 logger.py:37] Received request chatcmpl-ff4cebea510343c995842a1588603269: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following activities does the man in the video perform only once?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:48 engine.py:267] Added request chatcmpl-ff4cebea510343c995842a1588603269.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:50 logger.py:37] Received request chatcmpl-c7c7c337de3d4b5bb5e7f741160eb910: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which challenges do they not complete during the trip?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:50 engine.py:267] Added request chatcmpl-c7c7c337de3d4b5bb5e7f741160eb910.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:52 logger.py:37] Received request chatcmpl-c22656531f124b5aae714096393faa90: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the purpose of the man in the video processing the blue plastic barrel?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:52 engine.py:267] Added request chatcmpl-c22656531f124b5aae714096393faa90.
INFO 12-25 14:11:52 metrics.py:449] Avg prompt throughput: 39.2 tokens/s, Avg generation throughput: 113.0 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:54 logger.py:37] Received request chatcmpl-020a2956b80f4f55b774a04260aea230: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why are there many toys in the room?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:54 engine.py:267] Added request chatcmpl-020a2956b80f4f55b774a04260aea230.
INFO 12-25 14:11:55 logger.py:37] Received request chatcmpl-ede1556f3f0948a0ab65574433939c2e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the initial budget for each person at the start of the challenge?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:55 engine.py:267] Added request chatcmpl-ede1556f3f0948a0ab65574433939c2e.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:57 metrics.py:449] Avg prompt throughput: 25.6 tokens/s, Avg generation throughput: 125.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:11:59 logger.py:37] Received request chatcmpl-160b15205f2d4f8ca42e439415ecd9f7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is the most interesting toy for these cats based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:59 logger.py:37] Received request chatcmpl-40a1ef8c6ae64bc095153c79ce7eefeb: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the heroine in the video go shopping at Trader joe\'s?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:11:59 engine.py:267] Added request chatcmpl-160b15205f2d4f8ca42e439415ecd9f7.
INFO 12-25 14:11:59 engine.py:267] Added request chatcmpl-40a1ef8c6ae64bc095153c79ce7eefeb.
INFO 12-25 14:12:00 logger.py:37] Received request chatcmpl-02164a43fbde4b6b996dd39f1a93051b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what are the characteristics of these animals?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:00 engine.py:267] Added request chatcmpl-02164a43fbde4b6b996dd39f1a93051b.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:02 metrics.py:449] Avg prompt throughput: 39.4 tokens/s, Avg generation throughput: 113.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:03 logger.py:37] Received request chatcmpl-dbbd122531954b74b45fde344a00b0ea: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Where is the man\'s family most likely to be when he crosses the canyon in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:03 engine.py:267] Added request chatcmpl-dbbd122531954b74b45fde344a00b0ea.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:05 logger.py:37] Received request chatcmpl-f18f33f30a4041b8adede33aa3202d48: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT one of the things the video talks about during the autopilot phase of the plane during the flight to Salt Lake City?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:05 engine.py:267] Added request chatcmpl-f18f33f30a4041b8adede33aa3202d48.
INFO 12-25 14:12:06 logger.py:37] Received request chatcmpl-12e9952d14704e12bd833de2f152472d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the panda do in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:06 engine.py:267] Added request chatcmpl-12e9952d14704e12bd833de2f152472d.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:07 metrics.py:449] Avg prompt throughput: 42.7 tokens/s, Avg generation throughput: 126.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:08 logger.py:37] Received request chatcmpl-f13d16a2e7384aed97a83cde353d3812: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do dogs lie in a row by a window as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:08 engine.py:267] Added request chatcmpl-f13d16a2e7384aed97a83cde353d3812.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:10 logger.py:37] Received request chatcmpl-0ef2d68f07004be0b801bcdd6be4b081: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What successive activities do the people in the video engage in while in the car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:10 engine.py:267] Added request chatcmpl-0ef2d68f07004be0b801bcdd6be4b081.
INFO 12-25 14:12:11 logger.py:37] Received request chatcmpl-8eaeba97028540eda44c4ec05d6eb478: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many times does the traveler in the video reunite with the old grandpa?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:11 engine.py:267] Added request chatcmpl-8eaeba97028540eda44c4ec05d6eb478.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:12 metrics.py:449] Avg prompt throughput: 40.9 tokens/s, Avg generation throughput: 111.7 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:13 logger.py:37] Received request chatcmpl-cd59e42bef6f49caa58754d2c7a11495: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to what is shown in the video, why does the cameraman drive a car?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:13 engine.py:267] Added request chatcmpl-cd59e42bef6f49caa58754d2c7a11495.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:15 logger.py:37] Received request chatcmpl-89368b9c6a784db1b21c2e33e9984411: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which location appears in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:15 engine.py:267] Added request chatcmpl-89368b9c6a784db1b21c2e33e9984411.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:17 metrics.py:449] Avg prompt throughput: 25.8 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:17 logger.py:37] Received request chatcmpl-57c9ca3a25164f54b7b0ac4b982f66b4: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What\'s so special about the trip in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:17 engine.py:267] Added request chatcmpl-57c9ca3a25164f54b7b0ac4b982f66b4.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:19 logger.py:37] Received request chatcmpl-8421b595a3f7443281ec229f0678e87b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does a leopard climb on trees as depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:19 engine.py:267] Added request chatcmpl-8421b595a3f7443281ec229f0678e87b.
INFO 12-25 14:12:20 logger.py:37] Received request chatcmpl-04e0af1b338b43adab35e019207436ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video\'s main focus?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:20 engine.py:267] Added request chatcmpl-04e0af1b338b43adab35e019207436ac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:22 metrics.py:449] Avg prompt throughput: 37.5 tokens/s, Avg generation throughput: 125.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:25 logger.py:37] Received request chatcmpl-155dc6ea4ad842b7a2e0d9887e3237be: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which appears in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:25 logger.py:37] Received request chatcmpl-f9a76f2330e44cd18b8e96910370c3c7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What date did the individual in the video leave a place that Simon thought was very important to him?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:25 engine.py:267] Added request chatcmpl-155dc6ea4ad842b7a2e0d9887e3237be.
INFO 12-25 14:12:25 engine.py:267] Added request chatcmpl-f9a76f2330e44cd18b8e96910370c3c7.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:26 logger.py:37] Received request chatcmpl-95971e82f0754a2cab7b728c73a86a60: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the reason for people visiting this place according to what is shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:26 engine.py:267] Added request chatcmpl-95971e82f0754a2cab7b728c73a86a60.
INFO 12-25 14:12:26 logger.py:37] Received request chatcmpl-ae3221c42757408bae9fa368a6d69962: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do hermit crabs fight with each other?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:26 engine.py:267] Added request chatcmpl-ae3221c42757408bae9fa368a6d69962.
INFO 12-25 14:12:27 metrics.py:449] Avg prompt throughput: 52.5 tokens/s, Avg generation throughput: 91.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:31 logger.py:37] Received request chatcmpl-5a2982acb4b04fa498fcafededa64c42: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which animals compete for territory as shown in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:31 engine.py:267] Added request chatcmpl-5a2982acb4b04fa498fcafededa64c42.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:33 metrics.py:449] Avg prompt throughput: 12.6 tokens/s, Avg generation throughput: 133.6 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:33 logger.py:37] Received request chatcmpl-feba63a867a6420386d840fa52aebf21: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is the characteristics of the 16th location described in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:33 engine.py:267] Added request chatcmpl-feba63a867a6420386d840fa52aebf21.
INFO 12-25 14:12:34 logger.py:37] Received request chatcmpl-4ce5e89775064c19832f3bdb599a5ef5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What story does the photographers record based on the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:34 engine.py:267] Added request chatcmpl-4ce5e89775064c19832f3bdb599a5ef5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:35 logger.py:37] Received request chatcmpl-7c70cfc6146a44e28f7a40643a4106fa: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do people shed tears when the big sea turtle goes to sea in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:35 engine.py:267] Added request chatcmpl-7c70cfc6146a44e28f7a40643a4106fa.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:38 metrics.py:449] Avg prompt throughput: 40.4 tokens/s, Avg generation throughput: 123.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:38 logger.py:37] Received request chatcmpl-20aab40cccb1487791e17948862be0c0: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what does the younger tiger do when it is found by the dominant tiger?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:38 engine.py:267] Added request chatcmpl-20aab40cccb1487791e17948862be0c0.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:40 logger.py:37] Received request chatcmpl-6582d11f32e74a1e968d2ad4b0d8693c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which description of the video is inaccurate?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:40 engine.py:267] Added request chatcmpl-6582d11f32e74a1e968d2ad4b0d8693c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:43 metrics.py:449] Avg prompt throughput: 26.7 tokens/s, Avg generation throughput: 140.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:45 logger.py:37] Received request chatcmpl-6cec66088cff4332b0e2689d80b2af8c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why are the three dogs fighting with another dog in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:45 logger.py:37] Received request chatcmpl-910652316d514869a1e9cc79dc4c1136: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which is the best title of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:45 engine.py:267] Added request chatcmpl-6cec66088cff4332b0e2689d80b2af8c.
INFO 12-25 14:12:45 engine.py:267] Added request chatcmpl-910652316d514869a1e9cc79dc4c1136.
INFO 12-25 14:12:45 logger.py:37] Received request chatcmpl-9a2389140b18423c8ed14de4b275bc1a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options is not depicted in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:45 engine.py:267] Added request chatcmpl-9a2389140b18423c8ed14de4b275bc1a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:47 logger.py:37] Received request chatcmpl-1d7aa3f623ae488391685d044c67f665: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship of the woman standing next to the main character in the video when he visits Jatilui?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:48 engine.py:267] Added request chatcmpl-1d7aa3f623ae488391685d044c67f665.
INFO 12-25 14:12:48 metrics.py:449] Avg prompt throughput: 53.1 tokens/s, Avg generation throughput: 91.6 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:51 logger.py:37] Received request chatcmpl-90b2066438664d7d8d4584d0c91fec8a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video on the third day of training why is the man in the green top so far behind the contestant in the white top?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:51 engine.py:267] Added request chatcmpl-90b2066438664d7d8d4584d0c91fec8a.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:53 metrics.py:449] Avg prompt throughput: 15.8 tokens/s, Avg generation throughput: 140.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:54 logger.py:37] Received request chatcmpl-0fb7ca87b7384700935aa833c74f17ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which shark species is featured in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:54 engine.py:267] Added request chatcmpl-0fb7ca87b7384700935aa833c74f17ac.
INFO 12-25 14:12:54 logger.py:37] Received request chatcmpl-4b3dc04b9f8e4679968ad5bbec9e244a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why is there no male jaguar near the cub?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:55 engine.py:267] Added request chatcmpl-4b3dc04b9f8e4679968ad5bbec9e244a.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:57 logger.py:37] Received request chatcmpl-da494fd5b4c44933957c27e6410adad9: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What makes the fourth day of the family\'s arrival at their destination stand out in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:57 engine.py:267] Added request chatcmpl-da494fd5b4c44933957c27e6410adad9.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:12:58 metrics.py:449] Avg prompt throughput: 39.0 tokens/s, Avg generation throughput: 122.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:12:59 logger.py:37] Received request chatcmpl-949fc8f110cf4e5b87765a8997db961d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the difference in appearance between the female lead in the video, Friday and Wednesday?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:12:59 engine.py:267] Added request chatcmpl-949fc8f110cf4e5b87765a8997db961d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:01 logger.py:37] Received request chatcmpl-a1ea1d7e8847466eb42f7a9a471db479: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which appears according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:01 engine.py:267] Added request chatcmpl-a1ea1d7e8847466eb42f7a9a471db479.
INFO 12-25 14:13:02 logger.py:37] Received request chatcmpl-132efff868234d688020110a283434db: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following descriptions of the male protagonist\'s process from preparing for the marathon to successfully completing the marathon in the video is correct?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:02 engine.py:267] Added request chatcmpl-132efff868234d688020110a283434db.
INFO 12-25 14:13:03 metrics.py:449] Avg prompt throughput: 41.5 tokens/s, Avg generation throughput: 117.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:05 logger.py:37] Received request chatcmpl-4c9eb5aff4864b42b234fff7b39e3a7c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is wrong with the car when there is a woman in the vehicle?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:05 engine.py:267] Added request chatcmpl-4c9eb5aff4864b42b234fff7b39e3a7c.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:07 logger.py:37] Received request chatcmpl-d0c418d408a94e96bedd1ff113f81333: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video after all the matches are over why is everyone cheering and celebrating around the guy wearing a shirt with the word Qatar on it?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:07 engine.py:267] Added request chatcmpl-d0c418d408a94e96bedd1ff113f81333.
INFO 12-25 14:13:08 metrics.py:449] Avg prompt throughput: 29.4 tokens/s, Avg generation throughput: 124.7 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:10 logger.py:37] Received request chatcmpl-2cd2da4db5734dfe800600d28b36474e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video about?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:10 engine.py:267] Added request chatcmpl-2cd2da4db5734dfe800600d28b36474e.
INFO 12-25 14:13:10 logger.py:37] Received request chatcmpl-610f7b4e0cf84459b26dd6dbf8edcddc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which move in the video was done in both the warm-up phase and the official workout phase of Monday\'s workout?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:10 engine.py:267] Added request chatcmpl-610f7b4e0cf84459b26dd6dbf8edcddc.
INFO 12-25 14:13:11 logger.py:37] Received request chatcmpl-fffc7785790d4bfbbeda7b6690c91c11: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the video regarding?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:11 engine.py:267] Added request chatcmpl-fffc7785790d4bfbbeda7b6690c91c11.
INFO 12-25 14:13:13 metrics.py:449] Avg prompt throughput: 38.1 tokens/s, Avg generation throughput: 120.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:18 logger.py:37] Received request chatcmpl-fd37407f80464c4ba1e23778260311e7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the sports tracking device used by the male protagonist in the video for running?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:18 engine.py:267] Added request chatcmpl-fd37407f80464c4ba1e23778260311e7.
INFO 12-25 14:13:18 metrics.py:449] Avg prompt throughput: 12.0 tokens/s, Avg generation throughput: 110.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:13:19 logger.py:37] Received request chatcmpl-95616ce3b94a4597bd99cfa4ad60ab64: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what the atmosphere is in the house?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:19 engine.py:267] Added request chatcmpl-95616ce3b94a4597bd99cfa4ad60ab64.
INFO 12-25 14:13:19 logger.py:37] Received request chatcmpl-3af0af62470d47bf8a591da55f5c8e13: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the score of the first game of the semi-finals in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:19 engine.py:267] Added request chatcmpl-3af0af62470d47bf8a591da55f5c8e13.
INFO 12-25 14:13:20 logger.py:37] Received request chatcmpl-d33ce1b68caf4599b51d18dacf3d5853: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the maximum weight that the woman in the video can successfully bench press?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:20 engine.py:267] Added request chatcmpl-d33ce1b68caf4599b51d18dacf3d5853.
INFO 12-25 14:13:23 metrics.py:449] Avg prompt throughput: 40.5 tokens/s, Avg generation throughput: 134.4 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:28 logger.py:37] Received request chatcmpl-dbd149501f724bf99d897ef723fcff00: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the meaning of what the person in the video wrote on the blackboard?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:28 engine.py:267] Added request chatcmpl-dbd149501f724bf99d897ef723fcff00.
INFO 12-25 14:13:28 logger.py:37] Received request chatcmpl-11dbe778bd854dc1a440276abd567259: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What are the scoring rules for the finals and semifinals in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:28 engine.py:267] Added request chatcmpl-11dbe778bd854dc1a440276abd567259.
INFO 12-25 14:13:28 metrics.py:449] Avg prompt throughput: 27.1 tokens/s, Avg generation throughput: 79.8 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:13:28 logger.py:37] Received request chatcmpl-54942888d8864abda55f917b879a035c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the hero in the red top stop to give a close-up of a palm tree on the fourth day of the training ride?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:28 engine.py:267] Added request chatcmpl-54942888d8864abda55f917b879a035c.
INFO 12-25 14:13:29 logger.py:37] Received request chatcmpl-c5292df0b0b04283ba8703f5bb9276f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the subject matter of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:29 engine.py:267] Added request chatcmpl-c5292df0b0b04283ba8703f5bb9276f1.
INFO 12-25 14:13:33 metrics.py:449] Avg prompt throughput: 27.9 tokens/s, Avg generation throughput: 150.9 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:36 logger.py:37] Received request chatcmpl-0bd5427678c54324a24c69add6178be1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the difference between the actions of the lady on the left hand side of the male presenter at the beginning of the video wearing a black top and blue shorts and the others?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:36 logger.py:37] Received request chatcmpl-9898414d688345d3a2a8d07c3009807a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what does the cougar fight with?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:36 engine.py:267] Added request chatcmpl-0bd5427678c54324a24c69add6178be1.
INFO 12-25 14:13:36 engine.py:267] Added request chatcmpl-9898414d688345d3a2a8d07c3009807a.
INFO 12-25 14:13:37 logger.py:37] Received request chatcmpl-83d0896660e44b01aba1a73633825ae7: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following things is not mentioned in the introduction before the full body training formally begins?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:37 engine.py:267] Added request chatcmpl-83d0896660e44b01aba1a73633825ae7.
INFO 12-25 14:13:38 metrics.py:449] Avg prompt throughput: 44.5 tokens/s, Avg generation throughput: 102.5 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:41 logger.py:37] Received request chatcmpl-83a4e1c36bd44bf38afb9951c9638a4d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following describes the heroine\'s weekly fitness programme correctly?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:41 engine.py:267] Added request chatcmpl-83a4e1c36bd44bf38afb9951c9638a4d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:42 logger.py:37] Received request chatcmpl-023ced7f48944600bd62fbedaa6edaac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why do capybaras dive into water in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:42 engine.py:267] Added request chatcmpl-023ced7f48944600bd62fbedaa6edaac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:43 logger.py:37] Received request chatcmpl-2d0a1040aab543108a027ee7c45aff61: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is NOT included in what the woman in the video says during the drive home from track day practice?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:43 engine.py:267] Added request chatcmpl-2d0a1040aab543108a027ee7c45aff61.
INFO 12-25 14:13:43 metrics.py:449] Avg prompt throughput: 41.0 tokens/s, Avg generation throughput: 103.4 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO 12-25 14:13:44 logger.py:37] Received request chatcmpl-95ac0e53847f4aa499694102014e53f5: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, after using the leg press machine, which part of the body mainly relies on the strength of the next training movements?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:44 engine.py:267] Added request chatcmpl-95ac0e53847f4aa499694102014e53f5.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:47 logger.py:37] Received request chatcmpl-b97c884d6f3842e78806f63abee4b525: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened in the first game of the second round of 16 in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:47 engine.py:267] Added request chatcmpl-b97c884d6f3842e78806f63abee4b525.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:48 logger.py:37] Received request chatcmpl-9ea911f22a424b1f98435f9eedfe61b6: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What does the video depict?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:48 engine.py:267] Added request chatcmpl-9ea911f22a424b1f98435f9eedfe61b6.
INFO 12-25 14:13:48 metrics.py:449] Avg prompt throughput: 29.8 tokens/s, Avg generation throughput: 128.5 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:13:49 logger.py:37] Received request chatcmpl-b687fd8db5654b6fafc4e28ad8628a15: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why were the two male leads in the video, as well as the people around them, so excited when they reached the finish line?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:49 engine.py:267] Added request chatcmpl-b687fd8db5654b6fafc4e28ad8628a15.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:51 logger.py:37] Received request chatcmpl-3cc5cff313814767bc5de79f5d4a2f27: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, what is the primary challenge for developers of autonomous driving technology, as highlighted by the testing conducted in China?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:51 engine.py:267] Added request chatcmpl-3cc5cff313814767bc5de79f5d4a2f27.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:53 metrics.py:449] Avg prompt throughput: 43.4 tokens/s, Avg generation throughput: 125.8 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:13:54 logger.py:37] Received request chatcmpl-92221eaac1c24663a129454ec5c30a31: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In accordance with the video footage, which may be the reason for the death of the diver?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:54 engine.py:267] Added request chatcmpl-92221eaac1c24663a129454ec5c30a31.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:55 logger.py:37] Received request chatcmpl-1097b8769bc74fa6bf4ddf8a2b67d2cd: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options correctly describes the heroine\'s Tuesday exercise items and their order in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:55 engine.py:267] Added request chatcmpl-1097b8769bc74fa6bf4ddf8a2b67d2cd.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:13:57 logger.py:37] Received request chatcmpl-8d698045c60a46f6acb55bb671df3776: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the most likely role of the person shooting the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:57 engine.py:267] Added request chatcmpl-8d698045c60a46f6acb55bb671df3776.
INFO 12-25 14:13:58 logger.py:37] Received request chatcmpl-30da812e85d7496f8612cace0b225dfc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the information provided by the video, what is unique about the Factory 56 production line compared to other automotive factories?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:13:58 engine.py:267] Added request chatcmpl-30da812e85d7496f8612cace0b225dfc.
INFO 12-25 14:13:58 metrics.py:449] Avg prompt throughput: 57.2 tokens/s, Avg generation throughput: 114.1 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:03 logger.py:37] Received request chatcmpl-12a4f785e99d47e0864458ca771d8992: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, what was the halftime score between the two teams?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:03 engine.py:267] Added request chatcmpl-12a4f785e99d47e0864458ca771d8992.
INFO 12-25 14:14:03 metrics.py:449] Avg prompt throughput: 13.5 tokens/s, Avg generation throughput: 148.3 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:05 logger.py:37] Received request chatcmpl-a99fe0496a50463e87b000e1748cf21d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How often do the people in the video take water breaks per workout?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:05 engine.py:267] Added request chatcmpl-a99fe0496a50463e87b000e1748cf21d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:07 logger.py:37] Received request chatcmpl-7f8ff9df82594a1fb8fabac1e7b8d7ac: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What happened when the male protagonist attempted his second 21-kilometer long run in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:07 engine.py:267] Added request chatcmpl-7f8ff9df82594a1fb8fabac1e7b8d7ac.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:08 logger.py:37] Received request chatcmpl-d15a88d9bb894cd28aa03e7fae8b1e0e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the plot of the opera in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:08 engine.py:267] Added request chatcmpl-d15a88d9bb894cd28aa03e7fae8b1e0e.
INFO 12-25 14:14:08 metrics.py:449] Avg prompt throughput: 40.2 tokens/s, Avg generation throughput: 96.6 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:09 logger.py:37] Received request chatcmpl-bc7e537aeecf4f80b873d2ce3fe5d497: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which character in the middle of the video most closely resembles the man cutting the scallops?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:09 engine.py:267] Added request chatcmpl-bc7e537aeecf4f80b873d2ce3fe5d497.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:13 metrics.py:449] Avg prompt throughput: 14.0 tokens/s, Avg generation throughput: 138.4 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:15 logger.py:37] Received request chatcmpl-7b07e25185bd4db98a31da6823d04395: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, what advice does the friend give to the male protagonist during their remote video call on the phone?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:15 engine.py:267] Added request chatcmpl-7b07e25185bd4db98a31da6823d04395.
INFO 12-25 14:14:15 logger.py:37] Received request chatcmpl-f4ecc4d308b74a7595b8d668078432c1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options does not match the description in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:15 engine.py:267] Added request chatcmpl-f4ecc4d308b74a7595b8d668078432c1.
INFO 12-25 14:14:15 logger.py:37] Received request chatcmpl-a809600c8dd148708182237c96e0dd09: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is special about the board on the lower right corner of the video that keeps track of the locations controlled by each of the two sides?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:15 engine.py:267] Added request chatcmpl-a809600c8dd148708182237c96e0dd09.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:18 metrics.py:449] Avg prompt throughput: 44.2 tokens/s, Avg generation throughput: 110.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:20 logger.py:37] Received request chatcmpl-e2cac7a7ab584aab8c072c6af3e69e45: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, which of the following is excluded from the power value on the red or blue small card?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:20 engine.py:267] Added request chatcmpl-e2cac7a7ab584aab8c072c6af3e69e45.
INFO 12-25 14:14:21 logger.py:37] Received request chatcmpl-418cae0bf4f442bcb6bb1a425496e692: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many goals did the player interviewed by the male host at the beginning of the video wearing a top with the word QARAR score in his first match?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:21 engine.py:267] Added request chatcmpl-418cae0bf4f442bcb6bb1a425496e692.
INFO 12-25 14:14:21 logger.py:37] Received request chatcmpl-3e4d73fdb6f34478a6f2c633e3fcb68a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "The man and woman who had dinner with the female lead before the marathon officially started in the video, did they participate in the marathon, and what were their results?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:21 engine.py:267] Added request chatcmpl-3e4d73fdb6f34478a6f2c633e3fcb68a.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:23 metrics.py:449] Avg prompt throughput: 49.4 tokens/s, Avg generation throughput: 99.3 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:25 logger.py:37] Received request chatcmpl-a08afcd98b8c40968dec88d472e46a52: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is captured in this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:25 engine.py:267] Added request chatcmpl-a08afcd98b8c40968dec88d472e46a52.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:27 logger.py:37] Received request chatcmpl-2b638d8aa2fb4dd7953f50ee4738a68c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why did the video focus on the content behind the player wearing a black short-sleeved shirt and black trousers?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:27 engine.py:267] Added request chatcmpl-2b638d8aa2fb4dd7953f50ee4738a68c.
INFO 12-25 14:14:28 logger.py:37] Received request chatcmpl-4a9b500bad00460b8a26f8674368db56: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the proper sequence for the following items used in this video? (a) Stickers. (b) Watercolor pencils. (c) Gems. (d) Glue paper.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:28 engine.py:267] Added request chatcmpl-4a9b500bad00460b8a26f8674368db56.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:28 metrics.py:449] Avg prompt throughput: 44.8 tokens/s, Avg generation throughput: 109.9 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:31 logger.py:37] Received request chatcmpl-d91e641739734f65a4b2686faef5f5e1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How does the Factory 56\'s "TecLine" concept future-proof the production process for potential new car models?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:31 engine.py:267] Added request chatcmpl-d91e641739734f65a4b2686faef5f5e1.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:33 metrics.py:449] Avg prompt throughput: 15.3 tokens/s, Avg generation throughput: 125.2 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:34 logger.py:37] Received request chatcmpl-7f1783690a26454ca8b7768e91254c0b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Once the embroidery in the video is finished, which color of stitches is concealed beneath the pattern?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:34 engine.py:267] Added request chatcmpl-7f1783690a26454ca8b7768e91254c0b.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:36 logger.py:37] Received request chatcmpl-cc4bd1a6389a4cada8b47097abeca6a2: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which is not true about the failure of team DK in the last battle?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:36 engine.py:267] Added request chatcmpl-cc4bd1a6389a4cada8b47097abeca6a2.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:38 logger.py:37] Received request chatcmpl-18ace56aa89e4fadbda1b74e6ef45f74: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What title best summarizes this video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:38 engine.py:267] Added request chatcmpl-18ace56aa89e4fadbda1b74e6ef45f74.
INFO 12-25 14:14:38 logger.py:37] Received request chatcmpl-8db3618868684fb5b7f81941a496829e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "On which days of the week does the woman in the video take a rest?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:38 engine.py:267] Added request chatcmpl-8db3618868684fb5b7f81941a496829e.
INFO 12-25 14:14:39 metrics.py:449] Avg prompt throughput: 54.3 tokens/s, Avg generation throughput: 113.2 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.7%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:41 logger.py:37] Received request chatcmpl-a3db2193e447402995566b074b38ce3d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not exemplified by Miranda\'s experience of learning new languages in Seville?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:42 engine.py:267] Added request chatcmpl-a3db2193e447402995566b074b38ce3d.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:44 metrics.py:449] Avg prompt throughput: 14.4 tokens/s, Avg generation throughput: 124.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO 12-25 14:14:44 logger.py:37] Received request chatcmpl-e10c9b053a7241a99c5600816bd114bc: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the relationship between the two characters in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:44 engine.py:267] Added request chatcmpl-e10c9b053a7241a99c5600816bd114bc.
INFO 12-25 14:14:45 logger.py:37] Received request chatcmpl-c196c150025f48ec9978eeb3146af20d: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Based on the video, why did Miranda mention many things related to Sicily?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:45 engine.py:267] Added request chatcmpl-c196c150025f48ec9978eeb3146af20d.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:47 logger.py:37] Received request chatcmpl-b5007858645442eaa53812f79f3ba85c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the primary focus of the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:47 engine.py:267] Added request chatcmpl-b5007858645442eaa53812f79f3ba85c.
INFO 12-25 14:14:49 metrics.py:449] Avg prompt throughput: 38.6 tokens/s, Avg generation throughput: 130.8 tokens/s, Running: 4 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 1.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:51 logger.py:37] Received request chatcmpl-3f340da3fec8491aa3d23f4221dd93ae: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following is not discussed in the video when the heroine holds a cell phone in one hand and faces the mirror to record herself?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:51 engine.py:267] Added request chatcmpl-3f340da3fec8491aa3d23f4221dd93ae.
INFO 12-25 14:14:51 logger.py:37] Received request chatcmpl-22827f81a58a45988027c1bc7866f26b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As can be seen in the video, which of the items is not placed on the table?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:51 engine.py:267] Added request chatcmpl-22827f81a58a45988027c1bc7866f26b.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:53 logger.py:37] Received request chatcmpl-1870d246f591425883f2db473c94c5f3: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In the video, which fitness equipment is used by the heroine on push day, leg day, pull day and full body day?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:14:53 engine.py:267] Added request chatcmpl-1870d246f591425883f2db473c94c5f3.
INFO:     127.0.0.1:37152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:54 metrics.py:449] Avg prompt throughput: 45.8 tokens/s, Avg generation throughput: 113.1 tokens/s, Running: 3 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.6%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37164 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:14:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 98.0 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.8%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:00 logger.py:37] Received request chatcmpl-afc1449e4b7d4af7be4837b1e26bd504: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "According to the video, what are the tactics of team DK?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:00 engine.py:267] Added request chatcmpl-afc1449e4b7d4af7be4837b1e26bd504.
INFO 12-25 14:15:04 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 65.7 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:08 logger.py:37] Received request chatcmpl-d1db1d5973a84411a905d7396b534e1b: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many embroidery techniques does the author teach in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:08 engine.py:267] Added request chatcmpl-d1db1d5973a84411a905d7396b534e1b.
INFO 12-25 14:15:08 logger.py:37] Received request chatcmpl-e3507fdf7c33436eafc44490aba7db02: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Why does the male protagonist, wearing a white shirt and black shorts in the video, take painkillers during the race?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:08 engine.py:267] Added request chatcmpl-e3507fdf7c33436eafc44490aba7db02.
INFO 12-25 14:15:09 metrics.py:449] Avg prompt throughput: 28.1 tokens/s, Avg generation throughput: 49.2 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:14 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 67.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO 12-25 14:15:14 logger.py:37] Received request chatcmpl-5483a7afccc84be7ba410e67b4d3978e: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "How many questions did the man in the pink shirt ask Miranda in the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:14 engine.py:267] Added request chatcmpl-5483a7afccc84be7ba410e67b4d3978e.
INFO 12-25 14:15:19 metrics.py:449] Avg prompt throughput: 13.6 tokens/s, Avg generation throughput: 74.5 tokens/s, Running: 2 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.9%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO:     127.0.0.1:37140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:21 logger.py:37] Received request chatcmpl-753e8695e6924f9e8115c4d941b403f1: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Which of the following options describes the video\'s heroine\'s description of the giveaway in the correct order of presentation?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:21 engine.py:267] Added request chatcmpl-753e8695e6924f9e8115c4d941b403f1.
INFO 12-25 14:15:24 metrics.py:449] Avg prompt throughput: 14.8 tokens/s, Avg generation throughput: 28.8 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:15:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.5%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:31 logger.py:37] Received request chatcmpl-18b88feb21ba4592be33c86517e9b88c: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "After #41 completed his free throws, how many points was the team the author was rooting for ahead or behind the other team?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:31 engine.py:267] Added request chatcmpl-18b88feb21ba4592be33c86517e9b88c.
INFO 12-25 14:15:34 metrics.py:449] Avg prompt throughput: 15.8 tokens/s, Avg generation throughput: 27.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:38 logger.py:37] Received request chatcmpl-4beabf9d956d418084d640c5de4e2d4a: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What is the correct order in which the following events are told in the video? (a) Desserts in restaurants. (b) Pinguin frozen vegetables. (c) Lab test for vitamin C.". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:38 engine.py:267] Added request chatcmpl-4beabf9d956d418084d640c5de4e2d4a.
INFO 12-25 14:15:39 metrics.py:449] Avg prompt throughput: 18.5 tokens/s, Avg generation throughput: 22.5 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO 12-25 14:15:44 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.4%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:48 logger.py:37] Received request chatcmpl-44f01e0fe7e947419c7a42962747bf16: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "As depicted in the video, how does the story end?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:48 engine.py:267] Added request chatcmpl-44f01e0fe7e947419c7a42962747bf16.
INFO 12-25 14:15:49 metrics.py:449] Avg prompt throughput: 12.8 tokens/s, Avg generation throughput: 27.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:52 logger.py:37] Received request chatcmpl-f0418b38f7da48349e771d967842fb80: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "What sets apart the third set of stickers from the other two?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:52 engine.py:267] Added request chatcmpl-f0418b38f7da48349e771d967842fb80.
INFO 12-25 14:15:54 metrics.py:449] Avg prompt throughput: 13.0 tokens/s, Avg generation throughput: 28.2 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:15:57 logger.py:37] Received request chatcmpl-424b96833deb4723a75169eac8792372: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "Who gets advantage before 10:00 according to the video?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:15:57 engine.py:267] Added request chatcmpl-424b96833deb4723a75169eac8792372.
INFO 12-25 14:15:59 metrics.py:449] Avg prompt throughput: 13.4 tokens/s, Avg generation throughput: 26.1 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:16:05 logger.py:37] Received request chatcmpl-022d7a1cac9540b59d570ee3843a7850: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, which of the following is the key step in bullion stitch?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:16:05 engine.py:267] Added request chatcmpl-022d7a1cac9540b59d570ee3843a7850.
INFO 12-25 14:16:05 metrics.py:449] Avg prompt throughput: 12.2 tokens/s, Avg generation throughput: 28.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.1%, CPU KV cache usage: 0.0%.
INFO 12-25 14:16:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 39.6 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.3%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:16:13 logger.py:37] Received request chatcmpl-2c633374839d441fbaf8a6a727fd11ab: prompt: '<|im_start|>system\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n<|im_start|>user\nTask: Plan steps to answer: "In line with the video evidence, why does the heroine in the video only do butt training once a week?". Video Duration: 10.0s. Output JSON list.<|im_end|>\n<|im_start|>assistant\n', params: SamplingParams(n=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.1, top_p=1.0, top_k=-1, min_p=0.0, seed=None, stop=[], stop_token_ids=[], bad_words=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=512, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None, guided_decoding=None), prompt_token_ids: None, lora_request: None, prompt_adapter_request: None.
INFO 12-25 14:16:13 engine.py:267] Added request chatcmpl-2c633374839d441fbaf8a6a727fd11ab.
INFO 12-25 14:16:15 metrics.py:449] Avg prompt throughput: 14.7 tokens/s, Avg generation throughput: 26.9 tokens/s, Running: 1 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.2%, CPU KV cache usage: 0.0%.
INFO:     127.0.0.1:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
INFO 12-25 14:16:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 9.3 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:16:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:16:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:16:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:17:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:18:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:19:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:20:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:21:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:22:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:23:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:24:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:48 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:25:58 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:08 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:18 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:28 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:38 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:26:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:27:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:28:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:29:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:30:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:31:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:32:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:33:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:34:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:35:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:36:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:37:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:38:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:39:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:40:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:19 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:29 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:39 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:49 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:41:59 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:42:09 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:42:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:42:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:42:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:42:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:43:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:44:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:45:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:46:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:47:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:48:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:49:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:50:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:51:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:52:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:53:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:54:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:20 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:30 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:40 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:55:50 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:00 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:10 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:56:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:57:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:58:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 14:59:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:00:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:01:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:02:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:03:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:04:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:05:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:06:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:21 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:31 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:41 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:07:51 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:01 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:11 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:08:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:09:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:10:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:11:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:12:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:13:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:14:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:15:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:02 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:12 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:22 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:32 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:42 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO 12-25 15:16:52 metrics.py:449] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%.
INFO:     Shutting down
INFO 12-25 15:17:01 launcher.py:57] Shutting down FastAPI HTTP server.
[rank0]:[W1225 15:17:04.069629454 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
